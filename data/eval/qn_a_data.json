{
    "queries": {
        "32ef6672-1ec0-4c10-8b27-4007f4f32a16": "What is the primary objective of the proposed framework in the paper?",
        "d4756049-0274-41a6-8de3-259c35d78d4f": "How do users provide exemplars of the actions they want to count?",
        "31118474-50d4-45ab-8ce5-c6b89fb29922": "What role do the vocalized sounds \"one,\" \"two,\" and \"three\" play in the proposed method?",
        "7e3bdbe6-39a7-4796-9215-8b77c9249223": "How does the method localize the temporal positions of the utterances from the audio sequence?",
        "9f97711d-0189-463a-a8cf-dc255d002c03": "What is the purpose of the similarity map in the counting process?",
        "d5adabb2-fb49-4dde-808b-f86a31604ba4": "How is the final count of actions determined in the proposed framework?",
        "4d9d0fff-4184-4d22-a932-fdc8a9ea7920": "What type of data does the introduced dataset consist of, and how many subjects and action categories does it include?",
        "cd34e354-e25a-4929-9d8e-080fae574a1c": "How does the performance of the proposed method compare to frequency-based and transformer-based methods?",
        "c90facf1-f70c-405c-8ea5-b494dec103e4": "What is the average discrepancy between the predicted count and the ground truth value reported in the experiments?",
        "f8a2cad3-1094-43e7-82b3-00b8408217a8": "In what applications can counting human actions using wearable devices be beneficial, according to the introduction?",
        "17f21610-189d-4395-9c26-d3066513e95d": "What is the average discrepancy between the predicted count and the ground truth value in the experiments mentioned?",
        "396baf08-f8f0-43ca-a885-b9d05e287d82": "Why are class-specific counters considered impractical and unscalable for counting human actions?",
        "4804a4e8-7c8f-4753-81c8-dd6410a6ff67": "What is the main advantage of using class-agnostic counters over class-specific counters?",
        "d87bf991-9905-4953-a684-db1638e60f7d": "In what scenarios might the interest in counting actions not align with the dominant class?",
        "35b0531e-82ee-46c0-80c8-50dee2b02866": "How do wearable devices contribute to the task of counting human actions?",
        "d12a4877-43db-44fc-8486-6b789839cb26": "What applications are mentioned for counting human actions using wearable devices?",
        "0b648d23-10d6-451a-8a7b-846aed9d42e8": "What challenges are posed by infrequent actions in the context of counting human actions?",
        "24c7a67b-81a8-4c3d-8740-17ef880d2245": "How does the proposed method compare to frequency-based and transformer-based methods in terms of error?",
        "a463daee-df6d-4b46-9101-8bae1a7fe898": "What is the significance of the dataset and code being available on GitHub for this research?",
        "e629843b-9292-4cd7-bed8-16a53eb62f83": "What are the implications of being able to count actions from new classes and subjects not included in the training data?",
        "017bc1ce-58df-4187-94e2-114be35a1912": "What is the primary advantage of using class-agnostic counters over class-specific counters in the context of sensor data analysis?",
        "24ca969e-7de9-4466-9172-b000cf1decb4": "In what scenarios might the focus shift from counting dominant actions to identifying infrequent mistakes?",
        "8c12a405-2fcc-4248-bd3c-d462742cc606": "What are the two significant technical challenges associated with developing an exemplar-based counting method?",
        "0d8325ce-9322-4099-8344-c10f47e3488e": "How does the proposed method allow users to provide exemplars for counting actions?",
        "d29316ca-531d-4a08-84d3-156d1c281f6a": "What vocal sounds are suggested for users to specify exemplars in the counting process?",
        "08924186-7ca0-4773-879c-d846f86683ca": "What algorithmic approach is developed to detect the positions of counting utterances in the audio sequence?",
        "acdadf88-978e-40f8-a276-f11bfc83bc49": "How does the proposed method address the challenge of leveraging the provided exemplars effectively?",
        "99055101-e570-448b-bdef-249baed6f62d": "Why is it important to consider temporal ordering and distance when identifying counting utterances?",
        "142eb68a-4f28-4e7c-a847-5d4f6c9019d5": "What role do the identified positions of counting utterances play in the exemplar-based counting method?",
        "e8d4ec23-7fa4-4c1f-a19e-6de98e448f3c": "How does the proposed exemplar-based counting method aim to improve the analysis of real-world data containing undesired actions?",
        "537a9fcf-baf6-403e-9de3-e7372482e696": "What method is proposed for specifying exemplars in the counting process?",
        "8391f1c0-61b6-4cfd-9479-a7dc201d2ec0": "How does the algorithm developed in the paper identify the positions of counting utterances?",
        "f309a7fc-9de7-431f-8167-8ace994d5e48": "What are the two constraints considered in the optimization problem for detecting counting utterances?",
        "0100ff21-a16a-43ec-9a59-42af403370d0": "How are the exemplars extracted once their positions are identified?",
        "3e1baaaf-cef2-473e-8faa-dc358d646afe": "What is the role of the similarity map in the proposed exemplar-based counting method?",
        "21114822-a751-4b72-992c-3c2f04594ffa": "Which techniques are used to compute the similarity map between exemplars and the data sequence?",
        "bc6b1104-7488-40cf-a9db-1d0dd795bb5c": "How are the initial embedding sequence and the exemplar-infused embedding sequence utilized in the counting process?",
        "30c18b74-87aa-479b-a62a-20074e3e15ca": "What is the purpose of the density estimation module in the proposed method?",
        "53d1f24b-1c16-47fa-a0e8-7c9d2639b1cc": "How is the final count obtained from the density values in the proposed counting method?",
        "242727fc-3fac-4472-8e2b-1ea0a1b174c1": "What is the significance of using vocal sounds for specifying exemplars in this counting approach?",
        "f698506d-0fb2-4da3-991a-f05e6ad1f02f": "What is the primary purpose of the Temporal Density Map in the proposed method?",
        "5a23c71e-b658-4492-9f01-5544c1f427e4": "How does the novel distance-preserving loss contribute to the similarity measurement in the model?",
        "05c6f495-cae9-4b7d-a88e-46ce3823db21": "What role does the Diverse Wearable Counting dataset (DWC) play in the development and evaluation of the proposed method?",
        "70ebd277-49cb-4741-9de3-692a0f15fc28": "How does the exemplar-based data synthesis pipeline enhance the training process?",
        "7060d59a-e35e-4bd8-9799-c9a1b1b58520": "What types of signals are included in the input for the processing pipeline described in the document?",
        "88cf8cd9-54dd-4eb1-bd8f-750cc245c24d": "How many subjects and action categories are represented in the Diverse Wearable Counting dataset?",
        "dcdef816-1b37-4a44-a4e0-bc9e63e5bb19": "What distinguishes the DWC dataset from other existing datasets in terms of data collection?",
        "b6e022d1-0e9c-441b-b16b-6f6aacacc2c1": "What is the significance of using audio-specified exemplars in the counting process?",
        "a979903a-b7c9-4bc6-927c-74f19c4edec6": "How is the total count output derived from the intermediate 1D density profile?",
        "a1af9298-f041-450e-af96-1993f63b1429": "What challenges does the proposed method address regarding the representation of real-world scenarios in action counting?",
        "14a2c33e-6d72-4826-8600-d5fa253b2511": "What is the main purpose of the Diverse Wearable Counting dataset (DWC) introduced in the paper?",
        "1828396e-fcf5-4f0c-ad4c-6a94c846d908": "How does the proposed method utilize audio to enhance action counting?",
        "8c367593-e86d-4e58-874f-cd357bdf6259": "What are the three main contributions of the paper?",
        "c0bb2eb9-d688-4789-96cf-be3979ed60ff": "How does the dataset DWC differ from existing datasets in terms of data modalities?",
        "6f4c5b68-30f7-45be-bdaa-27fc7929a5bf": "What types of actions are included in the DWC, and how many distinct action categories are represented?",
        "ac7bfebf-ba58-4cf5-af0f-159f69147f33": "Why is the inclusion of synchronized audio data considered a significant feature of the DWC?",
        "5c96930b-bbd8-401c-86d6-b8f50710ff50": "What challenges does the proposed counting method aim to address in real-world scenarios?",
        "b2154a7a-f683-42f9-a6f8-780050a47bf2": "How does the exemplar-based data synthesis pipeline contribute to improving training data?",
        "61235bc4-851f-4727-8d62-b36870755f53": "In what contexts is action counting through wearable devices applied, according to the related work section?",
        "80b6718f-eca2-4500-af26-3a8b45a2fe91": "What is the significance of including instances where the action of interest is not the predominant action in the dataset?",
        "d2576825-e3c4-4e61-a6e7-e37cb7c74c2f": "What are the primary applications of action counting through wearable devices mentioned in the text?",
        "f6ab131b-1888-4ea4-9c39-c7e58bf56a51": "How do existing counting methodologies limit their adaptability in real-world scenarios?",
        "b769e1ad-a02d-4d9e-a179-59e9e14f116e": "What is the main drawback of class-specific counters in action counting?",
        "9cc59700-8178-4109-b65b-220eedd470ea": "What alternative approach to action counting is discussed in the document, and what is its limitation?",
        "f0c023a3-f5ea-4af8-a584-b1b293e6cf6e": "Which earlier strategies for action counting are mentioned in the context of class-agnostic counters?",
        "e2078f35-f926-4230-9393-c4925b93df05": "Why might class-agnostic counters only be effective for counting repetitions from the dominant class?",
        "20763859-94ad-4eaa-82f0-67bca78e6d99": "What types of action categories have existing methodologies predominantly focused on?",
        "d8aa77a9-7cbd-4cc7-a8b0-70eb4a49532c": "How do the methodologies based on Fourier analysis and wavelet transforms relate to action counting?",
        "a515ef64-fe94-43c2-815f-5db2a4f68a22": "What challenges do class-specific counters face when dealing with actions that have no prior training data?",
        "2b639641-8fbe-448c-b5ea-89cc04c2593f": "In what contexts are wearable devices used for action counting, according to the document?",
        "73cffc64-c393-4eda-82e0-0322934017eb": "What is the main limitation of class-specific counters in action counting?",
        "4e33a1ac-6dc5-468c-a266-7b5d951e764f": "How do class-agnostic counters differ from class-specific counters in their functionality?",
        "6a45ede6-d08d-4447-a162-efa21db60a59": "What types of analysis have been previously explored for repetitive action counting in videos?",
        "befdce95-fc7a-462d-850d-4e240940cb1a": "Which recent works have focused on leveraging temporal self-similarity for counting repetitive actions?",
        "b1b011d7-4517-430c-a7d4-dbe5639a5deb": "What is the significance of the contribution mentioned regarding wearable devices in the context of action counting?",
        "0e1df606-13d4-4b62-9e46-aff3f4cee9bd": "How does the proposed method for specifying exemplars differ from existing approaches in computer vision?",
        "9b99f917-04ca-4173-bb89-f4883c658507": "What role do predefined vocal sounds play in the innovative strategy introduced in the document?",
        "380df8b9-3bb2-41b5-9669-1c010a4d97f6": "Why is the adaptability of action counting methods important when faced with classes having no prior training data?",
        "015208fa-edde-449b-8125-a413945e0008": "What are some of the earlier strategies mentioned for counting actions, and what techniques do they employ?",
        "e45338c9-1e51-476d-87bb-8f4901865d0f": "In what way does the document highlight the novelty of the proposed approach compared to previous methods?",
        "c40cdd23-6925-4ce3-be1c-d819bed4dba6": "What innovative strategy does the discussed approach introduce for specifying exemplars in wearable devices?",
        "517ced69-702a-4e7d-b3c7-aa8185f77351": "How do recent works by Dwibedi et al. (2020) and Hu et al. (2022) utilize temporal self-similarity in their methods?",
        "bd388b07-a98e-49fd-9af3-9e76f10f448d": "In what way does the exemplar-based counting approach for wearable devices differ from traditional methods in computer vision?",
        "bbd2f1da-054b-41e9-8f63-476d98da5a57": "What challenges are associated with visualizing and parsing sensor data compared to image data?",
        "66339a42-ae2e-46a3-b420-9358f18f1807": "Why is it more difficult to determine the temporal extents of human actions in time series data than to draw bounding boxes in images?",
        "b838dfc2-8851-428d-9662-03edc7322e06": "What are the implications of requiring immediate results in sensor-based counting for the exemplar identification process?",
        "70152abf-d7ea-4d50-b6f3-6db11ea8b7b3": "How does the need for convenience and efficiency impact the design of exemplar-based counting methods for wearable devices?",
        "07f904a8-7e75-4dbf-8e99-3de01e0a9a23": "What are some existing methods in computer vision that utilize exemplars for counting objects, as mentioned in the context?",
        "b05e9879-10e8-4591-8fb0-065447a32d99": "Why is the approach discussed considered a pioneering effort in the field of wearable devices?",
        "04ae64de-9127-4d90-9610-21a508cf4547": "What are the limitations of current methods that require users to specify exemplars through bounding boxes in the context of time-series data?",
        "49c3497a-71ce-4331-b8be-5af1ae6c50e7": "What is the primary objective of the proposed method described in the document?",
        "e2ab869e-2c87-403f-b360-04e720221bb0": "How does the method utilize audio sequences in conjunction with sensor data?",
        "bd0b9ac3-3791-4fa6-8f40-1a6def1a8ee8": "What are the two fundamental stages of the proposed approach?",
        "946ccf15-b763-46fc-ab4d-b0187cd14475": "Can you explain the role of exemplar extraction in the overall method?",
        "c137fdb2-76eb-4995-981d-31ff2a489ae2": "What is the purpose of the sliding window feature embedding module?",
        "69d7584b-0121-4862-8033-1df168161a02": "How is the similarity between the sensor sequence and exemplars computed?",
        "556b4a95-a7f9-4e27-9ba2-d4843635ea77": "What does the exemplar-infused feature embedding module contribute to the process?",
        "367c6a07-c583-4f1c-ba56-51ed35c516c7": "Describe the significance of the temporal density map in the proposed approach.",
        "eb796dcc-92e9-4604-a7e3-d3739ceeda4a": "What predefined vocal sounds are used in the audio sequence, and what do they correspond to?",
        "3ef4cf8c-ca18-479b-8d75-1ed28afe5200": "How many modules are involved in the proposed method, and what are they?",
        "80a3361e-ddef-45b6-99e1-90845e6da645": "What are the two fundamental stages of the proposed approach for counting action occurrences in sensor data?",
        "05041635-0cc2-4940-a2de-be5765a2a325": "How does the method utilize audio sequences in conjunction with sensor data?",
        "36b4d303-78d7-42f5-93f7-0cee0b55ac01": "What are the five modules involved in the proposed approach, as depicted in Fig. 2?",
        "350c71f0-e836-4018-ae46-8698d3b1b7c8": "What is the purpose of exemplar extraction in the context of this approach?",
        "246317a3-ddca-40cc-b4a2-4292950f7980": "How does the naive approach to exemplar extraction differ from the proposed method?",
        "dd4795bd-88e4-4f86-9ede-d70d6ba9e700": "What two critical cues are highlighted as important for temporal position detection?",
        "476f98c0-d31b-4067-9ea7-4634021d325d": "How is the temporal position detection formulated in the proposed method?",
        "c5e1f2d3-4eef-40e3-8178-b92e16acda3c": "What constraints are placed on the indices i, j, and k in the optimization problem?",
        "1af061f6-fe86-41d8-89d6-4bcbddb3c1f7": "What does the term \"temporal proximity\" refer to in the context of this approach?",
        "c15538e5-c88c-46a5-99a0-4dea7dddffbf": "Why is it important to preserve the order of the sounds \"one, two, three\" during exemplar extraction?",
        "98e401e1-6cd8-4241-b2ce-4fee1fededad": "What are the two critical cues that the proposed method fails to exploit in temporal position detection?",
        "eeff8a66-f604-4d0a-bb14-55e50371846d": "How is the temporal position detection formulated in the context provided?",
        "8f9d996d-2451-47c5-ab29-6176282bacd2": "What do the indices i, j, and k represent in the optimization problem?",
        "5299e242-86aa-45c0-b712-257b3fe3d865": "What is the significance of the constraint \\( k - i \\leq R \\) in the optimization problem?",
        "df915e88-3f55-4dfd-97a5-9afe5a97d999": "How is the audio signal divided for the analysis in the proposed method?",
        "c720134c-ba2c-4a43-9b18-4f2f1beab78d": "What is the role of the BCResNet classifier in the context of this document?",
        "95b912d6-9abe-496b-aa66-363413928b07": "What is the time duration of each sliding window used in the analysis?",
        "c456d235-d773-4c79-8603-bf8b692c445a": "How does the complexity of the algorithm change with respect to the parameters R and M?",
        "58a13bfe-ad05-48c7-959c-e5f33d63cba5": "What type of data does the variable \\( X \\) represent in the context of sensor data?",
        "c450e1b8-5a58-4b4d-a331-0ce09b91752e": "How many times must the dynamic programming optimization be run for M - R + 1 groups of consecutive windows?",
        "8e6e7af4-b69c-4b22-8644-fabcda5c7646": "What is the primary optimization constraint used in the algorithm described in the document?",
        "483221a6-b0b8-447f-a8dd-1244f4dcf198": "How is the overall complexity of the algorithm calculated based on the number of consecutive windows (R) and the length of the sensor data sequence (M)?",
        "a59690f5-4631-4106-9a0c-5526ebd6205e": "What do the variables i\u2217, j\u2217, and k\u2217 represent in the context of the optimization problem?",
        "30623bd6-d264-4efc-acc1-552b3a655392": "Why are only the two locations with the highest classification confidence retained as exemplars?",
        "6ff143c6-a24f-4dd9-b731-e70a883c2a4e": "What are the three different scales used to extract exemplar sequences from the identified positions?",
        "1d1aee13-bf19-49c6-9be7-069a15dc1646": "How many total exemplars are generated from the two locations and three scales?",
        "2d54e7be-535e-4a68-8c7d-04af5e87f33e": "What is the rationale behind using a multi-scale approach for counting actions?",
        "3bea9d5a-0eed-4902-bc6c-8e0fc1c4fa0e": "Why is it necessary to use window-level sensor representation instead of individual time step values?",
        "5f2a753b-e3e4-4050-a93a-e6c646a294a0": "How are the sensor data sequences partitioned for feature embedding?",
        "a2ea2a49-7188-4bdb-bf6f-fd4e6bd589ee": "What types of sensor data are mentioned in the context, and how many values are recorded at each time step?",
        "3110c4eb-667d-4d4a-8b03-8225d004266c": "What is the purpose of embedding the sensor data points into a high-dimensional representation using the mapping \u03d5?",
        "9012e63a-280f-433f-9928-14a41be8b88c": "How is the similarity map S between the sensor embedding X\u2032 and the exemplar embedding E\u2032 estimated?",
        "8afd0699-7468-4a87-8518-c4a2944b4007": "Why are correlation and Dynamic Time Warping (DTW) not effective when directly applied to estimate similarity between X\u2032 and E\u2032?",
        "efde1447-dd29-44eb-823e-30e1357ba185": "What role does the ReLU function play in the computation of the correlation similarity Sc?",
        "e2048f62-dbad-4c5f-8eb1-646c46548ec1": "How does the Soft-DTW similarity calculation differ from traditional DTW in the context of this document?",
        "0095dfdf-14d8-4f55-831d-7a4e2dc615ee": "What is the significance of zero-padding in the correlation operation used to compute Sc?",
        "ab4a9239-e66f-4f6e-9644-5b4cc697da31": "How is the sliding window defined in the context of calculating the Soft-DTW similarity?",
        "04fa9c87-3f32-4a8a-9838-7209ea5bc835": "What normalization technique is applied to the Soft-DTW similarity values before the ReLU layer?",
        "0d19cc03-5689-4d32-babb-99233f357659": "What does the variable k represent in the calculation of Soft-DTW for the sliding window?",
        "897e844a-8466-491d-98aa-746a83f32979": "How does the combination of correlation and Soft-DTW improve the estimation of similarity between the embeddings?",
        "1f940636-44a7-4f7a-ae8a-5cdb8bbde226": "What is the purpose of combining DTW and correlation in the similarity estimation process described in the document?",
        "1faf8f2d-ab0c-4aa7-a07c-fd0b787b9c80": "How is the correlation between the whole sequence embedding and the exemplar embedding computed?",
        "35232c5f-8914-41a8-97f1-76bf609352d5": "What role does the Soft-DTW similarity play in the similarity estimation process?",
        "73164304-b3e6-4bb3-a835-e01950134883": "How is the similarity measure transformed from a distance metric to a non-negative similarity measure?",
        "6cafddf0-6db5-48e5-89db-ea2cfd4d1aa6": "What does the notation Sc and Sd represent in the context of the similarity computation?",
        "2901bb6a-fd15-43f9-b967-15d537bc3a14": "How does the final similarity profile S relate to the individual components Sc and Sd?",
        "1e8aaeaa-0dc9-4e0c-9129-e1656fadc275": "What is the significance of using a sliding window on the whole sequence embedding when calculating Soft-DTW similarity?",
        "9a5ba4b0-1775-47b4-a064-3a65ba7817c7": "Describe the function of the CGAP operation in the exemplar-infused feature embedding process.",
        "19f6c104-ac22-414c-8b52-4cba6436039a": "What is the effect of the element-wise multiplication (\u2299) in the context of refining the feature representation?",
        "faf81f50-7638-4b1b-a4ce-f06f2da5076e": "How many exemplars are considered at each scale in the final similarity profile S?",
        "6d261c39-1728-465b-92e8-29db9c97db43": "What is the purpose of the similarity map S in the exemplar-infused feature embedding process?",
        "d0d09cc4-4b96-4aed-8d2c-8509b6a6d902": "How does the CGAP function contribute to the refinement of feature representations?",
        "a5e77c0f-d512-4458-81d9-44bc73d0366b": "What role do the Kfusion blocks play in the feature embedding process?",
        "ed6c23ce-33a2-4f26-92fc-09f65aa15369": "Describe the process of generating multi-scale features using the Feature Pyramid Network (FPN).",
        "ce2b3592-b917-4b07-9572-7ba567b4d46b": "How are the multi-scale features Fs1, Fs2, and Fs3 derived from the fused feature F?",
        "cac9e37f-bc69-4f81-ae5c-3d612ea9b066": "What is the significance of the element-wise multiplication operation (\u2299) in the feature embedding process?",
        "3701f14d-6c94-48eb-81de-83699be772fc": "How does the temporal convolution counting head \u03c8 estimate temporal densities?",
        "add1f92d-b4c1-4b0d-b3a0-eeee3f06865b": "What is the training loss function Lc used for in the context of counting predictions?",
        "cd4238e4-6194-4cc7-9a08-6dec7799463b": "How are the sensor features X\u2032s1, X\u2032s2, and X\u2032s3 obtained and utilized in the density estimation process?",
        "8d098a55-1c32-4774-afcf-245eaa0dd0f8": "In what way does the final fused feature F relate to the input feature X\u2032 and the similarity map S?",
        "fd3d1def-29c9-4fde-83fe-92acddb6b624": "What is the purpose of using max-pooling in the context of down-sampling Fs1, Fs2, and X\u2032 s1, s2?",
        "09be4db5-7cb3-4065-9ffb-21efd72a60b2": "How is the counting loss \\( L_c \\) calculated in the proposed method?",
        "2da81443-35ec-4670-a69e-8c5578ce51a2": "What role does the density estimation head \\( \\psi \\) play in the overall architecture?",
        "f64cd801-63f4-43e4-bc18-654a9cd3e26f": "Why is it important to preserve the similarity relationship within the raw data space \\( X \\) when encoding?",
        "5042da7d-2f29-4d25-97ec-1b4f898de79b": "How is the k-nearest-neighbor graph constructed in the proposed method?",
        "202d3e14-f7a4-492e-8da8-36c5426a02b7": "What does the adjacency matrix \\( W \\) represent in the context of building the k-nearest-neighbor graph?",
        "a9706704-a3f1-4b95-9f7c-2bb4052e4dda": "How is the graph Laplacian \\( L \\) computed, and what does it signify in this framework?",
        "8187a927-f361-4ce2-9755-31e844fc0782": "What is the significance of the distance-preserving loss \\( L_{pl} \\) in the training process?",
        "9be74f5d-1287-4ad8-9f50-009c7356e268": "How does the overall training loss \\( L_{train} \\) combine the counting loss and the distance-preserving loss?",
        "a7c699e8-c46b-4a73-957a-a60aa47069a2": "What is the value of \\( \\lambda \\) used in the overall training loss, and what does it control?",
        "e07ceab4-17b0-4a7f-a1c2-3c95b601d357": "What is the purpose of building a k-nearest-neighbor graph in the context of the described method?",
        "ca9117dc-3338-481f-9755-6ea96268fea4": "How is the adjacency matrix W computed in the k-nearest-neighbor graph?",
        "71dc74f5-20f5-4d15-9274-7499b3582322": "What does the parameter k represent in the construction of the k-nearest-neighbor graph?",
        "fbd06c1f-e0a3-49d1-b5af-46c640ad0ce2": "How is the graph Laplacian L defined in the document?",
        "e36dfa05-2039-4b53-9fe9-8e3c301f1137": "What is the significance of the distance-preserving loss Lpl in the training process?",
        "429343a1-bf8e-4542-a709-01bdea0b33df": "Why is there a need for pretraining with synthesized data in this approach?",
        "eec9db1c-74e8-44b0-8901-93bfe18206e2": "What are the two main steps involved in the proposed data synthesis method?",
        "0cdd3f68-76da-41cb-b215-3a5f0db7d2ec": "How does the data synthesis method aim to enhance the model's robustness?",
        "444d987a-6eb0-47bb-b8ba-e83eec1755a5": "What role do predefined vocal sounds play in the data synthesis process?",
        "ed7072f2-ff28-44d8-8e76-e189e7a23f6f": "How does the introduction of noise or irrelevant actions affect the construction of sequences in the data synthesis method?",
        "22144f80-8269-42fb-9ea0-61d99f1cc564": "What are the top three categories represented in the DWC dataset, and what percentage of samples do they account for?",
        "6efc2d56-3745-4154-8c0d-a78521254a84": "How is the repetition count of samples distributed in the DWC dataset according to the provided statistics?",
        "0a2814cb-a237-4670-bb18-7b5bedf00e7a": "What criteria must a candidate template meet to be retained during the action template mining process?",
        "fc3ebf70-80ad-4c9e-83c8-0d7c03585751": "Why is a classification score threshold of 0.75 used in the selection of action templates?",
        "a78829a9-1824-4266-ae66-301154b95f23": "What is the purpose of constructing an action template database in the context of the DWC dataset?",
        "f62c9926-24ae-49fb-a5da-6e167184ad33": "How does the process of remapping indexes differ between exemplar extraction and data synthesis?",
        "067d7606-d82f-40bd-8255-1c0ca15145fd": "What are the implications of discarding template candidates that fall outside the established length bounds?",
        "2c5d8014-57fd-4a47-83e4-3c14bc9abac5": "In the action sequence generation process, how is a training sample synthesized?",
        "14e31a02-3887-433f-b94c-107ff02a516c": "What role do the temporal positions i\u2217, j\u2217, and k\u2217 play in the action template mining process?",
        "b0984b59-d397-4227-8e32-b7065fbc94cf": "How does the DWC dataset's sample duration distribution inform the analysis of action templates?",
        "711226d3-170d-4abf-9216-15d329dfc433": "What is the minimum classification score threshold for retaining action template candidates during data synthesis?",
        "aae819d8-fd80-43c8-aa99-e3445ab85907": "How does the process ensure that only templates with a high degree of certainty are selected?",
        "f30fa86d-69de-4d97-aa6b-9424356318f3": "What are the criteria for discarding template candidates based on their length?",
        "c61c1322-5146-4626-8a51-b0ee8f736a94": "How is the count of action templates sampled for synthesizing a training sample?",
        "12d66e93-3234-42fe-a606-811946d7e142": "What range of scaling factors is used for duration scaling of the action templates?",
        "8f1a071b-339a-42b0-872c-f293f6dcb929": "Describe the time shifting procedure applied to the stretched or compressed templates.",
        "d042d265-2abc-4f40-bcfb-60d3d7aef523": "What is the purpose of adding Gaussian noise to the synthesized training samples?",
        "7f2584d3-2277-48b4-9c3d-324ffafdf289": "How many irrelevant action sequences or static noise are incorporated into each training sample?",
        "71002515-4d2d-4208-b8d1-28ebe6ea3333": "What is the significance of constructing an action template database in the context of this document?",
        "de696dbf-cabb-4e7a-a56e-92a3fe005ad0": "How do the augmentation procedures contribute to the diversity of the synthesized training samples?",
        "d6a81ba0-e13e-4af4-bf48-881a3b101162": "What is the purpose of incorporating irrelevant action sequences or static noise into the synthesized training samples?",
        "987327dc-a3a2-4ade-b4c5-a5503901ec7b": "How many entries does the DWC dataset contain, and how many subjects were involved in its collection?",
        "ef1b57f7-95a8-4d3d-9ba6-675f9974886c": "What are the seven broad categories of activities included in the DWC dataset?",
        "60a92707-5074-44be-947a-a22bbe7e11fa": "What limitations do existing datasets for action counting from wearable devices have, according to the document?",
        "205891f4-1f24-4c32-9c4d-109b6aa3f44c": "What types of sensors were used for data collection in the DWC dataset, and what were their respective sampling frequencies?",
        "b303aa46-3f0a-4f60-b915-757ed7451a7d": "How many distinct action classes are represented in the DWC dataset?",
        "6cb99cb5-77d7-42c0-a053-7b061c04017f": "What device was used to collect data for the DWC dataset?",
        "7ad9c395-9748-4a4b-a799-7a1b49700ed3": "How does the DWC dataset aim to enhance diversity compared to existing datasets?",
        "37891ae1-ee80-4d33-8665-f467b1085685": "What instructions were given to subjects regarding the performance of activities during data collection?",
        "7262c8cf-df8e-4ca9-8db9-5d95928b1237": "Why is it important for the synthesized training data to encapsulate a range of possible scenarios?",
        "80eab700-07eb-4db7-b7c0-88c08b6180e2": "How many subjects participated in the data collection for the wearable-device dataset?",
        "7f312939-0cda-4344-8d63-b21fe01eae2b": "What types of sensors were used to collect data in this study?",
        "cc1311bb-b7eb-4473-a6c2-7922e033cd5e": "What was the sampling frequency for the accelerometer and gyroscope during data collection?",
        "a34b37bb-32fa-42e6-b469-ebfce20664e6": "How many distinct action classes are included in the dataset?",
        "6fc09c10-4a87-4fc4-bb36-b716d1eddec5": "What instructions were given to subjects regarding the utterance of words during the execution of activities?",
        "293b5d7c-bc8f-4f5d-ac34-ef71f06accf4": "What was the purpose of manually inspecting the collected data?",
        "75f1bdea-87b4-4bcc-b78e-774e9b49fe73": "Why were some samples discarded during the data collection process?",
        "3bbfabb3-c28d-414e-8b30-050bfb456725": "How was the data collection process initiated for the subjects?",
        "77f40012-2e34-408b-a95f-fd486fa0b9a8": "In what two phases was the data collected, and how many subjects participated in the first phase?",
        "dad155f2-4824-47d9-9b95-c0918c503040": "What issue arose due to the use of a third-party program for controlling the audio stream?",
        "53a1cd19-150f-4e5d-9193-34be2b39f658": "What are the performance metrics used to evaluate the methods in the experiment results on DWC?",
        "c38fb9fc-5881-4cca-ac9c-4c13c4959b17": "Which method achieved the lowest Mean Absolute Error (MAE) in the test set?",
        "191a7e43-88fd-48fa-8726-2fecd6c09de6": "How many entries were collected during the first phase of data collection?",
        "137eca49-d40b-4c78-829d-7fb6cb1a03b9": "What percentage of the temporal duration did the action of interest occupy in the first phase?",
        "85c11b2d-1913-45a0-a98e-2dd805cb0d5e": "What actions were selected for the second phase of data collection?",
        "897ff4de-ce26-4e6b-82e3-fce974d3c54b": "How many entries were collected during the second phase of data collection?",
        "210e9863-3484-4c60-90ff-632d5f257e99": "What is the total number of entries in the final DWC dataset?",
        "897771c9-8970-455b-8ea9-a979e9b44d27": "What is the range of the action of interest's temporal duration in the second phase?",
        "db5db884-1b8b-44f7-af86-008fff892617": "How many repetitions are included in the final DWC dataset?",
        "4da3c4a1-17b0-45e1-9dce-97227f6484f4": "Why was a second phase of data collection necessary according to the document?",
        "079d4cb1-5473-400b-a1b6-7ef02ad534a6": "What six actions were identified as potentially underrepresented in realistic situations during the second phase of the study?",
        "2ef95125-c84b-443c-bc21-d91fc74e58ab": "How many entries were collected during the second phase, and what was the range of the action of interest's temporal duration?",
        "6ba58817-f124-4663-b2f5-3c182357b8b7": "What is the total number of entries in the final DWC dataset, and how many repetitions does it contain?",
        "03c5d38e-d9a6-451a-980f-451fbc389ee2": "Describe the partitioning scheme used for dividing the DWC dataset into training, validation, and test data.",
        "4e132014-802e-4181-ae91-b5dc122cb3a6": "How many action categories were included in the training set, and how many subjects were involved?",
        "95b69604-61f8-4ce2-8002-a55a09b67962": "What methods were used as baselines for comparison in the experiments conducted on the DWC dataset?",
        "85ac2c3b-0c9d-44af-b390-1d6d49fd9b11": "What does the \"Mean\" method predict in the context of the experiments?",
        "1fdf033d-27c3-46e8-81b2-d2d979834d49": "How does the \"Frequency-based\" method determine the final count in the experiments?",
        "82704c7b-139c-4eb1-aa68-0c83386ccbc2": "Which two state-of-the-art methods were compared against the proposed method in the study?",
        "85b7d179-e80c-4e4c-94ca-680094e1aeab": "What was the purpose of separating subjects into different groups within the dataset partitioning?",
        "1e9c0cf8-8f47-4d85-afda-75c28cf6ec8a": "How were the subjects divided into training, test, and validation sets in the study?",
        "6d86a937-49ca-4832-8309-a6437ad88a86": "What are the four baseline models used for comparison in the proposed method?",
        "7b0a342f-8602-4079-8333-b67d81e787c6": "What does the \"Mean\" baseline model predict in the context of this study?",
        "435fa0dc-248d-4262-a065-31cf823645fa": "How did the authors adapt RepNet and TransRAC for sensor data?",
        "6c67ecd6-3abb-49bb-a44a-1600be5699b0": "What is the significance of the \"Dist. Preserving Loss\" component in the proposed method?",
        "6e55442e-d9f6-4e89-8c2a-f649a38ca72a": "What were the MAE and RMSE values for the model that included all components?",
        "2e6a029e-d1f6-45ae-ac90-d45c27ebe765": "How does the model's performance change with varying amounts of pretraining data?",
        "6979dfc8-5285-4692-a80d-aa978ee53d7a": "What does the term \"Constrained Detection\" refer to in the context of the components?",
        "be6343fb-3fc0-4bee-a1ba-e34121795c72": "What does the \"Similarity Estimation\" component contribute to the overall model performance?",
        "61bb61ba-a521-45c7-9eeb-9f451ce18aaa": "In the quantitative results for temporal location detection, how does the proposed method compare to the \"Greedy\" approach?",
        "dba5f537-0930-4b7e-b36d-b87b29b64259": "What evaluation metrics were used to assess the performance of the temporal location detection model?",
        "90e3a682-d395-4a67-a97e-4aba90a18e06": "How is the Mean Absolute Error (MAE) calculated according to the provided context?",
        "f7d176e5-00a9-4941-8416-45f46036fad4": "What was the purpose of pretraining the model on synthesized data?",
        "5b9f423e-b862-481b-8063-c57bc2c9060f": "How many epochs were used for both pretraining and training on the actual dataset?",
        "37963767-5d41-41dc-b79e-4d68f1ad5e69": "What optimizer and learning rate were employed during the model's training process?",
        "d7635981-5dc3-4562-8fac-189219bcca36": "What type of classifier was used in the exemplar extraction module, and on what data was it trained?",
        "b235e45f-d358-408c-b7ca-81a355becffa": "How was the audio window classifier treated during the training stages of the model?",
        "d849ac2f-e3d9-4bff-98b2-1e3e0833aa01": "What was the common length to which all input sensor data was padded?",
        "d612f036-3aaa-4ebb-a90b-52cce6766348": "What was the learning rate decay applied at the end of each epoch during training?",
        "9535781d-0120-4335-abd3-362c07045071": "How did the feature extraction process differ between the proposed model and the baseline models?",
        "5a2d2bef-6bf6-47e5-a806-25eb94a8e916": "What optimizer was used during the pre-training phase of the model?",
        "b0fd5e83-7bab-4c05-beaa-f4d39ea3c821": "What was the learning rate set for the Adam optimizer in this study?",
        "bc058fa5-13bc-408e-a4d3-8c8f612d501d": "How many epochs was the model trained on the actual training set after pre-training?",
        "09d13c7c-dc84-433d-9b3a-887df63b4f64": "What learning rate decay factor was applied at the end of each epoch?",
        "915a63ab-97bc-4427-b8cb-e741d6663993": "Which audio window classifier was utilized in the exemplar extraction module?",
        "f7e6dbbc-d0ad-4ff7-a24e-5103e0a8f756": "On what dataset was the BC ResNet classifier trained?",
        "5c9031d6-2826-4aef-9388-a367721b8bcd": "What was the common length to which all input sensor data was padded?",
        "962d2649-29f4-4ea0-89af-b275aafab75f": "What standardized window size was used for all baseline feature extractors?",
        "370cabbf-ba53-4173-9f02-e48978dc988e": "How many layers did each feature extractor consist of?",
        "63ae2029-248f-4045-8c04-a8777216de44": "Was the BC ResNet classifier updated during the training stages of the model?",
        "bc0e01c3-cca4-48fc-9b84-a01bf23f409f": "What is the dimension of the feature extraction layer used in the proposed method?",
        "18ad6860-3b6d-4c19-9729-71b38c234d86": "How many attention heads are utilized in the model described in the context?",
        "95a1d7a6-181a-4123-ac9b-db5761dd60d9": "What size is the adaptive pooling layer before the counting head?",
        "1c38225f-63fd-4866-8b96-59c1584288a8": "What was the length of the input sensor data for RepNet?",
        "0b1fecb2-9955-4409-b879-99b81bd2835c": "Did TransRAC require padding for its input data?",
        "bff2baf9-5611-4285-a755-6a8144ae03ab": "What optimizer was used during the training phase of the models?",
        "2d63357a-dfb4-488a-99a0-ba8777497b4f": "How many epochs were the models trained for?",
        "2858c379-00df-446b-ab2f-4d4b4995fb27": "What loss function was employed in the training process?",
        "c04ab6c4-7c71-4005-8d51-aeab17955d53": "How much lower was the MAE of the proposed method compared to other approaches?",
        "325d7364-45dd-4596-b4b6-6ea432fb4275": "What were the MAE values for RepNet when using the original transformer variant?",
        "5578250b-e131-437b-a957-e863e93b87e5": "What are the MAE values for RepNet when using the original transformer and its variants?",
        "d26d206b-400e-4b22-9055-9d0392663c44": "How do the MAE values of TransRAC compare to those of RepNet across the transformer variants?",
        "00fb8a56-6fd7-447f-b6df-985594dacf64": "What is the significance of the 30% difference in MAE values between the proposed method and the baseline methods?",
        "94a6a0d0-55e1-494c-8c0a-eb726abf63ee": "What components were evaluated in the ablation study of the proposed method?",
        "379afce7-e083-4540-a524-2fc41aaf166c": "How does the \"Dist. Preserving Loss\" component contribute to the performance of the proposed method?",
        "9dbb5521-7625-48da-836c-f7230b7f3926": "What is the role of the \"Constrained Detection\" component in the proposed method?",
        "d791d85e-164f-4b28-811e-4dde5a3af255": "What naive solution is employed in the absence of the \"Constrained Detection\" component?",
        "bfa6aad5-0688-43f3-b97b-4fca073df622": "How does the proposed method for \"Similarity Estimation\" differ from the naive correlation approach?",
        "799e7cbd-aa03-4cc7-a248-1a4760fa7361": "What dataset was used for pretraining in the proposed method?",
        "5dd43a48-9bba-4ad5-9b77-cab587c2488b": "What do the results of the ablation study indicate about the effectiveness of the proposed components?",
        "255102ac-2bde-43ad-b193-f9dc8d28578f": "What are the four evaluated components mentioned in the analysis presented in Table 2?",
        "f728f884-ac71-4563-a860-bfff00536fe3": "How does the distance-preserving loss contribute to the overall performance of the model?",
        "adb75412-48d0-4eed-ad27-6372d4418968": "What is the purpose of the dynamic programming algorithm in the context of constrained detection?",
        "32d9c621-eca1-493d-883c-6cfb4782a1f7": "How does the proposed method for exemplar similarity estimation differ from the naive correlation method?",
        "e1800faf-084a-4fba-8928-57ca17dc2663": "What was the size of the synthesized training data used in the default setting compared to the real training data?",
        "db376112-e2ee-4674-a152-101c912d0abe": "What impact does pretraining on the synthesized dataset have on the final results, according to the analysis?",
        "f61d850f-e72d-4a09-82ee-11dd4c2a692a": "How do the mean absolute error (MAE) and root mean square error (RMSE) values change with the number of audio exemplars used?",
        "1d40761a-625f-45f0-aadb-1118555b7663": "What do the qualitative results in Figure 5 illustrate about the model's predictions?",
        "17279fa2-33bf-4c8b-a1a9-328314f835ad": "What is the significance of the results presented in Table 3 regarding the number of exemplars?",
        "4eda790b-30d1-4256-94fa-a638f04baeef": "In the context of the analysis, what is the main focus of the further investigation conducted after the initial results?",
        "a82ba857-c310-42a1-a59c-d7d7b6553e9e": "What strategy was adopted in the default setting regarding the volume of synthesized training data compared to real training data?",
        "4c3aa6a6-f97e-4252-b7d1-4276cdec53d2": "How much larger is the synthesized training data in the default setting compared to the real training data?",
        "7a2d69b3-ccb1-4a10-9b5a-afad00cda9cf": "What were the results of using a synthesized dataset that is twice the size of the real training data?",
        "98834c17-f59a-4088-97e8-052a701365f6": "In Table 3, what are the MAE and RMSE values for using three exemplars?",
        "aa0e8886-917f-4733-8041-b132238c351e": "What does the term \"OBK\" stand for in the context of the evaluation metric used in the experiments?",
        "a37778c6-4e27-4c43-8104-f4966fc82a8c": "How does the performance change when using different numbers of audio exemplars according to Table 3?",
        "2fd6feee-fb7b-4173-a9c4-446de82b9df5": "What does the \"4x\" designation refer to in the context of the synthesized data used in the experiments?",
        "ce848f8c-c992-4369-bc50-fe2162c5f301": "What is the significance of the temporal localization of predefined utterances in the proposed approach?",
        "5216a93e-793d-442a-aa8f-ddc506067b40": "What does the qualitative results section illustrate with the four prediction examples?",
        "8142bb3c-f3c1-4c5d-93ff-77d3c23a1151": "How is the Off-By-K Error (OBK) metric defined in the context of the evaluation?",
        "51a4195e-9561-4b1a-8c8a-52d916d6769a": "What does \"2x\" and \"4x\" refer to in the context of the synthesized dataset size compared to the real training set?",
        "0087e472-bfb2-4143-ab4c-7ada02246122": "How does a synthesized dataset that is twice the size of the real training data impact performance?",
        "a4821c94-d56a-4e90-9a12-ed22ae0c2e5f": "What metric is used to evaluate the temporal localization of predefined utterances in the study?",
        "de4bc384-4776-4b68-b157-9a6aa430a0bd": "How is the Off-By-K Error (OBK) metric defined in the context of this research?",
        "4049f5fc-a198-472a-92ac-5d473b541069": "What does the Dirac delta function (\u03b4) represent in the OBK metric calculation?",
        "2d0e1c04-ec2b-45de-ac53-269d21a79b5f": "What baseline method was used for comparison in the temporal localization evaluation?",
        "024097d3-c09a-47ed-850a-7216417ccfb2": "What do the qualitative results in Fig. 5 demonstrate about the proposed method?",
        "14389a39-3fdc-4503-8d87-cc0ade307536": "How does the proposed few-shot method utilize vocal sounds from audio data?",
        "a8cc42af-0cb7-4d7d-8e99-13252337d276": "What is the primary goal of the proposed method in counting actions in real-world settings?",
        "407d9916-c33c-46f4-b8e7-f08ed3ac17db": "What type of dataset was used to validate the effectiveness of the proposed approach?",
        "e4107144-1df1-4948-a90a-4f7455059f5a": "What type of support did the project receive from the US National Science Foundation and AFOSR?",
        "74bbddc8-6791-4e00-8c69-b790d2fc3a51": "Which study focuses on monitoring worker fatigue using wearable devices?",
        "b5708334-dece-492b-9e1b-0e642eb80d74": "What is the main contribution of the paper by Belkin and Niyogi in 2003?",
        "dc1dab7e-d88d-4a30-a995-51f874996335": "In which conference was the work on tracking free-weight exercises presented?",
        "77e1a87c-c704-4ec0-9234-596db37a247b": "What is the primary focus of the research conducted by Bian et al. in 2019?",
        "f2800580-6cd9-407b-8850-583a9d9daf44": "Who are the authors of the paper discussing robust real-time periodic motion detection?",
        "44ab95d7-484e-4c6a-96ef-3f27654706c0": "What is the significance of the work by Azy and Ahuja in the context of moving object segmentation?",
        "d3bb8ceb-5e36-4707-9131-5f321b13c5bb": "Which publication discusses the periodicity of dynamic textures?",
        "9cc5990a-11e4-4f92-96d9-b9a73ce8ddf6": "What is the main application area of the research presented by Cutler and Davis in 2000?",
        "48e39a7e-63da-4dd5-b1c5-acc960a75574": "How does the study by Baghdadi et al. contribute to understanding changes in gait parameters?",
        "8ba5cdff-48e8-4ece-a02e-6652f26e6a72": "What is the main focus of the research presented by Chang, Chen, and Canny in 2007?",
        "e178ab76-9f90-4e3c-bc06-797d546674da": "Which conference did Chetverikov and Fazekas present their work on motion periodicity of dynamic textures?",
        "65708399-a9d1-40d9-a8ba-a146fdb500ad": "What type of motion detection does Cutler and Davis's 2000 paper address?",
        "aee3b5b5-969d-4b26-b784-fa46c3d62c7a": "What is the significance of the Soft-DTW loss function introduced by Cuturi and Blondel in 2017?",
        "69d23bee-1fa1-45c4-9c75-64c36294315a": "What technology does the Femo platform utilize for monitoring free-weight exercises, as described by Ding et al. in 2015?",
        "c52c6e5f-7dd2-490f-a254-b00f5a7f63ee": "What is the primary contribution of Dwibedi et al.'s 2020 paper regarding video repetition counting?",
        "5d460895-f4f0-49b7-b3a9-38605687d8ae": "How does AIFit, developed by Fieraru et al. in 2021, aim to enhance fitness training?",
        "0708dcf0-48f9-4f77-94ff-acf5861751ef": "In which year was the research on tracking free-weight exercises published?",
        "6b1f886e-6742-4c4c-903e-b32d6338b3eb": "What is the common theme among the papers listed in the context information?",
        "c27ce862-d36c-4327-97e7-7b84d95d609f": "Who are the authors of the paper that discusses robust real-time periodic motion detection?",
        "ccafc552-b69d-419b-b3c3-b416e15fd4bc": "What is the primary focus of the Femo platform mentioned in the 2015 paper?",
        "58a7cc59-8473-4c65-bf4a-a5b51d53dc05": "How does the 2020 study by Dwibedi et al. contribute to video repetition counting?",
        "8aaf26ba-ca33-4c33-b947-1b66c4b113fb": "What innovative approach does AIFit propose for fitness training feedback, as described in the 2021 paper?",
        "450e5730-e86b-4e38-81fa-97e49e03a3db": "In what context is the smartwatch step counter developed by Genovese et al. used?",
        "e2d966c1-d6f5-4c38-aec3-c517ce9e86ec": "What types of sensors are discussed in the 2020 paper by Hatamie et al. for healthcare monitoring?",
        "157d1fbd-5455-49c0-a4fa-d2578af6ff93": "What is the significance of viewpoint invariance in exercise repetition counting as explored by Hsu et al. in 2021?",
        "c4537e4c-eb14-477f-b98f-b3e5d96095a7": "How does the TransRAC model, introduced by Hu et al. in 2022, enhance repetitive action counting?",
        "19f582e0-c90c-4d45-b951-b96c7dc85ac1": "What are the main contributions of the 2023 study by Huang, Ranjan, and Hoai?",
        "6380e54c-b3c3-405c-8fd8-cd933e6ec022": "Which conference proceedings feature the majority of the studies mentioned in the context?",
        "2646dffd-0aee-4ad7-8404-15f3d59e9bf8": "What common theme can be identified across the studies listed in the provided context?",
        "4cf115c7-c09a-4706-b375-e19a42de41ef": "What type of sensors are discussed in the 2020 publication by Hsu et al. for healthcare monitoring?",
        "52580674-8937-4538-823e-24cda4e031d5": "What is the main focus of the viewpoint presented by Hsu, Zhang, Tsougenis, and Tsui in their 2021 paper?",
        "7fa02457-9c47-40aa-99c8-9523971c066c": "How does the TransRAC model, introduced by Hu et al. in 2022, enhance repetitive action counting?",
        "8655ad91-3ef2-438e-ae74-d962d7cda4cf": "What is the significance of interactive class-agnostic object counting as presented by Huang, Ranjan, and Hoai in 2023?",
        "6229b471-5690-4d14-9fcf-26d99946a9a1": "What technology does the Exersense algorithm utilize for real-time exercise segmentation and counting, according to Ishii et al. in 2021?",
        "faf0cb8c-b32a-42ac-8c77-4823f9b4e3c9": "What is the primary goal of the mobile fitness coach concept discussed by Kranz et al. in 2013?",
        "521dda53-c2d7-44dd-86b8-d35886ffd020": "In what context is the term \"Industrial wearable system\" used by Kong et al. in 2019, and what does it aim to achieve?",
        "bf7cf49c-3cd5-436b-b4e2-b2fe933a577d": "What innovative approach does Kim et al. propose for keyword spotting in their 2021 research?",
        "75cc895e-5dd5-438d-9238-752d0110f256": "How do the studies mentioned contribute to the field of physical exercise monitoring and analysis?",
        "6a5f857c-9040-43a0-8d12-70bba5daffe6": "What are the potential applications of the technologies discussed in the context of healthcare and fitness?",
        "20042e21-0c6b-4fd9-a666-b20f8604f6f9": "What is the main focus of the research conducted by Kim et al. (2021) regarding keyword spotting?",
        "b0abdf95-fe1c-448c-8993-56576c89873d": "How does the industrial wearable system discussed by Kong et al. (2019) contribute to Industry 4.0?",
        "6b963fb1-5002-4611-88f1-bf7e73b7d21e": "What technology is utilized in the mobile fitness coach developed by Kranz et al. (2013) for individualized skill assessment?",
        "b11c55d4-87c6-4c65-865e-db6ac36d8080": "What methodology did Kupke et al. (2016) employ to develop their step counter?",
        "ab4b6f74-b2eb-4498-a7ee-5d66ee9bf1bf": "What type of electrodes are used by Lee et al. (2015) for monitoring heart rate variability during sleep?",
        "2a6a908d-3971-4b8a-a484-bbfce0e34c3d": "What is the primary application of the Live Repetition Counting system presented by Levy and Wolf (2015)?",
        "f16d8396-b250-4ca9-a635-73c164cd928b": "What innovative approach does Liu et al. (2022) introduce in their work on visual counting?",
        "6a889b61-c417-4539-a289-d6a425d59b01": "In what year was the study on heart rate variability monitoring by Lee et al. published?",
        "2f1a3906-1b0b-40a4-98bb-ad01ebe7ac0e": "What are the key features of the wearable system highlighted in Kong et al. (2019)?",
        "02971c7b-6dce-4190-a328-278407fca76e": "How does the research by Liu et al. (2022) differ from traditional methods of visual counting?",
        "a5cb8a48-dc9e-4ac2-8313-7d97c0580150": "What is the primary focus of the study conducted by Lee et al. (2015) regarding heart rate variability?",
        "528f7464-e29f-4246-8258-0d308254ac66": "In which conference was the paper \"Live Repetition Counting\" by Levy and Wolf presented?",
        "8d797cc5-80de-4e35-bab7-eb7b5d518e1c": "What innovative approach does Liu et al. (2022) introduce in their work on visual counting?",
        "4db61cc5-0f71-4233-a133-31b7212bb88d": "What is the main contribution of the Pyraformer model proposed by Liu et al. (2021)?",
        "d20d74fb-d0ec-4063-9f06-137449896cc6": "How does the research by Lu et al. (2018) differ from traditional counting methods in computer vision?",
        "98b813b8-ff16-4e98-a381-50d1285ef2ab": "What technology does the RecoFit system utilize to recognize and count exercises, as described by Morris et al. (2014)?",
        "0e3abdcc-41ed-4d8c-a3bb-f4f5710cefa6": "What was the objective of the study conducted by Mortazavi et al. (2014) regarding exercise repetition recognition?",
        "71edf93f-4d99-47df-837f-c52ce8b9d05f": "Which conference proceedings include the work of Liu et al. (2022) on transformer-based visual counting?",
        "bfb4b3ed-118f-4ed3-b41b-36eb2461bbea": "What type of electrodes are used in the heart rate variability monitoring study by Lee et al. (2015)?",
        "3a060707-c2cb-4044-9645-cca6b771ff23": "How does the work of Liu et al. (2021) address the challenges of long-range time series modeling?",
        "30c3a0fa-21d4-4594-9dc0-880a5f668232": "What type of sensors are used in the sleep monitoring study by Nam, Kim, and Lee (2016)?",
        "0641b149-b720-4799-b76a-4ad01f7dd0ff": "What is the main focus of the research conducted by Nguyen et al. (2022) regarding object counting?",
        "29700f68-9d24-45f7-91e2-c42e5610d0cd": "How do Nishino, Maekawa, and Hara (2022) approach repetition counting in their study?",
        "296b921a-4c40-4b72-a49a-db8a43a841f8": "What is the significance of decomposed uncertainty in crowd counting as discussed by Oh, Olsen, and Ramamurthy (2020)?",
        "91807a6f-aeb1-42df-94ab-354c396c799e": "What systematic review topic is addressed by O\u2019Reilly et al. (2018) concerning wearable technology?",
        "c6066936-d334-43c2-a645-ede960ac6299": "How does the study by Patel et al. (2010) utilize wearable technology for stroke rehabilitation?",
        "b8c474e1-efac-4c9d-9f63-5c99bbe85d0f": "What machine learning technique is employed by Pillai et al. (2020) for personalized step counting?",
        "8b9ecc38-552f-4acd-a1a4-9d926b6d19ff": "In what year was the research on few-shot object counting and detection presented by Nguyen et al.?",
        "9feca725-2a9b-4fdf-93d4-80f67cb4ce54": "What type of publication is the work of Pillai et al. (2020) categorized as?",
        "e6abc7bf-0e90-4f81-960c-a7bee91f0b18": "What is the primary application of wearable inertial sensor systems as reviewed by O\u2019Reilly et al. (2018)?",
        "5e672913-a547-452d-8e8a-8f1bec0a73ff": "What novel approach is discussed by Patel et al. (2010) for monitoring rehabilitation outcomes in stroke survivors?",
        "7d1a6894-784c-42a4-baf9-f0b74ef92ff7": "How does the personalized step counting method proposed by Pillai et al. (2020) utilize wearable sensors?",
        "6a67dd1b-17d7-4c20-be4b-666b44f3b676": "What is the focus of the comparative study conducted by Prabhu et al. (2020) regarding exercise-based rehabilitation?",
        "eb62eca9-8838-4647-8c76-2cb875f05074": "What type of sensors are explored by Ramachandran and Liao (2022) for health monitoring?",
        "5637dc15-bb1a-404e-87dd-23a95fde2a51": "What is the main contribution of Ranjan and Hoai (2022a) in the field of counting in computer vision?",
        "7378b489-d667-496e-a6d2-263ffc33eb15": "How do Vicinal Counting Networks, as presented by Ranjan and Hoai (2022b), differ from traditional counting methods?",
        "32b198b7-ada9-4f01-9f9a-94c8bc025446": "What is the significance of the research conducted by Ranjan et al. (2021) on learning to count in computer vision?",
        "65a792ad-328f-475c-a437-7c5437162d82": "In what context is visual quasi-periodicity discussed by Pogalin et al. (2008)?",
        "c45587fb-df14-4f37-b2eb-94d87b524e54": "What are the potential applications of the wearable technology mentioned in Patel et al. (2010)?",
        "9b4d141e-a5e2-4b38-8e2d-e85449e1869e": "How do the studies referenced contribute to advancements in sports medicine and rehabilitation?",
        "12c043d3-224c-4a84-a73a-d4ecee6c0d6a": "What is the primary focus of the research conducted by Ramachandran and Liao in their 2022 paper on microfluidic wearable sensors?",
        "9ea842f1-e275-4b96-81f1-5f0cc0e63774": "In which conference did Ranjan and Hoai present their work on \"Exemplar Free Class Agnostic Counting\"?",
        "78f3b38f-733c-4c1f-965f-638daecad005": "What is the main contribution of the paper titled \"Learning To Count Everything\" by Ranjan et al. in 2021?",
        "4ef0f299-accf-4832-b4f2-f8e7eb397171": "How do the authors Runia, Snoek, and Smeulders approach real-world repetition estimation in their 2018 study?",
        "7d6f7196-b820-4392-91f9-16159c6c50ea": "What framework do Shi et al. propose for class-agnostic counting in their 2022 paper?",
        "6fd56408-e666-489b-bab3-d2914d6db6b9": "What type of exercises does the research by Soro et al. focus on in their 2019 papers?",
        "e7157f3a-f92d-42e1-919e-124a511811a8": "How many authors collaborated on the paper \"Recognition and Repetition Counting for Complex Physical Exercises with Deep Learning\" by Soro et al.?",
        "30ed34de-ede5-4581-9cbb-2d5a2979e874": "What is the significance of the term \"similarity-aware framework\" in the context of Shi et al.'s 2022 research?",
        "c1d21903-6664-43d5-9a1e-887a51c8278b": "Which publication features the work of Stiefmeier et al. on sensors and their applications?",
        "fccbb184-aa2b-4efa-ac04-59f6e50776fe": "What common theme can be identified in the works of Ranjan and Hoai regarding counting methodologies?",
        "d9922c52-7546-4b3e-8adf-d4a557b84ff7": "What is the main focus of the paper titled \"Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting\"?",
        "ddbfe30c-7cb5-4c17-bfca-7c98247defb2": "How does the work by Soro et al. (2019a) contribute to the field of exercise recognition and counting?",
        "108c70fb-1311-4d80-84c8-311aa4310cf8": "What type of activities does the study by Stiefmeier et al. (2008) track, and in what context?",
        "95aa0e69-5845-43de-afaa-003cbc62149a": "What is the significance of the MM-Fit framework introduced by Str\u00f6mb\u00e4ck et al. (2020)?",
        "45f36e38-8c78-45fa-8bf9-eb191ac76d93": "What methodology is employed by Thangali and Sclaroff (2005) for periodic motion detection?",
        "46751dcf-0fc8-4ddf-aa97-b7907e24d2ae": "What dataset is introduced by Warden (2018), and what is its primary application?",
        "23747377-55b9-4d69-950c-3ea9951b3b8f": "How do Wu et al. (2021) approach long-term series forecasting in their work on Autoformer?",
        "63d8162f-d116-43f0-ba34-12914b64b55d": "What is the contribution of Yang et al. (2021) to the field of object counting in their paper on class-agnostic few-shot learning?",
        "8b54deb0-d651-4146-9e8d-4cdd0b51b458": "In what year was the paper \"Recognition and Repetition Counting for Complex Physical Exercises with Deep Learning\" published?",
        "1019ae12-2f1d-4c74-b4c7-399d74e5cd2a": "What are the key features of the similarity-aware framework mentioned in the context?",
        "9c071fee-76cf-43ec-8c92-f9a1209e0e60": "What is the main focus of the paper by Thangali and Sclaroff (2005) regarding motion detection?",
        "7cda54c5-b76e-4ba6-a4d5-b68feb094c66": "What dataset is introduced by Warden (2018) for speech recognition, and what is its specific application?",
        "df479ad9-de53-4d9e-958c-f12a1fc064f3": "How does the Autoformer model proposed by Wu et al. (2021) contribute to long-term series forecasting?",
        "02ab81b7-7a24-4c0b-a0a3-eadff47dfd2a": "What is the significance of class-agnostic few-shot object counting as discussed by Yang et al. (2021)?",
        "76d76e0a-c83d-4a17-8f63-33e1020d1a8c": "In the work by You et al. (2023), what method is used to enhance feature similarity for few-shot object counting?",
        "79e0273c-19a2-4daf-9c98-75970c0d642a": "What approach do Zelman et al. (2020) use for counting exercises without requiring specific training?",
        "b759dd77-0296-4a23-b4f3-e0361d074f3e": "How does Zhang et al. (2020) address the challenges of temporal repetition counting in their research?",
        "0dd0fc90-a281-4e35-a271-036856d87213": "What innovative technique do Zhang et al. (2021) employ for counting repetitive activities using both visual and auditory data?",
        "8afe2f15-fc7e-4456-8322-aaf508641097": "What common theme can be identified in the research conducted by the authors listed in the context regarding counting methodologies?",
        "3e6e8112-e36c-423c-bd4f-a4b15559cf80": "How do the contributions of the papers mentioned in the context reflect advancements in computer vision and pattern recognition?",
        "301fb51c-9c0d-414a-a18a-4842875a53a9": "What is the main focus of the study conducted by Zelman et al. (2020) regarding exercise counting?",
        "b8d89b08-f577-436e-a369-07ac5d2c93c2": "How does the approach presented by Zhang et al. (2020) differ from traditional methods of repetition counting?",
        "b73b053e-333c-4f15-8ac5-0d45fade1608": "What unique combination of modalities is utilized in the research by Zhang et al. (2021) for counting repetitive activities?",
        "a075bac8-a9a7-4724-ac3a-d2687f22457e": "What is the significance of the Informer model introduced by Zhou et al. (2021) in the context of time-series forecasting?",
        "1c4afe35-cf39-4aec-988c-c4925b178794": "In which publication did Zelman et al. (2020) present their findings on accelerometer-based exercise counting?",
        "396b4099-f60c-4bc6-9c41-d758393ba287": "What conference proceedings featured the work of Zhang et al. (2021) on repetitive activity counting?",
        "41238ccc-9c35-4f50-ac64-2da2536c68b5": "How do the methods discussed in the provided context address the challenges of exercise-specific training or tuning?",
        "63a811ad-326c-44b9-850a-ce66e24c3394": "What year was the research by Zhou et al. (2021) presented at the AAAI Conference on Artificial Intelligence?",
        "20f71ec6-76b0-4aa5-81cd-062a67d240cb": "Which authors collaborated on the paper discussing context-aware and scale-insensitive temporal repetition counting?",
        "676831e7-918b-47d6-b4c1-1ff574f1dd5b": "What is the primary application area of the research conducted by the authors mentioned in the context?",
        "0496e41b-fd02-484d-af79-87c14e1d4b36": "What is the primary purpose of the absorber vessels at the Orbost Gas Plant?",
        "cda54acb-c04d-4707-b933-7b44aa00b0e2": "How often do the absorber vessels currently require mechanical cleaning due to fouling?",
        "2d287c93-8731-4ff9-9d7a-f6f7ee145ebe": "What are the key specifications that the export sales gas must meet at the Orbost Gas Plant?",
        "915a5b7b-72d0-42c6-81ab-dd40048c72b4": "What operational data is suggested to be analyzed using machine learning to address the fouling issue?",
        "269575e8-4317-4ba0-9cf4-838b954ff0df": "What significant operational achievement occurred in December 2021 regarding the absorber vessels?",
        "7e5c1569-30fc-49ef-b75c-60ececb99a66": "What is the main goal of the proposed project titled \u201cThe Application of Machine Learning to Reduce the Fouling of Absorber Vessels at Orbost Gas Processing Plant\u201d?",
        "301e1066-b928-41f5-ad47-5a4ce3a469e1": "How long have the absorber vessels been experiencing fouling issues since they began operating?",
        "a580fdfe-b92a-43fc-91b2-edc508cf7d62": "What type of data storage and analysis system is used at the Orbost Gas Plant for real-time data?",
        "668cd2d3-67a2-4cd1-9e13-924194560b21": "What are the potential benefits of replicating the conditions from the two dream runs in December 2021?",
        "2b824f4e-9ec5-4759-9df1-ffee66432ce1": "What specific differences in operational data are being investigated to understand the successful runs in December 2021?",
        "bc3ede22-0728-4a99-988e-b7df30f1d95b": "What specific fouling issues have the absorber vessels been experiencing since 2020?",
        "632a96f9-0565-4814-885e-2a1118da52ed": "How frequently do the absorber vessels require mechanical cleaning?",
        "30719dd5-1d3e-4f73-a858-df0c1b1b2abf": "What operational data differences contributed to the successful runs in December 2021?",
        "ee1c3c27-202c-4e20-90b6-5e91581c20c2": "What machine learning techniques could be applied to analyze the time series data from OGP?",
        "152d711d-93f7-42c7-bc29-d0cad37ee7c0": "Which parameters are measured in real-time at OGP that could influence the operation of the absorber vessels?",
        "d6686972-b4a3-4d33-8a04-4fccfed984b5": "How is the real-time data from OGP transmitted to the AVEVA PI system?",
        "98577014-759b-415e-b40c-5caa0b274f65": "What role does the AVEVA PI system play in the data analysis process for OGP?",
        "a47d5af1-cada-429b-818e-1798fe75ba3b": "Why is the quality and structure of the data important for machine learning applications?",
        "266016ff-ebda-49b9-8006-ac14c9b886ab": "What steps can be taken to replicate the successful operational runs observed in December 2021?",
        "fc03e389-97fa-4d6a-bbda-d6b15a0a5697": "How does the use of AVEVA PI system compare to other data management systems in industrial operations?",
        "dd566266-806a-4016-8354-a31c689e3495": "What is the primary focus of the \"Think Digital AI Roadmap\" document?",
        "33188237-b8b9-49f5-b73b-4588dd1ca068": "How does the AI Roadmap propose to integrate digital technologies into existing systems?",
        "1a784ec3-fef0-4abc-a959-1bfea9cd2928": "What are the key objectives outlined in the AI Roadmap?",
        "6ac6e1ca-10e3-41fa-bf1d-793c06eecb7a": "Who are the intended stakeholders for the AI Roadmap?",
        "50d737e2-0b34-485c-a43d-010845bad93b": "What challenges does the AI Roadmap identify in implementing digital strategies?",
        "a480c106-ab76-4546-9a78-5b5d1fb6a260": "How does the AI Roadmap suggest measuring the success of AI initiatives?",
        "5e544ff9-b5c4-412e-80bc-4ebe7cabbe43": "What specific technologies are highlighted in the AI Roadmap for digital transformation?",
        "7b8de721-3bcc-478a-b5e7-c8fe05ef3751": "What timeline does the AI Roadmap propose for achieving its goals?",
        "820d6895-9298-4fa0-80ba-371ecd6b9dc1": "How does the AI Roadmap address ethical considerations in AI deployment?",
        "20801477-55da-4808-a335-c04614343dab": "What resources or support does the AI Roadmap recommend for organizations looking to adopt AI?",
        "050cd8f2-8b81-4087-8042-50025fc4cb88": "What organization prepared the document in November 2023?",
        "47c6f4ee-8c59-459b-916b-4a719081cf35": "In what month and year was the document created?",
        "e74ed6ad-693e-4881-b2c7-1e9f73b77116": "What is the full name of the institute mentioned in the document?",
        "d5b98505-cbfe-433e-9755-5b538bcff6dc": "What is the primary focus of the Australian Institute for Machine Learning?",
        "741e187d-2f24-436d-a74e-fa054e51cbc7": "How does the date of preparation (November 2023) relate to the relevance of the document's content?",
        "531a0432-a71f-4e54-92a8-3609b2a2e062": "What type of information might the Australian Institute for Machine Learning provide in their documents?",
        "ec755e46-4f5f-4ce7-8301-6870ca1001fb": "Why is it important to note the preparation date of a document in the field of machine learning?",
        "46fd0cf6-d4c8-4b98-93c2-efbf0e8247b1": "What implications might the preparation date have on the findings or recommendations in the document?",
        "58d1cd06-f9e4-429b-8c7c-4e606795af41": "How might the Australian Institute for Machine Learning contribute to advancements in machine learning?",
        "f7d0d81f-ade2-4f66-a092-087799550401": "What could be the significance of the document being prepared by a specific institute?",
        "f84bc2d4-36be-47e9-9a1f-00b70c5b8064": "What is the primary goal of the collaboration between the Australian Institute of Machine Learning (AIML) and South Australian agencies and businesses?",
        "8f5bac99-5799-4ae3-a61d-6c2e7f4054ea": "How does Think Digital aim to enhance its services for pastoralists through the integration of AI and machine learning?",
        "4a21bd8a-60a0-4c7c-9ca8-02f62a864c7f": "What specific application has Think Digital recently launched in collaboration with PIRSA and Animal Health Australia?",
        "5da9fe6e-a447-42b5-a6ba-77ad894ced2d": "In what sector does Think Digital specialize, and what type of content do they create?",
        "6c512976-50e3-4fe3-a476-977818a18c47": "What is the intended outcome of the new product that Think Digital is developing for identifying emergency animal diseases in cattle?",
        "5910176c-a236-44f6-a6ad-acba811eb949": "How does AIML support agencies in the development of machine learning solutions?",
        "9c73d7c4-144d-4cac-9aa1-ee56489fc93f": "What is the significance of the Sheep Emergency Disease AR Tool in relation to Think Digital's objectives?",
        "1c5d9011-ce47-4273-b059-ffb9d3043221": "What type of technology does AIML provide as a foundation for further development in machine learning projects?",
        "a0814b19-8f04-482e-ab53-098131fca33c": "What are the key components outlined in the document for Think Digital's roadmap to integrate AI technology?",
        "a78117c8-a1db-4a11-912d-f8591997d44d": "Why is it important for Think Digital to incorporate AI and ML into their new product for pastoralists?",
        "e57a0b2b-f823-4eb8-9fe8-ddb31a5bf741": "What is the primary purpose of the document outlined in the project background section?",
        "ff045dfe-7694-4eb7-a03d-13bc80ef4dbd": "How does the SWOT analysis contribute to the overall vision for AI and machine learning?",
        "e85b0190-668e-4c1d-8148-9badec727e1e": "What are the key principles outlined in the roadmap for implementing AI and machine learning?",
        "2347dde2-feaa-44ff-ab68-5b532e6d7e38": "What does the AI maturity model aim to achieve for organizations looking to integrate machine learning?",
        "7b91d845-ea81-45d9-8cdb-cd1a59575a48": "What steps are suggested for becoming a machine learning organization according to the document?",
        "513e9e56-c0ba-438c-9de4-e644f5e5a6a8": "How is the model development roadmap structured to facilitate AI implementation?",
        "88e275bb-f4a0-4faf-a169-8ff5aabd89c0": "What are the main machine learning engineering principles highlighted in the document?",
        "a41380d6-83c8-4142-8262-ca1e7eae3b96": "What specific outcomes are expected from the \"Think Digital in 1 year\" section?",
        "9c310f28-1cfc-4726-93cb-42cc65732466": "How does the document propose to align organizational and infrastructural elements for AI advancement?",
        "b654f81f-93bc-4088-a207-7330ee06990a": "What recommendations are provided in Appendix B to address current challenges with the existing model?",
        "9817bb16-8dd3-45d8-85fc-56a118037805": "What are the two emergency animal diseases that Think Digital aims to detect using AI and ML in their augmented reality product?",
        "3f38517c-bb69-41d8-9b27-c8821161b76c": "How does Lumpy Skin Disease (LSD) affect cattle and water buffalo?",
        "c7af7534-6da7-4017-af2d-d80b09ca9f36": "What is the primary challenge faced by the cattle industry in North Australia regarding animal diseases?",
        "554ac857-b079-4b24-b2e9-4c0e80ce4f19": "What was the outcome of the initial engagement with the AIML Researchers led by Yifan Liu?",
        "82646a36-5aca-417d-b72c-95c78d282fd4": "What three classes did the custom model developed by the AIML Researchers classify images into?",
        "04f63b07-dd4e-4821-b6e0-b72b330bd42c": "Why was the model's accuracy considered unreliable when tested with previously unseen images?",
        "b8752331-021a-4dce-91b9-9ea76ac62a53": "What steps did the AIML Engineering team take after the project handover from the research team?",
        "2c773019-2046-4896-a95e-97042891a472": "What specific limitation does the current model have that affects its performance?",
        "100fd2e6-488c-45c3-a334-1fa994ff0479": "How did the AIML Engineering team improve the project documentation for Think Digital?",
        "b3aaddcd-58a0-4167-86f6-e70cd718dd76": "What is the significance of having a diverse training dataset for the model's generalization?",
        "35744457-25c2-47d3-ab93-f910699af25b": "What was the main conclusion of the research regarding the model's performance on unseen images?",
        "5baf4ae9-1f70-4773-bcfc-5877958f2a12": "Who was responsible for the initial project handover to the AIML Engineering team?",
        "fc48afad-c6d6-4bca-9ac7-72ac598709b6": "What specific improvements did the AIML Engineering team make to the project documentation?",
        "c0e3188e-158a-4c21-9ff4-b7e8cc54225e": "What is the primary limitation of the current machine learning model mentioned in the document?",
        "17d4da66-36db-4227-be1a-e595e59a8f39": "How many images are suggested as a necessary scale for quality training data in machine learning model development?",
        "90290b87-5f40-4b35-a7fe-e80866f7aa83": "What stage is Think Digital currently in regarding the development of a generalized AI model?",
        "cddd7c73-c194-4b00-a92d-4c5859ec4963": "What is the purpose of the strategic roadmap defined by Think Digital?",
        "264b89e5-9127-45e5-921f-a21cb7e1d9a5": "What was the validation accuracy of the model based on the small training dataset?",
        "eae11695-ea17-4c27-9b01-eab59b1080e0": "Who were the original researchers involved in the project before the AIML Engineering team?",
        "8a9d2b96-e751-449d-ad21-27976a7fe4db": "What is the significance of having a diverse training dataset for the model's performance?",
        "da894833-9991-4d84-8fd3-7c80555570cb": "What is Think Digital's primary strength in the context of its operations in rural Australia?",
        "50a1f411-4439-4052-bd63-ac6815682a8a": "How does Think Digital plan to leverage its rural network to enhance its AI model development?",
        "647b8f74-694a-44ee-be06-1b2a7b2a1e13": "What are the key weaknesses identified in Think Digital's current operations?",
        "b0a73431-cdbd-46f8-a45f-92b6c9f6a013": "In what ways can Think Digital address the lack of quality training data for its AI models?",
        "b4b7b8df-54e7-4759-af8f-2e26d3f8d143": "What opportunities exist for Think Digital to expand its partnerships in the agricultural sector?",
        "979c6aed-31e4-402b-9190-16364b0926c8": "How might regulatory changes impact Think Digital's data collection and AI usage?",
        "cc8c79e7-5431-4430-8864-7066ba054674": "What threats do competitors pose to Think Digital in terms of data and model development?",
        "2c16a947-68b1-49bd-95a3-dc30f7b75d6a": "How can Think Digital position itself as a trusted leader in disease detection within the agricultural industry?",
        "cb16663e-be2e-400d-9c6a-84cfcf48b86e": "What role do established partnerships with veterinary experts and farmers play in Think Digital's strategy?",
        "c4d3ab23-5ac2-4209-a577-276fe819b848": "Why is it important for Think Digital to create large, high-quality datasets for its AI initiatives?",
        "b995ab73-c543-4f76-82cf-737762c9d4ec": "What is the primary goal of leveraging the network mentioned in the context information?",
        "efacece0-c6f0-4565-a006-b24fcce5e7ed": "How can the business address the needs of the biosecurity government in Northern Australia?",
        "faecd854-324d-4ecb-8245-022a738a62fe": "What is identified as the biggest bottleneck in AI model development for the business?",
        "05b8b2e5-f320-4063-9c35-120e80f0d1e1": "What opportunity arises from the lack of quality training data?",
        "0924d57d-4a57-4d5a-abde-977aed1e8195": "How does the lack of internal technical expertise impact the business's competitive position?",
        "b1d2225c-5262-40be-9435-3cd80f2244f0": "Why is it important to create large, high-quality datasets for the business?",
        "aeab0052-4806-4d32-90aa-831f47c0e49d": "What processes should be streamlined to improve data collection and model training?",
        "cf170467-f49b-49c0-80d2-3665f69b2d4a": "How can developing a strong internal technology team benefit Think Digital?",
        "4fec6935-e1a3-4fe3-badb-244060650ce7": "In what ways can the tool be expanded beyond its initial use case?",
        "fe71de98-5739-4d7a-99ec-f2944b25c822": "What is the significance of capturing high-quality data for building AI models?",
        "4a1b6539-f0bb-4894-bd5c-16d28515a710": "What specific cattle diseases does Think Digital aim to help farm owners detect using AI technologies?",
        "efe31c8b-c3d9-448a-be10-06be88443a50": "How can machine learning contribute to the early detection of cattle diseases?",
        "69bc6eb4-07a9-401d-b3ff-fcdb41d716ee": "In what ways can AI assist in predicting the spread of cattle diseases?",
        "98fe575f-8bb3-4741-943c-5205a989f7b1": "What role do ML algorithms play in classifying different cattle diseases based on symptoms?",
        "f1c23dc2-2234-42cf-a67a-8a0889606d8d": "What is the significance of analyzing vast datasets in the context of cattle disease detection?",
        "bf3ad9c9-b64a-4e2c-8dd8-c2c6bf943c63": "How does the AI Maturity Model categorize companies in relation to their use of AI technologies?",
        "4e377d7f-bd74-4db3-80b1-0a3ff0b4b440": "What level of AI maturity do most companies currently fall into, according to the document?",
        "13eca91f-1457-4104-9c72-eac3c46c0826": "What are the potential benefits for cattle farm owners who embrace emerging AI technologies?",
        "403098a1-bfda-4360-80e4-33b5f6b583ec": "How can effective containment strategies be formulated using AI and machine learning?",
        "5ca5549d-b2cc-466f-b7e2-f2fbd8ff7dec": "What is the overall vision of Think Digital regarding the use of AI in cattle farming?",
        "8e949f80-11cd-4c50-a932-5cce502c4cc6": "What distinguishes companies at Level 1 from those at Level 2 in their approach to AI?",
        "9fa0e53d-fa89-4d6b-a8ec-a9913e942371": "At what level do companies begin to hire machine learning engineers and create data pipelines?",
        "215a6744-8504-42a3-a93d-18aedf76576e": "How do companies at Level 2 typically experiment with AI technologies?",
        "137b609e-2536-4295-b77e-20922c5fadd4": "What is a key characteristic of companies operating at Level 4 in terms of their AI applications?",
        "d026d46b-06d1-4808-8e82-1f8d90f4ea11": "What does it mean for a company to be at Level 5 in the context of AI utilization?",
        "410accbc-71e9-441e-9cf4-0df35475709b": "How do the AI strategies of Level 3 companies differ from those at Level 1?",
        "d60d8a8f-b638-4d3d-ae07-1afb31ef14fd": "What type of AI solutions are Level 2 companies likely to find insufficient for their unique business problems?",
        "b14c1b83-6f23-4067-be06-c7de8ae337bf": "What is the significance of custom models in the operations of companies at Level 4?",
        "acf55019-de39-4305-8c46-03046ba28f1d": "How does the value provided to customers change as companies progress from Level 1 to Level 5?",
        "7d822587-80e3-45fc-91c9-e2a8cedd2437": "What are the indicators that a company has moved from prototyping to operational use of AI?",
        "8719f682-d5f8-43c9-8c9b-6c07073cc125": "What distinguishes Level 4 companies from Level 1 companies in their use of machine learning?",
        "f693b61e-d27f-470d-8157-4dc5f9bbbf62": "How do Level 4 companies utilize machine learning to disrupt existing business processes?",
        "57190111-3957-4d61-aabd-bed690343209": "What is the primary characteristic of Level 5 companies in terms of their use of AI?",
        "98940bde-49d9-4394-b2a2-9b6317adcfb6": "Why is it stated that very few companies will reach Level 4 in AI maturity?",
        "40589171-7f97-4c80-9fbf-5a04feb5d3ac": "What must an organization commit to before increasing its AI maturity from Level 1?",
        "46952c14-aca2-4d3a-bdb1-540a3538a6f5": "How does the value provided by AI differ between Level 4 and Level 5 companies?",
        "6a1eef83-30d8-4c10-972f-21a9b9c4465f": "What types of models and processes are Level 4 companies expected to build?",
        "6c74a967-d83d-4055-b91c-33836ee2544d": "What is the significance of custom models in the context of Level 4 AI maturity?",
        "9ce6dd33-583c-48c1-b862-7470363d924b": "What level of AI maturity could most companies realistically achieve with investment and commitment?",
        "6641ca23-4e2e-4a67-bd0e-c261e45374f4": "In what ways can AI provide value to customers at Level 5 organizations?",
        "115b5ff0-8c32-4cc2-8999-5121167b9b16": "Why is it important for a company to align itself with machine learning as part of its core business rather than treating it as a separate feature?",
        "94ef122d-e7a7-4a86-8bcf-d5f3218be311": "What roles and expertise are necessary for building effective machine learning models according to the document?",
        "71635b99-612c-454d-ae04-e63e4a510897": "How does the complexity and sensitivity of data required for machine learning differ from existing production systems?",
        "95768618-782f-4857-8bd0-3c86ae48da37": "What are the key activities involved in data engineering for machine learning projects?",
        "8c8984f1-fe09-4a30-a907-b274d2e8c1ad": "Why is model training and evaluation considered a core activity in machine learning applications?",
        "cf21dc2f-7d4e-4094-95f8-0f15ce19ca35": "What types of hardware investments are necessary for effective model training and validation?",
        "9137ac31-5994-4f81-8257-d34f8910f912": "How should machine learning models be maintained after their initial training?",
        "a57142fb-949d-4ad0-863c-73ad9e12ff73": "What is the significance of continuous deployment in the context of machine learning products?",
        "266fb45d-979d-41f3-9195-4eae191cb4f3": "How do multi-disciplinary teams contribute to the success of machine learning initiatives?",
        "8843a731-248a-4a86-8715-4c34e5bfd12d": "What processes are essential for ensuring the successful integration and delivery of machine learning models into production environments?",
        "e987bffb-652c-41fa-b638-03a325cbd452": "What is the primary focus of model training and validation in machine learning applications?",
        "ee73687e-6781-415a-8192-14785c57489f": "Why is continuous deployment important for machine learning products?",
        "8063b733-1ce1-4816-a135-6ceafa861132": "What role do GPUs play in the model training process?",
        "5da8b13e-80aa-43de-aebf-77667ecfb24e": "How does a gold standard dataset contribute to the quality assurance of machine learning models?",
        "9199ec4c-4bec-4abe-bbe5-e2b18cd69aa9": "What is the purpose of model checkpointing in the training process?",
        "c3911101-90e4-4431-8377-0c24d78268dd": "Why is it necessary to maintain machine learning models over time?",
        "1612c074-7a13-4dd8-87a9-ffec252042b1": "What characteristics should a gold standard dataset possess for it to be effective?",
        "ea3a0533-1770-4f6a-ab71-dc0c7192be07": "How do data scientists and engineers collaborate in the model training process?",
        "3c5400a5-9f38-4f40-84cf-caae47225b45": "What is meant by \"frictionless mechanisms\" in the context of launching models into production?",
        "851cfaac-08a3-4c97-9b2a-021488404c4a": "How does the verification of data labels in a gold standard dataset impact model performance?",
        "8878b0ca-be25-430f-93c4-15cb6efa036e": "What are the key metrics that should be defined to monitor the performance of models in production?",
        "1c7ada10-2764-467c-a16b-c912b758b916": "How can customer feedback be utilized to assess the effectiveness of the model's predictions?",
        "53d2e073-98d3-4e4f-af71-5aefaac61a33": "What challenges might arise if a model trained on specific regional cattle data is used in a different region?",
        "cb80e657-bf0a-41e6-8722-a6f3229ff554": "What is the initial phase of model development referred to in the document, and what does it entail?",
        "98a43352-73ff-4967-a15d-f7712f0c73ff": "Why is it important to conduct feasibility studies before launching models into a production environment?",
        "a75c04f7-b6e1-4ff4-bbbb-f5637731e3cf": "What limitations have been identified in the model's ability to generalize over unseen data?",
        "07eed9b8-51c5-4c83-8d30-6a2405cc208b": "How does the document suggest Think Digital can progress from their current setup to a minimum viable product (MVP)?",
        "090c33bb-8c23-40cd-bd15-317a31780cd9": "What role does organizational knowledge play in the development of a complete AI platform according to the document?",
        "2c8d73d9-cad6-41ea-adb0-b5e956d40232": "What might indicate that the quality of a model's predictions is dropping over time?",
        "98b628d4-59f5-4398-8490-e2c4809fd2df": "How can monitoring customer behavior contribute to the ongoing improvement of AI models?",
        "0d906c68-2c27-44b0-bb99-3b06f10020b8": "What factors should be considered when determining the performance requirements for a model in production?",
        "b677fc86-2f80-4dea-8c28-f2caa30e6256": "How does the choice between real-time inference and batching requests impact model deployment?",
        "a46ab7a7-fba0-4bc2-82f0-13f430b7d274": "What are the key considerations for training hardware requirements when deploying a machine learning model?",
        "5a6286ee-525a-471f-87ac-bff7f24dd3e1": "How can the generalization of a model be assessed across different cattle farms and regions?",
        "832da1a3-1b60-448e-a168-abcf97805a54": "What is the significance of data labeling costs in the context of training and evaluating a machine learning model?",
        "35483409-15cd-4913-a756-a3a7962c026c": "How does the concept of \"gold standard\" data labeling differ from regular evaluation data in machine learning?",
        "1f333cbe-9531-471c-ba0f-17a47a064ddb": "Why is it important to have a fully automated end-to-end pipeline for training and deploying machine learning models?",
        "fdbeb963-107a-4a23-8196-47d9769f93d6": "What is a reasonable initial objective when starting to develop a classification model?",
        "087b78b1-72be-4365-a2f7-d547cb2e5254": "How can the total cost of ownership influence the decision between cloud and on-premises hosting for model training?",
        "97d6bfe3-2991-4bca-a24d-20a697e89d20": "In what ways can the quality of data labeling impact the performance of a machine learning model?",
        "39fb1fdb-c4b8-4ffd-8c96-d965389f9c36": "What is the primary focus of integration testing for machine learning models as described in the document?",
        "ab6edc73-d6e7-4ce9-a8c4-08106e29181d": "According to the document, what is the most significant factor contributing to gains in machine learning projects?",
        "2f9318fb-8ee0-4372-aa4f-9d14512bfa57": "What are the key steps outlined for ensuring a reliable training and deployment pipeline?",
        "6ab111ad-b43d-4009-9c11-4aaee888823b": "Why is it important to start with a reasonable objective when developing a machine learning model?",
        "eda3a1ca-ff49-4ffc-b25d-927cbf736863": "How should common-sense data and labels be added to the model training process?",
        "93ca92bb-ced6-4090-a4fc-a1d62b575a25": "What measures should be taken to ensure the reliability of the machine learning pipeline?",
        "cdd4f520-05a2-4e2b-8ed2-854fd1194e3e": "What role do veterinary experts play in the quality of data and labels for disease classification?",
        "20a5234a-c43c-4311-bf17-80e780a4893b": "How can the use of established models like Efficient Net benefit initial machine learning projects?",
        "9a7a8957-10e3-49a3-b4df-bf757c163f54": "What is the significance of precision and recall in the context of adding new classes and regions to the model?",
        "0e521319-8694-4a2b-9d54-a66b892c83ac": "Why is thorough testing before rollout considered crucial in the machine learning pipeline?",
        "5c970110-e1d0-4e6f-953c-adaff361aa98": "What are the three classes identified in the initial use case for machine learning at Think Digital?",
        "8faa885f-4180-48e5-aef9-aaa48a4eab41": "Why is it important to start with a simple use case in the development of machine learning models?",
        "520b007f-b46b-4555-9ac3-02437dbe6999": "What are the key transformations that Think Digital needs to undertake in its first year?",
        "32352e0a-8833-4216-ac20-b4cd9ad397aa": "How does organisational alignment contribute to achieving machine learning goals at Think Digital?",
        "d5936a06-0467-4388-a999-c41ecf7309cc": "What role does governance play in the management of machine learning projects?",
        "bb64e96b-a915-418f-86eb-4b725968698b": "Who should be responsible for building, maintaining, and monitoring machine learning models at Think Digital?",
        "3c87f087-40e5-404d-b315-0eb5f4c5ecb8": "What is the purpose of establishing a machine learning steering committee?",
        "3b48fb75-ef22-4b35-bec1-b0c13fce7c4b": "Who should be included in the machine learning steering committee at Think Digital?",
        "1154b7f2-0cf4-4470-bcc0-f05a4da2dc1f": "What are the key concerns for the governance of machine learning projects mentioned in the document?",
        "491372a9-b2b0-497f-839b-21596170ee3d": "How can Think Digital ensure compliance with privacy and data protection legislation in its machine learning initiatives?",
        "ff8bc7ac-7d1f-4865-9e7a-e740cc5363eb": "What are the primary responsibilities of a Chief Data Officer (CDO) in relation to machine learning culture?",
        "df417cc5-735e-4349-a23b-bede7f426b63": "How can a CDO identify opportunities for leveraging the company's data holdings for machine learning?",
        "3ab71da5-e1a6-41e4-8312-957e4307830e": "What types of external partnerships are essential for addressing current data limitations in the context provided?",
        "3fffc918-343b-4440-aa2c-27be55b96093": "What infrastructure considerations are necessary for supporting machine learning initiatives according to the document?",
        "e142641f-3b9b-40fc-baba-ab7f1de239de": "What are the key components of a local development and local model rollout setup for machine learning?",
        "b2182f46-7f9a-4e6c-99bb-381e53501a78": "How does the document suggest handling model rollout using CI/CD agents?",
        "3e895da7-aece-4144-83b4-d235bb5b883f": "What are the advantages of using cloud infrastructure for training and inference in machine learning?",
        "916c98e7-ad14-47ac-9bdd-c402a71150dd": "What types of workstations are mentioned for local model development, and what are their approximate costs?",
        "a072dc53-e437-454a-beec-6033cbde1814": "In the context of cloud training, what is the significance of storing training data in the cloud?",
        "3f2f9a07-b1c5-4304-b1ea-2ac73cfedb2b": "What are the potential performance requirements that need to be considered when provisioning infrastructure for machine learning?",
        "213a9eb6-111d-4e11-ba28-797348d6438f": "What is the primary storage solution for training data in the local development setup?",
        "07ac3d26-8943-4cae-8a77-3c3b19e53514": "How much does a typical local deep learning workstation cost in the provided context?",
        "c86e0d13-d5fa-4243-ac7b-89992750db91": "What type of workstation is used for model rollout in the CI/CD process?",
        "f4767c8d-6a38-498a-84a1-4ccac23a3aec": "What is the purpose of using a larger lab workstation for model rollout?",
        "a5826f46-cd52-4cce-919a-4e48c2d338cd": "How does the organization utilize cloud resources for inference?",
        "d043400c-4b2e-401b-8095-797552adca10": "What are the two options for cloud-based inference mentioned in the context?",
        "3f7ebf54-a4f8-496a-a6f7-b651936ea394": "What is the cost of a lambda labs workstation used for model rollout?",
        "9fdda640-b941-4f84-a90d-74ddda41d0ab": "In a cloud-savvy organization, what is the benefit of spinning up training nodes?",
        "55f76b95-e508-4a9a-8a85-41e3cd7f7156": "What is the cost of local deep learning workstations in the cloud-savvy scenario?",
        "f23cb140-903a-44f8-bf20-fee32d70bf26": "How does the CI/CD agent facilitate model training in the cloud?",
        "b328b745-a2e1-4ade-9975-8bb2decf667e": "What are the key cloud platforms mentioned for AI model development and inference in the document?",
        "dfeaca4e-a891-4160-8bbb-65794be3d018": "How does the document suggest validating organizational processes and infrastructure for machine learning systems?",
        "c505fc92-7a53-4252-a948-87aee7b26cd5": "What specific challenges related to building and deploying machine learning systems are highlighted in the document?",
        "7897be73-ada0-4f01-b46e-f6e958451de0": "What aspects of training infrastructure should be assessed according to the document?",
        "d5804a0b-3a8e-432d-8527-14255dc81b94": "How does the document propose measuring the usefulness of the machine learning model to customers?",
        "0158ebff-cc19-4ad6-948c-8db3b1b3358c": "What considerations are mentioned regarding the staffing needs for developing computer vision techniques?",
        "1be747ec-8da9-4e70-8122-9020f3655b2e": "What factors should be evaluated to ensure the production infrastructure can meet prediction requirements?",
        "f087f0d3-72f7-45a4-9a19-f4bacb31e5b2": "How does the document describe the importance of a steering committee in the context of machine learning model deployment?",
        "38f18a2d-e7e9-4b76-afdc-7b946265380e": "What is the significance of running a subset of data through the model locally during the testing phase?",
        "77761402-5b9f-4ae6-9049-15f59d6dadbb": "What are the implications of having a frictionless deployment process for machine learning models?",
        "8f590244-5633-459e-85ae-bafefda116ac": "How can we assess whether our training infrastructure can accommodate the volume of satellite imagery we have collected?",
        "a11b2bcb-1c6d-470c-a615-05386dbe927e": "What metrics should we use to evaluate if our production infrastructure can meet the required prediction cadence?",
        "23bec182-cb85-4e58-a151-85cd9a281ae3": "Do we have the necessary in-house expertise to effectively develop and troubleshoot our computer vision techniques?",
        "c9cd09f3-e2cd-474d-b7af-39c1657a03c5": "What steps can we take to ensure that the deployment of our model is seamless and efficient?",
        "a4c7ad53-a551-4e2e-9520-b9619535a72d": "How can we measure the accuracy and performance of our model once it is in production?",
        "ec79734a-d0f9-426a-aa41-7b8393f106cd": "What criteria should we use to determine if the model is providing tangible value to our customers?",
        "6d14b842-7104-489c-a49e-bbcb9df1377b": "Does our steering committee possess the expertise needed to support the development and deployment of the model?",
        "1934cc08-fe3a-4d0b-95f6-2c33bd279084": "How are we ensuring compliance with privacy laws in relation to the data we collect and use?",
        "17d6d808-d31a-44b3-b248-a7ace5dabd8a": "What processes do we have in place to allow users to access and delete their stored information?",
        "eeac5187-1101-4874-bd43-ca2f04434316": "How are we informing customers about the data collection and usage practices before obtaining their consent?",
        "8799af57-3e50-4081-915c-9ac84c4a1c94": "What AI maturity level is Think Digital expected to reach in the first year of adopting the roadmap?",
        "b1236e6a-5e22-471d-b7c5-b995832737ef": "What types of applications is Think Digital's engineering team expected to develop during this period?",
        "733de9fb-236a-4904-a3bc-30b13cd55c30": "How will Think Digital's engineering team experiment with AI technologies?",
        "82ceb96f-f224-4df7-830d-ede76b800592": "What kind of datasets will be used in the demonstrator-level applications?",
        "97f3bc2a-1254-4a77-8b17-ac40e09aba1a": "What approach will Think Digital take to learn about AI possibilities?",
        "957a6d50-03c1-46a1-ab91-d01bb2a1648d": "What happens if a pilot study shows promise in Think Digital's AI initiatives?",
        "634af046-ac90-4d10-9531-db8586afcf27": "How might successful pilot studies be integrated into Think Digital's platform?",
        "b50bad86-754f-49ed-be8b-f74fd7f3acc5": "What is the significance of developing prototypes in Think Digital's AI maturity advancement?",
        "09d91749-ffbf-4bf2-b136-e7027448bdb7": "Who may have access to the beta or hidden tools developed by Think Digital?",
        "5ff058e6-900f-45d7-a090-ef273e397f39": "What is the expected outcome of applying a hands-on approach to AI at Think Digital?",
        "da6c366a-f264-4853-9174-a8d152164749": "What is the primary goal of Think Digital in the next three years regarding AI and machine learning?",
        "c4d4d471-8064-4bbc-964e-9513afb5ef2d": "What specific pilot study is mentioned in the context, and what is its focus?",
        "a37407c6-9b8d-48a2-a8d2-f78fc096ab98": "What are the key tasks that Think Digital needs to accomplish to operationalize their AI model?",
        "3759fef7-c249-4c5a-bf11-7037391087ff": "What level of AI maturity is Think Digital aiming to achieve with their AI initiatives?",
        "5cf94c08-1c2e-4194-bac2-d07bc3b8b2d2": "How does Think Digital plan to measure the impact of the deployed AI model on customer engagement?",
        "2524c742-8962-4ec5-8fdf-c025ff16ad2a": "What challenges are identified in the context regarding the pilot study code that needs to be addressed?",
        "a1ccdc82-dfa7-4a5d-bb8d-9642b23006cd": "What steps should Think Digital take after successfully deploying their first AI model?",
        "0039ce0c-ef5e-4792-a2c0-476baf48723d": "How will additional pilot studies contribute to the development of the AI Platform?",
        "a74318c8-42b5-4556-99cc-eb9708a7c633": "What is the significance of monitoring the AI model's impact after deployment?",
        "c53bfaa8-9da1-4ab1-bb2d-2e1d94916b7a": "What might be required as pilot studies mature and are integrated into the AI Platform?",
        "c35aea2b-b918-4361-815e-523640c5cb6c": "What is the primary goal of the additional pilot studies mentioned in the document?",
        "3e726180-04fe-407b-8392-3c8e55ebad25": "How should the outcomes of the pilot studies be integrated into the existing AI Platform?",
        "f343d49b-34ef-4f26-acd7-56b8da7b33c5": "What challenges might arise when folding the first few pilots into the AI Platform?",
        "d27ef022-0ccc-4bcd-8df9-8deed985454f": "Why is ongoing organizational realignment important for Think Digital's AI maturity?",
        "103434b1-97d6-47a8-a5f6-07342abe6755": "What processes need to be developed for effective data management in the context of AI implementation?",
        "ba793b4e-2549-49a5-bb33-870e32b76bc6": "What changes are suggested for the workforce within the company to support AI integration?",
        "2f8c40a2-abf7-4b42-9f19-dcb53cd08674": "What roles are recommended to be considered for the machine learning engineering team?",
        "8380f09f-bcee-442a-afa7-46177d014369": "How does the document suggest the organization should respond to bugs and new data versions after deploying the first model?",
        "49b3274d-3bbb-4a22-ae2e-7c09e0956ad6": "What is the significance of automated data collection, labeling, and quality control in the AI development process?",
        "b966899b-893c-407b-83ed-fffc631c4553": "What is the expected outcome as the pilot studies mature into demonstrable capabilities?",
        "705005f8-c859-4727-add6-4f796fb2b63a": "What is the primary focus of the user-facing application at Think Digital in the proposed structure?",
        "57d85b38-90ed-49da-9f79-ed5873267c47": "How will customer data be captured in the AI processes at Think Digital?",
        "fb7482d8-e44c-4807-a30c-700f03e560aa": "What type of data is mentioned as an example of customer data in the document?",
        "a8421188-09ee-4e6f-9934-142527ffa4a6": "In what time frame is the proposed layout of tasks, data, and people expected to be implemented at Think Digital?",
        "1c7c683b-e4a6-4d87-a850-107ebe313bcd": "What role does manual annotation play in the data capture process described?",
        "f65de762-c7c1-4483-8f2e-8779d7a62471": "How does the proposed structure aim to enhance the AI processes at Think Digital?",
        "a669a841-7163-4431-9afb-f357c2c6450b": "What might be the significance of labeling in the context of the user-facing application?",
        "767647d7-8b92-4d49-8f06-394da4376c48": "Who are the potential users of the application mentioned in the document?",
        "3df7f878-d0c2-4642-8554-a7eb499a572e": "What implications could the proposed structure have for customer interaction at Think Digital?",
        "ac12b4d4-9372-4dc0-9ee1-c2961f8344bb": "How might the layout of tasks and data evolve over the next three years according to the document?",
        "14406418-5e3e-43b2-bdfe-fccbbcb00ad1": "What types of data will be collected to improve AI models for cattle disease identification?",
        "46ae7457-1b27-408a-80f1-8b8d5c7b8007": "Why is it important to gather diverse data on symptom variations in cattle?",
        "cf2ce19d-d248-46b7-aad3-732b10c46436": "How do environmental conditions impact the data collection process for cattle disease identification?",
        "7266b78a-d51d-4b23-afcf-278d88e6f49c": "What role do data engineers play in transforming raw data into usable datasets?",
        "d7c85143-4745-4972-aade-0fbe25af3562": "How do machine learning engineers collaborate with data scientists in the model development process?",
        "4453c603-ad5e-4a6f-8047-7bb91a1de59e": "What is the purpose of feeding data back to data engineers during the machine learning process?",
        "948b9224-ade2-4cd2-b23b-bae20ab1110f": "Why is it necessary to document diseases on various body parts of cattle?",
        "bf5bbff6-3be8-49b7-bcc8-8ba87d0a62d1": "What specific environmental factors should be considered when collecting data for AI models?",
        "a5a4db33-48f5-439c-a9b1-3534b1dce410": "How does the collection of data across different seasons contribute to the effectiveness of the AI models?",
        "95e2bc15-da51-4b0e-813d-64fd087ca5a8": "In what ways can the collected data be utilized for analytics and machine learning?",
        "0b478b73-6dc8-4996-bc5a-c7c00480fb1c": "Why is it important to gather data on symptom variations in cattle from different regions like Indonesia and Northern Australia?",
        "31fc4dda-af03-4ef0-85d8-2a6b3f8dff67": "What types of environmental conditions should be considered when collecting data on cattle diseases?",
        "e109b4b8-0a7c-44a1-a1f2-240301d27627": "How can macro photography enhance the accuracy of disease identification in cattle?",
        "3a86fb5a-6e28-4d86-80ff-22190e1df88a": "What role does the inclusion of images from multiple cattle breeds play in the data collection process?",
        "733ad948-9a20-492d-a20f-0147a8d9c976": "Why is it essential to document diseases on various body parts of cattle?",
        "b7a54960-cfec-4e3f-a819-e972714d0bc5": "How might different lighting conditions affect the data collection for cattle disease symptoms?",
        "567b9e9c-41c6-4c95-842c-6f72dba76490": "In what ways can seasonal variations impact the data collected on cattle diseases?",
        "b738e10a-0664-4063-a8b3-a11eee9745d7": "Why is it important to include a range of cattle ages and genders in the data collection?",
        "5d5f75c6-1c19-4c4d-8352-4823cb116898": "How can comparative analysis between images of healthy and diseased cattle improve disease identification?",
        "6da4870b-96c0-48bb-b810-6daa87deab69": "What strategies can Think Digital implement to ensure its AI models are adaptable to changing disease presentations?",
        "aa25506b-9f1a-46d0-8852-c8640af39fad": "What is the target AI maturity level that Think Digital aims to achieve within three years?",
        "e38797f9-0780-4ec2-a9f6-c632685f241f": "What is a key requirement for Think Digital to reach maturity level 3 in their AI advancement?",
        "1270291d-fb52-4129-8a9d-14199320422e": "How should machine learning be integrated into Think Digital's customer-facing business aspects?",
        "875b12f4-7a56-4790-9ac6-925a6e44fbc1": "What practices should be common for Think Digital regarding model monitoring and data versioning?",
        "a87607e8-af71-40b4-96f9-0e525e656ee0": "What should be the impact of machine learning models on the existing platform's performance and functionality?",
        "7957918d-e98b-463c-b8b7-6a3c89eff592": "Can you provide an example of how customers might derive value from a machine learning feature in Think Digital's offerings?",
        "a77b3c98-7f9f-4ac4-a159-025ece9182ec": "What type of funding should Think Digital focus on during this phase of AI maturity advancement?",
        "c1e4d188-466f-4937-9dbb-363c9cd4ded2": "What is the significance of having operational application features that leverage machine learning?",
        "1eb6c2d7-b94e-42a8-b9af-f939853ddb1b": "How important is access to machine learning expertise for Think Digital's development of new models?",
        "5e3a47d5-9f67-4d47-917e-0c829061fde1": "What role do mature data pipelines play in Think Digital's AI maturity advancement?",
        "8f4d1f09-f1f6-447d-981c-54a308947a34": "What were the three classes that the custom model developed by the AIML Research team classified images into?",
        "17547cd3-30de-4a13-98cc-d21cac2f720b": "What issue was identified with the model's accuracy when tested with previously unseen images?",
        "0d944071-33f5-4a84-89b8-e557d0365de9": "Who led the AIML Research team during the initial phase of the project?",
        "f468a687-bf30-4588-9b92-af9efd845f93": "What steps did the AIML Engineering team take after the project handover from the research team?",
        "eee41968-1e05-418a-b0ab-fb55d08cca50": "How many images were included in the small training dataset used for the model?",
        "630de532-f03e-4604-bf62-430d9211766a": "What support did the AIML Engineering team add to facilitate the setup of the development environment?",
        "d5ed6de3-b48a-40bf-8c97-1269e463d002": "What technology was used for deploying the Docker images onto cloud infrastructure?",
        "a2c80258-43e2-4ebd-8935-e84535619c98": "What purpose did the Docker Compose support serve in the project?",
        "4eb7fa56-cb2f-4524-8b2b-d58168a73a51": "How did the AIML Engineering team ensure the project documentation was more user-friendly for Think Digital?",
        "f87227c0-94dc-43d7-9bdf-234466f4914b": "What were the three types of Docker images set up by the AIML Engineering team?",
        "83f99077-bf3b-4649-955b-dad4f7dfccb0": "What is the recommended minimum scale of images needed to train a robust classification model for cattle diseases like FMD and LSD?",
        "fef23ab4-b05e-4ef0-a491-4c51e117f626": "Why is it important to capture images of cattle in various environmental conditions during data collection?",
        "277a78d3-0e36-4769-826c-403303a65936": "What specific characteristics should annotators focus on when labeling images for Lumpy Skin Disease (LSD)?",
        "96270adc-645b-4022-9732-eec60efb84bb": "How should the progression of nodules in LSD be documented during the annotation process?",
        "6d5d184b-81a4-42fa-af50-3007bc97f9e4": "What are the key lesion locations that need to be annotated for Foot and Mouth Disease (FMD)?",
        "1a3baa7f-f8d2-45c3-8028-3ab6c30c528b": "What secondary symptoms and behavioral changes should be recorded when annotating images for FMD?",
        "4302263d-0c50-47d0-b5f9-38963a432f2e": "Why is collaboration with veterinary experts important in the data annotation process for cattle diseases?",
        "22ade6b1-93e8-4027-adf3-6c0a4b86ccc3": "What types of cattle conditions should be represented in the dataset for effective model training?",
        "9c942fd9-2dd9-46bc-b424-f98523dd3f9d": "How should the data labeling process be organized in relation to data collection?",
        "da653ff8-d3a7-4e8a-8f48-c760c266e48b": "What specific features of nodules should be noted in the annotation guidelines for LSD?",
        "7fc5d684-5961-419b-aae1-e4b2515ac839": "What are the two diseases mentioned in the context that can lead to false positives in healthy cows?",
        "4ef3151c-647a-4243-86f8-6934f1cb4303": "How does the current model incorrectly identify healthy cows?",
        "ff9f394c-2dac-416f-9af4-93913057f344": "What does \"LS D\" stand for in the context of the document?",
        "ce5832b5-0cfa-4810-8ec4-d95dc227705b": "What is the significance of the examples provided in Figure 2?",
        "e324fdd5-fc57-4d16-8b75-a16d73726cae": "What implications do false positives have for the health management of cows?",
        "fd9e57ce-d7b3-47b1-ad7d-27761722dc84": "How might the identification of healthy cows as diseased affect livestock operations?",
        "8f2d4d42-f0a7-4c1b-8c8b-a22291ac4f4e": "What could be potential reasons for the model's inaccuracies in identifying diseases?",
        "cbd6a2ef-cb21-4f1d-83f3-f2918873b2fd": "In what ways could the current model be improved to reduce false positives?",
        "20c11819-aa1a-4e37-b7cb-8d8ac1e55f52": "What is the visual representation used in the document to illustrate the problem with the current model?",
        "5a04b49f-3cb1-428a-b490-54ac456aa8e8": "Why is it important to accurately identify diseases in livestock?",
        "41d37a09-2d2b-47b8-8fe2-4582cc0b8aed": "What does LSD stand for in the context of the figure provided?",
        "e5da4b6f-5a26-4cdd-a93d-ce4bbedd50a0": "How is a healthy cow misidentified in the examples shown in Figure 3?",
        "f990e418-5c2d-4a4a-95de-ef3742f803a0": "What is the significance of false positives in disease identification for livestock?",
        "08f580ea-cdf3-4730-8a4d-6b847c941699": "In the examples, what disease is incorrectly predicted as LSD on the right side of Figure 3?",
        "542e0f43-871f-43e0-a052-62866b29c449": "What implications might arise from a healthy cow being identified as having LSD?",
        "b14b98e4-eeb6-4f2e-ba08-51b8f9ea91bd": "How can false positives affect the management of livestock diseases?",
        "c8622f0a-2281-49ee-a1c2-b0d83918d443": "What visual evidence is presented in Figure 3 to illustrate the issue of false positives?",
        "fec2feaa-def0-4e24-a695-7cf64449942a": "Why is it important to differentiate between LSD and other diseases like FMD in livestock?",
        "cf0e9c45-9c05-4d2f-9e72-167a783a2bd4": "What might be the consequences of misidentifying FMD as LSD in cattle?",
        "fc1e352f-c215-4778-b23f-b5771e787c61": "How can the accuracy of disease identification be improved to reduce false positives?",
        "f465a11b-ccbb-4662-8d57-b8143091f473": "What does LSD stand for in the context of the cow identification mentioned in Figure 4?",
        "8711dcb2-4723-4142-82cc-c0035803faa9": "How is a cow identified as having LSD in the examples provided?",
        "4d6ac606-e941-4b34-9dd6-e356ddf28f85": "What is the significance of the cow being incorrectly identified as healthy in the context of LSD?",
        "0003510f-268d-4fac-90ba-9ad910f500bb": "What are the potential consequences of false positives in cow health identification?",
        "5def7186-405f-4148-8898-f3157994796d": "In the examples shown, what visual characteristics might lead to a cow being misidentified?",
        "427be915-dcd0-47db-b152-77a6d934741d": "How does the identification process differentiate between healthy cows and those with LSD?",
        "593a99c3-beff-4268-8c2d-0e1c3a5bae68": "What implications do false positives have for livestock management and disease control?",
        "bd3b502f-8a12-4f0e-95c3-f4a3022c8019": "Are there any specific indicators that could help reduce false positives in cow health assessments?",
        "efcfa463-7465-4524-b104-55c9eaa2af63": "What role does accurate identification play in the overall health of cattle populations?",
        "5ade2395-25e1-4f14-9f2b-a7ac5f67e4ec": "How might the examples in Figure 4 inform future practices in animal health monitoring?",
        "39fc00bb-ce42-40cc-9454-3a34b542c5cc": "What are the key themes highlighted in the City of Adelaide's Strategic Plan for 2024-2028?",
        "983cd2ea-2cc0-430b-951f-d37e1ffb644a": "How does the Strategic Plan aim to reflect the boldness of Adelaide?",
        "a8e77cc5-6f6c-4b5a-8a4a-ca7f137ed61d": "In what ways does the Strategic Plan promote innovation within the city?",
        "47044ad4-ef23-4a39-8a5f-1efbd1fffc3b": "What aspirations does the City of Adelaide have for its future as outlined in the Strategic Plan?",
        "8ad4c9c4-e88c-42d9-ac57-a4d8067302ce": "How does the Strategic Plan for 2024-2028 align with the city's identity as \"Adelaide\"?",
        "b9beaed1-2b93-47a9-9d6c-f1ed36394ff3": "What specific initiatives might be included in the Strategic Plan to foster a sense of community in Adelaide?",
        "3214fe78-7364-4d0d-8b60-9ef5076185d1": "How does the Strategic Plan address the challenges faced by the city in the coming years?",
        "888a7b97-ae6f-4a8e-8041-4b60e148e1b9": "What role do stakeholders play in the implementation of the Strategic Plan?",
        "f806f851-531b-4963-b10f-ae3938f13b09": "How will the success of the Strategic Plan be measured over its duration?",
        "a7ff8764-76fb-465e-9eb1-f10e1ae65cdf": "What are the anticipated outcomes of the Strategic Plan for the residents of Adelaide?",
        "75956fbf-dd21-4986-8dbc-3fd313b28cd9": "What are the key aspirations outlined for the community in Adelaide over the next ten years?",
        "db006c33-63d0-4623-b651-8e325c680281": "How does Adelaide plan to enhance its environmental resilience and sustainability by 2034?",
        "ac05aee7-654b-41a7-9a8d-1e8c3206569e": "In what ways does the strategic plan aim to grow and innovate Adelaide's economy?",
        "654127c4-e65e-49db-8577-01c2ff2d285d": "What characteristics define the vision for Adelaide's neighborhoods and public spaces in the next decade?",
        "a0e35414-64c5-47f7-aab1-414c964ec767": "How does the Corporation of Adelaide intend to position itself as a trusted employer and partner by 2034?",
        "71b9cec2-90da-473d-987a-d92451eebd95": "What role does cultural celebration play in the vision for Adelaide's community development?",
        "fcc20327-eced-4bf2-bfbb-51bbf9d055d0": "How will Adelaide's green infrastructure contribute to its identity as a leading Green City?",
        "dbb38ef9-0991-4349-8dba-c7630a1e50aa": "What strategies are proposed to attract investment and talent to Adelaide's economy?",
        "b469ac5a-d6ca-48ec-94c5-ab8ce9f90cbb": "In what ways does the strategic plan emphasize the importance of inclusivity within the community?",
        "1c5556d1-9d2a-45cd-b26e-b00e3e134695": "How does the vision for Adelaide reflect its historical and cultural identity in public space design?",
        "897db248-564e-4533-ab77-67431161fc20": "What is the significance of the Kaurna people's relationship with the land as acknowledged by the City of Adelaide?",
        "89969883-054b-44e4-bbac-dc237d0ffeec": "How does the City of Adelaide express respect for the cultural heritage of the Kaurna people?",
        "b21904a4-f0e6-4801-9de8-5a5ffb6080b5": "What are the key components outlined in the Strategic Plan 2024-2028 for the City of Adelaide?",
        "2783d24d-3cec-4309-a490-11ae547a54eb": "In what ways does the City of Adelaide extend respect to other Aboriginal Language Groups and First Nations?",
        "1bedfab6-a34c-4b6a-9380-198072f79a31": "What role does the Lord Mayor play in the context of the City of Adelaide's Strategic Plan?",
        "dde9fc20-c646-413a-adae-e2af55b7de4a": "How does the document address the importance of the Kaurna Elders in the community?",
        "036243db-a9be-41ca-ba5c-ca1a582cebe2": "What are the main aspirations mentioned in the Strategic Plan for the City of Adelaide?",
        "ae5a17fa-84fc-496b-b83d-91e3d8fb3a91": "How does the City of Adelaide plan to engage with its community according to the document?",
        "3975347a-a952-44b7-ae93-d89fee8e361c": "What environmental considerations are included in the Strategic Plan for the City of Adelaide?",
        "743eda07-0c4b-49ac-aa84-6fb22f778a36": "What is the purpose of the Resource Plan 2024-2028 as mentioned in the document?",
        "a9f87895-86f9-474e-bed6-4cd45e1734b5": "What is the primary focus of the City of Adelaide\u2019s Strategic Plan for 2024\u20132028?",
        "86dd62f1-6919-471c-85a1-37c921a718f9": "How does the Council plan to improve the economic viability for businesses in Adelaide?",
        "b77d6b67-d69f-41c0-93f7-7a34fa22a459": "What specific goal does the Strategic Plan set for the population of Adelaide by 2036?",
        "6610530a-38b3-4110-839e-bfed2964dc3e": "In what ways does the Strategic Plan aim to address functional homelessness in the city?",
        "3a47550c-f127-46b0-ac4c-b9ccdc95c897": "Who are the key stakeholders mentioned in the Strategic Plan consultation process?",
        "da43105c-372f-4a8a-86e8-5fbe73289f03": "What are the core responsibilities of the council referred to as \"roads, rates, and rubbish\"?",
        "8b2a40fe-b653-4352-bd12-efe49596c6b1": "How does the Strategic Plan propose to enhance residential access and affordability?",
        "3db8e131-8420-4186-b0da-0d4386ba756d": "What role does community feedback play in shaping the Strategic Plan?",
        "43784e77-a294-4eab-b3e5-258ef022c235": "What aspirations does the Council have for the streetscapes of Adelaide?",
        "166bafb7-e6ba-4653-b91d-09cf302e6302": "How does the Strategic Plan aim to provide certainty for business owners and potential investors?",
        "b54729b1-1770-4a39-972a-422dad0146b1": "What are the main goals of the Strategic Plan for the City of Adelaide from 2024 to 2028?",
        "ef511133-13a5-4b00-b84d-7093b1f72c82": "How does the Strategic Plan aim to improve economic viability for businesses in Adelaide?",
        "3c32be99-788a-4718-9c9f-f6ccaf63bfbf": "What specific target population size does the Strategic Plan set for Adelaide by 2036?",
        "1f6e3fb1-1edc-4443-9efd-7bb10211d1f5": "In what ways does the Strategic Plan propose to address functional homelessness?",
        "ecb97f3f-6507-470f-9b51-44a58e8ce392": "How does the Strategic Plan intend to enhance residential access and affordability?",
        "c3bed7d1-2631-49b5-97bd-22e46380d709": "What role do community feedback and consultation play in the development of the Strategic Plan?",
        "81b7572d-6419-413b-b012-be85cf83f609": "What commitments does the Strategic Plan make to ensure certainty for business owners and investors?",
        "9d0bcd27-1bda-42c5-9550-3e226015d70f": "How does the Strategic Plan plan to reduce kerbside waste in the City of Adelaide?",
        "6d56d411-41d7-41e5-bb60-2105c6c85d0c": "What is the significance of maintaining assets as outlined in the Strategic Plan?",
        "e0a3b65b-d53b-4daf-963a-d2deef5b67ea": "Who is the author of the Strategic Plan, and what is their title?",
        "53cfef01-e5ff-4d94-8938-a2f796e17a17": "What are the key challenges currently facing the city and community as outlined in the Plan?",
        "20aa0dd0-89e3-474a-b90e-d0bc216a5122": "How is the projected population growth expected to impact housing needs in the city?",
        "383b219e-0256-4be0-b7ce-ddd067ab3e00": "In what ways does the Plan propose to enhance social connectivity within the city?",
        "74fcc892-b1ed-487b-8479-ae402950585a": "What strategies are mentioned for addressing climate change and promoting climate resilience?",
        "15620429-2b63-4291-ac41-c2e66b770df6": "How does the Plan envision the future layout of the city in terms of neighborhoods and precincts?",
        "0ad7236d-36f0-4251-9000-65bcb6b42468": "What role does the revitalization of streets and precincts play in the city's development strategy?",
        "4a94667f-524e-417d-a65d-f80a70f6a9b7": "How are economic uncertainties influencing the city's approach to procurement and workforce development?",
        "70b00c79-da0c-4a55-abd3-8f4588cf926c": "What initiatives are suggested to support a circular economy and low-carbon city?",
        "4b62324d-1d54-4fbb-b9d0-459552b12832": "How does the Plan address the importance of health, wellbeing, equity, and inclusion for the changing population?",
        "37c45db0-f9d0-4719-8a92-231b70de2310": "What emerging trends in work and technology are highlighted as significant for the city's future economy?",
        "b0317dad-2f91-43e8-a269-c90b76fd42d2": "What strategies are proposed to protect residents and visitors from hazards like heatwaves in Adelaide?",
        "432a531b-27cf-4af7-bdc6-c37bbb365ab6": "How does the City of Adelaide plan to support a circular economy and low-carbon city initiatives?",
        "1e5afa63-a390-40ac-9795-73b47155075b": "What economic challenges are mentioned that have arisen from the COVID-19 pandemic?",
        "da84d1bf-bf78-4e3b-8317-0f7b408b17e6": "In what ways does the Strategic Plan suggest the City of Adelaide will adapt to emerging industries and digital transformation?",
        "d730fffc-a5d7-4b98-8dc6-d5e3b19edb7e": "How does the City of Adelaide intend to foster an inclusive and equitable economy?",
        "71c113b6-880a-4b9b-858c-7f4541225d22": "What historical significance does Colonel Light's planning of Adelaide hold in relation to its current urban layout?",
        "345dd26e-8c8b-4421-9dc0-67b6348a6422": "How many residents does the City of Adelaide serve, and what is its role in the broader South Australian community?",
        "e1d9dea6-5ba4-41e9-81fb-123eb51f8272": "What is the significance of the Park Lands in Adelaide, as described in the document?",
        "654439d8-a3ed-4232-a032-442f012e3499": "How does the document suggest that partnerships with private enterprises and government levels will be approached?",
        "2fb945b6-7e7c-41e8-a65d-1d3646cff911": "What is the overarching vision for the City of Adelaide as outlined in the Strategic Plan?",
        "cc27ef75-d350-4fd9-8c89-2f6c2802fbfd": "What is the population of the City of Adelaide, and how does it relate to the broader South Australian population?",
        "86e50372-392a-4878-855d-0959dfa08d96": "Who were the traditional custodians of the land on which Adelaide is built?",
        "69567d7a-f68a-4f89-8fca-ecb9b2569bdc": "In what year was Adelaide planned, and who was responsible for its design?",
        "d01bcc39-f373-413c-878a-1942b3b55e9b": "What are the key features of Colonel Light's original plan for Adelaide?",
        "cb62db43-e061-46a3-88ed-48bb457f346d": "How many parks and squares are included in the Park Lands of Adelaide?",
        "61a4d76a-8dac-4658-a0ca-8faeca610f77": "What is the significance of the Park Lands in relation to the city\u2019s heritage?",
        "d82e1efe-30f1-4012-95b7-030c9e9d316f": "What are some of the notable commercial and social spaces mentioned in the document?",
        "86a4ce35-b09d-41d2-ba1d-701430e95b27": "How does the City of Adelaide aim to balance its cultural heritage with contemporary design?",
        "27e78579-4991-4b71-bb37-094130ecfd41": "What is the Gross Regional Product of the City of Adelaide?",
        "d21a3b8c-a358-43c7-a901-363f32e90ec8": "How does the City of Adelaide describe its spirit in the face of global challenges?",
        "d183e29e-0fc2-475e-af1a-a922864905c4": "What percentage of the City of Adelaide's Gross State Product does the Gross Regional Product represent?",
        "9d859641-4be2-4fa5-9c75-e04f1084eb4f": "How many parks and squares are included in Adelaide's Park Lands?",
        "cd129655-2398-4720-9a3e-f9a2ca5ba30a": "What is the total land area of the City of Adelaide?",
        "af21a7c5-2a8c-4860-97e5-3be60ee0a7b8": "What proportion of Adelaide's residents are aged between 18 and 34?",
        "522bdd6f-298b-424b-95fd-69cf1fe7e2a9": "How many local businesses are reported in the City of Adelaide?",
        "d2ea477c-7b4c-4eaf-adfc-5d581451ecd9": "What percentage of Adelaide's population was born overseas?",
        "5a2062da-dac1-4cd2-84f2-aeac09ced6c6": "How many private dwellings are there in the City of Adelaide?",
        "f2b6ed29-665c-4a44-9284-6af1d920a1e8": "What is the total number of jobs available in the City of Adelaide?",
        "dabaa2fd-abcd-4a7f-a00a-5f6fac6d50e2": "What percentage of residents in Adelaide are renting their homes?",
        "87236c71-7417-4183-b987-218a13fbae2e": "How many residents in Adelaide study at TAFE or University?",
        "02f4c8c9-3545-4447-9d49-95dc038a55de": "What legislative acts guide the development of the City of Adelaide's Strategic Plan?",
        "383b1288-e107-48a7-8dd4-92fb5e79e595": "Who are the primary stakeholders that the Strategic Plan is designed to benefit?",
        "de821ccb-13fe-4a5c-8d91-286920f4260c": "How does the City of Adelaide plan to collaborate with other levels of government?",
        "12aee59e-dd84-4952-a000-77d009357223": "What role does the City of Adelaide play as a custodian of community assets?",
        "086343eb-f6f7-490a-935a-174934c57953": "In what ways does the City of Adelaide act as an advocate for its community?",
        "62a36f3a-95c4-4cd3-9724-ff7878c494d4": "What is the purpose of the Resource Plan mentioned in the context?",
        "a95c57f6-162f-4e68-96dd-e1baf089440a": "How does the City of Adelaide intend to leverage partnerships for community benefit?",
        "3a5d463d-2594-4d57-92e2-d640bcaf16cd": "What are the key roles identified for the City of Adelaide in implementing change?",
        "6fdbebbb-045b-4ceb-81f5-8a0dd5a52e24": "How does the City of Adelaide fulfill its regulatory responsibilities?",
        "23fc7659-1369-4f55-bd5b-847cc31ec14a": "What types of organizations does the City of Adelaide engage with as part of its facilitation efforts?",
        "37c7290c-d66c-4a9d-99e3-75a1b48c87cf": "What roles does the City of Adelaide identify in its approach to implementing and influencing change?",
        "d4220302-6177-4aed-8474-7c1e8f73ddda": "How does the City of Adelaide define its role as a \"Leader\" in the context of community development?",
        "edcecf02-c3ea-4a27-b853-ad9323fa3e2a": "What principles underpin the City of Adelaide's strategy for maintaining liveability while supporting growth?",
        "a3604a30-942d-439d-8838-a9d73192eeaa": "In what ways does the City of Adelaide act as an \"Advocate\" for its community?",
        "3385eacc-a32d-482a-b769-35eac54ca58c": "How does the City of Adelaide plan to ensure \"Quality Housing\" for its residents?",
        "8e0d7776-f862-4c47-a819-d99dd936ffa2": "What is the significance of \"Climate Resilience\" in the City of Adelaide's planning and development strategies?",
        "2480dbb3-2a60-4929-a71f-fa2de0cdd388": "How does the City of Adelaide aim to strengthen \"Community Connection\" among its residents?",
        "ae0ae74e-1ef0-4288-9666-f0a09d03f3ee": "What approach does the City of Adelaide take to manage its community assets as an \"Owner/Custodian\"?",
        "c259ce8a-bf62-4df0-9d9b-2e02755f2f8c": "How does the City of Adelaide intend to balance \"Economic Growth\" with the preservation of its liveability?",
        "2049e452-7007-44bb-ad53-08eac1f8dd35": "What role does the City of Adelaide play as a \"Facilitator/Initiator\" in addressing community issues?",
        "8b12028b-6acf-4ba7-9922-d9cc4f9fb2bf": "What principle emphasizes the importance of creating a high standard of living in the city?",
        "024f1de2-567b-4d92-b737-3684714400b4": "How does the strategic plan aim to balance quality housing with affordability?",
        "2d46a10c-911d-44cd-b838-5694464397a9": "In what ways does the plan propose to strengthen community connection and inclusivity?",
        "bd7d138e-dd8e-4469-9466-4ae0857afdcc": "What is the significance of \"Unique Experiences\" in the context of the strategic plan?",
        "17d6025e-3ac2-4fe9-b399-6f15fa0f3a48": "How does the strategic plan address the issue of climate resilience?",
        "eb073d96-1c9b-4d61-8994-563866ecf680": "What role does economic growth play in the City of Adelaide's strategic plan?",
        "81595047-cc73-42ab-b1a4-0ac937091298": "How does the principle of \"Budget Repair\" relate to the provision of quality services?",
        "0d3ff6ac-57bf-4a99-a801-37bdb225e51e": "What are the key areas of focus for innovation and investment according to the strategic plan?",
        "13d0d920-84bb-4857-ab16-9b18028bca3f": "How does the plan propose to attract and retain residents through its principles?",
        "6252bc2d-a3dc-49e9-b01c-6734ea34995e": "In what ways does the strategic plan aim to support both residents and visitors?",
        "84563fb6-ef3a-4201-9b0a-aabec1da59fb": "What is the target number of affordable rental properties to be delivered by 2028 according to the Council\u2019s Housing Strategy?",
        "558fb59c-7dd5-479d-a732-ba3e212f6e4b": "How does the Council plan to reduce rough sleeping and homelessness in the city?",
        "468de01c-a55b-4088-b295-bbe9e1f917f1": "What is the goal for increasing the city\u2019s population from 26,000 to 50,000 by 2036?",
        "06650ce1-6b98-4083-abd8-8fb0a425530f": "What percentage increase in family households living in the city is aimed for by 2036?",
        "9b101ee0-ce2f-4753-b7e6-0e88e76c2d1e": "How many State Government housing outcomes does the Council aim to support per month for people experiencing homelessness until 2026?",
        "9025c776-a0f2-41bf-b120-6360c8de9e54": "What role do community-led services play in enhancing social connections and active lifestyles?",
        "9dfc8fe6-a500-402f-8364-a0f407589fb3": "How does the Council intend to elevate the city\u2019s reputation for arts and cultural experiences?",
        "2ed9c1e1-ca57-461e-aa6f-5f2a39723476": "What strategies are in place to increase housing supply and reduce rental pressures in the city?",
        "9b51d523-9443-44ca-a463-18e0f08ac77c": "What is the target year for achieving functional zero homelessness in the city?",
        "ec52c137-fb7a-407c-8032-b6d836899fc0": "In what ways does the Council plan to celebrate and honor community cultures?",
        "1679081a-1610-4e83-aa87-f93718bdb129": "What percentage of the population is expected to be living in the city according to the document?",
        "24f834e4-1f37-4067-bec5-6f250cce8870": "By what year does the City of Adelaide aim to support 29 State Government housing outcomes for people experiencing homelessness?",
        "e4e43f64-1894-4db5-85fb-f5f7f2c17867": "What is the target increase in residents' life satisfaction from the current percentage to the desired percentage?",
        "ce3cabb2-0e7c-42e6-9ed6-d7fea5523003": "What strategy is to be reviewed by 2025 to enhance community engagement in active lifestyles?",
        "c425e4f7-81a6-4925-989f-bb3e6606dfcc": "How does the City of Adelaide plan to amplify its status as a UNESCO City of Music?",
        "8d6e64f4-8f8f-4c5d-85a8-780f14ed2c0d": "What is one key action to support Aboriginal and Torres Strait Islander peoples and culture mentioned in the document?",
        "e7cd42a7-0030-4c16-9966-6e4f82e9cc37": "What overarching policy is to be developed by 2025 to support diversity in arts and community development?",
        "ca2cfd88-d290-49d7-9691-b2b94c86d2f7": "What is the goal for increasing volunteer participation in the community?",
        "c780d7dc-d030-4922-a4d2-ebd8c4151f3a": "What plan is to be developed by 2026 to enhance community wellbeing?",
        "cd9a2b5e-abc2-4a76-a9cf-1288c3a91bdb": "How does the document propose to celebrate and elevate multicultural communities within the city?",
        "96c1877d-28fa-4499-8fe1-b6a641d6f6d8": "What is the primary goal of the new Stretch Reconciliation Action Plan to be established by 2024 in the City of Adelaide?",
        "f8aae89d-184e-4683-89da-f02874302e75": "How does the City of Adelaide plan to celebrate and elevate Kaurna culture and connection to Country?",
        "0fa79790-3e48-4c69-9af2-5f3bab30e3a7": "What specific target is set for increasing Aboriginal and Torres Strait Islander-led community reconciliation activities?",
        "e878d333-b7b2-45fa-a45c-1a89a45f58e9": "What initiatives are proposed to promote multicultural events and activities within the city?",
        "15509b6f-6300-4e27-a851-6058e78dba9b": "How does the City of Adelaide intend to ensure that its services and projects are accessible and inclusive for all residents?",
        "a8b461a5-302b-4af3-8047-e71c897d67ab": "What is the target percentage for Aboriginal and Torres Strait Islander employment at the City of Adelaide?",
        "16378ea8-3b2f-4bee-ba11-a0a05bac1e9a": "What are the key components of the new Diversity, Access and Inclusion Plan to be developed by 2024?",
        "e0299e73-82d4-4899-a5fb-b898f8ec8183": "What is the purpose of the Cultural Policy that is to be developed by 2024?",
        "390cf9bc-3234-49e3-a8a7-53442e44b20f": "How does the City of Adelaide plan to support belonging among people of diverse backgrounds?",
        "2b8bfe31-5706-4cac-b3e6-c41a532e1223": "What role does the Social Infrastructure Policy play in addressing current and emerging community needs?",
        "b36fec0f-0538-454f-8a04-7ec2163cb4d9": "What are the key objectives outlined for enhancing the Park Lands and open space in the document?",
        "0c754ff1-0327-4602-b220-b61c4ef2badb": "How does the document propose to support the transition to a low carbon emissions city?",
        "e4232091-81e0-4cb9-86b3-542acd594947": "What specific target is set for reducing community greenhouse gas emissions by 2030?",
        "631f0f3d-aa2e-43bc-9b5f-db60bdafbfda": "What role do partnerships with universities and researchers play in the city's sustainability efforts?",
        "baf900f8-d7c7-4edc-9d41-153a8d202eb8": "How many electric vehicle charging stations does the document aim to increase from the current number?",
        "660c4723-0c4e-4193-969b-56689611b139": "What is the timeline for reviewing Procurement Policies and Guidelines to support Circular Economy outcomes?",
        "a9f00af0-b7bb-4580-aab3-929c5a8f1ec7": "What measures are suggested to improve resource-use efficiency in buildings and industries?",
        "41d1a569-3c75-477f-8b45-62b299b7fa6f": "By what year does the document aim to develop a Sustainability Governance and Reporting Framework?",
        "bac1947d-4db1-42cd-86a4-5afd208bb380": "What strategies are mentioned for diverting waste from landfill in the community?",
        "b68cea8c-44e9-4404-8ffb-49e21cbf7217": "How does the document define success in terms of increasing green infrastructure in city assets?",
        "ed4cb43d-59f2-4e57-bcbc-24d2d6fd0959": "What measures are being proposed to ensure that all new dwellings built from 2025 are fully electric?",
        "d9673f44-1b6d-4b3f-9960-83250598213f": "How does the City of Adelaide plan to increase the diversion of residential kerbside waste from landfill to 80% by 2030?",
        "99271d6f-87fe-4424-a5f8-d617d721d47a": "What is the goal for the adaptive reuse of underutilised buildings in terms of annual dwelling delivery?",
        "a475e0b9-0797-4cf6-bef9-459944a3f577": "What framework is being developed by 2025 to enhance sustainability governance and reporting?",
        "85bafa0b-e37f-4089-a578-28bd4aadd3bd": "How will the community be supported in reducing their climate impact according to the new City of Adelaide Climate Strategy?",
        "46e487ae-8e50-4879-89bd-73ffaa588967": "What strategies are in place to protect and restore native habitats within the city?",
        "248ef9f6-ea02-4e45-8952-180e3341f9b8": "How does the City of Adelaide intend to measure and increase circular economy outcomes?",
        "b3fc093d-419f-4e60-839a-2f8a5a995e49": "What role do partnerships play in tracking green upgrades or new buildings in the community?",
        "1a2f1290-471f-42d7-8dd0-ae5226110a4b": "What is the significance of the Kadaltilla Charter and Business Plans in relation to the Park Lands?",
        "700d6a41-b85e-4eb5-90c3-9ab9b648dd53": "What actions are being advocated to prevent new development in the Park Lands?",
        "1a2334a3-bfb2-42d5-9bdd-84242500696c": "What is the primary goal of the Kadaltilla/Adelaide Parklands Authority Subsidiary as outlined in the document?",
        "47934a43-4d15-439c-9080-29f3ca5ece36": "How does the document propose to enhance the biodiversity and ecosystem health within the City of Adelaide by 2030?",
        "74d8d626-f083-4799-87df-89c199ca31e2": "What specific target is set for tree canopy cover by 2035?",
        "dd0d664b-34cb-4424-95f2-65a27aa2ee1b": "What strategies are suggested for converting underutilized areas into green spaces?",
        "bd1d779f-8f35-4d63-816d-ddd3dfc58391": "What is the significance of achieving world heritage listing for the Park Lands?",
        "73e69019-1208-4989-9514-a880425ae177": "How does the document address the issue of new development within the Park Lands?",
        "4a010339-76ae-4dd9-82a7-93820cdd3aa9": "What role does the Kadaltilla Charter and Business Plans play in the management of the Park Lands?",
        "b357f262-8bc7-4a43-ba94-90d25c2fc3f7": "What measures are proposed to protect and restore native habitats in the city?",
        "90f531c1-a2a1-4663-a701-8d0c526f25ee": "How does the document plan to support a net increase in street trees annually?",
        "271c845d-f7cf-4502-a591-f3426de16a92": "What is the intended outcome of the Adelaide Park Lands Management Strategy?",
        "58098587-317a-40dd-8e8c-842573620942": "What is the primary objective of the economic strategy outlined in the document?",
        "6f2c03ea-96d0-4e29-b99f-2639c6fa370e": "How does the strategy aim to support existing businesses in Adelaide?",
        "ef1c8ce0-05f9-4005-9b22-cda17855b347": "What role does the Adelaide Central Market Authority (ACMA) play in the economic growth plan?",
        "24dbbe6d-be05-493b-90c7-80c5c77381ad": "What are the key partnerships mentioned for activating and upgrading precincts in Adelaide?",
        "dbee2461-2268-4f58-b5b6-0f401a07a887": "What is the target increase in the number of visitors to the city by 2028?",
        "4aa1ba05-c07b-4666-8daa-e347f20c0b8a": "How does the strategy plan to enhance the information provided to visitors in Adelaide?",
        "706aa352-c9bb-4b85-a54b-29bb23c1a531": "In what ways does the document suggest reinforcing Adelaide's position as the State's central business district?",
        "5eed5ff4-f82f-47e1-87e1-41dd1fe2c21f": "What specific actions are proposed to stimulate investment and visitation in Adelaide?",
        "56b9c86f-a928-499e-9498-a73628644144": "How does the strategy intend to create a strong skilled workforce in the community?",
        "c1d879cf-8c6a-442a-848d-8600a19adaaa": "What measures will indicate the success of the initiatives outlined in the document?",
        "d2669ffe-7beb-48ec-8271-d36c72dbfabe": "What is the primary goal of the Adelaide Economic Development Strategy as outlined in the document?",
        "c0042bec-15b6-4bd4-a93e-7fd98760cf86": "How does the Council plan to support the Adelaide Economic Development Agency (AEDA) in achieving its objectives?",
        "156e0e0d-a4fa-429c-8409-431220dac5dc": "What sectors are identified for growth and development in the City of Adelaide's economic strategy?",
        "b017cd18-641c-49ef-aee1-7579905d4ef7": "What role do partnerships with universities and businesses play in improving employment opportunities according to the document?",
        "20d45b19-3e29-4ce6-8f8e-89b28d4e5037": "What is the target year for developing a new City of Adelaide Economic Development Strategy?",
        "b81d42af-4840-4e75-a37e-f5bb5fa4034f": "How does the document suggest reducing barriers for businesses in the city?",
        "3c35f6e1-8218-4d70-aa5b-caab797ef790": "What indicators of success are mentioned for measuring the effectiveness of the economic development initiatives?",
        "e0c1eaf4-fcce-4647-9445-c6df3ac525f8": "In what ways does the Council aim to increase spending across the city?",
        "243adf1a-3e6e-4934-8f05-08192cf75259": "What type of data and insights does the Council plan to deliver to the business community?",
        "78d67856-973e-49c1-aec2-1494f8b7880b": "How does the document propose to achieve a critical mass of jobs and investment in Adelaide?",
        "810207f7-bfd2-4350-8069-66311eccb2c9": "What percentage of businesses now view the city as a good place to do business, according to the document?",
        "a6ff0b73-63d1-49e7-96d3-9db6bd320ba0": "How is the City of Adelaide planning to increase the use of social enterprises and Aboriginal Torres Strait Islander owned businesses?",
        "5193feb0-ee34-41cf-823d-a0ee4e056d12": "What major development projects are mentioned as part of the council's efforts to drive economic and housing outcomes?",
        "817770a0-a4e1-475f-9443-01aa5dd1c843": "What is the purpose of maintaining the Future Fund as outlined in the document?",
        "d65a760c-da91-4b9f-abd1-0ab23d361c35": "By what year does the City of Adelaide plan to review the Strategic Property Action Plan?",
        "9330c6d8-e629-46c7-a1b9-abcb42a79fe2": "What types of commercial assets are mentioned for management opportunities in the Strategic Property Action Plan?",
        "315c34dc-ec06-41d4-9468-42ce9d0b8ca2": "What specific targets are to be developed in relation to City of Adelaide housing developments?",
        "6b6e95ef-4415-40a3-81bb-8fa406d6b2c3": "How does the council intend to support investment in revenue-generating activities?",
        "8b63c842-754d-4ceb-822c-19d874b6dfa3": "What is the significance of the increase in the number of new businesses and investments in the city?",
        "f422d89e-3af8-4bbc-9137-98b0b7c226c2": "What governance arrangements are mentioned for managing the Future Fund?",
        "63182019-df9f-4b89-8f07-0d5739df1e7c": "What are the key objectives outlined for managing community assets in the document?",
        "15f67438-55f2-4e1d-bcb2-5931cf113613": "How does the document propose to enhance the safety and accessibility of places within the community?",
        "cab66794-d2fc-49e5-a6ce-f7660eb424d4": "What specific street upgrade projects are scheduled to commence by 2025/2026?",
        "d28f0a11-6bc2-4985-8f59-a165599cde00": "What is the target year for developing and implementing an Integrated Transport Strategy?",
        "544c0523-4849-4a4c-9fdd-665819d60ad1": "How does the document plan to support the maintenance and development of community and cultural places?",
        "83fed39e-fc22-49cf-bc94-3787328ec3b1": "What measures are suggested to encourage safer road user behavior?",
        "5b0e0b8a-45ba-48d2-ab2b-d5416f1d6089": "What is the significance of revising the Asset Management Plans by June 2024?",
        "b1d94630-89a1-4be2-a5bc-6a455898de22": "How does the document define \"bold and interesting development\" in relation to community needs?",
        "37fc4dd3-224f-42d3-8bc8-48fd1c220d7e": "What role do partnerships play in achieving the objectives outlined in the document?",
        "d9a63734-783d-4d2d-9606-295a6c1bc0de": "What indicators of success are mentioned for the street and laneway upgrades?",
        "8ad62d6a-b20e-48de-80bc-996076551adf": "What is the primary goal of the City Plan being developed for Adelaide by 2024?",
        "969b8e6d-3a24-4537-bc91-948c60660254": "How does the plan aim to increase the number of dwellings in Adelaide by 2031?",
        "a21481e3-7e32-431d-b606-03b99ee55278": "What percentage of new dwellings is targeted to be affordable for low and moderate income earners?",
        "0d563f3d-9eb9-4e66-9146-7ba34fbdaba1": "What types of green spaces are being advocated for in the development of the City Plan?",
        "94928ab3-5bfb-4263-830e-7d645a050b88": "By what year does the plan aim to review the heritage overlays for local heritage places?",
        "6ae6c002-0e19-46f1-93dc-3a7cc85c48b2": "What is the current percentage of people who agree that the city is a welcoming and dynamic place, and what is the target percentage?",
        "e16cc5fa-12ce-4018-95af-8f22bad3d6f6": "How does the plan propose to support the adaptive reuse and improvement of existing buildings?",
        "b1f1c5b7-cc93-408e-8c63-181b47186d2a": "What specific measures are mentioned to ensure access and inclusion for vulnerable or minority groups?",
        "96c8a9f7-60be-499c-b4b1-f9f889857d15": "What is the target number of heritage places to be maintained or increased in the city?",
        "bce30228-f7d5-4287-b768-8af1681bd9e1": "What is the timeline for delivering conservation management plans for heritage assets?",
        "7049ce02-5fad-4cb3-aa3b-9ac892380878": "What is the target number of new dwellings to be available by 2026 and 2031, according to the strategic plan?",
        "5f08a1b2-85fb-4fcb-b15e-4d2685d0ebe7": "What percentage of new dwellings is designated for affordable purchase or rental for low and moderate income earners?",
        "041bcdb1-2df6-49eb-8551-6b4fced1f1bf": "By what year does the plan aim to review the heritage overlays to ensure the protection of local heritage places?",
        "e39ca0b7-a0eb-4f4f-899b-2fdb18a9e544": "What is the goal for the number of heritage places to be considered for increase beyond the current 1,850?",
        "d8ebc361-887c-4fa9-990b-6ed4a2eb52e7": "What specific plans are to be delivered for heritage assets by 2025?",
        "365e4a5a-e965-41ea-9084-9009ddc8160c": "How does the strategic plan propose to enhance access and inclusion for vulnerable or minority groups?",
        "6955938f-caee-440d-a6e2-ca19aecaf34d": "What initiatives are suggested to create sustained activation in the city?",
        "b2cd2e00-d4fe-4be9-9eb4-a0b61a2ac4fc": "By what year is the Disability Access and Inclusion Plan scheduled for review?",
        "4a7c002d-3b2b-49ef-9551-9781e05e14ee": "What is the timeline for reviewing the Wellbeing (Public Health) Plan?",
        "74415071-32ff-4404-9711-1644aad70e28": "What actions are proposed regarding the Dog and Cat Management Plan by 2024?",
        "fe462210-bd24-4985-9ab9-d6a3b5872e60": "What is the target date for implementing the Public Transparency Policy according to the document?",
        "bdb2a4c5-8e8c-46e9-b1c9-96cb3313dd73": "How does the corporation plan to enhance customer experience based on community feedback?",
        "8c68714a-0b29-49ca-b402-4964dcf3b683": "What measures are being taken to reduce the number of confidential Council decisions?",
        "d4ce8385-576f-4e7f-add9-0cc3e1b6aae6": "What is the goal related to the Voice of the Customer Survey scores?",
        "460bab6c-056e-4e64-91e8-32a129200577": "How does the corporation intend to achieve financial sustainability while delivering quality services?",
        "dbe2305b-ab29-4d7e-8b4a-4ef70396d5b0": "What specific review is planned for the Rating System, and by when should it be completed?",
        "76ad8511-e9eb-471f-8671-49fde8e724c7": "What are the key components of the internal audit program mentioned in the document?",
        "58f4d02a-f441-4f0a-8307-5da421caa8e1": "How will the corporation ensure that 100% of procurement aligns with its relevant policies?",
        "ff10a404-8b6e-497e-ac72-eb0f6173205b": "What strategies are outlined to improve service efficiency and identify new revenue streams?",
        "c23a997c-b6b3-4e1e-a0f7-eb30b687a5ad": "What is the timeline for reviewing Emergency Management Plans and responses?",
        "1b792e66-2854-4664-8253-8c438ab2f5ac": "What principle is emphasized for responsible financial management in the City of Adelaide's Strategic Plan 2024-2028?",
        "4db53b0b-0151-4423-bbd7-050c85540c3c": "By what year does the City of Adelaide aim to review its Rating System for optimum outcomes?",
        "0c55d2bc-fc15-400c-8799-eb35ca4070ed": "What is the target range for the Asset Renewal Funding Ratio as outlined in the Long-Term Financial Plan?",
        "210e80f2-3e61-4dbe-9331-ed4a66b6cffc": "What specific employment target is set for Aboriginal and Torres Strait Islander individuals within the City of Adelaide?",
        "5642f44f-413e-499c-b7d4-1a380b3c90f2": "What is one of the key actions to improve service efficiency mentioned in the document?",
        "27f4caea-0829-44f5-8bbf-2c0ed41eb32b": "What is the goal for the City of Adelaide's procurement practices in relation to local sourcing and climate strategies?",
        "92bf4b96-20ca-4208-b149-552e0d64b06e": "By what year does the City of Adelaide plan to deliver a Workforce Strategy?",
        "1fe30c62-ac04-4b42-b3af-7cca812dab23": "What program is the City of Adelaide planning to implement by 2025 to support workforce development?",
        "ff691d9b-7977-4ab0-97a8-8a228a306f2f": "How does the City of Adelaide intend to support informed decision-making and innovation within its organization?",
        "51b190a4-e57f-49fc-9a98-932be86ca5cc": "What is the desired outcome of the employee feedback tools and risk assessments mentioned in the document?",
        "8c33e3ff-8c86-4759-a72b-2d98045f76ec": "What is the target percentage for delivering Strategic and Capital Projects on time and on budget by 2024?",
        "0ce31491-2d50-499c-992d-129ce10c7247": "By what year is the review of the Strategic Planning Framework expected to be completed?",
        "5eee1ad6-9f5d-4fa0-94a9-9c995b994ad8": "What framework is being developed to achieve best practice outcomes through partnerships?",
        "87367a68-74cc-46b7-a015-6092b142fbcd": "How will community feedback be utilized in the context of service improvement?",
        "02e1bff7-138c-4da4-a056-2497bf7e8484": "What is the purpose of the Business Systems Roadmap mentioned in the document?",
        "b6bbd015-f1d0-4e88-bf5c-757a8d2a6bd3": "What specific upgrades are planned for the Workforce Management System?",
        "92ef67ad-a5de-4063-b421-c3fc730c6d2e": "By what year is the review of the Community Engagement approach scheduled to be completed?",
        "ea39905f-aeed-47e7-b977-e9d8e2f3504f": "What measures are being taken to improve staff awareness and engagement?",
        "be4cffc7-9b80-4722-b8ce-e78f94b4b261": "What is the goal of implementing data integration solutions for Customer Insights?",
        "b7a273a6-fbeb-4861-addb-a25bd66e7eb2": "What type of data is being developed as baseline measures in the Strategic Plan by 2024?",
        "c2cc4817-3e26-4d0f-8822-d048515db468": "What is the primary focus of the Strategic Plan for the City of Adelaide for the years 2024\u20132028?",
        "fa9fdba0-8e15-4d50-ad63-086a44e65318": "How does the Long Term Financial Plan support the overall Strategic Plan?",
        "4db0edf1-9039-4169-b640-b5c31eda3728": "What are the key components of the Resource Plan associated with the Strategic Plan?",
        "8ee68ef5-a15e-4ec2-a045-206cd85aa86a": "In what ways do the aspirations articulated in the Strategic Plan influence future policy positions of the Council?",
        "691a54e4-8322-42dc-aeca-01bd7f9a66d8": "What is the purpose of the Indicators of Success/Measures/Targets section in the Strategic Plan?",
        "c368cdc5-422a-4042-bd7f-0611fcc9c5bf": "How often is the Long Term Financial Plan revised, and what is its time frame?",
        "db9c1a9b-17e7-4635-920a-c9bed57c8364": "What role do the Principles play in shaping the four-year plan of the Strategic Plan?",
        "13cc9c8b-358d-4ade-943b-50b1aec3478c": "How does the City Plan relate to the overall vision for the future of Adelaide?",
        "96b51eab-c536-4438-8770-4966b9e16324": "What is the significance of the suite of related Strategies, Plans, and Policies in implementing the Strategic Plan?",
        "0381d794-ed85-42b0-be9e-4652336b6f5b": "What are the expected outcomes described under the Objectives and Outcomes section of the Strategic Plan?",
        "4428d79d-9ee8-4ea1-be3d-26efc3300f60": "What are the key objectives outlined in the Strategic Plan for the City of Adelaide from 2024 to 2028?",
        "47746844-6941-4d9c-b404-5be4b9f52040": "How will the Council measure the success of the Strategic Plan's implementation over the four-year period?",
        "013291d1-5d96-4ec1-ada6-a55c92af4140": "What types of resources are included in the Resource Plan to support the Strategic Plan?",
        "aa71431b-9868-4e4f-ac79-2568dc8c7739": "Can you list three related strategies or policies that fall under the \"Our Community\" category?",
        "a17ef721-499b-495d-addc-7c3cff6339d0": "What is the purpose of the \"Indicators of Success/Measures/Targets\" section in the Strategic Plan?",
        "8f53824d-05df-444f-9579-4efe7c17cedf": "How does the Strategic Plan intend to address environmental concerns within the City of Adelaide?",
        "d5888a0c-cb18-43ad-88e1-59bec9e8af2f": "What role does the Adelaide Economic Development Agency play in relation to the Strategic Plan?",
        "4bd24477-5741-4146-b1e5-9a8cb3e0f8d4": "Which statutory plans are mentioned in the context of \"Our Places\"?",
        "752e3573-a20a-481a-842e-c50076b31103": "How will the Council ensure that the Strategic Plan remains relevant over time?",
        "8742203a-8074-4fd1-8e12-c5921a953f24": "Where can one find a complete list of the strategies, plans, and policies related to the Strategic Plan?",
        "a756754e-91d4-4878-b1a8-e4df84c85156": "What is the primary goal of the Council's Financial Principles as outlined in the document?",
        "c39bdf22-3968-443a-b3e6-3a3d31948d5a": "How does the Council plan to adjust fees and charges in response to community needs?",
        "8c40b587-bd59-4767-9837-79791bcc3f97": "What is the significance of maintaining an operating surplus for the Council?",
        "a7fa1cd5-d912-4dd6-8ccc-5daad4e8df81": "In what ways does the Council intend to capitalize on external funding opportunities?",
        "efbb711b-f268-4159-a969-392f6b696093": "How does the Council propose to manage new or enhanced services that require increased operating costs?",
        "01b850e8-37f4-47fa-a417-c54ee17215ef": "What role do asset management plans play in the Council's capital renewal expenditure?",
        "dc094018-f2c5-474d-8539-0b3d112d96f2": "Under what circumstances does the Council consider using borrowings to fund projects?",
        "322ec5a3-b06c-44c8-9136-a9f074b79e34": "How does the Council ensure that its financial resources can withstand economic fluctuations?",
        "c3e31b8c-8d74-40fe-8d13-c5133d9f6188": "What factors does the Council consider when adjusting rate revenue?",
        "bcdf8188-9ae7-4c9c-a52c-b32a211c06e4": "How does the Council approach the disposal or repurposing of property assets?",
        "33c9a5ac-117d-4263-b2ac-5bc01cd8453f": "What are the key components of the Council's Financial Principles aimed at ensuring long-term financial sustainability?",
        "f12c850c-435a-460a-bab7-def3ec61b831": "How does the Council plan to achieve intergenerational equity in its financial decisions?",
        "1d84d626-62e3-461a-8cba-897909cd7252": "What is the purpose of the Resource Plan developed by the Council for 2024-2028?",
        "72aef7a2-64ba-4d30-8fee-6e5dd5781f9f": "In what ways do the Strategic Plan and Resource Plan interact with the Long-Term Financial Plan?",
        "6528fe2f-f82b-45ad-acf4-6257af865f96": "How does the Council ensure that its funding decisions contribute to financial sustainability?",
        "6295613c-4a36-48ca-93a4-e3b135e56449": "What role does the Capital City Council play in delivering services to the community?",
        "738506d2-f417-48b4-8304-1255fd32e5e5": "How does the Council measure progress towards its strategic objectives?",
        "5c68c75a-3aea-41f1-8c77-a6e462e15278": "What is the significance of maintaining existing service levels while seeking efficiency improvements?",
        "02168750-9097-4a16-b8c0-f93c89b224ae": "How often does the Council report on its progress towards achieving its objectives?",
        "29d47367-6a08-40dc-b520-f9bf94015192": "What are the implications of the Council's financial sustainability on future community benefits?",
        "1abe8b0f-9ff0-4b06-92e3-f82085a0ba95": "What is the primary purpose of the Long Term Financial Plan developed by the Council?",
        "ea07be02-41be-44ec-a3d1-2730c816f49f": "How does the Long Term Financial Plan ensure alignment with the Council's Strategic Plan?",
        "ff758077-bae5-4e24-9e10-fea6052e8768": "What financial principles are emphasized in the Long Term Financial Plan?",
        "1f0219f7-a650-4076-bad0-a2a261bd5976": "How does the plan address the Council's role and responsibilities?",
        "583d0c9a-789d-4795-989d-d61db08bbfae": "What assumptions are made regarding rates revenue in the Long Term Financial Plan?",
        "51569fbd-d29c-4212-b928-663e451f4df1": "How are salary and wage forecasts determined according to the plan?",
        "210b2a2d-24ba-4c9a-b248-4ca65397ad6c": "What is the planned annual funding amount for capital enhancements during the current term of council?",
        "0cab433e-6e5a-4dd5-9efe-2772070f5b5c": "In what ways does the Long Term Financial Plan align with Asset Management Plans?",
        "221a8469-649f-4f17-9dd2-72c75282253e": "How does the plan propose to manage fees and charges in relation to inflation?",
        "cb5ee70e-4506-4015-920a-84baf0ebf205": "What considerations are made regarding interest rates in the Long Term Financial Plan?",
        "beb32353-48a4-4c11-a283-28d587dbcc52": "What are the key guidelines that the Long Term Financial Plan must align with according to the document?",
        "e95d2fa4-2795-4302-99f0-060e5ba0cb49": "How is the Rates Revenue projected to grow in the Long Term Financial Plan?",
        "1fb7f892-986b-4482-828d-6d9fba32ea3d": "What is the target range for the Operating Surplus Ratio, and what are the projected values for the years 2023-24 to 2027-28?",
        "b881ef2b-1f14-47d0-9b8c-29a291dfa506": "What is the significance of the Asset Renewal Funding Ratio, and what is its target range?",
        "0093e75e-8be0-4ce2-92de-28a87c5e3910": "How does the Long Term Financial Plan ensure sustainability in relation to recent Council decisions?",
        "04dec1d3-dd4c-46fe-9183-943959b9b9a0": "What assumptions are made regarding salaries and wages forecasts once enterprise agreements expire?",
        "d254d053-2d05-4cbf-82e4-169ef79622ad": "What is the target for the Net Financial Liabilities ratio, and what are the projected values for the upcoming years?",
        "44196a38-8d82-4394-814e-dd4eb7a6a553": "How does the document define the maximum allowable value for the Asset Test Ratio?",
        "5b39febf-92ae-4156-89f7-603c2ec5bcda": "What is the planned annual funding amount for capital enhancements as per the Council's decision?",
        "25171f57-8659-45f6-a43b-4974686fada1": "What trend is observed in the Cash Flow from Operations Ratio over the four-year period?",
        "0a629838-fb0f-4abe-90e7-f7f86857ddef": "What are some of the key Council priorities mentioned for investment in the upcoming period?",
        "5caee24c-5365-4aa1-96b3-8c13343d1bc2": "Which major project is being developed in partnership with the State Government?",
        "65bc5eb2-a5aa-44ba-b8ce-1ee5fbbd23f3": "What is the significance of the former Adelaide Aquatic Centre site in the context of Council investments?",
        "895d6fbe-b021-4187-95c4-e962d11c8715": "Can you name one of the strategic property developments listed in the document?",
        "383b2bac-6903-4d77-9f1b-1ae50f90728b": "How does the redevelopment of the Franklin Street Bus Station fit into the Council's strategic plan?",
        "7af157ca-9407-47cc-ab51-3812f277266e": "What ongoing core services are mentioned in relation to the Council's investment priorities?",
        "5e48f19e-13ec-4e26-8e1a-5d12615bf569": "Which significant renewal projects are highlighted as influencing future years?",
        "55d06166-40d6-4813-ae58-68fcbc4fb561": "How does the King William Street Bridge project relate to the overall strategic plan?",
        "4b584f65-e555-4f5d-be86-e20e8d42c6a0": "What role does Market Square play in the Council's strategic property developments?",
        "7ed0b33b-1692-46ee-b4fe-00c36af0327f": "How might the upgrades to several streets impact the City of Adelaide's strategic goals?",
        "c043f972-cd78-4dbc-92f0-ddde9c19580c": "What percentage of the total annual revenue is accounted for by rate revenue according to the Treasury Policy?",
        "62bbdf66-7999-41c1-b506-64a3572e3a67": "How much does the Council assume rate income will grow annually?",
        "e0909d3d-c988-40e0-9e5c-f04b7b6c01c3": "Which facilities operated by the Council generate fee-based revenue?",
        "b1ade058-9ae4-439b-a81e-25fdf5019e5e": "What is the projected rate revenue for the year 2025-26?",
        "8e3170e2-1bf6-4e29-931d-b4b1073776d0": "How does the Council generate income from statutory charges?",
        "fb1ccb44-701a-4126-8f5a-4f1c69851ca1": "What is the total income projected for the year 2026-27?",
        "9158aa4f-96e6-4b7c-8d93-6ca2c5ff7379": "What are the two main components of the Council's income sources mentioned in the document?",
        "093158ea-4c96-4bed-9e9d-c0aa289e43e4": "How much is budgeted for employee costs in the year 2024-25?",
        "46b4664c-931f-4864-9417-b2457bf2ef40": "What type of financial activities does the Council's Treasury Policy support?",
        "7e9cc301-a6dd-4361-82a1-42c61b0be2c5": "What is the expected income from investment for the year 2027-28?",
        "7cd218cc-eb5b-43fe-84ae-f34797a6b6bc": "What is the total income projected for the year 2027-28?",
        "40245ab1-9ddd-4ca7-85c4-b0192c36f0d8": "How much are the statutory charges expected to increase from 2023-24 to 2027-28?",
        "ca958282-3b96-4eae-b8c8-315aaefb329c": "What is the operating surplus for the year 2026-27?",
        "f800adc8-3e0b-48c3-bfaa-1859b24a8523": "How much are new borrowings projected to be in 2025-26?",
        "424ac2f2-3619-4ded-ad67-58642fd83611": "What is the trend in employee costs from 2023-24 to 2027-28?",
        "41f5da4a-5ef9-453a-ba47-897e78b2d326": "What is the total amount of expenses projected for the year 2024-25?",
        "6dd1c568-aaef-4add-9e21-30c455d86dda": "How does the net borrowings figure change from 2023-24 to 2027-28?",
        "fe44dd35-9e5e-4a2c-a0f8-87bb17c0b323": "What is the projected finance cost for the year 2026-27?",
        "06293891-038c-44b0-b03d-0e3d301cde4f": "How much is the future fund expected to remain constant at over the five-year period?",
        "871e81bd-b492-4117-93b9-d3a55e50eab2": "What is the prudential borrowing limit for the year 2026-27?",
        "b7663140-d6c8-46b3-9082-eb68291ee91b": "What is the projected operating surplus for the year 2025-26?",
        "bfbb3d6e-e658-4176-a565-7e4582d4af84": "How much is allocated for major projects in the year 2023-24?",
        "111a0b81-466e-4bf2-acf6-10085fa32ff8": "What is the total capital expenditure projected for the year 2024-25?",
        "be54e310-49c5-44a2-9b22-4a418f0fb157": "What are the net borrowings expected to be in 2026-27?",
        "df466596-9fe1-4489-b138-80ea02d046d1": "How does the prudential borrowing limit change from 2023-24 to 2027-28?",
        "b9768e03-c701-4929-ac32-4262aff73ec3": "What is the amount set aside for renewal capital expenditure in 2025-26?",
        "f100cb99-40ea-4cfa-a5bb-a96b000dff3a": "How does the Future Fund amount remain consistent over the five-year period?",
        "83795b52-c140-4e13-bcc4-7e0e7886ae7f": "What is the total amount of new borrowings projected for the year 2024-25?",
        "5f55fbeb-f7a5-4030-9735-dbd36ee3ae21": "What role do Asset Management Plans play in the Council's financial planning?",
        "9d3eb2e6-e132-4614-83d4-8007453c8b4e": "How does the Council ensure the ongoing improvement of its assets?",
        "d043a745-4579-48a0-b04d-d38be8f341dc": "What is the purpose of the Asset Management Plans developed by the Council?",
        "ba546fb9-6c94-43dd-8e9e-873edf6854c2": "How does the Council ensure that its asset management aligns with community service levels and legislative requirements?",
        "2186b6c9-b259-4a8d-829f-6a5e32f9c5c3": "What role do rolling condition audits play in the management of the Council's assets?",
        "96999606-fa0a-4f54-931c-db661755b67e": "How is renewal and replacement capital expenditure determined according to the Asset Management Plans?",
        "8855f61c-bce9-4b2d-b925-7a1f4e3729f2": "What strategic objectives does the Council's property portfolio aim to address?",
        "2ceffc8e-bd6e-46d8-beef-21d607c1f05e": "Why is it important for the Council to protect the value and returns of its property portfolio?",
        "de5f26fe-c2d1-4c6f-a817-bde7ecf2f236": "What approach does the Property Strategy promote for managing the property portfolio?",
        "029c34ea-12e9-4b28-8bc3-efdcc6d914dc": "How does the Council plan to leverage partnerships with the private sector and other government tiers?",
        "0750ed9d-7ad4-4694-93b8-70b0898f83e3": "What is the significance of reinvesting proceeds from the sale of under-performing assets?",
        "4bd5179b-ceaf-4839-87f6-2a23feda1b2c": "How does the Council aim to avoid disruptive adjustments to its activities and revenue-raising efforts?",
        "7486f11d-6857-443d-afe3-de80ed057892": "What is the historical trend of the Local Government Price Index in relation to the Consumer Price Index (CPI)?",
        "9e763505-e17e-453f-ad33-3c0f2ea6b5d9": "How much are wages and salary increases projected to be for staff under the current Enterprise Agreements starting in 2024?",
        "7da5ca9f-ee2a-41c1-a4b3-4a2134c49919": "What specific focus areas are highlighted for the maintenance and renewal of assets in the city?",
        "aaeb96ab-ee1f-4c15-8d9b-7489637bfda9": "How might the changing population in the city affect service and infrastructure needs?",
        "44821d26-a909-47af-9fe9-ee38633bf877": "What impact is expected on Council revenue from commercial operations and fees due to post-COVID-19 work patterns?",
        "dbf6f743-fec1-43c1-84a5-096b72420281": "What are the implications of increasing interest rates on the Council\u2019s borrowings?",
        "7606b94b-7db7-45a0-bf20-b7254b46ac2b": "What are the four key areas of focus in the Council's ongoing program of works for technology investment?",
        "9e523af4-3a15-463d-8671-4ad89bc67917": "How does the Council plan to ensure the security and reliability of its technology solutions?",
        "1a6fd3a8-29ce-46ae-805f-eb8cd1decfdf": "In what ways does the Council intend to use data and insights to enhance customer engagement?",
        "917e4732-569f-45ea-b322-713f0d44713d": "What is the overarching goal of the Business Systems Roadmap for the Council over the next four years?",
        "c6a76e2d-ccb4-4bdb-b404-673f0e9f339e": "What are the four key areas of focus outlined in the Business Systems Roadmap for the Council's program of works over the next four years?",
        "3626e524-6739-4df5-9565-9f0d5d9d31db": "How does the Council plan to ensure that customers are at the center of its services?",
        "3bfb386f-0b98-4709-9145-53dce87a9ad1": "What measures are being taken to enhance the security and reliability of services provided by the Council?",
        "5576d5a1-40b9-4ea7-9c3d-32dae8b084c3": "In what ways does the Council intend to utilize data and insights to improve customer engagement and decision-making?",
        "1051dbbb-4be1-4a85-92a7-a5a8590c76b6": "What does the term \"seamless\" refer to in the context of the Council's service delivery?",
        "866dcc84-f69e-4a7c-bbf8-a33f7b7bcd50": "How many full-time equivalent (FTE) positions are projected for \"Our Community\" in the 2023-24 fiscal year?",
        "9fd39684-e134-4cbe-8738-0ef00006ecbe": "What is the total number of FTE positions across all areas for the 2024-25 fiscal year?",
        "18068d50-3f6f-486c-87d2-25808423809c": "Why is appropriate resourcing capacity and capability considered critical for delivering on the Strategic Plan responsibilities?",
        "41ce924f-99ff-43da-83a8-839cc7649b9f": "How does workforce planning contribute to the Corporation's ability to meet new and emerging challenges?",
        "29d38709-a037-4f38-9349-272f6655e981": "In what ways must the Corporation's operations reflect the Council's vision according to the document?",
        "6e2d0bb8-5c90-47a5-a648-88bf30ad8b3d": "What is the primary goal of workforce planning within the Corporation as outlined in the Strategic Plan?",
        "008bc7a8-3c65-4d7c-a659-19c58033f236": "How does the Corporation aim to align its operations with the Council\u2019s vision?",
        "5cb1325e-eb34-4e66-a7f4-e74f8a1663aa": "What strategies are mentioned for maintaining Full-Time Equivalent (FTE) numbers over the four-year period?",
        "95cbadfa-93e5-4877-ba33-e1400466a299": "In what situations might the Corporation consider using consultancy services or temporary staff?",
        "e3f1d487-e416-44dd-b5b8-86e445af816a": "What are the five core values that guide the City of Adelaide's workplace culture?",
        "7316aeb9-4c6e-4c29-a190-eaf64c0dc347": "How does the Corporation define its purpose in terms of service delivery and partnership?",
        "fdb617c6-1d73-430f-b3c4-6cf4c3c44dcc": "What is the significance of continuous improvement in the context of the Corporation's workforce planning?",
        "f1a7d869-18a0-49e3-8c34-bccbc8d1fadd": "How does the Corporation plan to ensure responsiveness to the changing needs of communities?",
        "28deb05d-fc36-4c47-bdf3-c99b49c98397": "What role do Employee Values and Behaviours play in the Corporation's culture?",
        "971c4f84-2309-4898-9e20-067dc9eadad5": "What does the Corporation aspire to be recognized as in terms of organizational performance?",
        "15acb2c2-36be-442f-817e-1764f82a4ba2": "What is the address of the City of Adelaide?",
        "480e7c79-66f3-4249-8b2d-61460ca956ab": "What is the phone number for the City of Adelaide?",
        "d3c1ca8d-9e24-4d98-9193-9de1677ea7e6": "What is the website for the City of Adelaide?",
        "c8e87315-ebcb-43af-a901-bab20c9d70db": "In which city is the City of Adelaide located?",
        "8202e774-373c-4184-aeef-9fc9e74bb191": "What is the postal code for the City of Adelaide?",
        "a57d066a-6715-4887-8e77-bf13e0949926": "What type of organization is referenced in the document?",
        "a4ac6103-1ade-4fe8-9ab6-1e312218125e": "How can one contact the City of Adelaide by phone?",
        "96f438e6-a4a3-4c86-bbc7-ad089169d5c9": "What street is the City of Adelaide located on?",
        "60316bed-dcfb-4c7a-a237-223ae3794317": "What is the significance of the number \"25\" in the context provided?",
        "e6e42b52-4594-4086-b4f0-1f96b7d8423b": "What information can be found on the City of Adelaide's website?"
    },
    "responses": {
        "32ef6672-1ec0-4c10-8b27-4007f4f32a16": "The primary objective of the proposed framework is to enable counting of human actions of interest using sensor data from wearable devices by allowing users to provide exemplars through vocalized sounds, facilitating accurate identification and counting of actions in real-world scenarios.",
        "d4756049-0274-41a6-8de3-259c35d78d4f": "Users provide exemplars of the actions they want to count by vocalizing predefined sounds such as \"one,\" \"two,\" and \"three.\" These vocalizations are then localized in the audio sequence to identify the corresponding action exemplars.",
        "31118474-50d4-45ab-8ce5-c6b89fb29922": "The vocalized sounds \"one,\" \"two,\" and \"three\" serve as predefined utterances that users can vocalize to provide exemplars of the actions they want to count. These sounds help localize temporal positions within the audio sequence, which are then used to identify the corresponding action class exemplars for counting.",
        "7e3bdbe6-39a7-4796-9215-8b77c9249223": "The method localizes the temporal positions of the utterances by analyzing the audio sequence to identify when the predefined sounds \"one,\" \"two,\" and \"three\" are vocalized. These identified positions are then used to determine the exemplars that represent the action class of interest.",
        "9f97711d-0189-463a-a8cf-dc255d002c03": "The purpose of the similarity map in the counting process is to compute the correlation between the identified exemplars of the actions and the entire sensor data sequence, which aids in estimating the density of the actions and ultimately provides the final count of instances.",
        "d5adabb2-fb49-4dde-808b-f86a31604ba4": "The final count of actions in the proposed framework is determined by summing the estimated density values generated from a similarity map, which compares exemplars of the actions (identified from vocalized sounds) to the entire sensor data sequence.",
        "4d9d0fff-4184-4d22-a932-fdc8a9ea7920": "The introduced dataset consists of real-world data from 37 subjects and includes 50 action categories, encompassing both sensor and audio data.",
        "cd34e354-e25a-4929-9d8e-080fae574a1c": "The proposed method outperforms frequency-based and transformer-based methods, achieving an average discrepancy of 7.47 between predicted counts and ground truth values, which is significantly lower than the errors reported by the other methods.",
        "c90facf1-f70c-405c-8ea5-b494dec103e4": "The average discrepancy between the predicted count and the ground truth value reported in the experiments is 7.47.",
        "f8a2cad3-1094-43e7-82b3-00b8408217a8": "Counting human actions using wearable devices can be beneficial in health monitoring and performance evaluation.",
        "17f21610-189d-4395-9c26-d3066513e95d": "The average discrepancy between the predicted count and the ground truth value in the experiments is 7.47.",
        "396baf08-f8f0-43ca-a885-b9d05e287d82": "Class-specific counters are considered impractical and unscalable for counting human actions because they are limited to a predefined set of action categories and cannot adapt to new or diverse actions not included in their training data. This restricts their applicability in real-world scenarios where a wide variety of actions may need to be counted, making them ineffective for tasks that require flexibility and adaptability, such as detecting infrequent actions in dynamic environments. In contrast, class-agnostic counters can handle any action class, enhancing scalability and usability.",
        "4804a4e8-7c8f-4753-81c8-dd6410a6ff67": "The main advantage of using class-agnostic counters over class-specific counters is their ability to count instances of actions from any arbitrary class, making them scalable and practical for diverse action categories, unlike class-specific counters that are limited to predefined classes.",
        "d87bf991-9905-4953-a684-db1638e60f7d": "The interest in counting actions may not align with the dominant class in scenarios such as sports training, where the focus is on identifying specific, infrequent mistakes rather than the prevalent actions. This misalignment occurs when the action of interest is rare and occurs briefly within a larger dataset dominated by other activities.",
        "35b0531e-82ee-46c0-80c8-50dee2b02866": "Wearable devices contribute to counting human actions by utilizing sensors to collect data on various movements, enabling the development of both class-specific and class-agnostic counting methods. Class-specific counters are limited to predefined actions, while class-agnostic counters can tally any action as long as it is the dominant activity in the data. This flexibility is crucial for applications in health monitoring and performance evaluation, allowing for accurate counting even in diverse and complex action scenarios.",
        "d12a4877-43db-44fc-8486-6b789839cb26": "The applications mentioned for counting human actions using wearable devices include health monitoring and performance evaluation.",
        "0b648d23-10d6-451a-8a7b-846aed9d42e8": "Infrequent actions pose challenges in counting human actions as they may be overshadowed by dominant activities, leading to difficulties in detection and accurate counting. Existing methods, often designed for prevalent actions, struggle to identify and quantify these brief occurrences, resulting in potential inaccuracies in performance evaluation and health monitoring.",
        "24c7a67b-81a8-4c3d-8740-17ef880d2245": "The proposed method demonstrates a lower average error of 7.47 in counting actions compared to frequency-based and transformer-based methods, indicating superior performance in handling instances of actions from new classes and subjects not included in the training data.",
        "a463daee-df6d-4b46-9101-8bae1a7fe898": "The availability of the dataset and code on GitHub enhances the research's significance by promoting transparency, reproducibility, and collaboration. It allows other researchers to validate the findings, build upon the proposed method, and apply it to different contexts or datasets, thereby advancing the field of action counting using wearable devices.",
        "e629843b-9292-4cd7-bed8-16a53eb62f83": "The ability to count actions from new classes and subjects not included in the training data implies greater scalability and flexibility in action recognition systems. It allows for the detection of a wider variety of actions, including infrequent or specific behaviors, which is particularly beneficial in applications like health monitoring and sports training. This capability reduces reliance on class-specific counters, making the system more adaptable to diverse real-world scenarios and enhancing its overall effectiveness.",
        "017bc1ce-58df-4187-94e2-114be35a1912": "The primary advantage of using class-agnostic counters over class-specific counters in sensor data analysis is their scalability, as they can tally repetitions from any arbitrary class, making them more versatile in handling diverse activities within the data, especially when the dominant class may not be the focus of interest.",
        "24ca969e-7de9-4466-9172-b000cf1decb4": "The focus might shift from counting dominant actions to identifying infrequent mistakes in scenarios such as sports training and skill evaluation, where the goal is to detect specific errors that occur rarely within a larger set of prevalent actions.",
        "8c12a405-2fcc-4248-bd3c-d462742cc606": "The two significant technical challenges associated with developing an exemplar-based counting method are: 1) devising a convenient exemplar provision scheme, and 2) effectively leveraging the provided exemplars for accurate counting.",
        "0d8325ce-9322-4099-8344-c10f47e3488e": "The proposed method allows users to provide exemplars for counting actions by enabling them to verbally count out loud (e.g., saying \"one,\" \"two,\" \"three\") at the start of the counting process. This vocal input serves as exemplars, which are then identified in the audio sequence using an efficient algorithm that detects their positions based on temporal ordering and distance constraints.",
        "d29316ca-531d-4a08-84d3-156d1c281f6a": "Users are suggested to specify exemplars in the counting process by verbally counting out loud \"one,\" \"two,\" \"three\" at the onset of the counting. Each utterance corresponds to one repetition.",
        "08924186-7ca0-4773-879c-d846f86683ca": "The algorithmic approach developed to detect the positions of counting utterances in the audio sequence involves solving a constrained optimization problem that incorporates constraints on temporal ordering and temporal distance between identified positions.",
        "acdadf88-978e-40f8-a276-f11bfc83bc49": "The proposed method addresses the challenge of leveraging provided exemplars effectively by implementing an intuitive vocal sound-based exemplar provision scheme. Users can specify exemplars by verbally counting out loud, which allows for easy identification of the counting utterances in the audio sequence. An efficient algorithm is then employed to detect the positions of these utterances, ensuring accurate extraction of the exemplars for counting purposes.",
        "99055101-e570-448b-bdef-249baed6f62d": "It is important to consider temporal ordering and distance when identifying counting utterances because these factors ensure accurate detection of the counting events within the audio sequence. Temporal ordering helps maintain the sequence of utterances, while temporal distance prevents misidentification of closely spaced utterances, ensuring that each count is recognized as a distinct event. This is crucial for effectively leveraging exemplars in the counting process.",
        "142eb68a-4f28-4e7c-a847-5d4f6c9019d5": "The identified positions of counting utterances in the exemplar-based counting method serve as reference points for extracting exemplars from the audio sequence. These positions, determined through an efficient algorithm, enable the system to accurately associate each utterance with a specific repetition, facilitating the counting of infrequent actions amidst dominant activities.",
        "e8d4ec23-7fa4-4c1f-a19e-6de98e448f3c": "The proposed exemplar-based counting method aims to improve the analysis of real-world data containing undesired actions by allowing users to specify exemplars of the actions they want to count. This method addresses the challenges of providing exemplars conveniently and effectively leveraging them by using vocal sounds for exemplar specification. Users can verbally count out loud to indicate repetitions, and an efficient algorithm is developed to accurately detect these counting utterances in the audio sequence, enabling precise counting of specific actions even when they are infrequent within the dominant data.",
        "537a9fcf-baf6-403e-9de3-e7372482e696": "The proposed method for specifying exemplars in the counting process involves using vocal sounds, where individuals verbally count out loud (\"one,\" \"two,\" \"three\") at the start of the counting. An efficient algorithm is then employed to detect the positions of these utterances in the audio sequence.",
        "8391f1c0-61b6-4cfd-9479-a7dc201d2ec0": "The algorithm identifies the positions of counting utterances by solving a constrained optimization problem that enforces constraints on the temporal ordering and distance between the identified positions of the utterances. This allows for accurate detection of the counting sounds provided as exemplars during the counting process.",
        "f309a7fc-9de7-431f-8167-8ace994d5e48": "The two constraints considered in the optimization problem for detecting counting utterances are temporal ordering and temporal distance between the identified positions.",
        "0100ff21-a16a-43ec-9a59-42af403370d0": "Once the positions of the counting utterances are identified, the exemplars are extracted from these locations in the audio sequence.",
        "3e1baaaf-cef2-473e-8faa-dc358d646afe": "The similarity map in the proposed exemplar-based counting method is used to compute the relationship between the embeddings of the exemplars and the entire data sequence. It serves as the foundation for generating exemplar-infused embeddings, which are then utilized for moment-by-moment density estimation to derive the final count.",
        "21114822-a751-4b72-992c-3c2f04594ffa": "The techniques used to compute the similarity map between exemplars and the data sequence include generating per-window embeddings for both the exemplars and the data sequence, and then applying Soft-DTW and correlation measures to establish the similarity map.",
        "bc6b1104-7488-40cf-a9db-1d0dd795bb5c": "The initial embedding sequence is generated from the whole data sequence, while the exemplar-infused embedding sequence is created by computing a similarity map between the initial embeddings and the extracted exemplars. Both sequences are then utilized in a density estimation module to estimate moment-by-moment density, ultimately leading to the final count by summing the density values.",
        "30c18b74-87aa-479b-a62a-20074e3e15ca": "The purpose of the density estimation module in the proposed method is to perform moment-by-moment density estimation using the initial and exemplar-infused embedding sequences, ultimately allowing for the calculation of the final count by summing the density values.",
        "53d1f24b-1c16-47fa-a0e8-7c9d2639b1cc": "The final count in the proposed counting method is obtained by summing the density values generated from the moment-by-moment density estimation module, which processes the initial and exemplar-infused embedding sequences.",
        "242727fc-3fac-4472-8e2b-1ea0a1b174c1": "The significance of using vocal sounds for specifying exemplars in this counting approach lies in their intuitive and non-intrusive nature, allowing for clear identification of counting positions in the audio sequence. By verbally counting \"one,\" \"two,\" \"three,\" the method effectively marks each repetition, facilitating accurate extraction of exemplars for further processing in the counting algorithm.",
        "f698506d-0fb2-4da3-991a-f05e6ad1f02f": "The primary purpose of the Temporal Density Map in the proposed method is to visualize the 1D density profile of the action counts, allowing for better interpretation and analysis of the sensor and audio data corresponding to the actions of interest.",
        "5a23c71e-b658-4492-9f01-5544c1f427e4": "The novel distance-preserving loss enhances similarity measurement by ensuring that high-dimensional embeddings maintain local patterns, thereby preserving the similarity relationships found in lower-dimensional spaces. This approach improves the model's ability to accurately assess similarities between different data points, particularly in the context of limited training data.",
        "05c6f495-cae9-4b7d-a88e-46ce3823db21": "The Diverse Wearable Counting dataset (DWC) plays a crucial role in the development and evaluation of the proposed method by providing synchronized sensor and audio data from 37 subjects performing 50 distinct action categories. This dataset enables the implementation of a novel distance-preserving loss for similarity measurement and supports the exemplar-based data synthesis pipeline, enhancing training data and improving counting accuracy. Additionally, its inclusion of non-predominant actions offers a realistic context for evaluating the method's performance in real-world scenarios.",
        "70ebd277-49cb-4741-9de3-692a0f15fc28": "The exemplar-based data synthesis pipeline enhances the training process by generating additional training data from limited samples, thereby improving model performance. It utilizes audio-specified exemplars to create diverse and realistic data representations, which help maintain local patterns and similarity relationships in high-dimensional embeddings. This approach addresses the challenge of limited training data and enables more effective learning from the Diverse Wearable Counting dataset.",
        "7060d59a-e35e-4bd8-9799-c9a1b1b58520": "The input for the processing pipeline includes sensor signals and audio signals containing the utterances \"one,\" \"two,\" and \"three,\" corresponding to three repetitions of the action of interest.",
        "88cf8cd9-54dd-4eb1-bd8f-750cc245c24d": "The Diverse Wearable Counting dataset comprises data from 37 subjects performing 50 distinct action categories.",
        "dcdef816-1b37-4a44-a4e0-bc9e63e5bb19": "The DWC dataset is distinguished from other datasets by its inclusion of synchronized audio data with vocal sounds that specify exemplars, collected from 37 subjects performing 50 distinct action categories. Additionally, it captures instances where the action of interest is not the predominant action, offering a more realistic representation of real-world scenarios.",
        "b6e022d1-0e9c-441b-b16b-6f6aacacc2c1": "The significance of using audio-specified exemplars in the counting process lies in their ability to provide clear, synchronized cues that enhance the accuracy of action recognition and counting. By incorporating vocal sounds that specify the actions, the method can better differentiate between similar actions and improve the overall performance of the counting system, especially in complex or noisy environments. This approach also aids in synthesizing training data, which is crucial given the limited availability of labeled data.",
        "a979903a-b7c9-4bc6-927c-74f19c4edec6": "The total count output is derived by summing the values of the intermediate 1D density profile, which represents the occurrences of the actions of interest over time.",
        "a1af9298-f041-450e-af96-1993f63b1429": "The proposed method addresses challenges in accurately counting actions in real-world scenarios by introducing a novel distance-preserving loss for better similarity measurement, utilizing an exemplar-based data synthesis pipeline to enhance training data, and leveraging synchronized audio data to specify action exemplars. This approach allows for improved representation of complex action sequences where the target action may not be predominant, thus reflecting more realistic conditions.",
        "14a2c33e-6d72-4826-8600-d5fa253b2511": "The main purpose of the Diverse Wearable Counting dataset (DWC) is to provide a comprehensive collection of sensor data sequences with synchronized audio exemplars from multiple subjects performing various actions, enabling the development and evaluation of novel counting methods that incorporate audio specifications and address real-world scenarios.",
        "1828396e-fcf5-4f0c-ad4c-6a94c846d908": "The proposed method utilizes audio by incorporating synchronized vocal sounds to specify exemplars of actions that need to be counted. This approach enhances action counting by providing clear audio cues that guide the counting process, particularly in scenarios where the target action may not be the most prominent in the data sequence.",
        "8c367593-e86d-4e58-874f-cd357bdf6259": "The three main contributions of the paper are: 1) the introduction of a novel strategy for using audio to specify exemplars for counting; 2) the development of a new counting method that incorporates a distance-preserving loss and an exemplar-based data synthesis pipeline; and 3) the creation of a unique dataset, the Diverse Wearable Counting dataset (DWC), which includes multiple data modalities for practical counting in real-world scenarios.",
        "c0bb2eb9-d688-4789-96cf-be3979ed60ff": "The Diverse Wearable Counting dataset (DWC) differs from existing datasets by incorporating synchronized audio data with vocal sounds that specify exemplars, alongside sensor data sequences. This multimodal approach allows for a more realistic representation of actions, including instances where the target action is not the predominant one in the sequence, enhancing the dataset's applicability to real-world scenarios.",
        "6f4c5b68-30f7-45be-bdaa-27fc7929a5bf": "The Diverse Wearable Counting dataset (DWC) includes 50 distinct action categories performed by 37 subjects.",
        "ac7bfebf-ba58-4cf5-af0f-159f69147f33": "The inclusion of synchronized audio data in the Diverse Wearable Counting dataset (DWC) is significant because it provides vocal sounds that specify exemplars, enhancing the training process for action counting. This multimodal approach allows for a more realistic representation of real-world scenarios, where the action of interest may not always be the predominant one, thereby improving the robustness and applicability of counting methods.",
        "5c96930b-bbd8-401c-86d6-b8f50710ff50": "The proposed counting method aims to address challenges related to limited training data, the need for realistic action representation in diverse scenarios, and the ability to accurately count actions that may not be the predominant activity in a data sequence. It leverages synchronized audio data to specify exemplars and incorporates an exemplar-based data synthesis pipeline to enhance performance in real-world applications.",
        "b2154a7a-f683-42f9-a6f8-780050a47bf2": "The exemplar-based data synthesis pipeline enhances training data by generating additional synthetic examples that reflect real-world scenarios, particularly in cases where the target action is not the predominant one in the data sequence. This approach, combined with synchronized audio data for specifying exemplars, allows for a more diverse and representative dataset, ultimately improving the performance of counting methods in various applications.",
        "61235bc4-851f-4727-8d62-b36870755f53": "Action counting through wearable devices is applied in health monitoring, sports training, and industrial contexts.",
        "80b6718f-eca2-4500-af26-3a8b45a2fe91": "Including instances where the action of interest is not the predominant action in the dataset enhances the realism and diversity of the training data. This approach allows the model to better generalize to real-world scenarios, where multiple actions may occur simultaneously, thereby improving its robustness and accuracy in action recognition and counting tasks.",
        "d2576825-e3c4-4e61-a6e7-e37cb7c74c2f": "The primary applications of action counting through wearable devices include health monitoring, sports training, and industrial contexts.",
        "f6ab131b-1888-4ea4-9c39-c7e58bf56a51": "Existing counting methodologies limit their adaptability in real-world scenarios primarily due to their focus on specific action categories, which restricts their ability to handle new or untrained actions. Class-specific counters are inadequate for the diverse range of actions encountered, while class-agnostic counters can only effectively count repetitions from the dominant class, failing to address the variability of actions in practical applications.",
        "b769e1ad-a02d-4d9e-a179-59e9e14f116e": "The main drawback of class-specific counters in action counting is their limited adaptability, as they struggle to manage action categories that lack prior training data, making them inadequate and unscalable for diverse real-world applications.",
        "9cc59700-8178-4109-b65b-220eedd470ea": "The alternative approach discussed is class-agnostic counters, which can count repetitions from the dominant class. Its limitation is that it is unable to count actions from less prevalent classes, making it less effective in diverse action scenarios.",
        "f0c023a3-f5ea-4af8-a584-b1b293e6cf6e": "The earlier strategies for action counting mentioned in the context of class-agnostic counters include Fourier analysis, wavelet transforms, peak detection, and singular value decomposition.",
        "e2078f35-f926-4230-9393-c4925b93df05": "Class-agnostic counters may only be effective for counting repetitions from the dominant class because they lack the specificity needed to accurately differentiate between multiple action categories. This limitation arises from their design, which does not account for variations in less frequent classes, leading to potential miscounts or inaccuracies when those classes are present alongside the dominant one.",
        "20763859-94ad-4eaa-82f0-67bca78e6d99": "Existing methodologies have predominantly focused on action categories such as physical exercises, health monitoring, sports training, and industrial activities.",
        "d8aa77a9-7cbd-4cc7-a8b0-70eb4a49532c": "Methodologies based on Fourier analysis and wavelet transforms are utilized in action counting to analyze and process the frequency components of motion data captured by wearable devices. These techniques help in identifying patterns and detecting peaks in the data, which are essential for accurately counting actions, especially in scenarios where class-specific training data is limited. They provide a foundation for developing class-agnostic counters that can adapt to various action categories.",
        "a515ef64-fe94-43c2-815f-5db2a4f68a22": "Class-specific counters face significant challenges when dealing with actions that have no prior training data, primarily due to their specialization, which limits adaptability. Without prior examples, these counters struggle to accurately recognize and count new action categories, making them inadequate and unscalable for the diverse range of actions encountered in real-world scenarios.",
        "2b639641-8fbe-448c-b5ea-89cc04c2593f": "Wearable devices are used for action counting in health monitoring, sports training, and industrial contexts.",
        "73cffc64-c393-4eda-82e0-0322934017eb": "The main limitation of class-specific counters in action counting is their lack of adaptability, particularly when encountering classes with no prior training data, making them inadequate and unscalable for the diverse range of action categories in real-world scenarios.",
        "4e33a1ac-6dc5-468c-a266-7b5d951e764f": "Class-agnostic counters are designed to count repetitions of actions without being tied to specific classes, making them more adaptable to new or unseen classes. In contrast, class-specific counters are specialized for particular classes, which limits their scalability and effectiveness when encountering classes with no prior training data.",
        "6a45ede6-d08d-4447-a162-efa21db60a59": "Previous analyses for repetitive action counting in videos have included Fourier analysis, wavelet transforms, peak detection, and singular value decomposition. More recent approaches have focused on leveraging temporal self-similarity to count actions from the dominant class.",
        "befdce95-fc7a-462d-850d-4e240940cb1a": "Recent works that have focused on leveraging temporal self-similarity for counting repetitive actions include Dwibedi et al. (2020) and Hu et al. (2022).",
        "b1b011d7-4517-430c-a7d4-dbe5639a5deb": "The significance of the contribution regarding wearable devices in action counting lies in its innovative approach to exemplar-based counting. It is the first to utilize vocal sounds for specifying exemplars, enabling more adaptable and scalable counting of repetitive actions, particularly in scenarios with no prior training data. This distinguishes it from existing methods in other fields, enhancing the functionality of wearable devices in real-world applications.",
        "0e1df606-13d4-4b62-9e46-aff3f4cee9bd": "The proposed method for specifying exemplars differs from existing approaches in computer vision by introducing a novel strategy that utilizes vocal sounds to define and detect exemplars, specifically tailored for wearable devices. This contrasts with traditional methods that rely on visual features or class-specific counters, which are often limited in adaptability and scalability.",
        "9b99f917-04ca-4173-bb89-f4883c658507": "Predefined vocal sounds serve as a novel mechanism for specifying exemplars in the innovative strategy introduced in the document. This approach allows for the detection and counting of repetitive actions in real-time, particularly in wearable devices, enhancing adaptability and scalability beyond traditional class-specific methods.",
        "380df8b9-3bb2-41b5-9669-1c010a4d97f6": "The adaptability of action counting methods is crucial when faced with classes having no prior training data because it allows for effective counting and recognition of new actions without relying on class-specific counters, which are limited and unscalable. This flexibility enables the system to generalize across a wider range of action categories, ensuring accurate performance in real-world scenarios where diverse and previously unseen actions may occur.",
        "015208fa-edde-449b-8125-a413945e0008": "Some of the earlier strategies for counting actions include Fourier analysis, wavelet transforms, peak detection, and singular value decomposition. These techniques employ mathematical transformations and signal processing methods to analyze and detect patterns in action data.",
        "e45338c9-1e51-476d-87bb-8f4901865d0f": "The document highlights the novelty of the proposed approach by introducing a unique method for specifying exemplars through vocal sounds, specifically designed for wearable devices. This distinguishes it from previous methods that primarily focus on class-specific or class-agnostic counters and exemplars in computer vision, making it a pioneering effort in the context of action counting.",
        "c40cdd23-6925-4ce3-be1c-d819bed4dba6": "The innovative strategy introduced for specifying exemplars in wearable devices involves the act of uttering and detecting predefined vocal sounds, allowing for a more convenient and efficient method of exemplar identification compared to traditional visual methods.",
        "517ced69-702a-4e7d-b3c7-aa8185f77351": "Recent works by Dwibedi et al. (2020) and Hu et al. (2022) utilize temporal self-similarity to effectively count repetitive actions from the dominant class in time-series data. They introduce innovative methods for specifying exemplars through vocal sounds, addressing the challenges of visualizing and parsing sensor data, and enabling efficient and immediate exemplar identification without the need for cumbersome procedures like bounding box drawing.",
        "bd388b07-a98e-49fd-9af3-9e76f10f448d": "The exemplar-based counting approach for wearable devices differs from traditional computer vision methods by allowing users to specify exemplars through vocal sounds rather than drawing bounding boxes. This innovation addresses the challenges of visualizing and parsing time-series sensor data, which is more complex than image data, and emphasizes the need for immediate and efficient exemplar identification without time-consuming procedures.",
        "bbd2f1da-054b-41e9-8f63-476d98da5a57": "The challenges associated with visualizing and parsing sensor data compared to image data include: 1) Greater difficulty in visualization and semantic parsing of time-series data; 2) The complexity of manually determining the temporal extents of actions, as opposed to simply drawing bounding boxes for objects in images; and 3) The need for immediate results in sensor-based counting, which necessitates a more efficient and convenient process for providing and identifying exemplars, avoiding time-consuming steps like visualization and drawing.",
        "66339a42-ae2e-46a3-b420-9358f18f1807": "Determining the temporal extents of human actions in time series data is more difficult than drawing bounding boxes in images due to the challenges in visualizing and semantically parsing sensor data, the complexity of accurately identifying action durations, and the need for immediate results that require a more efficient and convenient exemplar identification process.",
        "b838dfc2-8851-428d-9662-03edc7322e06": "Requiring immediate results in sensor-based counting for exemplar identification necessitates a streamlined and efficient process for specifying and detecting exemplars. This urgency complicates the visualization and semantic parsing of sensor data, as well as the determination of temporal extents of actions, making it essential to avoid time-consuming methods like data transmission and manual delineation. Consequently, the approach must prioritize convenience and speed to meet real-time demands.",
        "70152abf-d7ea-4d50-b6f3-6db11ea8b7b3": "The need for convenience and efficiency significantly influences the design of exemplar-based counting methods for wearable devices by prioritizing quick and intuitive user interactions. This is essential because users require immediate feedback from sensor data without engaging in complex or time-consuming tasks, such as visualizing data or manually defining temporal extents. The innovative approach of using vocal sounds to specify exemplars addresses these challenges, allowing for a more seamless and user-friendly experience in counting repetitive actions.",
        "07f904a8-7e75-4dbf-8e99-3de01e0a9a23": "Some existing methods in computer vision that utilize exemplars for counting objects include those by Liu et al. (2022), Yang et al. (2021), Ranjan et al. (2021), Ranjan and Hoai (2022b), Shi et al. (2022), Lu, Xie, and Zisserman (2018), You et al. (2023), Nguyen et al. (2022), and Huang, Ranjan, and Hoai (2023). These methods typically require users to specify exemplars by drawing bounding boxes around objects in images.",
        "b05e9879-10e8-4591-8fb0-065447a32d99": "The approach is considered pioneering because it uniquely introduces a method for specifying exemplars through vocal sounds in wearable devices, addressing the challenges of temporal data analysis. Unlike traditional methods that rely on visual bounding boxes, this strategy simplifies the process of exemplar identification in time-series data, making it more efficient and user-friendly for immediate sensor-based counting.",
        "04ae64de-9127-4d90-9610-21a508cf4547": "The limitations of current methods requiring users to specify exemplars through bounding boxes in time-series data include: \n\n1. **Complex Visualization**: Sensor data is harder to visualize and semantically parse than images, complicating exemplar specification.\n2. **Temporal Extent Challenges**: Determining the temporal boundaries of actions in time-series data is more difficult than drawing bounding boxes for objects in images.\n3. **Efficiency Requirements**: Time-sensitive applications necessitate a quick and efficient exemplar identification process, which is hindered by the time-consuming nature of traditional bounding box methods.",
        "49c3497a-71ce-4331-b8be-5af1ae6c50e7": "The primary objective of the proposed method is to tally the occurrences of a specific action class within a sequence of sensor data, utilizing synchronized audio sequences to identify exemplars and derive the overall count.",
        "e2ab869e-2c87-403f-b360-04e720221bb0": "The method utilizes audio sequences by first extracting exemplars from the audio data, which correspond to predetermined vocal sounds indicating action repetitions. These exemplars are then used to compute similarities with the sensor data sequences, facilitating feature fusion. This process allows the model to effectively count occurrences of specific actions by integrating information from both the audio and sensor data.",
        "bd0b9ac3-3791-4fa6-8f40-1a6def1a8ee8": "The two fundamental stages of the proposed approach are: (1) identification of exemplars, and (2) utilization of exemplars to derive the overall count.",
        "946ccf15-b763-46fc-ab4d-b0187cd14475": "Exemplar extraction plays a crucial role in the overall method by identifying predefined utterances in the audio data, which serve as reference points for subsequent analysis. This process enables the extraction of per-window embeddings and facilitates the computation of similarity between the entire sensor sequence and the extracted exemplars. Ultimately, this aids in feature fusion and the estimation of the temporal density map, allowing for accurate counting of specific action classes within the sensor data sequence.",
        "c137fdb2-76eb-4995-981d-31ff2a489ae2": "The purpose of the sliding window feature embedding module is to extract per-window embeddings from the sensor data sequence, which are then used to compute similarities with exemplars for feature fusion and subsequent density estimation.",
        "69d7584b-0121-4862-8033-1df168161a02": "The similarity between the sensor sequence and exemplars is computed through exemplar-based similarity estimation, which utilizes a Soft-DTW (Dynamic Time Warping) approach to create a similarity map. This process involves embedding the sensor data and exemplars, followed by calculating their similarity to facilitate feature fusion and density estimation.",
        "556b4a95-a7f9-4e27-9ba2-d4843635ea77": "The exemplar-infused feature embedding module enhances the process by integrating the extracted exemplars into the feature representation, allowing for improved similarity estimation and more accurate counting of action classes within the sensor data sequence.",
        "367c6a07-c583-4f1c-ba56-51ed35c516c7": "The temporal density map is significant in the proposed approach as it provides a structured representation of the frequency of specific action classes over time within the sensor data sequence. By estimating the density based on fused features and sensor embeddings, it enables accurate counting of action occurrences, facilitating better understanding and analysis of the temporal dynamics of the actions being monitored.",
        "eb796dcc-92e9-4604-a7e3-d3739ceeda4a": "The predefined vocal sounds used in the audio sequence are \"one,\" \"two,\" and \"three,\" which correspond to the initial three repetitions of the action being counted in the sensor data sequence.",
        "3ef4cf8c-ca18-479b-8d75-1ed28afe5200": "The proposed method involves five modules: (1) Exemplar Extraction, (2) Sliding Window Feature Embedding, (3) Exemplar-Based Similarity Estimation, (4) Exemplar-Infused Feature Embedding, and (5) Density Estimation.",
        "80a3361e-ddef-45b6-99e1-90845e6da645": "The two fundamental stages of the proposed approach for counting action occurrences in sensor data are: 1) identification of exemplars, and 2) utilization of these exemplars to derive the overall count.",
        "05041635-0cc2-4940-a2de-be5765a2a325": "The method utilizes audio sequences by synchronizing predetermined vocal sounds (\"one,\" \"two,\" \"three\") with the sensor data to identify specific action classes. It extracts exemplars based on the temporal positions of these sounds, ensuring the preservation of their order and proximity. This integration of audio and sensor data allows for accurate counting of action occurrences through a series of processing modules that analyze the fused features.",
        "36b4d303-78d7-42f5-93f7-0cee0b55ac01": "The five modules involved in the proposed approach are: (1) exemplar extraction, (2) sliding window feature embedding, (3) exemplar-based similarity estimation, (4) exemplar-infused feature embedding, and (5) density estimation.",
        "350c71f0-e836-4018-ae46-8698d3b1b7c8": "The purpose of exemplar extraction in this approach is to identify specific temporal positions in the sensor and audio data that correspond to predefined vocal sounds, ensuring the preservation of temporal ordering and proximity. This extraction serves as the foundation for accurately counting occurrences of the action class within the sensor data sequence.",
        "246317a3-ddca-40cc-b4a2-4292950f7980": "The naive approach to exemplar extraction relies on a pre-trained classifier to select the window with the highest classification score without considering the order or proximity of the predefined vocal sounds. In contrast, the proposed method formulates the exemplar extraction as a constrained optimization problem that explicitly incorporates both temporal ordering and proximity, ensuring that the selected exemplars maintain the correct sequence and are not too far apart in time.",
        "dd4795bd-88e4-4f86-9ede-d70d6ba9e700": "The two critical cues highlighted for temporal position detection are: (1) temporal ordering, which preserves the sequence of sounds (one, two, three), and (2) temporal proximity, which ensures that the distance between the predefined sounds is not excessively large.",
        "476f98c0-d31b-4067-9ea7-4634021d325d": "The temporal position detection in the proposed method is formulated as a constrained optimization problem, where the goal is to maximize the product of classification scores for three temporal positions corresponding to predefined vocal sounds (one, two, three). The optimization is subject to constraints that ensure the indices of the selected windows (i, j, k) maintain the order (1 \u2264 i < j < k \u2264 M) and that the distance between the first and last sounds is not excessively large (k - i \u2264 R).",
        "c5e1f2d3-4eef-40e3-8178-b92e16acda3c": "The constraints placed on the indices i, j, and k in the optimization problem are: \n\n1. \\(1 \\leq i < j < k \\leq M\\) \n2. \\(k - i \\leq R\\)\n\nThis ensures that the indices are in increasing order and that the distance between the first and last indices does not exceed a specified range R.",
        "1af061f6-fe86-41d8-89d6-4bcbddb3c1f7": "The term \"temporal proximity\" refers to the requirement that the distance between two predefined sounds in the audio sequence should not be excessively large, ensuring that the sounds occur close together in time.",
        "c15538e5-c88c-46a5-99a0-4dea7dddffbf": "Preserving the order of the sounds \"one, two, three\" during exemplar extraction is crucial because it ensures the correct temporal sequencing of actions, which is essential for accurately identifying and counting occurrences of the action class. This temporal ordering allows the model to leverage both the sequence of sounds and their proximity, leading to more reliable and contextually relevant feature extraction.",
        "98e401e1-6cd8-4241-b2ce-4fee1fededad": "The two critical cues that the proposed method fails to exploit in temporal position detection are: (1) temporal ordering, which requires the preservation of the order of sounds, and (2) temporal proximity, which ensures that the distance between two predefined sounds is not excessively large.",
        "eeff8a66-f604-4d0a-bb14-55e50371846d": "The temporal position detection is formulated as a constrained optimization problem, where the goal is to maximize the product of classification scores \\(C1_i C2_j C3_k\\) for indices \\(i, j, k\\) of a sliding window, subject to the constraints \\(1 \\leq i < j < k \\leq M\\) and \\(k - i \\leq R\\). This is solved using dynamic programming, with the overall complexity being \\(O(R(M - R + 1))\\).",
        "8f9d996d-2451-47c5-ab29-6176282bacd2": "In the optimization problem, the indices i, j, and k represent the positions of the sliding windows corresponding to the first, second, and third predefined sounds, respectively.",
        "5299e242-86aa-45c0-b712-257b3fe3d865": "The constraint \\( k - i \\leq R \\) in the optimization problem ensures that the indices \\( i \\), \\( j \\), and \\( k \\) representing the temporal positions of sounds are not too far apart, thereby maintaining temporal proximity. This prevents excessive gaps between the detected sounds, which is crucial for accurately capturing the intended sequence and timing of events in the audio signal.",
        "df915e88-3f55-4dfd-97a5-9afe5a97d999": "The audio signal is divided into M overlapping sliding windows, each lasting one second with a step size of 0.1 seconds.",
        "c720134c-ba2c-4a43-9b18-4f2f1beab78d": "The BCResNet classifier is used to compute classification scores for overlapping sliding windows of audio signals, which are essential for solving the temporal position detection optimization problem. It provides the necessary classification scores (C1, C2, C3) for each window, enabling the algorithm to optimize the selection of indices that respect the constraints of temporal ordering and proximity.",
        "95b912d6-9abe-496b-aa66-363413928b07": "The time duration of each sliding window used in the analysis is one second, with a step size of 0.1 seconds.",
        "c456d235-d773-4c79-8603-bf8b692c445a": "The complexity of the algorithm is O(R(M - R + 1)), where R is the upper bound for the temporal distance and M is the number of overlapping sliding windows. As R increases, the complexity grows linearly with R, while the term (M - R + 1) indicates that the complexity also depends on the number of windows M, particularly as R approaches M.",
        "58a13bfe-ad05-48c7-959c-e5f33d63cba5": "The variable \\( X \\) represents a sensor data sequence, where \\( N \\) is the length of the sequence and \\( d \\) is the number of sensor values at each time step (specifically, \\( d = 6 \\) for data from the accelerometer and gyroscope of a smartwatch).",
        "c450e1b8-5a58-4b4d-a331-0ce09b91752e": "The dynamic programming optimization must be run M - R + 1 times for M - R + 1 groups of consecutive windows.",
        "8e6e7af4-b69c-4b22-8644-fabcda5c7646": "The primary optimization constraint used in the algorithm is i < j < k.",
        "483221a6-b0b8-447f-a8dd-1244f4dcf198": "The overall complexity of the algorithm is calculated as O(R(M\u2212R+1)), where R is the number of consecutive windows and M is the length of the sensor data sequence. This is derived from the algorithm's complexity of O(R) for each group of R consecutive windows, which is executed M\u2212R+1 times.",
        "a59690f5-4631-4106-9a0c-5526ebd6205e": "In the context of the optimization problem, the variables i\u2217, j\u2217, and k\u2217 represent the locations of the three exemplars identified from the sensor data sequence, subject to the constraint that i < j < k.",
        "30623bd6-d264-4efc-acc1-552b3a655392": "Only the two locations with the highest classification confidence are retained as exemplars to minimize the impact of noisy data and ensure that the selected exemplars are the most representative of the underlying patterns in the sensor data. This approach enhances the reliability of the exemplars used for further analysis.",
        "6ff143c6-a24f-4dd9-b731-e70a883c2a4e": "The three different scales used to extract exemplar sequences are: X[s\u221210 :s+10], X[s\u221220 :s+20], and X[s\u221240 :s+40].",
        "1d1aee13-bf19-49c6-9be7-069a15dc1646": "A total of six exemplars are generated from the two locations and three scales.",
        "2d54e7be-535e-4a68-8c7d-04af5e87f33e": "The rationale behind using a multi-scale approach for counting actions is to capture actions at various levels of granularity. By extracting exemplar sequences at different scales from key positions, the method allows for a more comprehensive analysis of the actions, accommodating variations in their temporal extents and improving classification accuracy.",
        "3bea9d5a-0eed-4902-bc6c-8e0fc1c4fa0e": "Using window-level sensor representation is necessary because individual time step values provide limited information. By aggregating data into non-overlapping windows, we capture more contextual information and patterns, allowing for better analysis and classification of actions at various levels of granularity. This approach enhances the robustness of the model against noise and improves overall performance.",
        "5f2a753b-e3e4-4050-a93a-e6c646a294a0": "The sensor data sequences are partitioned into non-overlapping windows, with each window containing a fixed number of consecutive time steps. For feature embedding, groups of R consecutive windows are optimized to identify exemplars, and a multi-scale approach is used to extract sequences around the identified locations, resulting in six exemplars for further analysis.",
        "a2ea2a49-7188-4bdb-bf6f-fd4e6bd589ee": "The context mentions sensor data from a smartwatch, specifically from the accelerometer and gyroscope. At each time step, 6 sensor values are recorded.",
        "3110c4eb-667d-4d4a-8b03-8225d004266c": "The purpose of embedding the sensor data points into a high-dimensional representation using the mapping \u03d5 is to transform the original sensor values into a format that enhances the ability to estimate similarity between sequences, facilitating more effective comparison and analysis through methods like correlation and Dynamic Time Warping (DTW). This transformation helps mitigate issues related to scale and offset sensitivity in correlation and overreaction to static data in DTW.",
        "9012e63a-280f-433f-9928-14a41be8b88c": "The similarity map S between the sensor embedding X\u2032 and the exemplar embedding E\u2032 is estimated by combining correlation and Soft-DTW methods. First, the correlation is computed as Sc = ReLU(Norm(X\u2032 \u2297 E\u2032)), where \u2297 denotes the correlation operation. Then, Soft-DTW is applied to the sliding window of X\u2032 to obtain Sd_i = Soft-DTW(X\u2032[i\u2212k/2, i+k/2], E\u2032). Finally, Sd is normalized and passed through a ReLU layer to produce the final similarity map S = ReLU(Norm(Max(Sd) - Sd)).",
        "8afd0699-7468-4a87-8518-c4a2944b4007": "Correlation and Dynamic Time Warping (DTW) are not effective for estimating similarity between X\u2032 and E\u2032 because correlation is sensitive to scale and offset differences, while DTW can overreact to static data. These limitations hinder their ability to accurately capture the true similarity in the high-dimensional embeddings.",
        "efde1447-dd29-44eb-823e-30e1357ba185": "The ReLU function in the computation of the correlation similarity \\( S_c \\) serves to eliminate negative values resulting from the correlation operation, ensuring that the similarity measure is non-negative. This is crucial for effectively comparing the sensor embedding \\( X' \\) and the exemplar embedding \\( E' \\), as it mitigates the impact of scale and offset differences.",
        "e2048f62-dbad-4c5f-8eb1-646c46548ec1": "The Soft-DTW similarity calculation differs from traditional DTW by providing a smoother and more flexible alignment between sequences. While traditional DTW can be overly sensitive to static data and may produce abrupt changes in similarity scores, Soft-DTW incorporates a differentiable approach that allows for gradual transitions and better handling of noise in the data. This makes Soft-DTW more effective in estimating similarity between the high-dimensional embeddings of sensor data and exemplars, as it mitigates the issues of scale and offset sensitivity present in correlation and the rigidity of traditional DTW.",
        "0095dfdf-14d8-4f55-831d-7a4e2dc615ee": "Zero-padding in the correlation operation is significant because it preserves the length of the output signal, ensuring that the similarity map Sc has the same length as the input sequence embedding X\u2032. This allows for a direct comparison between the two sequences without losing information at the edges, which is crucial for accurate similarity estimation.",
        "ab4a9239-e66f-4f6e-9644-5b4cc697da31": "In the context of calculating the Soft-DTW similarity, the sliding window is defined as the segment of the sequence embedding X\u2032 that spans from index \\(i - \\frac{k}{2}\\) to \\(i + \\frac{k}{2}\\), where \\(k\\) is the length of the exemplar embedding E\u2032.",
        "04fa9c87-3f32-4a8a-9838-7209ea5bc835": "The normalization technique applied to the Soft-DTW similarity values before the ReLU layer is the operation \\( \\text{Norm}(\\text{Max}(S_d) - S_d) \\).",
        "0d19cc03-5689-4d32-babb-99233f357659": "In the calculation of Soft-DTW for the sliding window, the variable k represents the length of the exemplar embedding E\u2032.",
        "897e844a-8466-491d-98aa-746a83f32979": "The combination of correlation and Soft-DTW improves the estimation of similarity between embeddings by leveraging the strengths of both methods while mitigating their weaknesses. Correlation provides a robust measure of similarity that is less sensitive to scale and offset when applied to the entire sequence embedding, while Soft-DTW effectively handles temporal variations in the data by aligning sequences. This dual approach allows for a more accurate and nuanced similarity map, capturing both global and local patterns in the embeddings.",
        "1f940636-44a7-4f7a-ae8a-5cdb8bbde226": "The purpose of combining DTW and correlation in the similarity estimation process is to leverage the strengths of both methods: correlation provides a global similarity measure between the whole sequence and the exemplar, while Soft-DTW captures local similarities by assessing the distance between the exemplar and sliding windows of the sequence. This combination allows for a more comprehensive and nuanced similarity profile that emphasizes relevant features while suppressing irrelevant ones.",
        "1faf8f2d-ab0c-4aa7-a07c-fd0b787b9c80": "The correlation between the whole sequence embedding and the exemplar embedding is computed using the formula \\( Sc = \\text{ReLU}(\\text{Norm}(X' \\otimes E')) \\), where \\( \\otimes \\) denotes the correlation operation with zero-padding to maintain the length of the signals.",
        "35232c5f-8914-41a8-97f1-76bf609352d5": "The Soft-DTW similarity plays a crucial role in the similarity estimation process by calculating the distance between the exemplar embedding and a sliding window of the whole sequence embedding. This distance is then transformed into a similarity measure, ensuring non-negativity, which is combined with the correlation-based similarity to create a refined similarity profile that emphasizes relevant features.",
        "73164304-b3e6-4bb3-a835-e01950134883": "The similarity measure is transformed from a distance metric to a non-negative similarity measure by taking the negative of the Soft-DTW distance and adding the maximum value of the distance. This process ensures that the resulting similarity values are non-negative. Specifically, the transformation is expressed as \\( Sd = ReLU(Norm(Max(Sd) - Sd)) \\), where \\( Sd \\) represents the Soft-DTW distances.",
        "6cafddf0-6db5-48e5-89db-ea2cfd4d1aa6": "In the context of similarity computation, Sc represents the correlation between the whole sequence embedding and the exemplar embedding, while Sd represents the Soft-DTW similarity between the exemplar embedding and the sliding window on the whole sequence embedding.",
        "2901bb6a-fd15-43f9-b967-15d537bc3a14": "The final similarity profile \\( S \\) is obtained by element-wise multiplication of the individual components \\( Sc \\) and \\( Sd \\), expressed as \\( S = Sc \\odot Sd \\). Here, \\( Sc \\) represents the correlation between the whole sequence embedding and the exemplar embedding, while \\( Sd \\) is derived from the Soft-DTW similarity between the exemplar embedding and the sliding window of the whole sequence embedding.",
        "1e8aaeaa-0dc9-4e0c-9129-e1656fadc275": "The significance of using a sliding window on the whole sequence embedding when calculating Soft-DTW similarity lies in its ability to capture local variations and patterns within the sequence. By applying Soft-DTW to a sliding window, the method effectively assesses the similarity between the exemplar embedding and localized segments of the sequence, allowing for a more nuanced comparison that accounts for temporal dynamics and variations in the data. This enhances the overall similarity measure by providing a detailed profile that reflects both global and local features.",
        "9a5ba4b0-1775-47b4-a064-3a65ba7817c7": "The CGAP operation in the exemplar-infused feature embedding process performs channel-wise global average pooling among the exemplars. This operation aggregates the feature representations across different exemplars, allowing the model to emphasize relevant features while suppressing irrelevant ones, thereby refining the overall representation.",
        "19f6c104-ac22-414c-8b52-4cba6436039a": "The element-wise multiplication (\u2299) in the context of refining feature representation serves to combine the similarity profiles from the correlation and Soft-DTW operations. This operation emphasizes features that are relevant to the exemplars while suppressing irrelevant ones, thereby enhancing the overall feature representation for improved performance in subsequent processing stages.",
        "faf81f50-7638-4b1b-a4ce-f06f2da5076e": "The final similarity profile S considers two exemplars at three scales, resulting in a dimension of S \u2208 R^N_w\u00d76.",
        "6d261c39-1728-465b-92e8-29db9c97db43": "The purpose of the similarity map S in the exemplar-infused feature embedding process is to generate a refined representation that emphasizes features related to the exemplars while suppressing irrelevant features.",
        "d0d09cc4-4b96-4aed-8d2c-8509b6a6d902": "The CGAP (Channel-wise Global Average Pooling) function refines feature representations by performing global average pooling across the channels of the similarity map, emphasizing features related to exemplars while suppressing irrelevant ones. This process enhances the quality of the feature embeddings, leading to more accurate representations for subsequent tasks.",
        "a5e77c0f-d512-4458-81d9-44bc73d0366b": "The Kfusion blocks play a crucial role in the feature embedding process by refining the representation of features. They emphasize exemplar-related features while suppressing irrelevant ones, utilizing a combination of global average pooling and convolution operations to generate a fused feature representation that enhances the overall quality of the embeddings.",
        "ed6c23ce-33a2-4f26-92fc-09f65aa15369": "The process of generating multi-scale features using the Feature Pyramid Network (FPN) involves the following steps: \n\n1. **Input Feature Processing**: The initial feature representation \\( F \\) is obtained from the exemplar-infused feature embedding.\n2. **Multi-Scale Feature Extraction**: The FPN takes the input feature \\( F \\) and produces multi-scale features \\( Fs1, Fs2, Fs3 \\) that represent the fused features at different scales, from low to high.\n3. **Sensor Feature Processing**: The FPN also processes the input \\( X' \\) through a convolutional layer to generate multi-scale sensor features \\( X'_{s1}, X'_{s2}, X'_{s3} \\).\n4. **Down-Sampling**: Max-pooling is applied to down-sample \\( Fs1, Fs2, X'_{s1}, X'_{s2} \\) to match the length of \\( Fs3 \\) and \\( X'_{s3} \\).\n5. **Concatenation**: The down-sampled features are concatenated and subsequently fed into a density estimation head, which is implemented using a temporal convolution network.\n\nThis process effectively captures and utilizes multi-scale information for improved feature representation.",
        "ce2b3592-b917-4b07-9572-7ba567b4d46b": "The multi-scale features Fs1, Fs2, and Fs3 are derived from the final fused feature F using a Feature Pyramid Network (FPN). This process involves applying the FPN to F, which extracts the multi-scale features from low to high resolution.",
        "cac9e37f-bc69-4f81-ae5c-3d612ea9b066": "The element-wise multiplication operation (\u2299) in the feature embedding process is significant because it allows for the refinement of feature representations by emphasizing exemplar-related features while suppressing irrelevant ones. This operation integrates the similarity map with the feature representation, enhancing the model's ability to focus on relevant information during the embedding process.",
        "3701f14d-6c94-48eb-81de-83699be772fc": "The temporal convolution counting head \u03c8 estimates temporal densities by utilizing a temporal convolution network that processes multi-scale features extracted from a Feature Pyramid Network (FPN). It combines down-sampled features from different scales and sensor embeddings, allowing for effective modeling of temporal patterns to predict density maps. The final output is refined through a counting loss based on the squared error between the predicted and ground truth counts.",
        "add1f92d-b4c1-4b0d-b3a0-eeee3f06865b": "The training loss function \\( L_c \\) is used to measure the squared error between the predicted count \\( \\hat{c} \\) and the actual total count \\( \\text{sum}(T) \\) in the context of counting predictions. It quantifies the accuracy of the model's density estimation by penalizing deviations from the ground truth count.",
        "cd4238e4-6194-4cc7-9a08-6dec7799463b": "The sensor features X\u2032s1, X\u2032s2, and X\u2032s3 are obtained through a Feature Pyramid Network (FPN) that processes the refined feature representation F. Specifically, they are derived from the convolution of the initial sensor input X\u2032, followed by multi-scale feature extraction. These features are then down-sampled using max-pooling to match the length of the highest scale feature Fs3. Finally, X\u2032s1, X\u2032s2, and X\u2032s3 are concatenated and utilized in the density estimation head \u03c8, which employs a temporal convolution network to estimate temporal densities.",
        "8d098a55-1c32-4774-afcf-245eaa0dd0f8": "The final fused feature F is derived from the input feature X\u2032 and the similarity map S by refining the representation through a series of fusion blocks. The similarity map S emphasizes exemplar-related features while suppressing irrelevant ones, and the final feature F is computed by combining the previous features and applying convolutional operations along with normalization and activation functions. Thus, F relates to X\u2032 as its initial input and to S as the guiding factor for feature refinement.",
        "fd3d1def-29c9-4fde-83fe-92acddb6b624": "The purpose of using max-pooling in the context of down-sampling Fs1, Fs2, and X\u2032 s1, s2 is to reduce their dimensionality while retaining the most significant features, ensuring that all down-sampled sequences have the same length as Fs3 and X\u2032 s3 for subsequent concatenation and processing in the density estimation head.",
        "09be4db5-7cb3-4065-9ffb-21efd72a60b2": "The counting loss \\( L_c \\) is calculated as the squared error of the final count, expressed mathematically as \\( L_c = (\\text{sum}(T) - \\hat{c})^2 \\), where \\( \\hat{c} \\) is the ground truth count.",
        "2da81443-35ec-4670-a69e-8c5578ce51a2": "The density estimation head \\( \\psi \\) plays a crucial role in the overall architecture by processing the concatenated down-sampled features to produce a temporal density map, which is essential for accurately predicting the final count of the data sequence. It utilizes a temporal convolution network to enhance the estimation of similarity between exemplars and query data, thereby improving the model's performance in counting tasks.",
        "f64cd801-63f4-43e4-bc18-654a9cd3e26f": "Preserving the similarity relationship within the raw data space \\( X \\) during encoding is crucial because it ensures that the local patterns and distances between data points are maintained in the embedding space \\( X' \\). This is essential for accurately estimating the similarity between exemplars and query sequences, which directly impacts the performance of the model, especially when training data is limited and a robust feature extractor is lacking. By enforcing this preservation through a distance-preserving loss, we enhance the model's ability to capture relevant relationships in the data, leading to improved predictions and overall effectiveness.",
        "5042da7d-2f29-4d25-97ec-1b4f898de79b": "The k-nearest-neighbor graph is constructed by first computing the adjacency matrix \\( W \\) based on the similarity between raw data windows, where \\( W_{ij} = \\exp(-\\frac{||X_i - X_j||^2}{2\\sigma^2}) \\). Then, for each node, the top \\( k \\) nearest neighbors (with \\( k = 150 \\)) are retained from this adjacency matrix. The graph Laplacian \\( L \\) is computed as \\( L = D - W \\), where \\( D \\) is the degree matrix.",
        "202d3e14-f7a4-492e-8da8-36c5426a02b7": "The adjacency matrix \\( W \\) represents the similarity between windows in the k-nearest-neighbor graph, where each entry \\( W_{ij} \\) is computed as \\( \\exp(-||X_i - X_j||^2 / 2\\sigma^2) \\). This matrix captures the local patterns by indicating how closely related each window is to others based on their distances.",
        "a9706704-a3f1-4b95-9f7c-2bb4052e4dda": "The graph Laplacian \\( L \\) is computed as \\( L = D - W \\), where \\( D \\) is the degree matrix (with \\( D_{ii} = \\sum_j W_{ij} \\) and \\( D_{ij} = 0 \\) for \\( i \\neq j \\)) and \\( W \\) is the adjacency matrix representing the similarity between nodes. In this framework, \\( L \\) signifies the structure of the graph and is used to define a distance-preserving loss that encourages the encoder to maintain local patterns in the embedding space.",
        "8187a927-f361-4ce2-9755-31e844fc0782": "The distance-preserving loss \\( L_{pl} \\) is significant in the training process as it encourages the encoder to maintain the local distance relationships of the data in the embedding space \\( X' \\). By enforcing the preservation of local patterns through a k-nearest-neighbor graph, \\( L_{pl} \\) helps ensure that the similarity relationships within the raw data space \\( X \\) are better represented in the embeddings, which is crucial for accurately estimating the similarity between exemplars and query data, especially when training data is limited.",
        "9be74f5d-1287-4ad8-9f50-009c7356e268": "The overall training loss \\( L_{train} \\) combines the counting loss \\( L_c \\) and the distance-preserving loss \\( L_{pl} \\) as follows: \n\n\\[\nL_{train} = L_c + \\lambda L_{pl}\n\\]\n\nwhere \\( L_c \\) is the squared error of the final count, and \\( L_{pl} \\) encourages the encoder to preserve local distance relationships in the embedding space. The parameter \\( \\lambda \\) is a weighting factor set to 0.01.",
        "a7c699e8-c46b-4a73-957a-a60aa47069a2": "The value of \\( \\lambda \\) used in the overall training loss is 0.01. It controls the trade-off between the counting loss \\( L_c \\) and the distance-preserving loss \\( L_{pl} \\) in the training process.",
        "e07ceab4-17b0-4a7f-a1c2-3c95b601d357": "The purpose of building a k-nearest-neighbor graph is to represent the local patterns in the data by capturing the similarities between windows, which facilitates the computation of the graph Laplacian and helps in defining a distance-preserving loss for training the model.",
        "ca9117dc-3338-481f-9755-6ea96268fea4": "The adjacency matrix W in the k-nearest-neighbor graph is computed using the formula \\( W_{ij} = \\exp\\left(-\\frac{||X_i - X_j||^2}{2\\sigma^2}\\right) \\), which represents the similarity between the ith and jth windows. After calculating W, the top k nearest neighbors for each node are retained in the matrix.",
        "71dc74f5-20f5-4d15-9274-7499b3582322": "The parameter k in the construction of the k-nearest-neighbor graph represents the number of nearest neighbors to retain for each node in the graph, indicating how many closest points are considered for establishing local relationships. In this context, k is set to 150.",
        "fbd06c1f-e0a3-49d1-b5af-46c640ad0ce2": "The graph Laplacian \\( L \\) is defined as \\( L = D - W \\), where \\( D \\) is the degree matrix with \\( D_{ii} = \\sum_j W_{ij} \\) and \\( D_{ij} = 0 \\) for \\( i \\neq j \\).",
        "e36dfa05-2039-4b53-9fe9-8e3c301f1137": "The distance-preserving loss Lpl is significant in the training process as it helps maintain the local structure of the data by ensuring that similar data points remain close to each other in the learned representation. This is achieved by incorporating the graph Laplacian, which captures the relationships between neighboring windows, thereby enhancing the model's ability to generalize and reducing the risk of overfitting.",
        "429343a1-bf8e-4542-a709-01bdea0b33df": "Pretraining with synthesized data is necessary to address the scarcity of training data from wearable devices, which can lead to overfitting and poor generalization to out-of-distribution samples. By augmenting the existing dataset with synthesized action templates, the model's robustness and ability to generalize are enhanced, improving its performance in real-world scenarios.",
        "eec9db1c-74e8-44b0-8901-93bfe18206e2": "The two main steps involved in the proposed data synthesis method are: 1) mining action templates from an existing training set, and 2) randomly selecting a template to construct a sequence by aggregating multiple, randomly augmented versions of this template, interspersed with noise or repetitive irrelevant actions.",
        "0cdd3f68-76da-41cb-b215-3a5f0db7d2ec": "The data synthesis method enhances the model's robustness by augmenting the limited training dataset with generated sequences based on mined action templates. This approach helps prevent overfitting and improves the model's ability to generalize to out-of-distribution samples by introducing variability and noise into the training data.",
        "444d987a-6eb0-47bb-b8ba-e83eec1755a5": "Predefined vocal sounds play a crucial role in the data synthesis process by serving as action templates that augment the existing dataset. This augmentation helps improve the model's robustness and generalization capabilities, particularly in scenarios with limited training data.",
        "ed7072f2-ff28-44d8-8e76-e189e7a23f6f": "The introduction of noise or irrelevant actions in the data synthesis method can disrupt the construction of sequences by potentially diluting the meaningful patterns derived from the action templates. This can lead to a less coherent representation of the intended actions, making it harder for the model to learn and generalize effectively. Consequently, while noise may enhance variability, excessive irrelevant actions can hinder the model's performance by introducing confusion in the training data.",
        "22144f80-8269-42fb-9ea0-61d99f1cc564": "The top three categories represented in the DWC dataset are: \n\n1. Daily routines - 25%\n2. Physical exercise - 23%\n3. Rehab training - 14%\n\nThese three categories account for a total of 62% of the samples.",
        "6efc2d56-3745-4154-8c0d-a78521254a84": "The repetition count of samples in the DWC dataset is distributed across several ranges: 0-10, 10-25, 25-50, 50-75, 75-100, and greater than 100. The dataset shows a total of 500 samples, with varying counts in each range, indicating a diverse distribution of repetition counts among the samples.",
        "0a2814cb-a237-4670-bb18-7b5bedf00e7a": "A candidate template must meet the following criteria to be retained during the action template mining process: (1) Strong Confidence: the classification score must be greater than 0.75, ensuring high certainty; (2) Moderate Length: the template must fall within established length bounds to avoid excessively short or long templates.",
        "fc3ebf70-80ad-4c9e-83c8-0d7c03585751": "A classification score threshold of 0.75 is used in the selection of action templates to ensure strong confidence in the templates being selected. This threshold helps to avoid ambiguous cases by retaining only those candidates with a high degree of certainty, thereby improving the quality and reliability of the action templates.",
        "a78829a9-1824-4266-ae66-301154b95f23": "The purpose of constructing an action template database in the context of the DWC dataset is to create a foundation for synthesizing additional training data by identifying and retaining high-confidence, appropriately sized action templates from the original sensor data. This process enhances the dataset's diversity and quality for training models.",
        "f62c9926-24ae-49fb-a5da-6e167184ad33": "The process of remapping indexes in exemplar extraction involves obtaining the temporal positions of predefined utterances and mapping them to the original sensor data's time indexes. In contrast, during data synthesis, the remapping retains the position with the minimum classification score and selects template candidates based on criteria of strong confidence and moderate length. This results in a more selective approach in data synthesis compared to the direct mapping used in exemplar extraction.",
        "067d7606-d82f-40bd-8255-1c0ca15145fd": "The implications of discarding template candidates that fall outside the established length bounds include ensuring that only representative and typical action templates are retained, which enhances the quality and reliability of the action template database. This practice minimizes the risk of including ambiguous or irrelevant templates, ultimately leading to more effective training data synthesis and improved model performance.",
        "2c5d8014-57fd-4a47-83e4-3c14bc9abac5": "In the action sequence generation process, a training sample is synthesized by first extracting action templates from the original data based on predefined criteria, such as strong classification confidence (greater than 0.75) and moderate length. These templates are then used to randomly sample and create new training samples, forming a database that supports the generation of additional action sequences.",
        "14e31a02-3887-433f-b94c-107ff02a516c": "The temporal positions i\u2217, j\u2217, and k\u2217 are crucial in the action template mining process as they identify the locations of predefined utterances within the feature embedding sequence. These positions are then remapped to the original sensor data sequence to form template candidates, which are evaluated based on classification score and length criteria to construct an action template database for synthesizing additional training data.",
        "b0984b59-d397-4227-8e32-b7065fbc94cf": "The sample duration distribution in the DWC dataset provides insights into the typical lengths of actions across various categories, which is crucial for action template analysis. By understanding the duration ranges, researchers can establish appropriate length bounds for action templates, ensuring that only those with moderate lengths are retained. This helps in filtering out excessively short or long templates that may not accurately represent typical actions, thereby enhancing the quality and reliability of the action template database used for synthesizing training data.",
        "711226d3-170d-4abf-9216-15d329dfc433": "The minimum classification score threshold for retaining action template candidates during data synthesis is 0.75.",
        "aae819d8-fd80-43c8-aa99-e3445ab85907": "The process ensures that only templates with a high degree of certainty are selected by applying a strong confidence criterion, where only those candidates with a classification score greater than 0.75 are retained. This threshold minimizes ambiguity and guarantees that selected templates are reliable. Additionally, templates that do not meet established length bounds are discarded, further refining the selection to typical action representations.",
        "f30fa86d-69de-4d97-aa6b-9424356318f3": "The criteria for discarding template candidates based on their length are: (1) Strong Confidence: the classification score must be greater than 0.75, and (2) Moderate Length: candidates that fall outside established length bounds are discarded to avoid excessively short or long templates.",
        "c61c1322-5146-4626-8a51-b0ee8f736a94": "The count of action templates sampled for synthesizing a training sample is determined by first randomly selecting one action template and then uniformly sampling a count within the range [0.8C_l, 1.2C_u], where C_l and C_u are the minimum and maximum counts from the training set, respectively.",
        "12d66e93-3234-42fe-a606-811946d7e142": "The range of scaling factors used for duration scaling of the action templates is between 0.75 and 1.33.",
        "8f1a071b-339a-42b0-872c-f293f6dcb929": "The time shifting procedure involves randomly shifting the temporal position of the stretched or compressed template by a value between -10 and 10 time steps. This adjustment introduces variability in the timing of the action, enhancing the diversity of the synthesized training samples.",
        "d042d265-2abc-4f40-bcfb-60d3d7aef523": "The purpose of adding Gaussian noise to the synthesized training samples is to introduce variability and enhance the diversity of the data, which helps improve the robustness and generalization of the model during training.",
        "7f2584d3-2277-48b4-9c3d-324ffafdf289": "Each training sample incorporates one to two irrelevant action sequences or static noise.",
        "71002515-4d2d-4208-b8d1-28ebe6ea3333": "The significance of constructing an action template database lies in its role as a foundation for synthesizing additional training data. By selecting high-confidence and appropriately sized templates, the database ensures that the generated training samples exhibit a diverse range of temporal characteristics and amplitude variations, ultimately enhancing the robustness and effectiveness of the training process.",
        "de696dbf-cabb-4e7a-a56e-92a3fe005ad0": "The augmentation procedures contribute to the diversity of synthesized training samples by applying various transformations, including duration scaling, time shifting, amplitude scaling, and random noise addition. These techniques introduce variations in temporal characteristics and amplitude, ensuring that each synthesized sample is unique and representative of a broader range of potential actions. This diversity enhances the robustness of the training data, allowing the model to generalize better to different scenarios.",
        "d6a81ba0-e13e-4af4-bf48-881a3b101162": "The purpose of incorporating irrelevant action sequences or static noise into the synthesized training samples is to mimic real-world data conditions, thereby enhancing the diversity of the training data and ensuring it captures a wider range of possible scenarios.",
        "987327dc-a3a2-4ade-b4c5-a5503901ec7b": "The DWC dataset contains 1502 entries and involves 37 subjects in its collection.",
        "ef1b57f7-95a8-4d3d-9ba6-675f9974886c": "The seven broad categories of activities included in the DWC dataset are: kitchen activities, household chores, physical exercises, factory activities, daily routines, instrument-involved activities, and rehabilitation training.",
        "60a92707-5074-44be-947a-a22bbe7e11fa": "Existing datasets for action counting from wearable devices lack diversity in count values and action categories, with samples predominantly featuring the actions of interest. This results in limited variation within the data, which does not adequately represent real-world scenarios.",
        "205891f4-1f24-4c32-9c4d-109b6aa3f44c": "The DWC dataset utilized a Samsung Galaxy Watch 4 for data collection. The sampling frequencies were 100 Hz for both the 3-axis accelerometer and the 3-axis gyroscope, and 16 kHz for audio.",
        "b303aa46-3f0a-4f60-b915-757ed7451a7d": "The DWC dataset represents 50 distinct action classes.",
        "6cb99cb5-77d7-42c0-a053-7b061c04017f": "The device used to collect data for the DWC dataset was a Samsung Galaxy Watch 4.",
        "7ad9c395-9748-4a4b-a799-7a1b49700ed3": "The DWC dataset enhances diversity by incorporating a wider range of action categories and count values, featuring 1502 entries from 37 subjects across seven broad categories and 50 distinct action classes. This contrasts with existing datasets, which often lack variety in both the actions represented and the diversity within individual samples. Additionally, the dataset includes irrelevant action sequences and static noise to better mimic real-world conditions.",
        "37891ae1-ee80-4d33-8665-f467b1085685": "Subjects were instructed to wear the Samsung Galaxy Watch 4 on their preferred hand and perform a list of activities in their chosen order, with each activity accompanied by an illustrative guide and a brief textual description.",
        "7262c8cf-df8e-4ca9-8db9-5d95928b1237": "It is important for the synthesized training data to encapsulate a range of possible scenarios to ensure that the model can generalize well to real-world conditions. By incorporating diverse temporal characteristics, amplitude variations, and irrelevant action sequences, the training data better reflects the complexity and variability of actual user behavior, leading to improved performance and robustness in action recognition tasks.",
        "80eab700-07eb-4db7-b7c0-88c08b6180e2": "A total of 37 subjects participated in the data collection for the wearable-device dataset.",
        "7f312939-0cda-4344-8d63-b21fe01eae2b": "The study used a Samsung Galaxy Watch 4 equipped with a 3-axis accelerometer and a 3-axis gyroscope for data collection, with a sampling frequency of 100 Hz, and an audio recording at 16 kHz.",
        "cc1311bb-b7eb-4473-a6c2-7922e033cd5e": "The sampling frequency for both the accelerometer and gyroscope during data collection was 100 Hz.",
        "a34b37bb-32fa-42e6-b469-ebfce20664e6": "The dataset includes 50 distinct action classes.",
        "6fc09c10-4a87-4fc4-bb36-b716d1eddec5": "Subjects were instructed to sequentially utter the words \"one,\" \"two,\" \"three\" while executing the first three repetitions of each action, with each utterance corresponding to one repetition.",
        "293b5d7c-bc8f-4f5d-ac34-ef71f06accf4": "The purpose of manually inspecting the collected data was to annotate each sample with the number of repetitions of the action of interest and to discard samples where the sensor and audio signals were not synchronized within 30ms.",
        "75f1bdea-87b4-4bcc-b78e-774e9b49fe73": "Some samples were discarded during the data collection process due to a lack of synchronization between the sensor and audio signals, which exceeded the acceptable threshold of 30ms. Additionally, samples from subjects who performed actions incorrectly or took breaks were also excluded.",
        "3bbfabb3-c28d-414e-8b30-050bfb456725": "The data collection process was initiated by asking 37 subjects to wear a Samsung Galaxy Watch 4 while performing a list of activities in their chosen order. Each subject was instructed to sequentially utter \"one,\" \"two,\" \"three\" during the first three repetitions of each action. Data was collected in two phases, with the first phase involving 31 subjects performing each of the 50 actions once.",
        "77f40012-2e34-408b-a95f-fd486fa0b9a8": "The data was collected in two phases. In the first phase, 31 subjects participated.",
        "dad155f2-4824-47d9-9b95-c0918c503040": "The issue that arose due to the use of a third-party program for controlling the audio stream was instances of temporal mismatch between the audio and sensor signals.",
        "53a1cd19-150f-4e5d-9193-34be2b39f658": "The performance metrics used to evaluate the methods in the experiment results on DWC are Mean Absolute Error (MAE) and Root Mean Square Error (RMSE).",
        "c38fb9fc-5881-4cca-ac9c-4c13c4959b17": "The proposed method achieved the lowest Mean Absolute Error (MAE) in the test set, with a value of 7.47.",
        "191a7e43-88fd-48fa-8726-2fecd6c09de6": "The first phase of data collection yielded 1356 entries.",
        "137eca49-d40b-4c78-829d-7fb6cb1a03b9": "The action of interest occupied between 50% to 90% of the temporal duration in the first phase.",
        "85c11b2d-1913-45a0-a98e-2dd805cb0d5e": "The actions selected for the second phase of data collection were: picking up, shaking the clothes, slicing, tennis racket swinging, drinking and eating, and stretching.",
        "897ff4de-ce26-4e6b-82e3-fce974d3c54b": "The second phase of data collection yielded 146 entries.",
        "210e9863-3484-4c60-90ff-632d5f257e99": "The total number of entries in the final DWC dataset is 1502.",
        "897771c9-8970-455b-8ea9-a979e9b44d27": "The range of the action of interest's temporal duration in the second phase is from 10% to 20%.",
        "db5db884-1b8b-44f7-af86-008fff892617": "The final DWC dataset includes 49,258 repetitions.",
        "4da3c4a1-17b0-45e1-9dce-97227f6484f4": "A second phase of data collection was necessary because the first phase lacked sufficient diversity to address various practical scenarios, particularly for counting non-dominant actions. This phase aimed to include additional actions that better represent realistic situations.",
        "079d4cb1-5473-400b-a1b6-7ef02ad534a6": "The six actions identified as potentially underrepresented in realistic situations during the second phase of the study are: picking up, shaking the clothes, slicing, tennis racket swinging, drinking and eating, and stretching.",
        "2ef95125-c84b-443c-bc21-d91fc74e58ab": "During the second phase, 146 entries were collected, and the temporal duration of the action of interest ranged from 10% to 20%.",
        "6ba58817-f124-4663-b2f5-3c182357b8b7": "The final DWC dataset contains a total of 1502 entries and includes 49,258 repetitions.",
        "03c5d38e-d9a6-451a-980f-451fbc389ee2": "The DWC dataset was partitioned into training, validation, and test sets by first dividing the data into two parts: one with 35 action categories and the other with 15. The subjects were then separated into two groups, with 25 subjects assigned to the training set (combined with the 35 action categories) and 12 subjects assigned to the test set (combined with the 15 action categories). The remaining data constituted the validation set, ensuring no shared subjects or action categories between the training and testing data.",
        "4e132014-802e-4181-ae91-b5dc122cb3a6": "The training set included 35 action categories and involved 25 subjects.",
        "95b69604-61f8-4ce2-8002-a55a09b67962": "The methods used as baselines for comparison in the experiments conducted on the DWC dataset were: 1) Mean, which outputs the mean count of samples in the training data; 2) Frequency-based, which predicts the final count based on the estimated dominant frequency; 3) RepNet (Dwibedi et al. 2020); and 4) TransRAC (Hu et al. 2022).",
        "85ac2c3b-0c9d-44af-b390-1d6d49fd9b11": "The \"Mean\" method predicts the average count of samples from the training data, serving as a baseline for comparison with other models in the experiments.",
        "1fdf033d-27c3-46e8-81b2-d2d979834d49": "The \"Frequency-based\" method determines the final count by predicting it based on the estimated dominant frequency of the actions performed in the dataset. This involves analyzing the frequency of occurrences of each action to derive a count that reflects the most prevalent actions in the collected data.",
        "82704c7b-139c-4eb1-aa68-0c83386ccbc2": "The two state-of-the-art methods compared against the proposed method in the study are RepNet and TransRAC.",
        "85b7d179-e80c-4e4c-94ca-680094e1aeab": "The purpose of separating subjects into different groups within the dataset partitioning was to ensure that there were no shared subjects or action categories between the training and testing data, thereby enhancing the validity of the experiments and preventing data leakage.",
        "1e9c0cf8-8f47-4d85-afda-75c28cf6ec8a": "The subjects were divided into three sets: the training set consisted of 25 subjects combined with 35 action categories, the test set included 12 subjects with 15 action categories, and the remaining data was used for the validation set.",
        "6d86a937-49ca-4832-8309-a6437ad88a86": "The four baseline models used for comparison in the proposed method are: 1) Mean, 2) Frequency-based, 3) RepNet, and 4) TransRAC.",
        "7b0a342f-8602-4079-8333-b67d81e787c6": "The \"Mean\" baseline model predicts the mean count of the samples in the training data for each action category.",
        "435fa0dc-248d-4262-a065-31cf823645fa": "The authors adapted RepNet and TransRAC for sensor data by utilizing state-of-the-art feature extractors to enhance the models' performance in counting repetitive actions.",
        "6c67ecd6-3abb-49bb-a44a-1600be5699b0": "The \"Dist. Preserving Loss\" component is significant in the proposed method as it enhances the model's ability to maintain the distribution of action counts during training, leading to improved accuracy in predicting repetitive actions. This is evidenced by the lower Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) achieved when this component is included, indicating its contribution to better performance compared to baseline models.",
        "6e55442e-d9f6-4e89-8c2a-f649a38ca72a": "The MAE value for the model that included all components was 7.66, and the RMSE value was 12.25.",
        "2e6a029e-d1f6-45ae-ac90-d45c27ebe765": "The model's performance improves as the amount of pretraining data increases, as indicated by lower Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) values. Specifically, with more pretraining data, the MAE decreased from 11.30 to 7.66, and the RMSE reduced from 16.15 to 12.25, demonstrating enhanced accuracy and effectiveness in the model's predictions.",
        "6979dfc8-5285-4692-a80d-aa978ee53d7a": "The term \"Constrained Detection\" refers to a component in the proposed method that utilizes specific constraints to improve the accuracy of detecting and counting repetitive actions in sensor data.",
        "be6343fb-3fc0-4bee-a1ba-e34121795c72": "The \"Similarity Estimation\" component significantly enhances the overall model performance by improving accuracy, as indicated by a reduction in Mean Absolute Error (MAE) from 10.32 to 7.66 and a decrease in Root Mean Square Error (RMSE) from 14.96 to 12.25 when included in the model.",
        "61bb61ba-a521-45c7-9eeb-9f451ce18aaa": "The proposed method outperforms the \"Greedy\" approach in temporal location detection, achieving a lower Mean Absolute Error (MAE) of 7.66 compared to the Greedy method's higher error rates. Additionally, the proposed method demonstrates improved performance in terms of Root Mean Square Error (RMSE) as well.",
        "dba5f537-0930-4b7e-b36d-b87b29b64259": "The evaluation metrics used to assess the performance of the temporal location detection model were Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).",
        "90e3a682-d395-4a67-a97e-4aba90a18e06": "The Mean Absolute Error (MAE) is calculated using the formula: MAE = (1/n) * \u03a3|ci - \u02c6ci|, where n is the number of test samples, ci is the ground truth count, and \u02c6ci is the predicted count.",
        "f7d176e5-00a9-4941-8416-45f46036fad4": "The purpose of pretraining the model on synthesized data was to enhance its performance by providing a larger dataset (ten times the volume of the actual training set) for initial training, allowing the model to learn more robust features before fine-tuning on the actual data.",
        "5b9f423e-b862-481b-8063-c57bc2c9060f": "The model was pretrained for 30 epochs and then trained on the actual dataset for an additional 30 epochs, totaling 60 epochs.",
        "37963767-5d41-41dc-b79e-4d68f1ad5e69": "The optimizer used during the model's training process was Adam, with a learning rate of 10^-4.",
        "d7635981-5dc3-4562-8fac-189219bcca36": "The classifier used in the exemplar extraction module was BC ResNet, and it was trained on Speech Command data.",
        "b235e45f-d358-408c-b7ca-81a355becffa": "The audio window classifier, implemented as BC ResNet, was frozen and not updated during the training stages of the model. It was trained on Speech Command data prior to its use in the exemplar extraction module.",
        "d849ac2f-e3d9-4bff-98b2-1e3e0833aa01": "All input sensor data was padded to a common length of 28,000.",
        "d612f036-3aaa-4ebb-a90b-52cce6766348": "The learning rate decay applied at the end of each epoch during training was 0.95.",
        "9535781d-0120-4335-abd3-362c07045071": "The feature extraction process in the proposed model utilized a BC ResNet audio window classifier trained on Speech Command data, which remained frozen during training. In contrast, the baseline models embedded sensor data into per-window embeddings before feeding them into the feature extractor, without the use of a pre-trained classifier.",
        "5a2d2bef-6bf6-47e5-a806-25eb94a8e916": "The optimizer used during the pre-training phase of the model was the Adam optimizer.",
        "b0fd5e83-7bab-4c05-beaa-f4d39ea3c821": "The learning rate set for the Adam optimizer in this study was 10\u22124.",
        "bc058fa5-13bc-408e-a4d3-8c8f612d501d": "The model was trained on the actual training set for 30 epochs after pre-training.",
        "09d13c7c-dc84-433d-9b3a-887df63b4f64": "The learning rate decay factor applied at the end of each epoch was 0.95.",
        "915a63ab-97bc-4427-b8cb-e741d6663993": "The audio window classifier utilized in the exemplar extraction module was BC ResNet (Kim et al. 2021).",
        "f7e6dbbc-d0ad-4ff7-a24e-5103e0a8f756": "The BC ResNet classifier was trained on the Speech Command dataset.",
        "5c9031d6-2826-4aef-9388-a367721b8bcd": "All input sensor data was padded to a common length of 28,000.",
        "962d2649-29f4-4ea0-89af-b275aafab75f": "The standardized window size used for all baseline feature extractors was 50.",
        "370cabbf-ba53-4173-9f02-e48978dc988e": "Each feature extractor consisted of three layers.",
        "63ae2029-248f-4045-8c04-a8777216de44": "No, the BC ResNet classifier was frozen and not updated during the training stages of the model.",
        "bc0e01c3-cca4-48fc-9b84-a01bf23f409f": "The dimension of the feature extraction layer used in the proposed method is 256.",
        "18ad6860-3b6d-4c19-9729-71b38c234d86": "The model utilizes 8 attention heads.",
        "95a1d7a6-181a-4123-ac9b-db5761dd60d9": "The adaptive pooling layer before the counting head is of size 96.",
        "1c38225f-63fd-4866-8b96-59c1584288a8": "The length of the input sensor data for RepNet was padded to 28,000.",
        "0b1fecb2-9955-4409-b879-99b81bd2835c": "No, TransRAC did not require padding for its input data.",
        "bff2baf9-5611-4285-a755-6a8144ae03ab": "The optimizer used during the training phase of the models was the Adam optimizer with a learning rate of 10\u22125.",
        "2d63357a-dfb4-488a-99a0-ba8777497b4f": "The models were trained for 60 epochs.",
        "2858c379-00df-446b-ab2f-4d4b4995fb27": "The loss function employed in the training process was the count loss (L c).",
        "c04ab6c4-7c71-4005-8d51-aeab17955d53": "The proposed method achieved a minimum 30% lower MAE compared to other approaches, including strong baselines like RepNet and TransRAC.",
        "325d7364-45dd-4596-b4b6-6ea432fb4275": "The MAE value for RepNet when using the original transformer variant was 10.82.",
        "5578250b-e131-437b-a957-e863e93b87e5": "The MAE values for RepNet using the original transformer and its variants are as follows: Original Transformer - 10.82, Autoformer - 13.76, Informer - 11.99, and Pyraformer - 11.29.",
        "d26d206b-400e-4b22-9055-9d0392663c44": "The MAE values for RepNet across the transformer variants are 10.82, 13.76, 11.99, and 11.29, while the MAE values for TransRAC are 12.97, 14.12, 11.55, and 12.99. Overall, RepNet consistently outperforms TransRAC in terms of MAE across all transformer variants.",
        "00fb8a56-6fd7-447f-b6df-985594dacf64": "The 30% difference in MAE values between the proposed method and the baseline methods signifies a substantial improvement in accuracy and performance of the proposed method, indicating its effectiveness in time-series forecasting despite extensive optimization efforts on the baseline methods. This difference highlights the advantages of the unique components and strategies employed in the proposed method.",
        "94a6a0d0-55e1-494c-8c0a-eb726abf63ee": "The components evaluated in the ablation study of the proposed method include: (1) Pretraining on the synthesized dataset, (2) Distance Preserving Loss, (3) Constrained Detection using a dynamic programming algorithm, and (4) Similarity Estimation for exemplar similarity.",
        "379afce7-e083-4540-a524-2fc41aaf166c": "The \"Dist. Preserving Loss\" component enhances the performance of the proposed method by effectively maintaining the spatial relationships between data points during training. This loss function ensures that similar instances are closer together in the feature space, leading to improved accuracy in the model's predictions, as evidenced by the lower MAE values compared to baseline methods.",
        "9dbb5521-7625-48da-836c-f7230b7f3926": "The \"Constrained Detection\" component in the proposed method utilizes a dynamic programming algorithm to identify the temporal locations of counting utterances while adhering to temporal ordering and proximity constraints. This approach improves detection accuracy compared to a naive solution that simply selects the audio window with the highest classification score.",
        "d791d85e-164f-4b28-811e-4dde5a3af255": "In the absence of the \"Constrained Detection\" component, a naive solution employed is selecting the audio window with the highest classification score.",
        "bfa6aad5-0688-43f3-b97b-4fca073df622": "The proposed method for \"Similarity Estimation\" differs from the naive correlation approach by utilizing a more sophisticated technique that incorporates a distance-preserving loss and dynamic programming for detecting temporal locations, leading to improved performance. In contrast, the naive correlation approach simply selects the audio window with the highest classification score, which is less effective.",
        "799e7cbd-aa03-4cc7-a248-1a4760fa7361": "The dataset used for pretraining in the proposed method is a synthesized dataset.",
        "5dd43a48-9bba-4ad5-9b77-cab587c2488b": "The results of the ablation study indicate that all proposed components significantly enhance the overall performance of the method, as evidenced by improved MAE values compared to naive alternatives.",
        "255102ac-2bde-43ad-b193-f9dc8d28578f": "The four evaluated components mentioned in the analysis presented in Table 2 are: (1) Pretraining, (2) Dist. Preserving Loss, (3) Constrained Detection, and (4) Similarity Estimation.",
        "f728f884-ac71-4563-a860-bfff00536fe3": "The distance-preserving loss enhances the model's performance by ensuring that similar audio features are closer together in the embedding space, which improves the accuracy of temporal location detection and similarity estimation. This contributes to more effective classification and overall better results, as evidenced by the positive impact shown in the analysis presented in Table 2.",
        "adb75412-48d0-4eed-ad27-6372d4418968": "The purpose of the dynamic programming algorithm in the context of constrained detection is to accurately identify the temporal locations of counting utterances while adhering to temporal ordering and proximity constraints, improving detection performance compared to a naive solution that only selects the audio window with the highest classification score.",
        "32d9c621-eca1-493d-883c-6cfb4782a1f7": "The proposed method for exemplar similarity estimation differs from the naive correlation method by utilizing a distance-preserving loss and a dynamic programming algorithm to better capture the temporal relationships and constraints in the data, leading to improved performance compared to simply selecting the audio window with the highest classification score.",
        "e1800faf-084a-4fba-8928-57ca17dc2663": "The size of the synthesized training data used in the default setting is ten times the size of the real training data.",
        "db376112-e2ee-4674-a152-101c912d0abe": "Pretraining on the synthesized dataset significantly enhances the final results, demonstrating the most substantial impact among the evaluated components. The analysis indicates that utilizing a large volume of synthesized training data, ten times the size of the real training data, leads to improved performance metrics.",
        "f61d850f-e72d-4a09-82ee-11dd4c2a692a": "The mean absolute error (MAE) and root mean square error (RMSE) values decrease as the number of audio exemplars used increases. Specifically, with one exemplar, MAE is 9.08 and RMSE is 14.88; with two exemplars, MAE is 8.74 and RMSE is 14.29; and with three exemplars, MAE is 7.66 and RMSE is 12.25.",
        "1d40761a-625f-45f0-aadb-1118555b7663": "The qualitative results in Figure 5 illustrate that the model's predictions are generally close to the ground truth values, indicating its effectiveness. For instance, in examples (a) and (b), the predictions are within a reasonable range of the actual values, demonstrating the model's accuracy. However, example (d) shows a slight deviation, suggesting areas for potential improvement. Overall, the figure highlights the model's strong performance in predicting counting utterances.",
        "17279fa2-33bf-4c8b-a1a9-328314f835ad": "The results in Table 3 highlight the impact of varying the number of audio exemplars on model performance, as indicated by the Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) metrics. Specifically, using three exemplars yields the lowest MAE (7.66) and RMSE (12.25), demonstrating that increasing the number of exemplars improves the model's accuracy in predicting outcomes. This suggests that incorporating more exemplars enhances the model's ability to generalize and perform better on the validation set.",
        "4eda790b-30d1-4256-94fa-a638f04baeef": "The main focus of the further investigation is to examine the impact of different amounts of pretraining data on the performance of the model, particularly given that pretraining on the synthesized dataset was identified as the most crucial component.",
        "a82ba857-c310-42a1-a59c-d7d7b6553e9e": "The strategy adopted in the default setting involved using a large volume of synthesized training data, specifically ten times the size of the real training data.",
        "4c3aa6a6-f97e-4252-b7d1-4276cdec53d2": "The synthesized training data in the default setting is ten times larger than the real training data.",
        "7a2d69b3-ccb1-4a10-9b5a-afad00cda9cf": "Using a synthesized dataset that is twice the size of the real training data resulted in a marked improvement in performance, as indicated by the experimental results.",
        "98834c17-f59a-4088-97e8-052a701365f6": "The MAE and RMSE values for using three exemplars are 7.66 and 12.25, respectively.",
        "aa0e8886-917f-4733-8041-b132238c351e": "The term \"OBK\" stands for \"Off-By-K Error,\" which is an evaluation metric used to assess the performance of the model in the experiments.",
        "a37778c6-4e27-4c43-8104-f4966fc82a8c": "According to Table 3, the performance improves as the number of audio exemplars increases. The Mean Absolute Error (MAE) decreases from 9.08 with one exemplar to 7.66 with three exemplars, while the Root Mean Square Error (RMSE) also decreases from 14.88 to 12.25. This indicates that using more exemplars leads to better performance in the model's predictions.",
        "2fd6feee-fb7b-4173-a9c4-446de82b9df5": "The \"4x\" designation refers to a synthesized dataset that is four times the size of the real training data used in the experiments.",
        "ce848f8c-c992-4369-bc50-fe2162c5f301": "The significance of the temporal localization of predefined utterances in the proposed approach lies in its critical role in enhancing the accuracy of predictions. By accurately localizing these utterances, the model can better align synthesized data with real training data, leading to improved performance metrics, as evidenced by the positive results observed in the experiments. This localization allows for more effective exemplar analysis and contributes to the overall robustness of the model.",
        "5216a93e-793d-442a-aa8f-ddc506067b40": "The qualitative results section illustrates four prediction examples that demonstrate the model's performance in estimating counts based on input sensor data. Each example includes the predicted count alongside the ground truth value, highlighting the model's accuracy and the effectiveness of the synthesized training data. The predictions show varying degrees of accuracy, with some predictions closely matching the ground truth, indicating the model's capability in different scenarios.",
        "8142bb3c-f3c1-4c5d-93ff-77d3c23a1151": "The Off-By-K Error (OBK) metric is defined as OBK = (1/N) * \u03a3(\u03b4(|ti - \u02c6ti| \u2264 K)), where N is the total number of predictions, ti is the ground truth, \u02c6ti is the predicted value, and K is a threshold that determines how close the prediction must be to the ground truth to be considered correct.",
        "51a4195e-9561-4b1a-8c8a-52d916d6769a": "In the context of the synthesized dataset size compared to the real training set, \"2x\" refers to a dataset that is twice the size of the real training set, while \"4x\" indicates a dataset that is four times the size of the real training set.",
        "0087e472-bfb2-4143-ab4c-7ada02246122": "A synthesized dataset that is twice the size of the real training data significantly improves performance, as indicated by the results of our experiments. This enhancement is evident in the quantitative analysis of exemplar localization, where the increased dataset size contributes to better accuracy in predicting temporal locations.",
        "a4821c94-d56a-4e90-9a12-ed22ae0c2e5f": "The metric used to evaluate the temporal localization of predefined utterances in the study is the Off-By-K Error (OBK) metric.",
        "de4bc384-4776-4b68-b157-9a6aa430a0bd": "The Off-By-K Error (OBK) metric is defined as OBK = (1/N) * \u03a3 \u03b4(|ti - \u02c6ti| \u2264 K), where \u03b4 is the Dirac delta function, N is the total number of temporal locations, ti is the predicted temporal location, and \u02c6ti is the ground truth temporal location. This metric measures the temporal discrepancy in seconds between predicted and ground truth locations, assessing the accuracy of temporal localization in the context of the research.",
        "4049f5fc-a198-472a-92ac-5d473b541069": "In the OBK metric calculation, the Dirac delta function (\u03b4) represents a binary indicator that evaluates whether the absolute difference between the predicted temporal location (ti) and the ground truth temporal location (\u02c6ti) is within a specified threshold (K). It contributes to measuring the accuracy of temporal localization by counting instances where the prediction is sufficiently close to the ground truth.",
        "2d0e1c04-ec2b-45de-ac53-269d21a79b5f": "The baseline method used for comparison in the temporal localization evaluation was a naive greedy scheme.",
        "024097d3-c09a-47ed-850a-7216417ccfb2": "The qualitative results in Fig. 5 demonstrate that the proposed method effectively utilizes exemplars to accurately count the actions of interest.",
        "14389a39-3fdc-4503-8d87-cc0ade307536": "The proposed few-shot method utilizes vocal sounds from audio data to gather exemplars, which are then used to efficiently estimate action frequency over time. This approach enhances the counting of actions in real-world settings by leveraging the temporal localization of predefined utterances.",
        "a8cc42af-0cb7-4d7d-8e99-13252337d276": "The primary goal of the proposed method is to count actions in real-world settings by utilizing vocal sounds from audio data to gather exemplars, which efficiently estimate action frequency over time.",
        "407d9916-c33c-46f4-b8e7-f08ed3ac17db": "The effectiveness of the proposed approach was validated using a comprehensive dataset, specifically through experiments on a validation set.",
        "e4107144-1df1-4948-a90a-4f7455059f5a": "The project received partial support from the US National Science Foundation through Award NSDF DUE-2055406 and from AFOSR via Award FA2386-23-1-4058.",
        "74bbddc8-6791-4e00-8c69-b790d2fc3a51": "The study that focuses on monitoring worker fatigue using wearable devices is \"Monitoring worker fatigue using wearable devices: A case study to detect changes in gait parameters\" by Baghdadi et al. (2021).",
        "b5708334-dece-492b-9e1b-0e642eb80d74": "The main contribution of the paper by Belkin and Niyogi in 2003 is the introduction of Laplacian Eigenmaps, a method for dimensionality reduction and data representation that utilizes the properties of the Laplace operator on graphs to preserve local structures in high-dimensional data.",
        "dc1dab7e-d88d-4a30-a995-51f874996335": "The work on tracking free-weight exercises was presented at the ACM international joint conference on Pervasive and Ubiquitous Computing.",
        "77e1a87c-c704-4ec0-9234-596db37a247b": "The primary focus of the research conducted by Bian et al. in 2019 is the development of a passive capacitive-based approach for recognizing and counting full body gym workouts.",
        "f2800580-6cd9-407b-8850-583a9d9daf44": "The authors of the paper discussing robust real-time periodic motion detection are Cutler, R. and Davis, L. S.",
        "44ab95d7-484e-4c6a-96ef-3f27654706c0": "The work by Azy and Ahuja (2008) is significant in the context of moving object segmentation as it addresses the segmentation of periodically moving objects, contributing to advancements in the detection and analysis of dynamic scenes in computer vision. Their research provides foundational techniques that enhance the understanding and processing of periodic motion, which is crucial for applications in various fields such as surveillance, robotics, and human-computer interaction.",
        "d3bb8ceb-5e36-4707-9131-5f321b13c5bb": "The publication that discusses the periodicity of dynamic textures is \"On Motion Periodicity of Dynamic Textures\" by Chetverikov and Fazekas, presented at the British Machine Vision Conference.",
        "9cc5990a-11e4-4f92-96d9-b9a73ce8ddf6": "The main application area of the research presented by Cutler and Davis in 2000 is robust real-time periodic motion detection and analysis.",
        "48e39a7e-63da-4dd5-b1c5-acc960a75574": "The study by Baghdadi et al. contributes to understanding changes in gait parameters by utilizing wearable devices to monitor worker fatigue, providing empirical data on how fatigue affects gait characteristics. This research highlights the relationship between fatigue levels and alterations in gait, thereby enhancing knowledge of gait dynamics in occupational settings.",
        "8ba5cdff-48e8-4ece-a02e-6652f26e6a72": "The main focus of the research presented by Chang, Chen, and Canny in 2007 is on tracking free-weight exercises.",
        "e178ab76-9f90-4e3c-bc06-797d546674da": "Chetverikov and Fazekas presented their work on motion periodicity of dynamic textures at the British Machine Vision Conference.",
        "65708399-a9d1-40d9-a8ba-a146fdb500ad": "Cutler and Davis's 2000 paper addresses robust real-time periodic motion detection.",
        "aee3b5b5-969d-4b26-b784-fa46c3d62c7a": "The significance of the Soft-DTW loss function introduced by Cuturi and Blondel in 2017 lies in its ability to provide a differentiable alternative to the traditional Dynamic Time Warping (DTW) distance, enabling the optimization of time-series models through gradient-based methods. This allows for more effective training of models on sequential data, improving performance in tasks such as time-series classification and regression.",
        "69d23bee-1fa1-45c4-9c75-64c36294315a": "The Femo platform utilizes RFID technology for monitoring free-weight exercises, as described by Ding et al. in 2015.",
        "c52c6e5f-7dd2-490f-a254-b00f5a7f63ee": "The primary contribution of Dwibedi et al.'s 2020 paper is the development of a class-agnostic method for counting repetitions in videos, enabling accurate counting of exercise repetitions in diverse and uncontrolled environments.",
        "5d460895-f4f0-49b7-b3a9-38605687d8ae": "AIFit, developed by Fieraru et al. in 2021, aims to enhance fitness training by providing automatic 3D human-interpretable feedback models. This system analyzes users' movements during workouts to deliver personalized guidance and improve exercise performance.",
        "0708dcf0-48f9-4f77-94ff-acf5861751ef": "The research on tracking free-weight exercises was published in 2007.",
        "6b1f886e-6742-4c4c-903e-b32d6338b3eb": "The common theme among the listed papers is the analysis and monitoring of human motion, particularly in the context of exercise and physical activity, utilizing various computational techniques and technologies.",
        "c27ce862-d36c-4327-97e7-7b84d95d609f": "The authors of the paper \"Robust Real-Time Periodic Motion Detection, Analysis, and Applications\" are Cutler, R. and Davis, L. S.",
        "ccafc552-b69d-419b-b3c3-b416e15fd4bc": "The primary focus of the Femo platform is to monitor free-weight exercises using RFID technology.",
        "58a7cc59-8473-4c65-bf4a-a5b51d53dc05": "The 2020 study by Dwibedi et al. contributes to video repetition counting by introducing a class-agnostic approach that enables accurate counting of exercise repetitions in diverse and uncontrolled environments. This method enhances the robustness and applicability of video analysis for fitness monitoring, allowing for effective tracking of various exercises without the need for specific class labels.",
        "8aaf26ba-ca33-4c33-b947-1b66c4b113fb": "AIFit proposes an innovative approach for fitness training feedback by utilizing automatic 3D human-interpretable feedback models, which provide real-time, personalized insights into exercise performance.",
        "450e5730-e86b-4e38-81fa-97e49e03a3db": "The smartwatch step counter developed by Genovese et al. is used in the context of monitoring slow and intermittent ambulation.",
        "e2d966c1-d6f5-4c38-aec3-c517ce9e86ec": "The 2020 paper by Hatamie et al. discusses textile-based chemical and physical sensors for healthcare monitoring.",
        "157d1fbd-5455-49c0-a4fa-d2578af6ff93": "The significance of viewpoint invariance in exercise repetition counting, as explored by Hsu et al. in 2021, lies in its ability to accurately count repetitions regardless of the observer's angle or position. This enhances the robustness and applicability of exercise monitoring systems, allowing for consistent performance in diverse real-world scenarios.",
        "c4537e4c-eb14-477f-b98f-b3e5d96095a7": "The TransRAC model enhances repetitive action counting by utilizing transformers to encode multi-scale temporal correlations, allowing for improved accuracy and robustness in counting actions across varying time scales.",
        "19f582e0-c90c-4d45-b951-b96c7dc85ac1": "The main contributions of the 2023 study by Huang, Ranjan, and Hoai include advancements in exercise monitoring techniques, specifically focusing on improving the accuracy and efficiency of repetitive action counting using novel algorithms or methodologies.",
        "6380e54c-b3c3-405c-8fd8-cd933e6ec022": "The majority of the studies mentioned in the context feature in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
        "2646dffd-0aee-4ad7-8404-15f3d59e9bf8": "The common theme identified across the studies is the development of technologies and methods for monitoring and analyzing physical activities and fitness, utilizing various sensors and computer vision techniques.",
        "4cf115c7-c09a-4706-b375-e19a42de41ef": "The 2020 publication by Hsu et al. discusses textile-based chemical and physical sensors for healthcare monitoring.",
        "52580674-8937-4538-823e-24cda4e031d5": "The main focus of the viewpoint presented by Hsu, Zhang, Tsougenis, and Tsui in their 2021 paper is on invariant exercise repetition counting, emphasizing methods that accurately count exercise repetitions regardless of the viewpoint or perspective from which the activity is observed.",
        "7fa02457-9c47-40aa-99c8-9523971c066c": "The TransRAC model enhances repetitive action counting by utilizing transformers to encode multi-scale temporal correlations, allowing for improved accuracy and robustness in recognizing and counting repetitive actions.",
        "8655ad91-3ef2-438e-ae74-d962d7cda4cf": "The significance of interactive class-agnostic object counting, as presented by Huang, Ranjan, and Hoai in 2023, lies in its ability to count objects without requiring prior knowledge of their classes. This approach enhances flexibility and applicability in various real-world scenarios, allowing for more efficient and adaptable object counting in diverse environments.",
        "6229b471-5690-4d14-9fcf-26d99946a9a1": "The Exersense algorithm utilizes an IMU (Inertial Measurement Unit) sensor for real-time exercise segmentation and counting, according to Ishii et al. in 2021.",
        "faf0cb8c-b32a-42ac-8c77-4823f9b4e3c9": "The primary goal of the mobile fitness coach concept discussed by Kranz et al. in 2013 is to enable individualized skill assessment using personalized mobile devices.",
        "521dda53-c2d7-44dd-86b8-d35886ffd020": "The term \"Industrial wearable system\" used by Kong et al. in 2019 refers to a technology designed to enhance human capabilities in the context of Industry 4.0. It aims to empower workers by integrating wearable devices that facilitate real-time data collection, monitoring, and analysis to improve productivity and safety in industrial environments.",
        "bf7cf49c-3cd5-436b-b4e2-b2fe933a577d": "Kim et al. (2021) propose an innovative approach for keyword spotting called Broadcasted Residual Learning, which enhances efficiency in recognizing keywords.",
        "75cc895e-5dd5-438d-9238-752d0110f256": "The studies mentioned contribute to the field of physical exercise monitoring and analysis by introducing innovative methods and technologies for tracking and analyzing exercise performance. They enhance the accuracy of exercise repetition counting, improve real-time segmentation and classification of physical activities using sensors, and leverage advanced algorithms like transformers for better temporal correlation in repetitive actions. These advancements facilitate more effective monitoring, personalized feedback, and skill assessment in physical exercise, ultimately promoting better health outcomes and training efficiency.",
        "6a5f857c-9040-43a0-8d12-70bba5daffe6": "The technologies discussed have several potential applications in healthcare and fitness, including:\n\n1. **Health Monitoring**: Textile-based sensors can provide real-time health monitoring, tracking vital signs and physical activity.\n2. **Exercise Tracking**: Algorithms for exercise segmentation and counting can enhance personal fitness training by accurately tracking repetitions and types of exercises performed.\n3. **Personalized Coaching**: Mobile fitness coaches can offer individualized skill assessments and tailored workout plans based on user data.\n4. **Repetitive Action Analysis**: Advanced counting algorithms can improve the accuracy of exercise performance analysis, aiding in rehabilitation and fitness optimization.\n5. **Wearable Technology**: Industrial wearable systems can empower users in both healthcare and fitness settings by providing actionable insights based on real-time data.",
        "20042e21-0c6b-4fd9-a666-b20f8604f6f9": "The main focus of the research conducted by Kim et al. (2021) is on developing a method called Broadcasted Residual Learning to enhance the efficiency of keyword spotting systems.",
        "b0abdf95-fe1c-448c-8993-56576c89873d": "The industrial wearable system discussed by Kong et al. (2019) contributes to Industry 4.0 by enhancing human-centric capabilities, enabling real-time data collection and analysis, and facilitating improved decision-making and productivity in manufacturing environments.",
        "6b963fb1-5002-4611-88f1-bf7e73b7d21e": "The mobile fitness coach developed by Kranz et al. (2013) utilizes personalized mobile devices for individualized skill assessment.",
        "b11c55d4-87c6-4c65-865e-db6ac36d8080": "Kupke et al. (2016) employed artificial neural networks to develop their step counter.",
        "ab4b6f74-b2eb-4498-a7ee-5d66ee9bf1bf": "Lee et al. (2015) used capacitively coupled textile electrodes for monitoring heart rate variability during sleep.",
        "2a6a908d-3971-4b8a-a484-bbfce0e34c3d": "The primary application of the Live Repetition Counting system presented by Levy and Wolf (2015) is to accurately count repetitions of physical exercises in real-time.",
        "f16d8396-b250-4ca9-a635-73c164cd928b": "Liu et al. (2022) introduce the CounTR model, a transformer-based approach for generalized visual counting, which enhances the accuracy and efficiency of counting objects in images.",
        "6a889b61-c417-4539-a289-d6a425d59b01": "The study on heart rate variability monitoring by Lee et al. was published in 2015.",
        "2f1a3906-1b0b-40a4-98bb-ad01ebe7ac0e": "The key features of the wearable system highlighted in Kong et al. (2019) include its human-centric design, integration with Industry 4.0 technologies, real-time data collection and analysis, and the ability to enhance worker safety and productivity through monitoring and feedback.",
        "02971c7b-6dce-4190-a328-278407fca76e": "The research by Liu et al. (2022) introduces a transformer-based approach for visual counting, termed CounTR, which differs from traditional methods by leveraging deep learning techniques to generalize counting across various scenarios, rather than relying on handcrafted features or simpler models. This allows for improved accuracy and adaptability in counting tasks compared to conventional visual counting methods.",
        "a5cb8a48-dc9e-4ac2-8313-7d97c0580150": "The primary focus of the study conducted by Lee et al. (2015) is on monitoring heart rate variability during sleep using capacitively coupled textile electrodes integrated into a bed.",
        "528f7464-e29f-4246-8258-0d308254ac66": "The paper \"Live Repetition Counting\" by Levy and Wolf was presented at the IEEE International Conference on Computer Vision.",
        "8d797cc5-80de-4e35-bab7-eb7b5d518e1c": "Liu et al. (2022) introduce the CounTR model, a transformer-based approach for generalized visual counting, which enhances the accuracy and efficiency of counting objects in images.",
        "4db61cc5-0f71-4233-a133-31b7212bb88d": "The main contribution of the Pyraformer model proposed by Liu et al. (2021) is the introduction of low-complexity pyramidal attention mechanisms for efficient long-range time series modeling and forecasting.",
        "d20d74fb-d0ec-4063-9f06-137449896cc6": "The research by Lu et al. (2018) introduces a class-agnostic counting approach, which allows for counting objects without requiring prior knowledge of their specific classes. In contrast, traditional counting methods typically rely on predefined categories and often require extensive training on labeled datasets for each class. This makes Lu et al.'s method more flexible and applicable to a wider range of scenarios in computer vision.",
        "98b813b8-ff16-4e98-a381-50d1285ef2ab": "The RecoFit system utilizes a wearable sensor to recognize and count repetitive exercises, as described by Morris et al. (2014).",
        "0e3abdcc-41ed-4d8c-a3bb-f4f5710cefa6": "The objective of the study conducted by Mortazavi et al. (2014) was to determine the single best axis for exercise repetition recognition.",
        "71edf93f-4d99-47df-837f-c52ce8b9d05f": "The work of Liu et al. (2022) on transformer-based visual counting is included in the Proceedings of the British Machine Vision Conference.",
        "bfb4b3ed-118f-4ed3-b41b-36eb2461bbea": "The study by Lee et al. (2015) used capacitively coupled textile electrodes for heart rate variability monitoring.",
        "3a060707-c2cb-4044-9645-cca6b771ff23": "Liu et al. (2021) address the challenges of long-range time series modeling by introducing Pyraformer, which utilizes low-complexity pyramidal attention mechanisms. This approach effectively captures long-range dependencies while maintaining computational efficiency, making it suitable for forecasting tasks in time series data.",
        "30c3a0fa-21d4-4594-9dc0-880a5f668232": "The sleep monitoring study by Nam, Kim, and Lee (2016) used a tri-axial accelerometer and a pressure sensor.",
        "0641b149-b720-4799-b76a-4ad01f7dd0ff": "The main focus of the research conducted by Nguyen et al. (2022) is on Few-Shot Object Counting and Detection.",
        "29700f68-9d24-45f7-91e2-c42e5610d0cd": "Nishino, Maekawa, and Hara (2022) approach repetition counting by utilizing few-shot and weakly supervised learning techniques with body-worn accelerometers.",
        "296b921a-4c40-4b72-a49a-db8a43a841f8": "The significance of decomposed uncertainty in crowd counting, as discussed by Oh, Olsen, and Ramamurthy (2020), lies in its ability to improve the accuracy and reliability of crowd density estimates by separating different sources of uncertainty. This approach allows for a more nuanced understanding of the factors affecting crowd counting, leading to better-informed decision-making in applications such as urban planning and public safety.",
        "91807a6f-aeb1-42df-94ab-354c396c799e": "O\u2019Reilly et al. (2018) address the topic of wearable inertial sensor systems for lower limb exercise detection and evaluation in their systematic review.",
        "c6066936-d334-43c2-a645-ede960ac6299": "The study by Patel et al. (2010) utilizes wearable technology to monitor rehabilitation outcomes in stroke survivors by employing sensors that track various physical activities and movements. This approach allows for real-time data collection and analysis, facilitating personalized rehabilitation programs and improving patient engagement in their recovery process.",
        "b8c474e1-efac-4c9d-9f63-5c99bbe85d0f": "Pillai et al. (2020) employed a domain adapted LSTM network approach for personalized step counting.",
        "8b9ecc38-552f-4acd-a1a4-9d926b6d19ff": "The research on few-shot object counting and detection by Nguyen et al. was presented in 2022.",
        "9feca725-2a9b-4fdf-93d4-80f67cb4ce54": "The work of Pillai et al. (2020) is categorized as an arXiv preprint.",
        "e6abc7bf-0e90-4f81-960c-a7bee91f0b18": "The primary application of wearable inertial sensor systems, as reviewed by O\u2019Reilly et al. (2018), is for lower limb exercise detection and evaluation.",
        "5e672913-a547-452d-8e8a-8f1bec0a73ff": "Patel et al. (2010) discuss a novel approach for monitoring rehabilitation outcomes in stroke survivors that utilizes wearable technology to track and analyze physical activity and movement patterns.",
        "7d1a6894-784c-42a4-baf9-f0b74ef92ff7": "The personalized step counting method proposed by Pillai et al. (2020) utilizes wearable sensors by employing a domain-adapted Long Short-Term Memory (LSTM) network to analyze data collected from these sensors. This approach allows for the customization of step counting algorithms based on individual user patterns and behaviors, enhancing accuracy in tracking physical activity.",
        "6a67dd1b-17d7-4c20-be4b-666b44f3b676": "The focus of the comparative study conducted by Prabhu et al. (2020) is on recognition and repetition counting for local muscular endurance exercises in exercise-based rehabilitation, utilizing artificial intelligence models.",
        "eb62eca9-8838-4647-8c76-2cb875f05074": "Ramachandran and Liao (2022) explored microfluidic wearable electrochemical sweat sensors for health monitoring.",
        "5637dc15-bb1a-404e-87dd-23a95fde2a51": "The main contribution of Ranjan and Hoai (2022a) in the field of counting in computer vision is the development of an exemplar-free class-agnostic counting method, which allows for accurate counting of objects without the need for specific class examples.",
        "7378b489-d667-496e-a6d2-263ffc33eb15": "Vicinal Counting Networks, as presented by Ranjan and Hoai (2022b), differ from traditional counting methods by utilizing a novel approach that focuses on learning from vicinal distributions, allowing for more accurate counting in complex scenarios without relying on explicit object annotations. This contrasts with traditional methods that typically depend on labeled data and fixed counting techniques.",
        "32b198b7-ada9-4f01-9f9a-94c8bc025446": "The research conducted by Ranjan et al. (2021) on learning to count in computer vision is significant because it introduces a novel approach to counting objects in images without requiring prior examples of the objects to be counted. This method enhances the flexibility and applicability of counting algorithms across diverse scenarios, making it a valuable contribution to the field of computer vision.",
        "65a792ad-328f-475c-a437-7c5437162d82": "Visual quasi-periodicity is discussed by Pogalin et al. (2008) in the context of computer vision and pattern recognition, specifically at the IEEE Conference on Computer Vision and Pattern Recognition.",
        "c45587fb-df14-4f37-b2eb-94d87b524e54": "The potential applications of the wearable technology mentioned in Patel et al. (2010) include monitoring rehabilitation outcomes in stroke survivors, enhancing patient engagement in recovery, and providing real-time feedback on physical activity and progress during rehabilitation.",
        "9b4d141e-a5e2-4b38-8e2d-e85449e1869e": "The studies referenced contribute to advancements in sports medicine and rehabilitation by integrating wearable technology and artificial intelligence to enhance monitoring and assessment of rehabilitation outcomes. They focus on personalized data collection, such as step counting and exercise recognition, which allows for tailored rehabilitation programs. Additionally, the development of microfluidic sensors for health monitoring provides real-time physiological data, improving the understanding of patient progress and recovery. Overall, these innovations facilitate more effective and individualized rehabilitation strategies.",
        "12c043d3-224c-4a84-a73a-d4ecee6c0d6a": "The primary focus of the research conducted by Ramachandran and Liao in their 2022 paper is the development of microfluidic wearable electrochemical sweat sensors for health monitoring.",
        "9ea842f1-e275-4b96-81f1-5f0cc0e63774": "Ranjan and Hoai presented their work on \"Exemplar Free Class Agnostic Counting\" at the Asian Conference on Computer Vision (ACCV) in 2022.",
        "78f3b38f-733c-4c1f-965f-638daecad005": "The main contribution of the paper \"Learning To Count Everything\" by Ranjan et al. (2021) is the development of a novel framework for counting objects in images without requiring prior knowledge of the object classes, enabling effective counting across diverse scenarios.",
        "4ef0f299-accf-4832-b4f2-f8e7eb397171": "In their 2018 study, Runia, Snoek, and Smeulders approach real-world repetition estimation by utilizing a method based on the mathematical operations of division, gradient, and curl to analyze and estimate repetitions in various activities.",
        "7d6f7196-b820-4392-91f9-16159c6c50ea": "Shi et al. propose a similarity-aware framework for class-agnostic counting, which is detailed in their 2022 paper titled \"Represent, Compare, and Learn.\"",
        "6fd56408-e666-489b-bab3-d2914d6db6b9": "The research by Soro et al. in their 2019 papers focuses on recognition and repetition counting for complex physical exercises using deep learning.",
        "e7157f3a-f92d-42e1-919e-124a511811a8": "The paper \"Recognition and Repetition Counting for Complex Physical Exercises with Deep Learning\" by Soro et al. has four authors.",
        "30ed34de-ede5-4581-9cbb-2d5a2979e874": "The term \"similarity-aware framework\" in Shi et al.'s 2022 research signifies an approach that focuses on representing and comparing data in a way that enhances the ability to count objects or instances without relying on specific class labels. This framework is particularly important for class-agnostic counting, as it allows for more flexible and accurate counting across diverse scenarios by leveraging the inherent similarities among different instances.",
        "c1d21903-6664-43d5-9a1e-887a51c8278b": "The work of Stiefmeier et al. is featured in the publication \"Sensors.\"",
        "fccbb184-aa2b-4efa-ac04-59f6e50776fe": "The common theme identified in the works of Ranjan and Hoai is the development of class-agnostic counting methodologies that focus on accurately counting objects without requiring specific class labels, as demonstrated in their various papers on exemplar-free counting and vicinal counting networks.",
        "d9922c52-7546-4b3e-8adf-d4a557b84ff7": "The main focus of the paper \"Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting\" is to develop a framework that enables counting objects without relying on specific class labels, utilizing similarity-aware techniques to improve the accuracy of counting in various contexts.",
        "ddbfe30c-7cb5-4c17-bfca-7c98247defb2": "The work by Soro et al. (2019a) significantly advances the field of exercise recognition and counting by introducing a deep learning approach specifically designed for recognizing complex physical exercises and accurately counting repetitions. Their methodology enhances the ability to analyze and interpret exercise data, contributing to improved monitoring and feedback in fitness applications.",
        "108c70fb-1311-4d80-84c8-311aa4310cf8": "The study by Stiefmeier et al. (2008) tracks wearable activity in the context of car manufacturing.",
        "95aa0e69-5845-43de-afaa-003cbc62149a": "The MM-Fit framework introduced by Str\u00f6mb\u00e4ck et al. (2020) is significant for its application of multimodal deep learning techniques to automate exercise logging across various sensing devices, enhancing the accuracy and efficiency of tracking physical activities.",
        "45f36e38-8c78-45fa-8bf9-eb191ac76d93": "Thangali and Sclaroff (2005) employed a methodology for periodic motion detection that involves space-time sampling.",
        "46751dcf-0fc8-4ddf-aa97-b7907e24d2ae": "The dataset introduced by Warden (2018) is the \"Speech Commands\" dataset, and its primary application is for limited-vocabulary speech recognition.",
        "23747377-55b9-4d69-950c-3ea9951b3b8f": "Wu et al. (2021) approach long-term series forecasting in their work on Autoformer by utilizing a decomposition transformer model that incorporates auto-correlation mechanisms. This allows the model to effectively capture both seasonal and trend components of time series data, enhancing its forecasting accuracy over extended periods.",
        "63d8162f-d116-43f0-ba34-12914b64b55d": "Yang et al. (2021) contributed to the field of object counting by introducing a class-agnostic few-shot learning framework that enables effective counting of objects without requiring prior knowledge of their categories. Their approach enhances the ability to generalize across different object classes, improving counting performance in scenarios with limited labeled data.",
        "8b54deb0-d651-4146-9e8d-4cdd0b51b458": "The paper \"Recognition and Repetition Counting for Complex Physical Exercises with Deep Learning\" was published in 2019.",
        "1019ae12-2f1d-4c74-b4c7-399d74e5cd2a": "The key features of the similarity-aware framework for class-agnostic counting include the ability to represent and compare objects without relying on specific class labels, enabling effective counting across diverse object categories. It leverages deep learning techniques to enhance recognition and counting accuracy in various contexts.",
        "9c071fee-76cf-43ec-8c92-f9a1209e0e60": "The main focus of the paper by Thangali and Sclaroff (2005) is on periodic motion detection and estimation through space-time sampling techniques.",
        "7cda54c5-b76e-4ba6-a4d5-b68feb094c66": "Warden (2018) introduced the \"Speech Commands\" dataset for limited-vocabulary speech recognition. Its specific application is to enable the recognition of a small set of spoken commands.",
        "df479ad9-de53-4d9e-958c-f12a1fc064f3": "The Autoformer model proposed by Wu et al. (2021) enhances long-term series forecasting by utilizing a decomposition transformer architecture that incorporates auto-correlation mechanisms. This allows the model to effectively capture temporal dependencies and seasonal patterns in time series data, leading to improved forecasting accuracy over extended periods.",
        "02ab81b7-7a24-4c0b-a0a3-eadff47dfd2a": "The significance of class-agnostic few-shot object counting, as discussed by Yang et al. (2021), lies in its ability to accurately count objects without requiring specific class labels or extensive training data for each object category. This approach enhances flexibility and efficiency in various applications, allowing for effective counting in diverse and dynamic environments with minimal prior knowledge.",
        "76d76e0a-c83d-4a17-8f63-33e1020d1a8c": "In the work by You et al. (2023), the method used to enhance feature similarity for few-shot object counting is called \"Similarity-Aware Feature Enhancement.\"",
        "79e0273c-19a2-4daf-9c98-75970c0d642a": "Zelman et al. (2020) use an accelerometer-based approach for counting exercises that does not require exercise-specific training or tuning.",
        "b759dd77-0296-4a23-b4f3-e0361d074f3e": "Zhang et al. (2020) address the challenges of temporal repetition counting by proposing a context-aware and scale-insensitive approach that enhances the accuracy of counting repeated activities in varying conditions. Their method leverages contextual information to improve detection and counting performance, making it robust to changes in scale and context.",
        "0dd0fc90-a281-4e35-a271-036856d87213": "Zhang et al. (2021) employ a novel technique that integrates both visual and auditory data to enhance the accuracy of counting repetitive activities.",
        "8afe2f15-fc7e-4456-8322-aaf508641097": "The common theme identified in the research conducted by the authors is the development and application of innovative counting methodologies across various domains, including motion detection, speech recognition, object counting, and activity recognition, often utilizing advanced techniques such as few-shot learning and context-aware algorithms.",
        "3e6e8112-e36c-423c-bd4f-a4b15559cf80": "The contributions of the mentioned papers reflect significant advancements in computer vision and pattern recognition by introducing innovative methodologies for motion detection, speech recognition, and object counting. Thangali and Sclaroff's work on periodic motion detection enhances the understanding of dynamic scenes, while Warden's dataset facilitates improved speech recognition systems. Wu et al.'s Autoformer model advances time series forecasting through novel transformer architectures. The studies by Yang et al. and You et al. focus on few-shot object counting, showcasing techniques that improve performance with limited data. Additionally, Zelman et al. and Zhang et al. explore automated counting methods using accelerometer data and context-aware approaches, respectively, further pushing the boundaries of activity recognition. Collectively, these contributions demonstrate a trend towards more efficient, accurate, and adaptable systems in the fields of computer vision and pattern recognition.",
        "301fb51c-9c0d-414a-a18a-4842875a53a9": "The main focus of the study conducted by Zelman et al. (2020) is the development of an accelerometer-based system that can automatically count ten different exercises without requiring exercise-specific training or tuning.",
        "b8d89b08-f577-436e-a369-07ac5d2c93c2": "The approach presented by Zhang et al. (2020) differs from traditional methods of repetition counting by being context-aware and scale-insensitive, allowing it to accurately count repetitions across varying conditions without the need for exercise-specific training or tuning. Traditional methods often rely on fixed parameters and specific exercise models, which can limit their adaptability and accuracy in diverse scenarios.",
        "b73b053e-333c-4f15-8ac5-0d45fade1608": "Zhang et al. (2021) utilize a unique combination of visual and auditory modalities for counting repetitive activities.",
        "a075bac8-a9a7-4724-ac3a-d2687f22457e": "The Informer model introduced by Zhou et al. (2021) is significant in time-series forecasting as it enhances the efficiency and accuracy of long sequence predictions by utilizing a self-attention mechanism that reduces computational complexity. This allows for better handling of long-range dependencies in time-series data, making it particularly effective for forecasting tasks where traditional models struggle with scalability and performance.",
        "1c4afe35-cf39-4aec-988c-c4925b178794": "Zelman et al. (2020) presented their findings in the \"Journal of Healthcare Engineering.\"",
        "396b4099-f60c-4bc6-9c41-d758393ba287": "The work of Zhang et al. (2021) on repetitive activity counting was featured in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
        "41238ccc-9c35-4f50-ac64-2da2536c68b5": "The methods discussed in the context address the challenges of exercise-specific training or tuning by utilizing accelerometer data and advanced algorithms that enable automated counting of various exercises without the need for tailored training for each specific activity. This approach leverages context-aware techniques and scale-insensitive models to accurately recognize and count repetitions across different exercises, thereby eliminating the requirement for extensive exercise-specific adjustments.",
        "63a811ad-326c-44b9-850a-ce66e24c3394": "The research by Zhou et al. was presented in 2021.",
        "20f71ec6-76b0-4aa5-81cd-062a67d240cb": "The authors who collaborated on the paper discussing context-aware and scale-insensitive temporal repetition counting are Zhang, H.; Xu, X.; Han, G.; and He, S.",
        "676831e7-918b-47d6-b4c1-1ff574f1dd5b": "The primary application area of the research conducted by the authors is automated counting of exercises and repetitive activities using accelerometer data and computer vision techniques.",
        "0496e41b-fd02-484d-af79-87c14e1d4b36": "The primary purpose of the absorber vessels at the Orbost Gas Plant is to remove hydrogen sulfide (H2S) from untreated gas to ensure that the export sales gas meets strict specifications for various contaminants.",
        "cda54acb-c04d-4707-b933-7b44aa00b0e2": "The absorber vessels currently require mechanical cleaning due to fouling every 12 to 15 days.",
        "2d287c93-8731-4ff9-9d7a-f6f7ee145ebe": "The export sales gas at the Orbost Gas Plant must meet strict specifications regarding the concentrations of solids particles, water, mercury, oxygen, and hydrogen sulfide (H2S).",
        "915a5b7b-72d0-42c6-81ab-dd40048c72b4": "The operational data suggested for analysis using machine learning to address the fouling issue includes time series data of pressure, temperature, flow rate, and injection rate of the related equipment at the Orbost Gas Plant.",
        "269575e8-4317-4ba0-9cf4-838b954ff0df": "In December 2021, the Orbost Gas Plant achieved two \"dream runs\" where the absorber vessels operated with minimal deposition of sulfur, a significant operational milestone that had only been accomplished twice in the plant's four-year history.",
        "7e5c1569-30fc-49ef-b75c-60ececb99a66": "The main goal of the proposed project titled \u201cThe Application of Machine Learning to Reduce the Fouling of Absorber Vessels at Orbost Gas Processing Plant\u201d is to analyze operational data using machine learning techniques to identify the factors that led to successful operations (the \"dream runs\") and to replicate those conditions, thereby minimizing the fouling of absorber vessels and reducing the frequency of mechanical cleaning.",
        "301e1066-b928-41f5-ad47-5a4ce3a469e1": "The absorber vessels at the Orbost Gas Plant have been experiencing fouling issues since they began operating in 2020, requiring mechanical cleaning every 12 to 15 days.",
        "a580fdfe-b92a-43fc-91b2-edc508cf7d62": "The Orbost Gas Plant uses the AVEVA PI system for real-time data storage, visualization, and simple analysis.",
        "668cd2d3-67a2-4cd1-9e13-924194560b21": "The potential benefits of replicating the conditions from the two dream runs in December 2021 include: \n\n1. **Reduced Fouling**: Achieving minimal deposition of sulfur, leading to extended operational periods without the need for mechanical cleaning.\n2. **Increased Efficiency**: Enhancing the overall efficiency of the absorber vessels, which can improve gas processing and reduce downtime.\n3. **Cost Savings**: Lower maintenance and cleaning costs due to less frequent interventions.\n4. **Improved Gas Quality**: Ensuring that the export sales gas consistently meets strict specifications, enhancing product reliability.\n5. **Data-Driven Insights**: Utilizing machine learning to analyze operational data could provide insights into optimal conditions, facilitating better decision-making for future operations.",
        "2b824f4e-9ec5-4759-9df1-ffee66432ce1": "The specific differences in operational data being investigated to understand the successful runs in December 2021 include variations in pressure, temperature, flow rate, and injection rate of the related equipment at the Orbost Gas Plant. These parameters are analyzed to identify the conditions that led to minimal sulphur deposition during the two \"dream runs,\" which contrasts with the typical fouling issues experienced prior to and after that period.",
        "bc3ede22-0728-4a99-988e-b7df30f1d95b": "Since 2020, the absorber vessels have been experiencing fouling issues that necessitate mechanical cleaning every 12 to 15 days.",
        "632a96f9-0565-4814-885e-2a1118da52ed": "The absorber vessels require mechanical cleaning every 12 to 15 days due to fouling issues.",
        "30719dd5-1d3e-4f73-a858-df0c1b1b2abf": "The successful runs in December 2021 were attributed to improved operational data, including optimized pressure, temperature, flowrate, and injection rate metrics. These parameters were likely more stable and within optimal ranges compared to previous periods, reducing fouling issues and enhancing overall system efficiency. The application of machine learning on the time series data from the AVEVA PI system can help identify these key operational differences and replicate the success in future operations.",
        "ee1c3c27-202c-4e20-90b6-5e91581c20c2": "Machine learning techniques that could be applied to analyze the time series data from OGP include:\n\n1. **Time Series Forecasting**: Techniques like ARIMA, SARIMA, or Prophet can predict future operational metrics based on historical data.\n2. **Anomaly Detection**: Algorithms such as Isolation Forest or LSTM-based models can identify unusual patterns or fouling issues in the data.\n3. **Regression Analysis**: Linear regression or more complex models like Random Forest Regression can help understand the relationships between operational parameters and performance outcomes.\n4. **Clustering**: K-means or DBSCAN can group similar operational conditions to identify patterns associated with successful runs.\n5. **Neural Networks**: Recurrent Neural Networks (RNNs) or Long Short-Term Memory (LSTM) networks can capture temporal dependencies in the data for more complex modeling.\n\nThese techniques can help analyze the operational data to replicate successful performance in future operations.",
        "152d711d-93f7-42c7-bc29-d0cad37ee7c0": "The parameters measured in real-time at OGP that could influence the operation of the absorber vessels include pressure, temperature, flowrate, and injection rate.",
        "d6686972-b4a3-4d33-8a04-4fccfed984b5": "The real-time data from OGP is measured by local devices and gauges, which then transmit the data to the AVEVA PI system for storage, visualization, and analysis.",
        "98577014-759b-415e-b40c-5caa0b274f65": "The AVEVA PI system plays a crucial role in the data analysis process for OGP by collecting, storing, and visualizing real-time operational data from local devices. This high-quality data, including time series measurements of pressure, temperature, flowrate, and injection rate, serves as a foundation for machine learning applications aimed at analyzing operational differences and optimizing future performance.",
        "a47d5af1-cada-429b-818e-1798fe75ba3b": "The quality and structure of data are crucial for machine learning applications because they directly impact the accuracy and reliability of the models. High-quality data ensures that the algorithms can learn effectively, while well-structured data facilitates easier analysis and processing. Inconsistent or poor-quality data can lead to misleading results and hinder the ability to replicate successful operational outcomes, such as the dream runs in December 2021.",
        "266016ff-ebda-49b9-8006-ac14c9b886ab": "To replicate the successful operational runs observed in December 2021, the following steps can be taken:\n\n1. **Data Analysis**: Utilize machine learning to analyze the time series data (pressure, temperature, flowrate, injection rate) from the AVEVA PI system to identify key operational parameters that contributed to the success in December 2021.\n\n2. **Identify Differences**: Compare the operational data from December 2021 with other periods to pinpoint specific differences that led to improved performance.\n\n3. **Optimize Cleaning Schedule**: Review and potentially adjust the mechanical cleaning schedule of the absorber vessels to minimize fouling and maintain optimal operational conditions.\n\n4. **Implement Best Practices**: Document and implement any best practices or operational adjustments identified during the analysis that were present during the successful runs.\n\n5. **Continuous Monitoring**: Establish a continuous monitoring system to track the identified key parameters in real-time, allowing for timely adjustments to maintain optimal performance.\n\n6. **Feedback Loop**: Create a feedback loop for ongoing analysis and adjustments based on real-time data to ensure sustained operational success.",
        "fc03e389-97fa-4d6a-bbda-d6b15a0a5697": "The AVEVA PI system excels in industrial operations by providing real-time data storage, visualization, and analysis, which are crucial for monitoring and optimizing processes. Compared to other data management systems, AVEVA PI is widely adopted, ensuring high-quality, well-structured data suitable for machine learning applications. This facilitates better insights into operational performance, such as identifying factors contributing to fouling issues and replicating successful operational conditions.",
        "dd566266-806a-4016-8354-a31c689e3495": "The primary focus of the \"Think Digital AI Roadmap\" document is to outline strategies and guidelines for integrating artificial intelligence into digital transformation initiatives.",
        "33188237-b8b9-49f5-b73b-4588dd1ca068": "The AI Roadmap proposes to integrate digital technologies into existing systems by leveraging advanced data analytics, enhancing automation processes, and fostering interoperability among various platforms to improve efficiency and decision-making.",
        "1a784ec3-fef0-4abc-a959-1bfea9cd2928": "The key objectives outlined in the AI Roadmap include enhancing AI research and development, promoting ethical AI practices, fostering collaboration between industry and academia, improving AI education and workforce skills, and ensuring robust data governance and security.",
        "6ac6e1ca-10e3-41fa-bf1d-793c06eecb7a": "The intended stakeholders for the AI Roadmap include government agencies, industry leaders, academic institutions, technology developers, and the general public.",
        "50d737e2-0b34-485c-a43d-010845bad93b": "The AI Roadmap identifies challenges such as data privacy concerns, integration with existing systems, lack of skilled personnel, resistance to change within organizations, and the need for clear regulatory frameworks in implementing digital strategies.",
        "a480c106-ab76-4546-9a78-5b5d1fb6a260": "The AI Roadmap suggests measuring the success of AI initiatives through key performance indicators (KPIs) that assess impact, efficiency, and user satisfaction, along with regular evaluations and feedback loops to ensure alignment with business objectives.",
        "5e544ff9-b5c4-412e-80bc-4ebe7cabbe43": "The AI Roadmap for digital transformation highlights technologies such as machine learning, natural language processing, computer vision, and robotic process automation.",
        "7b8de721-3bcc-478a-b5e7-c8fe05ef3751": "The AI Roadmap proposes a timeline of achieving its goals over the next five to ten years, with specific milestones set for each phase of development.",
        "820d6895-9298-4fa0-80ba-371ecd6b9dc1": "The AI Roadmap addresses ethical considerations in AI deployment by establishing guidelines for responsible AI use, promoting transparency, ensuring accountability, and advocating for fairness and inclusivity in AI systems. It emphasizes the importance of stakeholder engagement and the need for ongoing assessment of AI impacts on society.",
        "20801477-55da-4808-a335-c04614343dab": "The AI Roadmap recommends organizations to utilize resources such as training programs, AI toolkits, best practice guidelines, and access to AI expertise through partnerships or consulting services to effectively adopt AI technologies.",
        "050cd8f2-8b81-4087-8042-50025fc4cb88": "The document was prepared by the Australian Institute for Machine Learning.",
        "47c6f4ee-8c59-459b-916b-4a719081cf35": "November 2023",
        "e74ed6ad-693e-4881-b2c7-1e9f73b77116": "Australian Institute for Machine Learning",
        "d5b98505-cbfe-433e-9755-5b538bcff6dc": "The primary focus of the Australian Institute for Machine Learning is to advance research and development in machine learning and artificial intelligence.",
        "741e187d-2f24-436d-a74e-fa054e51cbc7": "The date of preparation, November 2023, indicates that the document's content is current and reflects the latest developments and research in the field, ensuring its relevance to contemporary discussions and applications.",
        "531a0432-a71f-4e54-92a8-3609b2a2e062": "The Australian Institute for Machine Learning may provide information on research findings, machine learning methodologies, project outcomes, data analysis techniques, and applications of machine learning in various fields.",
        "ec755e46-4f5f-4ce7-8301-6870ca1001fb": "It is important to note the preparation date of a document in machine learning because it provides context for the relevance and applicability of the information, ensuring that users are aware of the timeliness of the data, methodologies, and findings presented.",
        "46fd0cf6-d4c8-4b98-93c2-efbf0e8247b1": "The preparation date of November 2023 may indicate that the findings or recommendations are based on the most current data and trends available at that time. This could affect the relevance and applicability of the conclusions, as they may not account for developments or changes that occur after this date. Additionally, any recommendations may need to be revisited or updated in light of future advancements in the field.",
        "58d1cd06-f9e4-429b-8c7c-4e606795af41": "The Australian Institute for Machine Learning contributes to advancements in machine learning through cutting-edge research, collaboration with industry partners, and the development of innovative algorithms and applications that address real-world challenges.",
        "f7d0d81f-ade2-4f66-a092-087799550401": "The significance of the document prepared by the Australian Institute for Machine Learning could lie in its potential contributions to advancements in machine learning research, the establishment of best practices, or the development of innovative applications that could impact various industries.",
        "f84bc2d4-36be-47e9-9a1f-00b70c5b8064": "The primary goal of the collaboration between the Australian Institute of Machine Learning (AIML) and South Australian agencies and businesses is to develop new or improved services based on machine learning, demonstrating the feasibility of these solutions for further technological advancement.",
        "8f5bac99-5799-4ae3-a61d-6c2e7f4054ea": "Think Digital aims to enhance its services for pastoralists by integrating AI and machine learning to develop a new product that assists in the identification of Emergency Animal diseases in cattle. This initiative builds on their existing expertise in immersive content and training, leveraging AI and ML technologies to provide more effective educational tools and support for producers in managing animal health risks.",
        "4a21bd8a-60a0-4c7c-9ca8-02f62a864c7f": "Think Digital has recently launched the Sheep Emergency Disease AR Tool in collaboration with PIRSA and Animal Health Australia to educate producers about emergency animal diseases in sheep.",
        "5da9fe6e-a447-42b5-a6ba-77ad894ced2d": "Think Digital specializes in the creation of immersive and interactive content for the agriculture, food, and fiber sectors. They develop educational tools, such as the Sheep Emergency Disease AR Tool, to help producers understand emergency animal diseases.",
        "6c512976-50e3-4fe3-a476-977818a18c47": "The intended outcome of the new product that Think Digital is developing is to help pastoralists identify emergency animal diseases in cattle using AI and machine learning technology.",
        "5910176c-a236-44f6-a6ad-acba811eb949": "AIML supports agencies in developing machine learning solutions by collaborating to define, validate, and demonstrate the feasibility of these solutions. They provide foundational technology and expertise, enabling agencies to enhance their services, as seen in projects like the Sheep Emergency Disease AR Tool developed with Think Digital and PIRSA.",
        "9c73d7c4-144d-4cac-9aa1-ee56489fc93f": "The significance of the Sheep Emergency Disease AR Tool in relation to Think Digital's objectives lies in its role as a foundational application that demonstrates the potential of immersive technology in educating producers about emergency animal diseases. This tool aligns with Think Digital's goal of enhancing training and education in agriculture, while also serving as a stepping stone for integrating AI and machine learning into future products aimed at identifying emergency animal diseases in cattle.",
        "1c5d9011-ce47-4273-b059-ffb9d3043221": "AIML provides a foundational technology for developing machine learning projects by offering expertise in defining, proving, and demonstrating the feasibility of machine learning solutions.",
        "a0814b19-8f04-482e-ab53-098131fca33c": "The key components outlined in the document for Think Digital's roadmap to integrate AI technology include: \n\n1. **High-Level Guiding Principles**: Establishing foundational principles to guide the integration of AI and ML.\n2. **Feasibility Assessment**: Iteratively defining and proving the feasibility of AI solutions for identifying emergency animal diseases.\n3. **Development Plan**: Creating a concrete plan for the next steps in product development.\n4. **Collaboration with AIML**: Engaging with the Australian Institute of Machine Learning for expertise and support.\n5. **Focus on User Education**: Ensuring the new product effectively educates pastoralists about emergency animal diseases.",
        "a78117c8-a1db-4a11-912d-f8591997d44d": "Incorporating AI and ML into Think Digital's new product for pastoralists is important because it enhances the accuracy and efficiency of identifying Emergency Animal Diseases in cattle. These technologies can analyze vast amounts of data quickly, providing real-time insights and predictive analytics that improve decision-making for pastoralists. This integration not only supports better animal health management but also aligns with Think Digital's mission to innovate in agricultural education and training.",
        "e57a0b2b-f823-4eb8-9fe8-ddb31a5bf741": "The primary purpose of the document outlined in the project background section is to provide a comprehensive framework for advancing the organization's capabilities in AI and machine learning, including strategic planning, alignment, and implementation guidelines.",
        "ff045dfe-7694-4eb7-a03d-13bc80ef4dbd": "The SWOT analysis contributes to the overall vision for AI and machine learning by identifying strengths, weaknesses, opportunities, and threats within the organization. This assessment helps in aligning resources and strategies with the vision, ensuring that the organization can leverage its strengths and opportunities while addressing weaknesses and mitigating threats. Ultimately, it informs decision-making and prioritizes initiatives that support the long-term goals of becoming a machine learning organization.",
        "e85b0190-668e-4c1d-8148-9badec727e1e": "The key principles outlined in the roadmap for implementing AI and machine learning include organizational alignment, infrastructural alignment, a focus on data collection, and a structured approach to model development and testing. Additionally, the roadmap emphasizes the importance of advancing AI maturity and conducting pilot studies to evaluate the effectiveness of AI platforms.",
        "2347dde2-feaa-44ff-ab68-5b532e6d7e38": "The AI maturity model aims to provide organizations with a structured framework to assess their current capabilities in machine learning, identify areas for improvement, and develop a strategic roadmap for successful integration and advancement of AI technologies.",
        "7b91d845-ea81-45d9-8cdb-cd1a59575a48": "The suggested steps for becoming a machine learning organization include establishing a clear vision for AI and machine learning, aligning organizational and infrastructural strategies, developing a model development roadmap, conducting pilot studies, and advancing AI maturity through continuous data collection and evaluation.",
        "513e9e56-c0ba-438c-9de4-e644f5e5a6a8": "The model development roadmap is structured to facilitate AI implementation by outlining key phases such as initial assessment, design, development, testing, and deployment. It incorporates principles of machine learning engineering, aligns with organizational and infrastructural goals, and emphasizes continuous improvement through pilot studies and data collection. This structured approach ensures that AI initiatives are systematically integrated into the organization, enhancing overall AI maturity.",
        "88e275bb-f4a0-4faf-a169-8ff5aabd89c0": "The main machine learning engineering principles highlighted in the document include model development best practices, organizational and infrastructural alignment, iterative testing and validation, data collection strategies, and a focus on AI maturity advancement.",
        "a41380d6-83c8-4142-8262-ca1e7eae3b96": "The \"Think Digital in 1 year\" section is expected to outline specific outcomes related to initial organizational and infrastructural alignment, the establishment of foundational AI and machine learning practices, and the initiation of pilot projects to test and refine digital strategies.",
        "9c310f28-1cfc-4726-93cb-42cc65732466": "The document proposes to align organizational and infrastructural elements for AI advancement by establishing a clear vision for AI and machine learning, implementing a roadmap with defined principles, and utilizing an AI maturity model. It emphasizes the importance of organizational alignment through continuous assessment and adaptation, while also focusing on infrastructural alignment by developing machine learning engineering principles and conducting pilot studies to test the AI platform. This integrated approach aims to ensure that both organizational strategies and technical infrastructures are effectively synchronized to support AI initiatives.",
        "b654f81f-93bc-4088-a207-7330ee06990a": "Appendix B provides recommendations to enhance the existing model, including improving data collection processes, increasing organizational alignment, implementing machine learning engineering principles, and conducting pilot studies to test the AI platform.",
        "9817bb16-8dd3-45d8-85fc-56a118037805": "The two emergency animal diseases that Think Digital aims to detect using AI and ML in their augmented reality product are Foot and Mouth Disease (FMD) and Lumpy Skin Disease (LSD).",
        "3f38517c-bb69-41d8-9b27-c8821161b76c": "Lumpy Skin Disease (LSD) affects cattle and water buffalo by causing skin nodules, which can lead to reduced milk production and, in severe cases, death.",
        "c7af7534-6da7-4017-af2d-d80b09ca9f36": "The primary challenge faced by the cattle industry in North Australia regarding animal diseases is the lack of diverse training data for accurately detecting and classifying diseases like Lumpy Skin Disease (LSD) and Foot and Mouth Disease (FMD) using AI and ML technologies. This limitation affects the model's ability to generalize and reliably identify these diseases in cattle.",
        "554ac857-b079-4b24-b2e9-4c0e80ce4f19": "The initial engagement with the AIML Researchers led by Yifan Liu resulted in the development of a data pre-processing solution and a custom model that classified images into three categories: Foot and Mouth Disease (FMD), Lumpy Skin Disease (LSD), and Healthy. An API endpoint was established, and while the model showed high validation accuracy with a small training dataset, it struggled with generalization and accuracy on unseen images due to a lack of diverse training data.",
        "82646a36-5aca-417d-b72c-95c78d282fd4": "The custom model developed by the AIML Researchers classified images into three classes: 1. Foot and Mouth Disease (FMD), 2. Lumpy Skin Disease (LSD), and 3. Healthy.",
        "04f63b07-dd4e-4821-b6e0-b72b330bd42c": "The model's accuracy was considered unreliable when tested with previously unseen images due to its inability to generalize well, primarily caused by a lack of suitably diverse training data.",
        "b8752331-021a-4dce-91b9-9ea76ac62a53": "After the project handover from the research team, the AIML Engineering team took the following steps: they conducted verification checks and reviewed the codebase provided by the research team. Additionally, they refined the project documentation, including updating READMEs, to facilitate easier use by Think Digital.",
        "2c773019-2046-4896-a95e-97042891a472": "The current model's specific limitation is its poor generalization due to a lack of sufficiently diverse training data, which affects its performance when tested with previously unseen images.",
        "100fd2e6-488c-45c3-a334-1fa994ff0479": "The AIML Engineering team improved the project documentation for Think Digital by conducting verification checks and reviewing the existing codebase. They refined the documentation, including updating READMEs, to enhance usability and facilitate easier implementation of the AI and ML tools developed for detecting emergency animal diseases.",
        "b3aaddcd-58a0-4167-86f6-e70cd718dd76": "The significance of having a diverse training dataset for the model's generalization lies in its ability to accurately recognize and classify a wide range of scenarios and variations in data. A diverse dataset ensures that the model is exposed to different conditions, breeds, and manifestations of diseases, which enhances its robustness and reliability when encountering unseen images. Without this diversity, the model may perform well on the training data but fail to generalize to real-world situations, leading to unreliable predictions in critical applications like disease detection in cattle.",
        "35744457-25c2-47d3-ab93-f910699af25b": "The main conclusion of the research was that the model's performance was unreliable on unseen images due to a lack of diverse training data, despite achieving high validation accuracy on a small training dataset.",
        "5baf4ae9-1f70-4773-bcfc-5877958f2a12": "The initial project handover to the AIML Engineering team was the responsibility of the research team, specifically led by Akide Liu et al.",
        "fc48afad-c6d6-4bca-9ac7-72ac598709b6": "The AIML Engineering team improved the project documentation by refining and updating the READMEs to enhance usability for Think Digital.",
        "c0e3188e-158a-4c21-9ff4-b7e8cc54225e": "The primary limitation of the current machine learning model is that it does not generalize well due to a lack of suitably diverse training data.",
        "17d4da66-36db-4227-be1a-e595e59a8f39": "The necessary scale for quality training data in machine learning model development is between 100,000 to 1 million images.",
        "90290b87-5f40-4b35-a7fe-e80866f7aa83": "Think Digital is currently in the early stages of building a generalized AI model, having established an API endpoint and deployed a preliminary model. However, the model's generalization capabilities are limited due to insufficiently diverse training data. A strategic roadmap has been defined to outline key milestones for developing and maintaining the AI systems.",
        "cddd7c73-c194-4b00-a92d-4c5859ec4963": "The purpose of the strategic roadmap defined by Think Digital is to outline important milestones necessary for the development and maintenance of AI systems, ensuring a structured approach to building a generalized AI model that delivers value to end users.",
        "264b89e5-9127-45e5-921f-a21cb7e1d9a5": "The validation accuracy of the model based on the small training dataset was high.",
        "eae11695-ea17-4c27-9b01-eab59b1080e0": "The original researchers involved in the project before the AIML Engineering team were Akide Liu et al.",
        "8a9d2b96-e751-449d-ad21-27976a7fe4db": "Having a diverse training dataset is crucial for a model's performance because it enhances the model's ability to generalize to unseen data. A lack of diversity can lead to overfitting, where the model performs well on the training data but fails to accurately predict outcomes in real-world scenarios. A sufficiently large and varied dataset, ideally comprising 100K to 1 million images, ensures that the model can learn from a wide range of examples, improving its reliability and effectiveness when deployed.",
        "da894833-9991-4d84-8fd3-7c80555570cb": "Think Digital's primary strength in rural Australia is its strong rural network established through educational programs, which enables effective partnerships with veterinary experts and farmers. This network facilitates data collection essential for developing advanced AI models for disease detection.",
        "50a1f411-4439-4052-bd63-ac6815682a8a": "Think Digital plans to leverage its strong rural network in Australia by forming nationwide partnerships with farmers and veterinary experts to collect and source crucial data from cattle farms. This data will enhance the development of their AI models, particularly for disease detection, while also addressing the need for high-quality training datasets to overcome current limitations.",
        "647b8f74-694a-44ee-be06-1b2a7b2a1e13": "The key weaknesses identified in Think Digital's current operations are insufficient training data, lack of internal technical expertise, and inadequate technology infrastructure to test and deploy AI models.",
        "b0a73431-cdbd-46f8-a45f-92b6c9f6a013": "Think Digital can address the lack of quality training data for its AI models by leveraging its strong rural network to establish partnerships with more data providers, such as farms and veterinary clinics. This collaboration can facilitate the collection of diverse and high-quality datasets. Additionally, creating a proprietary dataset focused on animal diseases can provide a competitive edge. Investing in technology infrastructure and enhancing internal technical expertise will also be essential to effectively test and deploy AI models.",
        "b4b7b8df-54e7-4759-af8f-2e26d3f8d143": "Think Digital can expand its partnerships in the agricultural sector by collaborating with more data providers, such as farms and veterinary clinics, to enhance data collection for AI model development. Additionally, leveraging its strong rural network and existing partnerships can help establish itself as a trusted leader in disease detection, addressing biosecurity needs and potentially expanding into broader agricultural applications.",
        "979c6aed-31e4-402b-9190-16364b0926c8": "Regulatory changes in data collection and AI usage could significantly impact Think Digital by imposing stricter guidelines on how data is gathered, stored, and utilized. This may limit their ability to access and leverage data from farms and veterinary clinics, hindering their AI model development. Additionally, compliance with new privacy regulations could require increased investment in technology infrastructure and training, further straining their resources. Ultimately, these changes could affect their competitive edge and ability to innovate in disease detection models.",
        "cc8c79e7-5431-4430-8864-7066ba054674": "Competitors pose several threats to Think Digital in terms of data and model development, including: \n\n1. **Access to Superior Data**: Competitors may acquire better quality data, which is essential for developing effective AI models.\n2. **Advanced Model Development**: They could build more sophisticated models that outperform Think Digital's offerings.\n3. **Internal Capabilities**: Competitors might enhance their internal technical expertise and intellectual property, giving them a competitive edge.\n4. **Stronger Partnerships**: They may establish stronger relationships with key stakeholders, such as farmers and veterinary clinics, which could limit Think Digital's access to critical data sources.\n5. **Regulatory Challenges**: Changes in regulations regarding data collection, privacy, and AI usage could impact Think Digital's operations and data access.",
        "2c16a947-68b1-49bd-95a3-dc30f7b75d6a": "Think Digital can position itself as a trusted leader in disease detection within the agricultural industry by leveraging its strong rural network and established partnerships to collect high-quality data. By addressing its weaknesses, such as insufficient training data and lack of technical expertise, Think Digital can develop proprietary datasets and advanced AI models. Additionally, forming strategic alliances with more data providers and focusing on biosecurity needs will enhance its credibility and market presence, allowing it to lead in disease detection solutions.",
        "cb16663e-be2e-400d-9c6a-84cfcf48b86e": "Established partnerships with veterinary experts and farmers play a critical role in Think Digital's strategy by enhancing its rural network, facilitating data collection for AI model development, and addressing biosecurity needs. These collaborations enable the company to leverage expert knowledge and access vital information from farms, which is essential for creating high-quality datasets and maintaining a competitive edge in disease detection.",
        "c4d3ab23-5ac2-4209-a577-276fe819b848": "It is important for Think Digital to create large, high-quality datasets for its AI initiatives because these datasets are essential for developing effective AI models, particularly for disease detection in livestock. High-quality data will help overcome current limitations, enhance model accuracy, and provide a competitive edge in the market. Additionally, leveraging their strong rural network can facilitate partnerships for data collection, addressing the critical need for sufficient training data and improving overall technical capabilities.",
        "b995ab73-c543-4f76-82cf-737762c9d4ec": "The primary goal of leveraging the network is to create nationwide partnerships for collecting and sourcing data from cattle farms, which is essential for developing and maintaining advanced AI models.",
        "efacece0-c6f0-4565-a006-b24fcce5e7ed": "The business can address the needs of the biosecurity government in Northern Australia by leveraging partnerships to collect high-quality data from cattle farms, which is essential for developing effective AI models to prevent disease outbreaks. By creating a proprietary dataset and enhancing internal technical expertise, the business can improve its AI capabilities and streamline data collection processes. This will enable the development of robust models that can classify diseases, ultimately supporting biosecurity efforts in the region.",
        "faecd854-324d-4ecb-8245-022a738a62fe": "The biggest bottleneck in AI model development for the business is the lack of quality training data.",
        "05b8b2e5-f320-4063-9c35-120e80f0d1e1": "The opportunity arising from the lack of quality training data is the potential to create a proprietary dataset, which can provide a competitive edge in AI model development before competitors enter the market.",
        "0924d57d-4a57-4d5a-abde-977aed1e8195": "The lack of internal technical expertise can significantly weaken a business's competitive position by increasing risks and the likelihood of competitors gaining an advantage. Without skilled personnel, the business may struggle to efficiently capture high-quality data, develop robust AI models, and effectively deploy them, ultimately hindering innovation and responsiveness to market needs. This gap can lead to missed opportunities in creating proprietary datasets and limit the ability to address critical challenges, such as biosecurity, thereby allowing competitors to establish stronger market positions.",
        "b1d2225c-5262-40be-9435-3cd80f2244f0": "Creating large, high-quality datasets is essential for developing effective AI models, as it addresses the current limitations in training data. High-quality datasets enable better model training, enhance the accuracy of disease classification, and provide a competitive edge in the market. Additionally, improving data collection processes and building a strong internal technology team will facilitate efficient data capture and deployment, ultimately leading to better outcomes for the business and its partnerships.",
        "aeab0052-4806-4d32-90aa-831f47c0e49d": "To improve data collection and model training, the following processes should be streamlined: \n\n1. Establish nationwide partnerships with cattle farms for efficient data sourcing.\n2. Develop a proprietary dataset to enhance data quality and address the current lack of training data.\n3. Build a strong internal technology team to enhance data capture and model development capabilities.\n4. Implement standardized data collection protocols to ensure consistency and reliability.\n5. Utilize technology to automate data collection and processing, reducing manual effort and errors.",
        "cf170467-f49b-49c0-80d2-3665f69b2d4a": "Developing a strong internal technology team will enable Think Digital to efficiently capture high-quality data, build superior AI models, and enhance the end-user experience. This team can leverage partnerships to source crucial data from cattle farms, address biosecurity needs, and create proprietary datasets, ultimately providing a competitive edge in the market.",
        "4fec6935-e1a3-4fe3-badb-244060650ce7": "The tool can be expanded beyond its initial use case by leveraging partnerships to collect data from cattle farms for AI model development, addressing biosecurity needs to prevent disease outbreaks, and later classifying other diseases. Additionally, creating a proprietary dataset can enhance model quality and provide a competitive edge, while building an internal technology team will improve data capture and model deployment capabilities.",
        "fe71de98-5739-4d7a-99ec-f2944b25c822": "Capturing high-quality data is essential for building AI models as it directly impacts the model's accuracy and effectiveness. High-quality datasets enable the development of robust AI solutions, address current limitations, and provide a competitive edge in the market. Additionally, efficient data collection processes enhance the ability to train and deploy better models, ultimately leading to improved outcomes in applications such as biosecurity and disease classification.",
        "4a1b6539-f0bb-4894-bd5c-16d28515a710": "Think Digital aims to help farm owners detect Foot-and-Mouth Disease (FMD) and Lumpy Skin Disease (LSD) using AI technologies.",
        "efe31c8b-c3d9-448a-be10-06be88443a50": "Machine learning can contribute to the early detection of cattle diseases by analyzing large datasets of images and symptoms to classify and differentiate between diseases like Foot-and-Mouth Disease and Lumpy Skin Disease. This enables timely interventions, predicts disease spread, and aids in developing effective containment strategies.",
        "69bc6eb4-07a9-401d-b3ff-fcdb41d716ee": "AI can assist in predicting the spread of cattle diseases by analyzing large datasets for early detection, classifying diseases through image analysis, and formulating effective containment strategies. Machine learning algorithms can differentiate between diseases based on symptoms, enabling timely interventions.",
        "98fe575f-8bb3-4741-943c-5205a989f7b1": "ML algorithms play a crucial role in classifying different cattle diseases by analyzing symptoms from images and vast datasets. They enable early detection, predict disease spread, and help differentiate between diseases like Foot-and-Mouth Disease and Lumpy Skin Disease, facilitating timely interventions.",
        "f1c23dc2-2234-42cf-a67a-8a0889606d8d": "Analyzing vast datasets is significant in cattle disease detection as it enables early identification of diseases, predicts their spread, and aids in developing effective containment strategies. Machine learning algorithms can classify and differentiate between diseases based on symptoms, ensuring timely interventions and improving overall herd health management.",
        "bf3ad9c9-b64a-4e2c-8dd8-c2c6bf943c63": "The AI Maturity Model categorizes companies into different levels based on their use of AI technologies. Most companies currently fall into Level 1, where they have awareness of AI but are not actively utilizing it. Higher levels (4 and 5) represent companies that are fully leveraging AI technologies and benefiting from advanced applications.",
        "4e377d7f-bd74-4db3-80b1-0a3ff0b4b440": "Most companies currently fall into Level 1 of the AI maturity model.",
        "13eca91f-1457-4104-9c72-eac3c46c0826": "Cattle farm owners who embrace emerging AI technologies can benefit from early disease detection, improved disease classification, and effective containment strategies. AI and machine learning can analyze large datasets to predict disease spread and ensure timely interventions, ultimately enhancing herd health and farm productivity.",
        "403098a1-bfda-4360-80e4-33b5f6b583ec": "Effective containment strategies can be formulated using AI and machine learning by leveraging ML algorithms to analyze large datasets for early disease detection, predicting disease spread, and classifying cattle diseases based on symptoms. This enables timely interventions and targeted containment measures, ultimately improving disease management in cattle farming.",
        "5ca5549d-b2cc-466f-b7e2-f2fbd8ff7dec": "Think Digital's overall vision for AI in cattle farming is to empower farm owners to utilize AI technologies for the early detection and management of cattle diseases, such as Foot-and-Mouth Disease and Lumpy Skin Disease, through advanced image analysis and machine learning algorithms. This approach aims to enhance disease prediction, containment strategies, and timely interventions.",
        "8e949f80-11cd-4c50-a932-5cce502c4cc6": "Companies at Level 1 are primarily aware of AI but do not apply it to their business problems, often influenced by hype. In contrast, companies at Level 2 are actively prototyping AI systems informally, experimenting with data and tools to explore potential applications, though their efforts are still in the early stages and may lack operational effectiveness.",
        "9fa0e53d-fa89-4d6b-a8ec-a9913e942371": "Companies begin to hire machine learning engineers and create data pipelines at Level 3 - Operational, when they have transitioned prototypes into operational environments and are actively utilizing AI in their business functions.",
        "215a6744-8504-42a3-a93d-18aedf76576e": "Companies at Level 2 typically experiment with AI technologies by prototyping systems informally, using research-quality code in environments like Jupyter notebooks. They explore data requirements and computational needs while testing off-the-shelf models from cloud providers like AWS, Azure, and Google Cloud to identify potential quick wins, although these generic solutions often fall short of addressing their unique business challenges.",
        "137b609e-2536-4295-b77e-20922c5fadd4": "A key characteristic of companies operating at Level 4 is their use of custom machine learning models and processes to disrupt existing business processes in innovative ways, rather than relying on off-the-shelf solutions.",
        "d026d46b-06d1-4808-8e82-1f8d90f4ea11": "Level 5 in AI utilization means that a company is using machine learning pervasively, making AI integral to its operations and the primary value it offers to customers.",
        "410accbc-71e9-441e-9cf4-0df35475709b": "The AI strategies of Level 3 companies differ from those at Level 1 in that Level 3 companies have moved beyond mere awareness and are actively implementing AI solutions in their daily operations. They have transitioned from informal prototyping to operationalizing AI, employing machine learning engineers, creating data pipelines, and integrating AI features into their applications. In contrast, Level 1 companies are still in the awareness phase, discussing AI without practical application or strategy, often driven by hype rather than informed decision-making.",
        "d60d8a8f-b638-4d3d-ae07-1afb31ef14fd": "Level 2 companies are likely to find generic, off-the-shelf AI models insufficient for their unique business problems, as these solutions often fail to address specific needs and complexities inherent to their operations.",
        "b14c1b83-6f23-4067-be06-c7de8ae337bf": "The significance of custom models in the operations of companies at Level 4 lies in their ability to disrupt existing business processes by providing tailored solutions that address unique challenges. Unlike off-the-shelf models, custom models enable companies to create innovative functionalities and processes that are not available in the market, thereby enhancing their competitive advantage and driving significant value for customers and stakeholders.",
        "acf55019-de39-4305-8c46-03046ba28f1d": "As companies progress from Level 1 to Level 5, the value provided to customers evolves significantly. \n\n- **Level 1 (Awareness)**: Minimal value; companies are aware of AI but not applying it, leading to limited customer benefits.\n- **Level 2 (Prototyping)**: Value begins to emerge through experimentation, but solutions are often generic and may not address specific customer needs effectively.\n- **Level 3 (Operational)**: Increased value as AI is integrated into daily operations, enhancing specific features or processes that directly benefit customers.\n- **Level 4 (Systemic)**: Substantial value creation through custom AI solutions that disrupt existing processes, offering unique functionalities that improve customer experiences.\n- **Level 5 (Transformational)**: Maximum value, as AI becomes integral to the company's offerings, fundamentally transforming how customers interact with products and services.",
        "7d822587-80e3-45fc-91c9-e2a8cedd2437": "Indicators that a company has moved from prototyping to operational use of AI include:\n\n1. Integration of AI systems into daily business functions.\n2. Employment of machine learning engineers and data scientists.\n3. Development of data pipelines and versioned datasets.\n4. Implementation of machine learning operations (MLOps) practices.\n5. At least one feature in their application stack utilizing AI to enhance value for customers or internal stakeholders.",
        "8719f682-d5f8-43c9-8c9b-6c07073cc125": "Level 4 companies distinguish themselves from Level 1 companies by using machine learning to fundamentally disrupt and innovate their business processes, rather than merely applying off-the-shelf models. Level 4 companies develop custom models and new functionalities that create unique value, while Level 1 companies typically utilize AI in a limited, non-disruptive manner.",
        "f693b61e-d27f-470d-8157-4dc5f9bbbf62": "Level 4 companies utilize machine learning to disrupt existing business processes by developing custom models and innovative processes that create new functionalities not previously available in the market. This goes beyond simply applying off-the-shelf models; it involves building tailored solutions that enhance value for customers and internal stakeholders, thereby fundamentally transforming how the business operates.",
        "57190111-3957-4d61-aabd-bed690343209": "The primary characteristic of Level 5 companies in terms of their use of AI is that they utilize machine learning pervasively, with AI being the core value they provide to customers, generating revenue from every component of their systems.",
        "98940bde-49d9-4394-b2a2-9b6317adcfb6": "Very few companies will reach Level 4 in AI maturity because it requires not just the application of existing models, but the development of custom machine learning solutions that fundamentally disrupt existing business processes. This level of innovation and integration is complex and resource-intensive, making it challenging for most organizations to achieve.",
        "40589171-7f97-4c80-9fbf-5a04feb5d3ac": "An organization must commit to improving core values and investing in custom AI models, processes, and pipelines before increasing its AI maturity from Level 1.",
        "46952c14-aca2-4d3a-bdb1-540a3538a6f5": "The value provided by AI at Level 4 companies is focused on disrupting existing business processes through the development of custom machine learning models and innovative functionalities. In contrast, Level 5 companies derive their core value from AI, integrating it pervasively across their systems to create revenue-generating components, making AI central to their business model.",
        "6a1eef83-30d8-4c10-972f-21a9b9c4465f": "Level 4 companies are expected to build custom machine learning models, develop innovative processes and pipelines, and create new functionalities that disrupt existing business processes, rather than relying on off-the-shelf solutions.",
        "6c74a967-d83d-4055-b91c-33836ee2544d": "The significance of custom models in the context of Level 4 AI maturity lies in their ability to disrupt existing business processes by creating unique solutions tailored to specific needs. Unlike off-the-shelf models, custom models enable companies to develop innovative functionalities and processes that provide distinct value to customers and stakeholders, setting them apart in the market. This level of AI maturity reflects a deeper integration of machine learning into the core operations of the business, driving significant transformation and competitive advantage.",
        "9ce6dd33-583c-48c1-b862-7470363d924b": "Most companies could realistically achieve Level 3 AI maturity with sufficient investment and commitment, where they utilize AI in at least one feature of their application stack or information processing tasks to enhance value for customers or internal stakeholders.",
        "6641ca23-4e2e-4a67-bd0e-c261e45374f4": "AI can provide value to customers at Level 5 organizations by integrating machine learning into every aspect of their services, enabling personalized experiences, predictive analytics, and automated decision-making. This pervasive use of AI enhances customer engagement, optimizes service delivery, and drives revenue through tailored offerings and insights that were previously unavailable in the market.",
        "115b5ff0-8c32-4cc2-8999-5121167b9b16": "Aligning machine learning with a company's core business is crucial because it ensures that ML initiatives receive comprehensive support across all levels, fostering collaboration among multi-disciplinary teams. This integration allows for effective data management, continuous model training, and deployment, which are essential for maintaining and improving machine learning applications. Treating ML as a separate feature risks isolation, inefficiency, and underutilization of resources, ultimately hindering the company's ability to leverage AI for strategic advantage.",
        "94ef122d-e7a7-4a86-8bcf-d5f3218be311": "To build effective machine learning models, the necessary roles and expertise include:\n\n1. **Multi-disciplinary Teams**: Involvement of machine learning experts, subject matter experts (e.g., veterinary experts, cattle farm owners), data engineers, and software engineers.\n2. **Data Engineering**: Expertise in acquiring, cleaning, organizing, and managing large and complex datasets.\n3. **Model Training and Evaluation**: Data scientists and engineers skilled in model training, validation, and implementation of data loading and evaluation processes.\n4. **Continuous Deployment**: Knowledge in continuous integration, testing, and delivery to ensure smooth deployment of models into production. \n\nThese roles must work collaboratively and be supported by the organization to align with the company's AI and machine learning vision.",
        "71635b99-612c-454d-ae04-e63e4a510897": "The complexity and sensitivity of data required for machine learning differ from existing production systems in that machine learning often necessitates larger, more intricate, and more sensitive datasets. These datasets must be meticulously labeled, cleaned, and organized, which is a more demanding process than typical data management in production systems. Additionally, machine learning data can be more volatile, requiring new management methods and continuous updates to ensure model accuracy and relevance.",
        "95768618-782f-4857-8bd0-3c86ae48da37": "The key activities involved in data engineering for machine learning projects include:\n\n1. **Data Acquisition**: Gathering relevant data from various sources.\n2. **Data Cleaning**: Removing inaccuracies and inconsistencies from the data.\n3. **Data Organization**: Structuring and formatting data for easy access and analysis.\n4. **Data Storage**: Storing data in appropriate databases or data lakes for scalability and security.\n5. **Data Accessibility**: Ensuring that data is readily available to teams and systems that require it.\n6. **Model Training Support**: Facilitating the loading of data for model training and evaluation.\n7. **Continuous Maintenance**: Regularly updating and managing data pipelines to accommodate evolving data needs.",
        "8c8984f1-fe09-4a30-a907-b274d2e8c1ad": "Model training and evaluation are considered core activities in machine learning applications because they are essential for developing accurate and reliable models. This process involves significant investment in computational resources and requires collaboration among multi-disciplinary teams to ensure that models are effectively trained on comprehensive, high-quality data. Additionally, models must be continuously maintained and evaluated to adapt to changing data and performance requirements, making ongoing training and validation crucial for successful deployment and integration into business operations.",
        "cf21dc2f-7d4e-4094-95f8-0f15ce19ca35": "Effective model training and validation require investments in high-performance hardware, particularly GPUs, either in the cloud or as dedicated machine learning infrastructure. Additionally, robust data management systems are necessary to handle large, complex datasets, ensuring they are cleaned, organized, and accessible for training and evaluation.",
        "9137ac31-5994-4f81-8257-d34f8910f912": "Machine learning models should be maintained through continuous evaluation and retraining, ensuring alignment with organizational goals. This involves creating multi-disciplinary teams, managing data effectively, and investing in necessary computational resources. Implementing continuous integration and deployment practices is essential for seamless updates and improvements to the models. Regularly monitoring model performance and adapting to new data and business needs is crucial for long-term success.",
        "a57142fb-949d-4ad0-863c-73ad9e12ff73": "Continuous deployment is significant in machine learning products as it enables seamless integration of models into production environments, ensuring they are consistently updated and improved. This process facilitates rapid iteration, allowing teams to respond quickly to changes in data and user needs, ultimately enhancing the product's effectiveness and reliability. Continuous integration, testing, and delivery are essential to maintain model performance and adapt to evolving requirements.",
        "266fb45d-979d-41f3-9195-4eae191cb4f3": "Multi-disciplinary teams contribute to the success of machine learning initiatives by integrating diverse expertise, such as data engineering, domain knowledge, and software development. This collaboration ensures that machine learning is embedded into the core business processes, facilitating comprehensive data management, effective model training, and continuous deployment. By removing traditional boundaries and fostering organizational alignment, these teams enhance the capability to deliver on the company's AI vision, ultimately leading to more effective and sustainable machine learning solutions.",
        "8843a731-248a-4a86-8715-4c34e5bfd12d": "Essential processes for successful integration and delivery of machine learning models into production environments include:\n\n1. **Organizational Alignment**: Ensure that machine learning is embedded in the core business strategy with support at all levels.\n\n2. **Multi-Disciplinary Teams**: Form teams that include machine learning experts, domain specialists, and engineers to leverage diverse expertise.\n\n3. **Data Engineering**: Establish robust data management practices to acquire, clean, and organize comprehensive labeled datasets for model training.\n\n4. **Model Training and Evaluation**: Invest in necessary computational resources and implement systematic training, validation, and maintenance of models.\n\n5. **Continuous Deployment**: Develop frictionless processes for continuous integration, testing, and delivery of models into production.",
        "e987bffb-652c-41fa-b638-03a325cbd452": "The primary focus of model training and validation in machine learning applications is to develop and maintain models that accurately predict outcomes based on a gold standard dataset, ensuring quality assurance and confidence before deployment into production environments.",
        "ee73687e-6781-415a-8192-14785c57489f": "Continuous deployment is important for machine learning products because it enables the seamless integration of updated models into production, ensuring that they remain effective and relevant. This process allows for ongoing model evaluation and improvement, driven by new data and changing conditions. By implementing continuous integration and testing, organizations can maintain high-quality standards through a gold standard dataset, ensuring that only models that meet performance criteria are deployed, ultimately enhancing the product's reliability and user satisfaction.",
        "8063b733-1ce1-4816-a135-6ceafa861132": "GPUs play a crucial role in the model training process by providing the necessary computational power to efficiently handle the large datasets and complex calculations involved in training machine learning models. They accelerate the training time, enabling faster iterations and experimentation, which is essential for optimizing model performance.",
        "5da8b13e-80aa-43de-aebf-77667ecfb24e": "A gold standard dataset contributes to the quality assurance of machine learning models by serving as a benchmark for model evaluation. It consists of verified data labels and diverse examples that reflect real-world scenarios, ensuring that models meet a defined level of accuracy before deployment. This dataset acts as a gatekeeper, allowing only models that successfully pass its criteria to be pushed into production, thereby enhancing the reliability and effectiveness of the deployed models.",
        "9199ec4c-4bec-4abe-bbe5-e2b18cd69aa9": "The purpose of model checkpointing in the training process is to save the current state of a model at specific intervals, allowing for recovery in case of interruptions, evaluation of model performance at different stages, and the ability to resume training from a specific point rather than starting over. This ensures efficient use of resources and helps maintain model quality over time.",
        "c3911101-90e4-4431-8377-0c24d78268dd": "It is necessary to maintain machine learning models over time to ensure they remain effective and relevant. Continuous maintenance allows for updates based on new data, adapts to changing conditions, and ensures models meet quality standards, such as those set by a gold standard dataset. This ongoing process helps maintain model accuracy and reliability in real-world applications.",
        "1612c074-7a13-4dd8-87a9-ffec252042b1": "A gold standard dataset should possess the following characteristics: \n\n1. **Verified Data Labels**: Each data point must have accurate and reliable labels to ensure quality.\n2. **Diversity**: It should encompass a wide range of scenarios and variations, reflecting real-world conditions.\n3. **Separation from Training Data**: The dataset must be distinct from the training data to provide unbiased evaluation.\n4. **Quality Assurance**: It should serve as a benchmark for model performance, ensuring only high-quality models are deployed.\n5. **Comprehensive Coverage**: It should cover all relevant categories and edge cases to thoroughly test model capabilities.",
        "ea3a0533-1770-4f6a-ab71-dc0c7192be07": "Data scientists and engineers collaborate in the model training process by defining the training objectives and metrics, while engineers focus on implementing the necessary infrastructure for data loading, model training, and evaluation. This partnership ensures that models are continuously maintained and validated against a gold standard dataset, which serves as a benchmark for quality assurance before deployment into production.",
        "3c5400a5-9f38-4f40-84cf-caae47225b45": "\"Frictionless mechanisms\" in the context of launching models into production refer to streamlined processes that enable seamless integration, continuous deployment, and efficient management of machine learning models in a live environment. This includes automated workflows for model testing, validation against a gold standard dataset, and deployment, ensuring that only high-quality models are released for use.",
        "851cfaac-08a3-4c97-9b2a-021488404c4a": "The verification of data labels in a gold standard dataset is crucial for model performance as it establishes a reliable benchmark for accuracy. Accurate labels ensure that the model is trained and evaluated against high-quality data, which enhances its ability to generalize to real-world scenarios. This quality assurance process helps in identifying models that meet performance standards before deployment, ultimately leading to more effective and trustworthy machine learning applications.",
        "8878b0ca-be25-430f-93c4-15cb6efa036e": "Key metrics to monitor the performance of models in production include:\n\n1. **Accuracy**: Measure the proportion of correct predictions made by the model.\n2. **Precision and Recall**: Evaluate the model's ability to identify relevant instances and minimize false positives/negatives.\n3. **F1 Score**: A balance between precision and recall, useful for imbalanced datasets.\n4. **AUC-ROC**: Assess the model's ability to distinguish between classes.\n5. **Model Drift**: Monitor changes in model performance over time due to shifts in data distribution or customer behavior.\n6. **Customer Feedback**: Collect qualitative insights on model predictions to identify unexpected use cases or quality issues.\n7. **Latency**: Measure the time taken for the model to generate predictions, ensuring it meets performance requirements.\n8. **Error Rate**: Track the frequency of incorrect predictions to identify potential areas for improvement. \n\nThese metrics will help ensure the model remains effective and relevant in a production environment.",
        "1c7ada10-2764-467c-a16b-c912b758b916": "Customer feedback can be utilized to assess the effectiveness of the model's predictions by collecting insights on the accuracy and relevance of the predictions from users. This feedback helps identify any decline in prediction quality, reveals unexpected use cases, and highlights areas where the model may struggle, particularly with data it hasn't been trained on. By analyzing this feedback alongside defined performance metrics, organizations can make informed adjustments to improve model performance and ensure it meets customer needs.",
        "53d2e073-98d3-4e4f-af71-5aefaac61a33": "Using a model trained on specific regional cattle data in a different region may lead to challenges such as poor performance due to differences in cattle breeds, environmental factors, and disease prevalence. The model may not generalize well to the new data, resulting in inaccurate predictions. Additionally, users from the new region may have different behaviors or needs that the model was not designed to address, potentially leading to customer dissatisfaction and unexpected use cases. Monitoring and customer feedback will be crucial to identify these issues and mitigate risks.",
        "cb80e657-bf0a-41e6-8722-a6f3229ff554": "The initial phase of model development referred to in the document is the \"feasibility study.\" This phase entails collecting data, training a model, and identifying its limitations, particularly in generalizing over unseen data. It serves as a foundational step to determine the possibilities for the AI-assisted cattle disease tool before advancing to production.",
        "98a43352-73ff-4967-a15d-f7712f0c73ff": "Conducting feasibility studies before launching models into a production environment is crucial because they help identify the model's limitations, assess its ability to generalize over unseen data, and determine its suitability for real-world applications. These studies provide insights into potential performance issues, customer behavior changes, and necessary adjustments, ensuring that only viable models are deployed. This process ultimately aids in building organizational knowledge and developing effective AI solutions.",
        "a75c04f7-b6e1-4ff4-bbbb-f5637731e3cf": "The model has been identified to have severe limitations in generalizing over unseen data, particularly when applied to different regions or customer behaviors that were not included in the training dataset. This can lead to a drop in prediction quality and unexpected usage scenarios that the model was not designed to handle.",
        "07eed9b8-51c5-4c83-8d30-6a2405cc208b": "The document suggests that Think Digital can progress to a minimum viable product (MVP) by conducting feasibility studies for new models, collecting and analyzing data, and iteratively refining their models based on performance metrics and customer feedback. They should focus on understanding the limitations of their models, particularly in generalizing to unseen data, and continuously repeat this process across multiple models to build organizational knowledge and develop a robust AI-assisted cattle disease tool.",
        "090c33bb-8c23-40cd-bd15-317a31780cd9": "Organizational knowledge is crucial in developing a complete AI platform as it enables the identification of model limitations, informs the feasibility studies, and guides the iterative process of model development. This knowledge is gained through repeated experimentation and feedback, which helps in understanding data behavior, customer needs, and improving model generalization over time.",
        "2c8d73d9-cad6-41ea-adb0-b5e956d40232": "Indicators that the quality of a model's predictions is dropping over time may include a decline in defined performance metrics, negative customer feedback on predictions, and the model's inability to generalize to new or unseen data, particularly in regions or contexts not covered during training.",
        "98b628d4-59f5-4398-8490-e2c4809fd2df": "Monitoring customer behavior helps identify shifts in data and usage patterns, allowing for timely adjustments to AI models. By defining performance metrics and gathering customer feedback, organizations can detect quality declines and unexpected use cases. This ongoing evaluation informs model improvements, enhances generalization to unseen data, and ultimately contributes to the development of more effective AI solutions.",
        "0d906c68-2c27-44b0-bb99-3b06f10020b8": "When determining the performance requirements for a model in production, consider the following factors:\n\n1. **Inference Time**: Assess whether real-time predictions are necessary or if batch processing is acceptable.\n2. **Hardware Requirements**: Evaluate the GPU RAM needed, model architecture size, and hosting options (cloud vs. on-premises).\n3. **Data Labeling Costs**: Analyze the similarity of data across different sources and the amount needed for effective training and evaluation.\n4. **Quality of Data Labels**: Ensure high standards for data labeling, particularly for gold standard datasets, to maintain model accuracy.\n5. **Total Cost of Ownership**: Consider the overall costs associated with deployment, including infrastructure and maintenance.",
        "b677fc86-2f80-4dea-8c28-f2caa30e6256": "The choice between real-time inference and batching requests significantly impacts model deployment by influencing performance requirements, resource allocation, and cost management. Real-time inference necessitates low latency and high availability, which may require more powerful hardware and increased operational costs. In contrast, batching requests allows for more efficient resource utilization and can reduce costs, but may not meet applications needing immediate responses. Ultimately, the decision should align with the specific use case and performance expectations of the deployed model.",
        "a46ab7a7-fba0-4bc2-82f0-13f430b7d274": "Key considerations for training hardware requirements when deploying a machine learning model include:\n\n1. **Performance Requirements**: Determine the necessary inference time and whether real-time processing is needed or if batching requests is acceptable.\n\n2. **GPU Memory Needs**: Assess the GPU RAM required based on the size of the data and the complexity of the model architecture.\n\n3. **Hosting Environment**: Decide whether to host the model on cloud infrastructure or on-premises, considering the implications for scalability and maintenance.\n\n4. **Total Cost of Ownership**: Evaluate the overall costs associated with both cloud and on-premises solutions, including hardware, software, and operational expenses.\n\n5. **Data Labeling Costs**: Consider the costs and quality of data labeling for training and evaluation, ensuring the model generalizes well across different datasets.\n\n6. **Integration Testing**: Establish specifications for data labeling quality to ensure reliable performance during both training and evaluation phases.",
        "5a6286ee-525a-471f-87ac-bff7f24dd3e1": "The generalization of a model across different cattle farms and regions can be assessed by evaluating its performance on diverse datasets that represent various farms and geographical locations. Key steps include:\n\n1. **Cross-Validation**: Use k-fold cross-validation with data from multiple farms to ensure the model performs consistently across different environments.\n2. **Performance Metrics**: Analyze metrics such as accuracy, precision, recall, and F1-score on test datasets from different regions to gauge generalization.\n3. **Domain Adaptation**: Implement techniques to adapt the model to new data distributions, ensuring it can handle variations in cattle data.\n4. **Data Diversity**: Ensure the training dataset includes samples from various farms and regions to improve the model's robustness.\n5. **Real-World Testing**: Deploy the model in real-world settings across different farms and monitor its performance to identify any discrepancies or areas for improvement. \n\nBy following these steps, one can effectively assess and enhance the model's generalization capabilities.",
        "832da1a3-1b60-448e-a168-abcf97805a54": "Data labeling costs are significant in training and evaluating a machine learning model because they directly impact the quality and quantity of the data used for model development. High-quality labeled data is essential for ensuring that the model generalizes well across different datasets, such as cattle data from various regions. Additionally, the costs associated with data labeling can influence the overall budget and feasibility of deploying the model in production, as they affect the total cost of ownership and the resources required for maintaining data quality and consistency.",
        "35483409-15cd-4913-a756-a3a7962c026c": "The concept of \"gold standard\" data labeling refers to a high-quality, meticulously curated dataset used for rigorous model evaluation, akin to \"integration testing.\" It ensures that the data meets specific specifications and quality standards, providing a reliable benchmark for model performance. In contrast, regular evaluation data is typically used for more general assessments, similar to \"unit testing,\" and may not adhere to the same stringent quality criteria. Gold standard data is essential for validating a model's effectiveness in real-world applications, while regular evaluation data serves as a preliminary check on model accuracy.",
        "1f333cbe-9531-471c-ba0f-17a47a064ddb": "Having a fully automated end-to-end pipeline for training and deploying machine learning models is crucial because it ensures reliability, efficiency, and scalability. It allows for consistent performance monitoring, simplifies the integration of new data, and reduces the risk of human error. Automation streamlines the process from data preparation to model deployment, enabling teams to focus on improving model performance rather than managing manual tasks. This is essential for meeting performance requirements, managing hardware resources effectively, and ensuring high-quality data labeling, ultimately leading to better model generalization and faster time-to-market.",
        "fdbeb963-107a-4a23-8196-47d9769f93d6": "A reasonable initial objective when starting to develop a classification model is to simplify the task, such as classifying a single disease instead of multiple diseases. This allows for a more manageable starting point and helps ensure the model can achieve good performance before scaling up.",
        "087b78b1-72be-4365-a2f7-d547cb2e5254": "The total cost of ownership (TCO) can significantly influence the decision between cloud and on-premises hosting for model training by encompassing various factors such as hardware costs, maintenance, scalability, and operational expenses. Cloud hosting may offer lower initial costs and greater scalability, while on-premises solutions might incur higher upfront investments but provide more control over resources and potentially lower long-term costs. Evaluating TCO helps organizations assess which option aligns better with their performance requirements, data labeling costs, and overall budget constraints.",
        "97d6bfe3-2991-4bca-a24d-20a697e89d20": "The quality of data labeling significantly impacts the performance of a machine learning model in several ways:\n\n1. **Accuracy**: High-quality labels ensure that the model learns from correct examples, leading to better predictions. Poor labeling can introduce noise, causing the model to learn incorrect patterns.\n\n2. **Generalization**: Well-labeled data that reflects diverse scenarios helps the model generalize better to unseen data. Inconsistent or biased labels can limit the model's ability to perform well across different datasets.\n\n3. **Training Efficiency**: Accurate labels reduce the need for extensive retraining and fine-tuning, saving time and resources. In contrast, mislabeled data can lead to longer training times and increased costs.\n\n4. **Evaluation Metrics**: The reliability of evaluation metrics depends on the quality of the labeled data used for testing. Poor labeling can skew results, making it difficult to assess the model's true performance.\n\n5. **Integration Testing**: High-quality labels are essential for gold-standard testing, ensuring that the model meets performance requirements before deployment. This helps identify potential issues early in the development process. \n\nOverall, the effectiveness of a machine learning model is heavily reliant on the quality of its training and evaluation data labels.",
        "39fb1fdb-c4b8-4ffd-8c96-d965389f9c36": "The primary focus of integration testing for machine learning models is to ensure that the entire pipeline\u2014from training to deployment\u2014is reliable, automated, and can be executed easily by anyone. This includes verifying the integrity of data and labels, maintaining high precision and recall during model updates, and implementing fail-safe checks before rollout.",
        "ab6edc73-d6e7-4ce9-a8c4-08106e29181d": "The most significant factor contributing to gains in machine learning projects is the quality of data and labels, rather than the algorithms used.",
        "2f9318fb-8ee0-4372-aa4f-9d14512bfa57": "The key steps for ensuring a reliable training and deployment pipeline are:\n\n1. Establish a fully automated, end-to-end pipeline for training, evaluation, gold-standard testing, and deployment that is easy to run.\n2. Begin with a clear and reasonable objective, focusing on a specific classification task.\n3. Incrementally add common-sense data and labels, training small models initially and measuring precision and recall for each class against the gold standard.\n4. Maintain pipeline reliability through fail-safe checks and thorough testing before rollout.",
        "6ab111ad-b43d-4009-9c11-4aaee888823b": "Starting with a reasonable objective is crucial in machine learning model development because it helps to define a clear scope and focus for the project. This ensures that the model is built on manageable tasks, allowing for effective integration testing and reliable evaluation. A well-defined objective facilitates the systematic addition of data and labels, ensuring that precision and recall remain high, ultimately leading to better performance and more meaningful results.",
        "eda3a1ca-ff49-4ffc-b25d-927cbf736863": "To add common-sense data and labels to the model training process, follow these steps: \n\n1. Ensure a reliable and automated end-to-end pipeline for training, evaluation, and deployment.\n2. Start with a focused objective, such as classifying a single disease.\n3. Incrementally integrate common-sense data and labels, focusing on one classification or region at a time. Train small models initially and measure precision and recall against a gold standard.\n4. Maintain pipeline reliability with fail-safe checks and thorough testing before deployment.\n\nThis method emphasizes the importance of high-quality data and labels, which are crucial for improving model performance.",
        "93ca92bb-ced6-4090-a4fc-a1d62b575a25": "To ensure the reliability of the machine learning pipeline, the following measures should be taken:\n\n1. **Automate the Pipeline**: Ensure the entire training, evaluation, testing, and deployment process is fully automated and can be easily executed by anyone.\n\n2. **Establish Clear Objectives**: Start with a focused objective, such as classifying a single disease, to simplify the initial model development.\n\n3. **Incremental Data Integration**: Introduce data and labels gradually, focusing on one classification at a time, and continuously measure performance metrics like precision and recall.\n\n4. **Implement Fail-Safe Checks**: Incorporate robust fail-safes and conduct thorough testing before deploying any updates to maintain pipeline reliability.\n\n5. **Prioritize Data Quality**: Invest in high-quality input data and labels, verified by experts, to drive significant improvements in model performance.",
        "cdd4f520-05a2-4e2b-8ed2-854fd1194e3e": "Veterinary experts play a crucial role in ensuring the quality of data and labels for disease classification by verifying and validating the accuracy of the labels associated with various diseases. Their expertise helps in identifying relevant features and nuances in the data, which enhances the reliability of the training and evaluation processes. By providing high-quality, accurate labels, they contribute to the overall effectiveness of the machine learning models, leading to improved precision and recall in disease classification.",
        "20a5234a-c43c-4311-bf17-80e780a4893b": "The use of established models like Efficient Net can benefit initial machine learning projects by providing a reliable and effective starting point for classification tasks. These models are well-tested and can deliver significant performance improvements with minimal effort, allowing teams to focus on optimizing data quality and labels rather than developing complex algorithms from scratch. This approach streamlines the development process, ensuring a robust pipeline that can be easily automated and maintained, ultimately leading to better outcomes in the long run.",
        "9a7a8957-10e3-49a3-b4df-bf757c163f54": "Precision and recall are crucial metrics when adding new classes and regions to a model because they help assess the model's performance on these new additions. High precision indicates that the model is accurately identifying relevant instances, while high recall shows that it is capturing most of the relevant instances. Monitoring these metrics ensures that the integration of new data does not degrade the model's overall effectiveness, allowing for informed decisions on whether to continue expanding the model or to refine it further. This iterative approach helps maintain reliability and quality in the model's predictions.",
        "0e521319-8694-4a2b-9d54-a66b892c83ac": "Thorough testing before rollout is crucial in the machine learning pipeline to ensure the reliability and effectiveness of the model in real-world scenarios. It helps identify integration issues, validate the end-to-end pipeline, and confirm that the model performs well across various conditions and data inputs. This reduces the risk of failures and ensures that the model meets performance standards, ultimately leading to better outcomes and user trust.",
        "5c970110-e1d0-4e6f-953c-adaff361aa98": "The three classes identified in the initial use case for machine learning at Think Digital are FMD (Foot and Mouth Disease), LSD (Lumpy Skin Disease), and healthy.",
        "8faa885f-4180-48e5-aef9-aaa48a4eab41": "Starting with a simple use case in machine learning development is crucial because it allows for focused experimentation and quicker iterations. By tackling a three-class problem initially, teams can efficiently validate their models, streamline processes, and ensure alignment within the organization. This approach minimizes complexity, accelerates time to production, and lays a solid foundation for scaling up to more complex scenarios in the future.",
        "520b007f-b46b-4555-9ac3-02437dbe6999": "In its first year, Think Digital needs to undertake the following key transformations:\n\n1. **Organisational Alignment**: Hire appropriate staff and establish processes to align the company with machine learning goals, fostering a culture that supports these initiatives.\n\n2. **Infrastructural Alignment**: Ensure the necessary infrastructure is in place to support machine learning projects, including data management and computational resources.\n\n3. **Pilot Machine Learning Projects**: Initiate one or more pilot projects focusing on a simple three-class problem (FMD, LSD, and healthy) to validate the approach and gain practical experience.\n\n4. **Governance Establishment**: Create a governance framework to oversee machine learning projects, ensuring compliance with privacy and data protection regulations, and appoint a responsible team or individual.\n\n5. **Steering Committee Formation**: Establish a machine learning steering committee to provide oversight on project direction, scope, budget, timelines, and methodologies, including representation from stakeholders and experts.",
        "32352e0a-8833-4216-ac20-b4cd9ad397aa": "Organisational alignment at Think Digital is crucial for achieving machine learning goals as it ensures that the entire company is focused on a unified objective. By hiring the right staff and establishing governance and steering committees, Think Digital can create a culture that supports machine learning initiatives. This alignment facilitates effective communication, accountability, and compliance with data protection regulations, ultimately leading to successful pilot projects and the efficient deployment of machine learning models.",
        "d5936a06-0467-4388-a999-c41ecf7309cc": "Governance plays a crucial role in the management of machine learning projects by establishing control systems, ensuring compliance with privacy and data protection laws, and defining accountability mechanisms. It involves appointing responsible teams, such as a Chief Data Officer, and forming a steering committee to oversee project direction, scope, budget, and timelines. This structured approach facilitates organizational alignment and supports the successful implementation of machine learning initiatives.",
        "bb64e96b-a915-418f-86eb-4b725968698b": "The responsibility for building, maintaining, and monitoring machine learning models at Think Digital should lie with a dedicated machine learning team, which reports to the Chief Data Officer or an equivalent position. This team should be supported by a machine learning steering committee that includes customer advocates and senior stakeholders to oversee project direction and governance.",
        "3c87f087-40e5-404d-b315-0eb5f4c5ecb8": "The purpose of establishing a machine learning steering committee is to provide oversight and guidance for machine learning projects, ensuring alignment with organizational goals, managing scope, budget, and timelines, and facilitating accountability among teams. The committee serves as an advisory body, comprising customer advocates, senior stakeholders, and field experts, to steer the direction and methods of machine learning initiatives.",
        "3b48fb75-ef22-4b35-bec1-b0c13fce7c4b": "The machine learning steering committee at Think Digital should include the following members:\n\n1. Chief Data Officer (or equivalent) - to oversee compliance and governance.\n2. Senior stakeholders from relevant departments (e.g., IT, Marketing, Operations) - to ensure organizational alignment.\n3. Customer advocates - to represent user needs and perspectives.\n4. Machine learning experts - to provide technical guidance and insights.\n5. Legal and compliance representatives - to address privacy and data protection issues.\n\nThis diverse group will ensure effective oversight of the machine learning initiatives.",
        "1154b7f2-0cf4-4470-bcc0-f05a4da2dc1f": "The key concerns for the governance of machine learning projects mentioned in the document include:\n\n1. Establishing a responsible person or team for building, maintaining, and monitoring models, reporting to the Chief Data Officer or equivalent.\n2. Ensuring compliance with privacy and data protection legislation.\n3. Forming a machine learning steering committee to oversee the direction, scope, budget, timelines, and methods of the projects.",
        "491372a9-b2b0-497f-839b-21596170ee3d": "Think Digital can ensure compliance with privacy and data protection legislation in its machine learning initiatives by establishing a robust governance framework. This includes appointing a dedicated team responsible for building, maintaining, and monitoring models, ensuring they report to the Chief Data Officer. Additionally, forming a machine learning steering committee will provide oversight on project direction, scope, and methods, ensuring alignment with legal requirements. Regular audits and training on data protection laws for all team members will further reinforce compliance.",
        "ff8bc7ac-7d1f-4865-9e7a-e740cc5363eb": "The primary responsibilities of a Chief Data Officer (CDO) in relation to machine learning culture include:\n\n1. **Building a Machine Learning Culture**: Foster an environment that encourages innovation and collaboration around data and AI initiatives.\n2. **Hiring Talent**: Recruit skilled engineers and data scientists to support machine learning efforts.\n3. **Strategic Roadmap Development**: Establish a clear strategic plan in collaboration with the steering committee to guide machine learning projects.\n4. **Data Utilization**: Understand and leverage the company\u2019s data assets to identify opportunities for machine learning applications.\n5. **External Partnerships**: Develop key partnerships with data collection agencies and experts to enhance data quality and address limitations.\n6. **Infrastructure Provisioning**: Ensure the appropriate infrastructure is in place to support machine learning initiatives, including local and cloud resources.",
        "df417cc5-735e-4349-a23b-bede7f426b63": "A Chief Data Officer (CDO) can identify opportunities for leveraging the company's data holdings for machine learning by thoroughly assessing the existing data assets, understanding their quality and relevance, and aligning them with business objectives. This involves collaborating with key stakeholders to pinpoint specific use cases, exploring external partnerships for data enhancement, and ensuring the necessary infrastructure is in place to support machine learning initiatives. Additionally, the CDO should foster a machine learning culture within the organization and develop a strategic roadmap that prioritizes data-driven projects.",
        "3ab71da5-e1a6-41e4-8312-957e4307830e": "Essential external partnerships for addressing current data limitations include data collection agencies, data labeling services, cattle farm owners, and veterinary experts. These partnerships help enhance data quality, ensure accurate labeling, and provide domain-specific insights necessary for effective machine learning initiatives.",
        "3fffc918-343b-4440-aa2c-27be55b96093": "To support machine learning initiatives, the document outlines several infrastructure considerations:\n\n1. **Data Storage**: Provision appropriate storage for training data, either on local NAS or in the cloud.\n2. **Computational Resources**: Utilize local deep learning workstations for model development and larger lab workstations for model rollout.\n3. **Inference Options**: Implement cloud-based solutions for CPU or GPU inference, depending on the organization's capabilities.\n4. **Scalability**: Ensure infrastructure can handle the spatial resolution of training data and inference performance requirements.\n5. **Cloud Utilization**: For cloud-savvy organizations, leverage cloud training nodes and AI platforms for enhanced capabilities. \n\nThese considerations are essential for building a robust machine learning culture and effectively leveraging data.",
        "e142641f-3b9b-40fc-baba-ab7f1de239de": "The key components of a local development and local model rollout setup for machine learning include:\n\n1. **Training Data Storage**: Utilize local Network Attached Storage (NAS) for storing training data.\n2. **Model Development Infrastructure**: Employ local deep learning workstations for training and model development.\n3. **Model Rollout**: Use a CI/CD agent to deploy models on larger lab workstations equipped with multiple GPUs.\n4. **Inference Options**: Implement cloud-based inference for CPU or GPU, depending on performance needs and cost considerations.",
        "b2182f46-7f9a-4e6c-99bb-381e53501a78": "The document suggests handling model rollout using CI/CD agents by conducting the rollout on a larger lab workstation after training the model on local deep learning workstations. This involves using a CI/CD agent to manage the deployment of a fully quantized and optimized model for CPU prediction, with the option for cloud-based inference for both CPU and GPU.",
        "3e895da7-aece-4144-83b4-d235bb5b883f": "The advantages of using cloud infrastructure for training and inference in machine learning include:\n\n1. **Scalability**: Easily scale resources up or down based on training and inference needs without significant upfront investment in hardware.\n2. **Cost Efficiency**: Pay-per-usage models allow organizations to only pay for the resources they consume, reducing overall costs.\n3. **Access to Advanced Tools**: Cloud platforms often provide access to state-of-the-art AI tools and frameworks, facilitating faster development and deployment.\n4. **Collaboration**: Cloud infrastructure enables easier collaboration among teams, allowing multiple users to access and work on projects simultaneously.\n5. **Flexibility**: Organizations can quickly adapt to changing requirements and experiment with different models and configurations without being constrained by local hardware limitations.\n6. **Data Storage and Management**: Centralized cloud storage simplifies data management and ensures that large datasets are easily accessible for training and inference.",
        "916c98e7-ad14-47ac-9bdd-c402a71150dd": "The types of workstations mentioned for local model development include local deep learning workstations costing approximately $8,000 AUD and larger lab workstations (e.g., Lambda Labs 4x GPU machines) costing around $20,000 AUD.",
        "a072dc53-e437-454a-beec-6033cbde1814": "Storing training data in the cloud is significant because it enables scalable access to large datasets, facilitates collaboration among teams, and supports efficient resource allocation for machine learning initiatives. It allows for flexible infrastructure provisioning, ensuring that the necessary computational power is available for training and inference, while also simplifying data management and integration with external data sources.",
        "3f2f9a07-b1c5-4304-b1ea-2ac73cfedb2b": "When provisioning infrastructure for machine learning, consider the following performance requirements:\n\n1. **Data Storage**: Ensure adequate storage capacity and speed for training data, whether on-premises or in the cloud.\n2. **Computational Power**: Assess the need for local deep learning workstations or cloud-based training nodes, depending on the scale of model development.\n3. **Inference Performance**: Determine the requirements for real-time or batch inference, which may necessitate CPU or GPU resources in the cloud.\n4. **Scalability**: Infrastructure should be scalable to accommodate varying workloads and data sizes.\n5. **Latency**: Evaluate acceptable latency levels for model inference, especially for real-time applications.\n6. **Cost Efficiency**: Consider the cost implications of on-premises versus cloud solutions, including pay-per-usage models for cloud inference.",
        "213a9eb6-111d-4e11-ba28-797348d6438f": "The primary storage solution for training data in the local development setup is a local NAS (Network Attached Storage).",
        "07ac3d26-8943-4cae-8a77-3c3b19e53514": "A typical local deep learning workstation costs around $6,000 to $8,000 AUD.",
        "c86e0d13-d5fa-4243-ac7b-89992750db91": "The type of workstation used for model rollout in the CI/CD process is a larger lab workstation, such as a Lambda Labs 4x GPU machine, which costs approximately $20,000 AUD.",
        "f4767c8d-6a38-498a-84a1-4ccac23a3aec": "The purpose of using a larger lab workstation for model rollout is to leverage its enhanced computational power, such as multiple GPUs, to efficiently conduct model deployment and inference, particularly for fully quantized and optimized models, ensuring faster processing and improved performance compared to standard workstations.",
        "a5826f46-cd52-4cce-919a-4e48c2d338cd": "The organization utilizes cloud resources for inference by leveraging cloud-based CPU and GPU services on a pay-per-usage model. After training models on local workstations or cloud GPU nodes, the optimized models are deployed in the cloud for inference, allowing for scalable and cost-effective processing.",
        "d043400c-4b2e-401b-8095-797552adca10": "The two options for cloud-based inference mentioned are: 1. Cloud for CPU-based inference - pay per usage (CPU time), and 2. Cloud for GPU-based inference.",
        "3f7ebf54-a4f8-496a-a6f7-b651936ea394": "The cost of a Lambda Labs workstation used for model rollout is approximately $20,000 AUD.",
        "9fdda640-b941-4f84-a90d-74ddda41d0ab": "The benefit of spinning up training nodes in a cloud-savvy organization is the ability to leverage scalable resources on-demand, allowing for efficient model training without the need for significant upfront investment in hardware. This approach enables organizations to pay only for the compute time used, facilitating faster experimentation and deployment of AI models while optimizing costs.",
        "55f76b95-e508-4a9a-8a85-41e3cd7f7156": "The cost of local deep learning workstations in a cloud-savvy scenario is approximately $6,000 to $8,000 AUD.",
        "f23cb140-903a-44f8-bf20-fee32d70bf26": "The CI/CD agent facilitates model training in the cloud by automating the deployment of training nodes, allowing organizations to spin up GPU resources on demand for model training. This enables efficient use of cloud infrastructure, where users can pay for GPU and CPU time only when needed, streamlining the process from local development to cloud-based training and inference.",
        "b328b745-a2e1-4ade-9975-8bb2decf667e": "The key cloud platforms mentioned for AI model development and inference are AWS SageMaker, Google Colab, and Google API platform.",
        "dfeaca4e-a891-4160-8bbb-65794be3d018": "The document suggests validating organizational processes and infrastructure for machine learning systems by building an internal machine learning system. This approach allows organizations to test various aspects of their infrastructure and processes, including training and production capabilities, staffing expertise, deployment efficiency, model usefulness, and the understanding of the steering committee. It emphasizes the importance of addressing challenges related to robust machine learning system development and ensuring that the infrastructure is adequately provisioned to support the model's requirements.",
        "c505fc92-7a53-4252-a948-87aee7b26cd5": "The document highlights several specific challenges related to building and deploying machine learning systems, including:\n\n1. **Training Infrastructure**: Ensuring the system can handle the volume of training data.\n2. **Production Infrastructure**: Verifying that the serving host can meet the required prediction cadence, whether in real-time or batch operations.\n3. **Staffing**: Assessing whether the organization has the necessary expertise to develop and troubleshoot the applied techniques.\n4. **Deployment Processes**: Evaluating the smoothness of model deployment and the ability to monitor its performance in production.\n5. **Usefulness**: Determining if the model delivers value to customers and how this is measured.\n6. **Steering Committee Understanding**: Ensuring that the committee comprehends the model's functionality and implications.",
        "7897be73-ada0-4f01-b46e-f6e958451de0": "The aspects of training infrastructure that should be assessed include:\n\n1. **Training Infrastructure**: Adequacy of the system to handle the training data.\n2. **Production Infrastructure**: Capacity of the serving host for required prediction cadence (real-time or batch).\n3. **Staffing**: Availability of in-house expertise for developing and troubleshooting computer vision techniques.\n4. **Deployment Processes**: Smoothness of model deployment and monitoring capabilities in production.\n5. **Usefulness**: Value provided by the model to customers and measurement methods.\n6. **Steering Committee**: Understanding of the model by the committee.",
        "d5804a0b-3a8e-432d-8527-14255dc81b94": "The document proposes measuring the usefulness of the machine learning model to customers by evaluating whether the model provides actual value. This involves assessing its accuracy and performance in production, as well as gathering feedback on its effectiveness in meeting customer needs.",
        "0158ebff-cc19-4ad6-948c-8db3b1b3358c": "The considerations mentioned regarding staffing needs for developing computer vision techniques include ensuring that the organization has the appropriate expertise in-house to develop and troubleshoot the techniques applied to satellite imagery.",
        "1be747ec-8da9-4e70-8122-9020f3655b2e": "To ensure the production infrastructure can meet prediction requirements, the following factors should be evaluated:\n\n1. **Training Infrastructure**: Assess if the system can handle the volume of training data.\n2. **Production Infrastructure**: Determine if the serving host can meet the required prediction cadence (real-time or batch).\n3. **Staffing**: Evaluate if there is sufficient in-house expertise for development and troubleshooting.\n4. **Deployment Processes**: Check if the model deployment is smooth and if there are mechanisms to monitor its performance and accuracy.\n5. **Usefulness**: Measure the model's value to customers and how this is quantified.\n6. **Steering Committee**: Ensure the committee understands the model and its implications.",
        "f087f0d3-72f7-45a4-9a19-f4bacb31e5b2": "The document emphasizes the importance of a steering committee in machine learning model deployment by highlighting its role in ensuring that the committee understands the model. This understanding is crucial for addressing challenges related to infrastructure, staffing, deployment processes, and the overall usefulness of the model, thereby facilitating effective oversight and decision-making throughout the deployment lifecycle.",
        "38f18a2d-e7e9-4b76-afdc-7b946265380e": "Running a subset of data through the model locally during the testing phase is significant because it allows developers to validate the model's functionality, assess the adequacy of the training and production infrastructure, and ensure that organizational processes are aligned for effective deployment. This initial testing helps identify potential challenges, verify the model's performance, and confirm that it delivers value to customers before full-scale implementation.",
        "77761402-5b9f-4ae6-9049-15f59d6dadbb": "A frictionless deployment process for machine learning models implies increased efficiency and speed in bringing models to production, allowing for rapid iteration and updates. It enhances collaboration among teams, reduces the risk of errors during deployment, and facilitates real-time monitoring and performance evaluation. This streamlined approach can lead to improved model accuracy and usefulness, ultimately providing greater value to customers and ensuring that organizational processes are aligned with technological capabilities.",
        "8f590244-5633-459e-85ae-bafefda116ac": "To assess whether our training infrastructure can accommodate the volume of satellite imagery collected, we should evaluate the following:\n\n1. **Capacity Analysis**: Determine if the current system's storage and processing capabilities can handle the size and complexity of the imagery.\n2. **Performance Testing**: Conduct stress tests to measure how the infrastructure performs under peak loads.\n3. **Scalability Assessment**: Evaluate if the infrastructure can be scaled up or out to meet future demands.\n4. **Resource Utilization**: Monitor CPU, memory, and disk usage during training to identify any bottlenecks.\n5. **Benchmarking**: Compare our infrastructure's performance against industry standards or similar use cases.\n\nBy systematically addressing these areas, we can ensure our training infrastructure is adequate for our needs.",
        "a11b2bcb-1c6d-470c-a615-05386dbe927e": "To evaluate if your production infrastructure can meet the required prediction cadence, consider the following metrics:\n\n1. **Throughput**: Measure the number of predictions processed per second to ensure it meets real-time or batch requirements.\n2. **Latency**: Assess the time taken to generate predictions from the moment a request is made to when the result is returned.\n3. **Resource Utilization**: Monitor CPU, memory, and GPU usage to determine if the infrastructure can handle peak loads.\n4. **Error Rate**: Track the frequency of prediction errors to ensure reliability and accuracy.\n5. **Scalability**: Evaluate the system's ability to scale up or down based on demand without performance degradation.\n6. **Uptime**: Measure system availability to ensure it meets operational requirements for continuous service.\n7. **Response Time Variability**: Analyze fluctuations in response times to identify potential bottlenecks.\n\nThese metrics will help ensure your production infrastructure is capable of meeting the required prediction cadence effectively.",
        "23bec182-cb85-4e58-a151-85cd9a281ae3": "Yes, we have the necessary in-house expertise to develop and troubleshoot our computer vision techniques, as indicated by our staffing capabilities and the presence of a knowledgeable steering committee.",
        "c9cd09f3-e2cd-474d-b7af-39c1657a03c5": "To ensure a seamless and efficient deployment of your model, consider the following steps:\n\n1. **Assess Infrastructure**: Verify that both your training and production infrastructures can handle the required data volume and processing speed.\n\n2. **Evaluate Staffing**: Ensure you have the necessary expertise in-house to develop, troubleshoot, and maintain the model.\n\n3. **Streamline Deployment Processes**: Implement a frictionless deployment process with monitoring capabilities to track the model's performance and accuracy in real-time.\n\n4. **Measure Usefulness**: Establish metrics to evaluate the model's value to customers and gather feedback for continuous improvement.\n\n5. **Engage the Steering Committee**: Ensure the committee has a solid understanding of the model and the expertise to support its development and deployment.\n\n6. **Implement Governance**: Adhere to privacy laws, provide users with access to their data, and inform them about data collection practices. \n\nBy addressing these areas, you can enhance the efficiency and effectiveness of your model deployment.",
        "a4c7ad53-a551-4e2e-9520-b9619535a72d": "To measure the accuracy and performance of your model in production, you can implement the following strategies:\n\n1. **Monitoring Metrics**: Track key performance indicators (KPIs) such as accuracy, precision, recall, and F1 score in real-time to assess model performance.\n\n2. **A/B Testing**: Conduct A/B tests to compare the performance of the deployed model against previous versions or alternative models.\n\n3. **User Feedback**: Collect feedback from users to evaluate the model's usefulness and impact on customer satisfaction.\n\n4. **Logging and Analysis**: Implement logging to capture predictions and outcomes, allowing for post-hoc analysis of model performance and error rates.\n\n5. **Regular Audits**: Schedule regular audits to review model performance and ensure it meets the required standards and adapts to changing data patterns.\n\n6. **Governance Compliance**: Ensure compliance with privacy laws and regulations, which can also impact the model's performance and trustworthiness.\n\nBy combining these methods, you can effectively measure and maintain the accuracy and performance of your model in production.",
        "ec79734a-d0f9-426a-aa41-7b8393f106cd": "To determine if the model is providing tangible value to customers, we should evaluate the following criteria:\n\n1. **Usefulness**: Assess whether the model meets customer needs and expectations. This can be measured through customer feedback, satisfaction surveys, and usage metrics.\n\n2. **Performance Metrics**: Monitor accuracy, precision, recall, and other relevant performance indicators to ensure the model is delivering reliable results.\n\n3. **Impact on Business Outcomes**: Analyze how the model influences key business metrics, such as revenue growth, cost savings, or operational efficiency.\n\n4. **User Engagement**: Track user adoption rates and engagement levels with the model to gauge its practical utility.\n\n5. **Return on Investment (ROI)**: Calculate the financial benefits derived from the model compared to the costs of development and deployment.\n\nBy systematically evaluating these criteria, we can determine the model's tangible value to our customers.",
        "6d14b842-7104-489c-a49e-bbcb9df1377b": "Yes, the steering committee possesses the necessary expertise to support the development and deployment of the model, as they understand the model's requirements and can provide internal guidance for its construction and implementation.",
        "1934cc08-fe3a-4d0b-95f6-2c33bd279084": "We ensure compliance with privacy laws by implementing robust governance practices, which include informing customers before collecting or using their data, providing users with the ability to access and delete their information, and regularly reviewing our data handling processes to align with legal requirements.",
        "17d6d808-d31a-44b3-b248-a7ace5dabd8a": "We have processes in place that comply with privacy laws, allowing users to access and delete their stored information. Users are informed prior to data collection and usage, ensuring transparency and control over their data.",
        "eeac5187-1101-4874-bd43-ca2f04434316": "We are informing customers about our data collection and usage practices by providing clear and transparent communication prior to obtaining their consent. This includes detailed privacy notices that outline what data is collected, how it will be used, and the rights customers have regarding their information. Additionally, we ensure that customers have the opportunity to review this information and ask questions before consenting to data collection.",
        "8799af57-3e50-4081-915c-9ac84c4a1c94": "Think Digital is expected to reach an AI maturity level of 2 in the first year of adopting the roadmap.",
        "b1236e6a-5e22-471d-b7c5-b995832737ef": "Think Digital's engineering team is expected to develop prototypes, experiment with research-level code, and create demonstrator-level applications using static datasets. They will also explore promising pilot studies for potential integration into the platform as beta tools.",
        "733de9fb-236a-4904-a3bc-30b13cd55c30": "Think Digital's engineering team will experiment with AI technologies by developing prototypes, experimenting with research-level code, and creating demonstrator-level applications using static datasets. They will adopt a hands-on approach to learn about AI possibilities, testing various models to identify effective solutions. Promising pilot studies may lead to the integration of successful tools into the platform as beta features for select customers.",
        "82ceb96f-f224-4df7-830d-ede76b800592": "The datasets used in the demonstrator-level applications will be static datasets extracted from the platform.",
        "97f3bc2a-1254-4a77-8b17-ac40e09aba1a": "Think Digital will take a hands-on approach to learn about AI possibilities by developing prototypes, experimenting with research-level code, and creating demonstrator-level applications using static datasets. They will evaluate models through pilot studies to identify promising solutions for potential integration into their platform.",
        "957a6d50-03c1-46a1-ab91-d01bb2a1648d": "If a pilot study shows promise in Think Digital's AI initiatives, the organization may adopt it into the platform as a beta or hidden tool for select customers to access.",
        "634af046-ac90-4d10-9531-db8586afcf27": "Successful pilot studies can be integrated into Think Digital's platform by adopting promising prototypes as beta or hidden tools for select customers. This approach allows the organization to evaluate the effectiveness of the pilot while gathering user feedback, ultimately facilitating the transition of successful models into fully integrated features on the platform.",
        "b50bad86-754f-49ed-be8b-f74fd7f3acc5": "The significance of developing prototypes in Think Digital's AI maturity advancement lies in facilitating hands-on learning and experimentation. By creating demonstrator-level applications and testing various models, the engineering team can identify effective solutions and refine their approach. Successful prototypes can lead to the adoption of promising tools into the platform, enhancing overall AI capabilities and driving innovation.",
        "09d91749-ffbf-4bf2-b136-e7027448bdb7": "Access to the beta or hidden tools developed by Think Digital may be granted to select customers who participate in pilot studies that show promise.",
        "5ff058e6-900f-45d7-a090-ef273e397f39": "The expected outcome of applying a hands-on approach to AI at Think Digital is achieving an AI maturity level of 2 within the first year. This includes the engineering team developing prototypes, experimenting with research-level code, and creating demonstrator-level applications using static datasets. The organization will gain insights into AI possibilities through practical experimentation, potentially adopting successful pilot studies into the platform as beta tools for select customers.",
        "da6c366a-f264-4853-9174-a8d152164749": "The primary goal of Think Digital in the next three years regarding AI and machine learning is to transition into an active ML organization by operationalizing at least one AI model in production that provides value to customers, while developing additional pilot studies and achieving a Level 3 AI maturity level.",
        "c4d4d471-8064-4bbc-964e-9513afb5ef2d": "The specific pilot study mentioned is focused on automatically classifying cattle diseases, including FMD (Foot-and-Mouth Disease), LSD (Lumpy Skin Disease), and healthy cattle.",
        "a37407c6-9b8d-48a2-a8d2-f78fc096ab98": "To operationalize their AI model, Think Digital needs to accomplish the following key tasks:\n\n1. Generalize and productionize the pilot study code for reliability.\n2. Establish a robust deployment infrastructure for both code and hardware.\n3. Orchestrate the retraining of the model to ensure it remains effective.\n4. Deploy the model into a service accessible via the app/website.\n5. Monitor the model's performance in production and measure customer impact.\n6. Undertake additional pilot studies to expand capabilities.\n7. Integrate matured pilot studies into the existing AI Platform, making necessary updates and adjustments.",
        "3759fef7-c249-4c5a-bf11-7037391087ff": "Think Digital is aiming to achieve Level 3 AI maturity with their AI initiatives, focusing on operationalizing their models, ensuring reliable deployment, and integrating multiple pilot studies into a cohesive AI platform.",
        "5cf94c08-1c2e-4194-bac2-d07bc3b8b2d2": "Think Digital plans to measure the impact of the deployed AI model on customer engagement by monitoring its effect on user behavior, specifically assessing customer \"uplift\" through metrics such as increased app usage and automation effectiveness. They will track how the model influences customer interactions and return rates to the app, ensuring continuous evaluation and updates based on performance data.",
        "2524c742-8962-4ec5-8fdf-c025ff16ad2a": "The challenges identified regarding the pilot study code that need to be addressed include: \n\n1. Generalization of the code for broader applicability.\n2. Productionization to ensure the model is ready for real-world use.\n3. Establishing reliable deployment infrastructure at both code and hardware levels.\n4. Orchestrating model retraining and deployment into a service for the app/website.\n5. Monitoring the model's impact and measuring customer uplift.\n6. Updating and reworking the system as additional pilot studies are integrated into the AI Platform.",
        "a1ccdc82-dfa7-4a5d-bb8d-9642b23006cd": "After successfully deploying their first AI model, Think Digital should take the following steps:\n\n1. **Operationalize the Model**: Ensure the model is integrated into a reliable deployment infrastructure, including both code and hardware.\n\n2. **Orchestrate Retraining**: Set up processes for regular retraining of the model to adapt to new data and improve performance.\n\n3. **Deploy the Model**: Implement the model as a service accessible through the app or website.\n\n4. **Monitor Performance**: Continuously monitor the model's impact on customer engagement and measure uplift in usage.\n\n5. **Conduct Additional Pilot Studies**: Initiate further pilot studies to expand AI capabilities, ensuring they are easily updatable and responsive to feedback.\n\n6. **Integrate into AI Platform**: Fold successful pilot studies into the existing AI Platform, making necessary updates and adjustments as the organization learns and evolves.",
        "0039ce0c-ef5e-4792-a2c0-476baf48723d": "Additional pilot studies will enhance the development of the AI Platform by providing new use cases and data that can improve model accuracy and functionality. As these studies mature, they will be integrated into the AI Platform, allowing for iterative improvements and refinements. This process will facilitate the operationalization of AI models, ensuring they are reliable, easily updatable, and capable of delivering measurable value to customers. Ultimately, these pilot studies will help Think Digital achieve a higher level of AI maturity and better serve its users.",
        "a74318c8-42b5-4556-99cc-eb9708a7c633": "Monitoring the AI model's impact after deployment is crucial for ensuring its effectiveness, reliability, and value to customers. It allows Think Digital to assess the model's performance, identify areas for improvement, and measure customer uplift. This ongoing evaluation helps in making necessary adjustments, ensuring the model remains relevant and beneficial as new data and requirements emerge, ultimately supporting the organization's goal of achieving a higher AI maturity level.",
        "c53bfaa8-9da1-4ab1-bb2d-2e1d94916b7a": "As pilot studies mature and are integrated into the AI Platform, Think Digital will need to focus on several key requirements: \n\n1. **Model Retraining**: Establish processes for orchestrating the retraining of models to ensure they remain accurate and relevant.\n2. **Deployment Infrastructure**: Develop reliable deployment infrastructure for both code and hardware to facilitate seamless integration into services used by the app/website.\n3. **Monitoring and Evaluation**: Implement systems to monitor the model's performance in production, measuring its impact on customer engagement and overall value.\n4. **Iterative Updates**: Create a framework for rolling out updates in response to bugs and new data, ensuring the model can adapt over time.\n5. **Integration of Additional Pilots**: As new pilot studies are completed, they should be integrated into the AI Platform, which may require system updates and adjustments based on lessons learned. \n\nThese steps will help Think Digital achieve a Level 3 AI maturity level and enhance their operational capabilities.",
        "c35aea2b-b918-4361-815e-523640c5cb6c": "The primary goal of the additional pilot studies is to develop and integrate demonstrable capabilities into the AI Platform, ensuring it is adaptable and aligned with organizational needs as AI components are adopted.",
        "3e726180-04fe-407b-8392-3c8e55ebad25": "The outcomes of the pilot studies should be systematically integrated into the existing AI Platform by first ensuring that the initial model is effectively deployed and monitored. As each pilot study demonstrates its capabilities, the insights and functionalities should be incorporated into the platform, which may require updates and adjustments to accommodate new features. Additionally, processes for automated data collection, labeling, and quality control must be established. To support this integration, the organization should consider building a dedicated team of machine learning engineers, data scientists, and potentially a chief data officer to drive the development and enhancement of the platform.",
        "f343d49b-34ef-4f26-acd7-56b8da7b33c5": "Challenges that may arise when folding the first few pilots into the AI Platform include the need for system updates and rework as the organization adapts to integrating AI components. Additionally, there may be difficulties in ensuring continued organizational alignment and developing processes for automated data collection, labeling, and quality control. Furthermore, the shift in the workforce to include machine learning engineers and data scientists may pose challenges in terms of recruitment and team dynamics.",
        "d27ef022-0ccc-4bcd-8df9-8deed985454f": "Ongoing organizational realignment is crucial for Think Digital's AI maturity as it facilitates the integration of new AI capabilities into existing systems, ensures the development of essential processes for data management, and supports the formation of a skilled team necessary for advancing AI initiatives. This alignment enables the organization to adapt and evolve as it learns from pilot studies, ultimately enhancing its overall AI effectiveness.",
        "103434b1-97d6-47a8-a5f6-07342abe6755": "To ensure effective data management in AI implementation, the following processes need to be developed:\n\n1. **Automated Data Collection**: Establish systems for seamless and continuous data gathering.\n2. **Data Labeling**: Implement processes for accurate and efficient labeling of data to support model training.\n3. **Quality Control**: Develop protocols for monitoring and ensuring the quality of data throughout its lifecycle.\n4. **System Updates and Maintenance**: Create procedures for regularly updating and maintaining the AI platform in response to new data and identified issues.\n5. **Organizational Alignment**: Foster ongoing alignment within the organization to support AI integration and maturity.\n6. **Team Development**: Build a core team comprising machine learning engineers, data scientists, and a chief data officer to drive feature development and integration.",
        "ba793b4e-2549-49a5-bb33-870e32b76bc6": "To support AI integration, the company should undertake pilot studies to refine its AI platform, ensuring it is adaptable and responsive to new data. Organizational realignment is essential for AI maturity, necessitating the development of processes for automated data collection, labeling, and quality control. Additionally, the workforce should evolve to include a dedicated machine learning engineering team, data scientists, and potentially a chief data officer to drive the integration of AI features.",
        "2f8c40a2-abf7-4b42-9f19-dcb53cd08674": "The recommended roles for the machine learning engineering team include machine learning engineers, data scientists, and a chief data officer.",
        "8380f09f-bcee-442a-afa7-46177d014369": "The document suggests that the organization should respond to bugs and new data versions by ensuring the first model is monitored and easily updatable. As pilot studies progress, they should be integrated into the existing AI Platform, which may require updates and adjustments to the system. Additionally, the organization should develop processes for automated data collection, labeling, and quality control, while also considering the establishment of a dedicated machine learning engineering team and data scientists to support ongoing AI integration.",
        "49b3274d-3bbb-4a22-ae2e-7c09e0956ad6": "Automated data collection, labeling, and quality control are crucial in the AI development process as they enhance efficiency, accuracy, and scalability. These processes ensure that high-quality, consistent data is available for training models, which is essential for improving model performance and reliability. Additionally, they facilitate quicker updates and adaptations to the AI system, allowing organizations to respond effectively to new data and evolving requirements. This ultimately supports the integration of AI components into existing systems and drives organizational alignment towards AI maturity.",
        "b966899b-893c-407b-83ed-fffc631c4553": "The expected outcome as the pilot studies mature into demonstrable capabilities includes the integration of successful pilots into the AI Platform, necessitating updates and adjustments to the system. This process will enhance organizational alignment and require the development of automated data processes. Additionally, the establishment of a dedicated team comprising machine learning engineers, data scientists, and potentially a chief data officer will be crucial for advancing AI maturity and feature development.",
        "705005f8-c859-4727-add6-4f796fb2b63a": "The primary focus of the user-facing application at Think Digital is to capture customer data through manual annotation, such as labeling cattle.",
        "57d85b38-90ed-49da-9f79-ed5873267c47": "Customer data will be captured through the existing user-facing application, which will be instrumented to collect data in the form of labels, such as manual annotations.",
        "fb7482d8-e44c-4807-a30c-700f03e560aa": "The type of customer data mentioned as an example in the document is labels, specifically manual annotation of cattle.",
        "a8421188-09ee-4e6f-9934-142527ffa4a6": "The proposed layout of tasks, data, and people at Think Digital is expected to be implemented in 3 or more years.",
        "1c7c683b-e4a6-4d87-a850-107ebe313bcd": "Manual annotation plays a crucial role in the data capture process by providing labeled data, which is essential for training AI models effectively.",
        "f65de762-c7c1-4483-8f2e-8779d7a62471": "The proposed structure aims to enhance AI processes at Think Digital by integrating user-facing applications that capture customer data through manual annotations, thereby improving data quality and enabling more effective AI training and decision-making.",
        "a669a841-7163-4431-9afb-f357c2c6450b": "The significance of labeling in the context of the user-facing application lies in its role in capturing and organizing customer data, which enhances the accuracy of AI processes and improves user experience through personalized interactions and insights.",
        "767647d7-8b92-4d49-8f06-394da4376c48": "The potential users of the application include customers who provide data through manual annotation, as well as employees at Think Digital who will utilize the captured customer data for AI processes.",
        "3df7f878-d0c2-4642-8554-a7eb499a572e": "The proposed structure at Think Digital could enhance customer interaction by enabling more efficient data capture and analysis through the user-facing application. This would allow for personalized services and improved responsiveness to customer needs, ultimately leading to a more engaging and tailored customer experience.",
        "ac12b4d4-9372-4dc0-9ee1-c2961f8344bb": "The layout of tasks and data at Think Digital over the next three years may evolve to include a user-facing application that captures customer data through manual annotations, such as labeling cattle, integrated into a structured AI process.",
        "14406418-5e3e-43b2-bdfe-fccbbcb00ad1": "To improve AI models for cattle disease identification, the following types of data will be collected: \n\n1. **Images** of cattle showing various symptoms, including different breeds and body parts.\n2. **Analytics** on user interactions with the app, such as time spent, success and failure points.\n3. **Model feedback** through rankings or ratings of prediction accuracy.\n4. **Environmental data** capturing conditions like lighting, cleanliness, and seasonal variations. \n\nThis diverse data will help ensure comprehensive coverage of disease manifestations across different regions and contexts.",
        "46ae7457-1b27-408a-80f1-8b8d5c7b8007": "Gathering diverse data on symptom variations in cattle is important because diseases can manifest differently across regions and breeds. This comprehensive data collection ensures that AI models for disease identification are accurate and effective, accounting for variations in environmental conditions, lighting, and seasonal changes. By including a wide range of symptoms and contexts, the models can better recognize and diagnose diseases in diverse cattle populations.",
        "cf2ce19d-d248-46b7-aad3-732b10c46436": "Environmental conditions significantly impact the data collection process for cattle disease identification by influencing the visibility and presentation of symptoms. Variations in lighting, cleanliness, and weather can affect how diseases manifest in cattle, leading to differences in symptom visibility. For instance, images taken in muddy conditions may obscure certain symptoms, while poor lighting can hinder accurate identification. Additionally, collecting data across different seasons ensures a comprehensive understanding of how environmental factors affect disease expression, which is crucial for developing robust AI models.",
        "7266b78a-d51d-4b23-afcf-278d88e6f49c": "Data engineers play a crucial role in transforming raw data into usable datasets by processing unstructured data from a data lake into structured, queryable formats. They implement ETL (Extract, Transform, Load) processes to organize and optimize the data for machine learning and analytics, enabling machine learning engineers and data scientists to effectively analyze and model the data.",
        "d7c85143-4745-4972-aade-0fbe25af3562": "Machine learning engineers collaborate with data scientists by reviewing and visualizing datasets prepared by data engineers, identifying applicable machine learning techniques, and iterating on model development. They ensure that data collection and ETL processes meet the requirements for effective model training. Together, they test, validate, and deploy machine learning products into user-facing applications.",
        "4453c603-ad5e-4a6f-8047-7bb91a1de59e": "The purpose of feeding data back to data engineers during the machine learning process is to ensure that the captured data and ETL processes are adequate for creating usable datasets. This feedback helps data engineers refine data collection methods and transform raw data into structured formats that machine learning engineers can effectively utilize for model development and validation.",
        "948b9224-ade2-4cd2-b23b-bae20ab1110f": "Documenting diseases on various body parts of cattle is necessary to capture the diverse manifestations of symptoms across different breeds and environmental conditions. This comprehensive data collection enhances the accuracy of AI models for disease identification, ensuring that variations in symptoms due to factors like region, cleanliness, and lighting are adequately represented.",
        "bf5bbff6-3be8-49b7-bcc8-8ba87d0a62d1": "When collecting data for AI models, specific environmental factors to consider include:\n\n1. **Lighting Conditions**: Capture images in various lighting scenarios, both indoors and outdoors.\n2. **Environmental Cleanliness**: Document data in clean and muddy conditions to reflect different exposure levels.\n3. **Time of Day**: Collect data at different times to account for variations in natural light.\n4. **Seasonal Variations**: Gather data across different seasons to represent diverse weather conditions, such as sun, rain, and cloudiness.\n5. **Geographical Differences**: Consider regional variations in cattle diseases, as symptoms may differ across locations.",
        "a5a4db33-48f5-439c-a9b1-3534b1dce410": "The collection of data across different seasons enhances the effectiveness of AI models by providing a comprehensive understanding of how environmental factors influence cattle disease symptoms. Seasonal variations can affect lighting, weather conditions, and cattle behavior, leading to diverse symptom presentations. This diversity allows machine learning models to learn from a broader range of scenarios, improving their accuracy and robustness in real-world applications. Additionally, it ensures that the models are trained on data that reflects the conditions under which they will be deployed, leading to better performance in identifying diseases across different contexts.",
        "95e2bc15-da51-4b0e-813d-64fd087ca5a8": "The collected data can be utilized for analytics and machine learning in several ways: \n\n1. **User Behavior Analysis**: By analyzing how long users spend in the app and identifying areas where they succeed or fail, insights can be gained to improve user experience and app functionality.\n\n2. **Model Training and Validation**: The diverse and comprehensive data collected, including images and symptom variations, can be used to train machine learning models for accurate cattle disease identification.\n\n3. **Data Transformation**: Raw data will be transformed into queryable formats, enabling efficient access and analysis for machine learning applications.\n\n4. **Iterative Model Development**: Machine learning engineers and data scientists will explore and visualize datasets to develop, test, and validate new models, ensuring continuous improvement of AI products.\n\n5. **Feedback Loop**: Model feedback, such as ranking predictions, will inform data engineers to refine data collection and ETL processes, enhancing the overall quality of the datasets used for analytics and machine learning.",
        "0b478b73-6dc8-4996-bc5a-c7c00480fb1c": "Gathering data on symptom variations in cattle from regions like Indonesia and Northern Australia is important because diseases can manifest differently due to environmental conditions, cattle breeds, and other contextual factors. This diverse data collection enables accurate disease identification, enhances AI model training, and ensures adaptability to varying disease presentations, ultimately improving cattle health management.",
        "31fc4dda-af03-4ef0-85d8-2a6b3f8dff67": "When collecting data on cattle diseases, consider the following environmental conditions: varying cleanliness levels, types of dirt exposure, different lighting conditions (indoor and outdoor), seasonal weather variations (sun, rain, cloudiness), and the time of day. Additionally, account for the ages and genders of cattle, as symptoms may differ among them.",
        "e109b4b8-0a7c-44a1-a1f2-240301d27627": "Macro photography enhances the accuracy of disease identification in cattle by providing detailed images of symptoms across various body parts and conditions. This allows for precise comparisons between healthy and diseased states, accounting for variations due to breed, environmental factors, and age. By capturing these nuances, macro photography aids in developing robust AI models that can adapt to diverse disease presentations.",
        "3a86fb5a-6e28-4d86-80ff-22190e1df88a": "The inclusion of images from multiple cattle breeds in the data collection process is essential for accurately identifying disease symptoms, as diseases can manifest differently across breeds and regions. This diversity allows for comprehensive documentation of symptom variations, accounting for environmental factors and ensuring that AI models are trained on relevant and adaptable data.",
        "733ad948-9a20-492d-a20f-0147a8d9c976": "Documenting diseases on various body parts of cattle is essential to accurately identify and differentiate symptoms that may vary by region, breed, and environmental conditions. This comprehensive data collection, including detailed imaging and comparative analysis, enhances the effectiveness of AI models in diagnosing diseases and adapting to diverse presentations, ultimately improving cattle health management.",
        "b7a54960-cfec-4e3f-a819-e972714d0bc5": "Different lighting conditions can significantly impact data collection for cattle disease symptoms by affecting the visibility and clarity of symptoms in images. Poor lighting may obscure subtle signs of disease, while optimal lighting can enhance detail and contrast, aiding in accurate identification. Additionally, variations in natural light throughout the day and across seasons can alter the appearance of symptoms, making it essential to capture data under diverse lighting conditions to ensure comprehensive and reliable analysis.",
        "567b9e9c-41c6-4c95-842c-6f72dba76490": "Seasonal variations can impact data collected on cattle diseases by influencing the manifestation of symptoms, the prevalence of certain diseases, and the environmental conditions under which data is gathered. Different seasons may affect cattle health due to changes in weather, such as increased humidity or temperature, which can exacerbate or mitigate disease symptoms. Additionally, variations in cleanliness and exposure to different types of dirt can alter disease presentation. Collecting data across seasons ensures a comprehensive understanding of how these factors affect disease identification and management in diverse cattle populations.",
        "b738e10a-0664-4063-a8b3-a11eee9745d7": "Including a range of cattle ages and genders in data collection is important because symptoms of diseases can vary significantly among different demographics. This diversity ensures a comprehensive understanding of disease presentation, allowing for more accurate identification and analysis, which is crucial for effective disease management and AI model training.",
        "5d5f75c6-1c19-4c4d-8352-4823cb116898": "Comparative analysis between images of healthy and diseased cattle enhances disease identification by allowing for the clear differentiation of symptoms across various breeds and environmental conditions. By documenting diverse symptom variations and utilizing detailed imaging techniques, it becomes easier to recognize subtle differences that indicate disease presence. This approach ensures that AI models are trained on comprehensive data, improving their accuracy and adaptability in real-world scenarios.",
        "6da4870b-96c0-48bb-b810-6daa87deab69": "Think Digital can implement the following strategies to ensure its AI models are adaptable to changing disease presentations:\n\n1. **Diverse Data Collection**: Gather comprehensive data on symptom variations across different cattle breeds and regions, including images of affected body parts and environmental conditions.\n\n2. **Environmental and Contextual Factors**: Collect data under various conditions, such as different lighting, cleanliness levels, and seasonal variations, while considering cattle age and gender differences.\n\n3. **Detailed Imaging and Comparative Analysis**: Utilize macro photography for detailed symptom images and conduct comparative analysis with healthy cattle images to improve disease identification accuracy.\n\nBy employing these strategies, Think Digital can enhance the adaptability and robustness of its AI models to effectively respond to evolving disease presentations.",
        "aa25506b-9f1a-46d0-8852-c8640af39fad": "Think Digital aims to achieve a target AI maturity level of 3 within three years.",
        "e38797f9-0780-4ec2-a9f6-c632685f241f": "A key requirement for Think Digital to reach maturity level 3 in their AI advancement is to have at least one operational application feature that fully integrates machine learning into customer-facing aspects of their business, along with established practices for monitoring models, data versioning, and seamless model deployment.",
        "1270291d-fb52-4129-8a9d-14199320422e": "Machine learning should be integrated into Think Digital's customer-facing business aspects by developing at least one operational application that utilizes machine learning to provide tangible value to customers, such as an app for diagnosing cattle diseases. This integration should include robust monitoring of models, data versioning, and mature data pipelines to ensure seamless deployment without affecting existing functionalities. Additionally, Think Digital should invest in research to explore innovative applications of machine learning within their tools, leveraging available expertise to develop new models.",
        "875b12f4-7a56-4790-9ac6-925a6e44fbc1": "Think Digital should implement the following common practices for model monitoring and data versioning: \n\n1. **Continuous Model Monitoring**: Regularly track model performance metrics to ensure accuracy and reliability in real-time applications.\n2. **Data Versioning**: Maintain a systematic versioning system for datasets to ensure reproducibility and traceability of model training and evaluation.\n3. **Mature Data Pipelines**: Establish robust data pipelines that facilitate seamless data flow and processing for machine learning models.\n4. **Automated Deployment**: Utilize automated deployment processes to integrate new models into production without disrupting existing functionalities.\n5. **Feedback Loops**: Incorporate mechanisms for collecting user feedback to refine models and improve their effectiveness over time. \n\nThese practices will support Think Digital in achieving a maturity level of 3 and enhancing their machine learning capabilities.",
        "a87607e8-af71-40b4-96f9-0e525e656ee0": "The impact of machine learning models on the existing platform's performance and functionality should be positive, enabling seamless integration without degrading performance. The platform should support operational applications that leverage machine learning, enhancing customer value, such as disease diagnosis for cattle through an app. Additionally, established practices like model monitoring and frictionless deployment will ensure reliability and efficiency in operations.",
        "7957918d-e98b-463c-b8b7-6a3c89eff592": "Customers might derive value from a machine learning feature in Think Digital's offerings by using an app that diagnoses cattle diseases. This feature leverages machine learning to analyze data and provide accurate health assessments, enabling farm owners to make informed decisions about their livestock's care and management.",
        "a77b3c98-7f9f-4ac4-a159-025ece9182ec": "Think Digital should focus on funding for research and development of disruptive machine learning applications and new model development, leveraging their existing machine learning operations and expertise.",
        "c1e4d188-466f-4937-9dbb-363c9cd4ded2": "The significance of having operational application features that leverage machine learning lies in their ability to enhance customer value and operational efficiency. By integrating machine learning into customer-facing applications, businesses can provide innovative solutions, such as disease diagnosis for farm animals, which directly benefits users. Additionally, mature practices like model monitoring, data versioning, and seamless deployment ensure reliability and performance, enabling organizations to explore disruptive applications of machine learning and drive continuous improvement.",
        "1eb6c2d7-b94e-42a8-b9af-f939853ddb1b": "Access to machine learning expertise is crucial for Think Digital's development of new models, as it enables the company to effectively research and implement innovative applications of machine learning, ensuring they meet their goal of achieving a maturity level of 3 within three years.",
        "5e3a47d5-9f67-4d47-917e-0c829061fde1": "Mature data pipelines are crucial for Think Digital's AI maturity advancement as they enable seamless integration and deployment of machine learning models into operational applications. They ensure efficient monitoring, data versioning, and frictionless model deployment, allowing the company to leverage AI effectively without disrupting existing functionalities. This infrastructure supports the development of innovative machine learning solutions, ultimately enhancing customer value and driving the company's progress towards maturity level 3.",
        "8f4d1f09-f1f6-447d-981c-54a308947a34": "The custom model developed by the AIML Research team classified images into three classes: 1. Foot and Mouth Disease (FMD), 2. Lumpy Skin Disease (LSD), and 3. Healthy.",
        "17547cd3-30de-4a13-98cc-d21cac2f720b": "The issue identified with the model's accuracy was that, despite high validation accuracy on the small training dataset of approximately 5000 images, the model's accuracy was unreliable when tested with previously unseen images.",
        "0d944071-33f5-4a84-89b8-e557d0365de9": "Yifan Liu led the AIML Research team during the initial phase of the project.",
        "f468a687-bf30-4588-9b92-af9efd845f93": "After the project handover from the research team, the AIML Engineering team took several steps: they conducted verification checks and reviewed the provided codebase, refined project documentation, and updated READMEs for better usability. They added Docker support for model training, backend API hosting, and front-end development, along with Docker Compose for simplified testing. Finally, they deployed these components on cloud infrastructure using Terraform scripts via Kubernetes to test system performance and gather information on model performance and hardware requirements.",
        "eee41968-1e05-418a-b0ab-fb55d08cca50": "The small training dataset used for the model included roughly 5000 images.",
        "630de532-f03e-4604-bf62-430d9211766a": "The AIML Engineering team added Docker support to facilitate the setup of the development environment. They created multiple Docker images for model training, backend API hosting, and the front-end, and included Docker Compose support to simplify testing and development.",
        "d5ed6de3-b48a-40bf-8c97-1269e463d002": "The technology used for deploying the Docker images onto cloud infrastructure was Terraform scripts via Kubernetes.",
        "a2c80258-43e2-4ebd-8935-e84535619c98": "The Docker Compose support served to simplify the testing and development of the Docker images, facilitating easier setup and management of the development environment for the AIML Engineering team.",
        "4eb7fa56-cb2f-4524-8b2b-d58168a73a51": "The AIML Engineering team ensured the project documentation was more user-friendly for Think Digital by refining the existing documentation, updating READMEs, and adding Docker support for easier setup of the development environment. They created multiple Docker images for model training, backend API hosting, and front-end development, along with Docker Compose support to simplify testing and development.",
        "f87227c0-94dc-43d7-9bdf-234466f4914b": "The three types of Docker images set up by the AIML Engineering team were: 1. Model training, 2. Backend API hosting, and 3. The Front-end.",
        "83f99077-bf3b-4649-955b-dad4f7dfccb0": "The recommended minimum scale of images needed to train a robust classification model for cattle diseases like Foot and Mouth Disease (FMD) and Lumpy Skin Disease (LSD) is between 100,000 to 1 million images.",
        "fef23ab4-b05e-4ef0-a491-4c51e117f626": "Capturing images of cattle in various environmental conditions is crucial for training a robust classification model for diseases like FMD and LSD. Diverse conditions, such as lighting, perspective, and cleanliness, ensure the model can accurately recognize and classify cattle health across real-world scenarios. This variability enhances the model's effectiveness and reliability by providing a comprehensive dataset that reflects the range of conditions cattle may experience.",
        "277a78d3-0e36-4769-826c-403303a65936": "Annotators should focus on the following characteristics when labeling images for Lumpy Skin Disease (LSD): \n\n1. **Nodule Characteristics**: Size, shape, and texture of nodules.\n2. **Progression Stages**: Document changes from early-stage nodules (small and firm) to later stages (necrosis or ulceration).\n3. **Skin Texture Changes**: Observe alterations in skin texture around nodules.\n4. **Inflammation Signs**: Note signs of inflammation, such as reddened skin or rough patches. \n\nThese details are crucial for accurate data annotation and effective model training.",
        "96270adc-645b-4022-9732-eec60efb84bb": "The progression of nodules in Lumpy Skin Disease (LSD) should be documented by annotating their size, shape, and texture at various stages, from small and firm to necrotic or ulcerated. Additionally, changes in skin texture and signs of inflammation, such as reddened skin or rough patches around the nodules, must be recorded to provide a comprehensive understanding of the disease's progression.",
        "6d5d184b-81a4-42fa-af50-3007bc97f9e4": "The key lesion locations that need to be annotated for Foot and Mouth Disease (FMD) are around the mouth, feet, and teats. Annotators should also document the condition of these lesions, including whether they are blisters, ulcerations, or raw areas.",
        "1a3baa7f-f8d2-45c3-8028-3ab6c30c528b": "When annotating images for Foot and Mouth Disease (FMD), secondary symptoms and behavioral changes to record include excessive drooling, swelling, redness, and signs of lameness or reluctance to move.",
        "4302263d-0c50-47d0-b5f9-38963a432f2e": "Collaboration with veterinary experts is crucial in the data annotation process for cattle diseases because they provide the necessary expertise to ensure accurate and reliable annotations. Their knowledge helps in identifying specific disease characteristics, such as lesion types and progression, as well as secondary symptoms. This collaboration enhances the quality of the dataset, leading to more effective and nuanced disease identification in classification models.",
        "22ade6b1-93e8-4027-adf3-6c0a4b86ccc3": "The dataset for effective model training should represent various cattle breeds and include images showcasing a range of health conditions and disease stages, specifically for Foot and Mouth Disease (FMD) and Lumpy Skin Disease (LSD). It should capture diverse environmental conditions (muddy, wet, dry, clean, dirty, dusty) and focus on specific regions of interest, such as lesions around the mouth, feet, and teats for FMD, and nodules for LSD. A minimum of 100,000 to 1 million images is recommended for robustness. Data labeling should include detailed annotations on lesion characteristics, progression, and secondary symptoms, in collaboration with veterinary experts.",
        "9c942fd9-2dd9-46bc-b424-f98523dd3f9d": "The data labeling process should be organized to run concurrently with data collection. As images are collected, they should be annotated and verified in real-time, following established guidelines that detail specific characteristics relevant to each disease. For Lumpy Skin Disease (LSD), focus on nodules' size, shape, texture, and progression, while for Foot and Mouth Disease (FMD), emphasize lesion locations and conditions. Collaboration with veterinary experts is essential to ensure the accuracy and reliability of annotations, providing a comprehensive dataset for effective model training.",
        "da653ff8-d3a7-4e8a-8f48-c760c266e48b": "The annotation guidelines for Lumpy Skin Disease (LSD) should note the following specific features of nodules: size, shape, texture, and progression from early stages (small and firm) to later stages (necrosis or ulceration). Additionally, changes in skin texture and signs of inflammation, such as reddened skin or rough patches around the nodules, should also be documented.",
        "7fc5d684-5961-419b-aae1-e4b2515ac839": "The two diseases mentioned are LS D (Lumpy Skin Disease) and FMD (Foot-and-Mouth Disease).",
        "4ef3151c-647a-4243-86f8-6934f1cb4303": "The current model incorrectly identifies healthy cows by generating false positives, such as classifying a healthy cow as having Lumpy Skin Disease (LS D) or Foot-and-Mouth Disease (FMD).",
        "ff9f394c-2dac-416f-9af4-93913057f344": "\"LS D\" stands for \"Lumpy Skin Disease.\"",
        "ce5832b5-0cfa-4810-8ec4-d95dc227705b": "The examples in Figure 2 highlight the issue of false positives in the current model, demonstrating how healthy cows can be incorrectly identified as having Lumpy Skin Disease (LS D) and Foot-and-Mouth Disease (FMD). This underscores the need for improved accuracy in disease detection to prevent misdiagnosis.",
        "e324fdd5-fc57-4d16-8b75-a16d73726cae": "False positives can lead to unnecessary treatments or interventions for healthy cows, increasing veterinary costs and stress for the animals. Additionally, misidentifying healthy cows as diseased can disrupt herd management practices and affect overall herd health monitoring.",
        "fd9e57ce-d7b3-47b1-ad7d-27761722dc84": "The identification of healthy cows as diseased can lead to unnecessary culling, increased veterinary costs, and loss of productivity, ultimately affecting the profitability and efficiency of livestock operations.",
        "8f2d4d42-f0a7-4c1b-8c8b-a22291ac4f4e": "Potential reasons for the model's inaccuracies in identifying diseases include insufficient training data, mislabeling of training examples, variations in disease presentation, and limitations in the model's algorithm or features used for classification.",
        "cbd6a2ef-cb21-4f1d-83f3-f2918873b2fd": "To reduce false positives in the current model, the following improvements could be implemented: \n\n1. **Enhanced Training Data**: Incorporate a more diverse and representative dataset that includes a wider range of healthy and diseased examples to improve the model's ability to distinguish between conditions.\n\n2. **Feature Optimization**: Refine the features used for classification by identifying and prioritizing those that are most indicative of the specific diseases, reducing reliance on less relevant indicators.\n\n3. **Algorithm Tuning**: Adjust the model's sensitivity and specificity parameters to better balance the trade-off between false positives and false negatives.\n\n4. **Cross-Validation**: Implement rigorous cross-validation techniques to ensure the model generalizes well to unseen data, thereby reducing misclassifications.\n\n5. **Regular Updates**: Continuously update the model with new data and feedback to adapt to changing patterns in disease presentation and improve accuracy over time.",
        "20c11819-aa1a-4e37-b7cb-8d8ac1e55f52": "The visual representation used in the document is Figure 2, which shows examples of false positives: a healthy cow identified as LS D on the left and as FMD on the right.",
        "5a04b49f-3cb1-428a-b490-54ac456aa8e8": "Accurately identifying diseases in livestock is crucial to prevent misdiagnosis, which can lead to unnecessary culling, economic losses, and the spread of diseases. Correct identification ensures effective treatment and management, safeguarding animal health and food security.",
        "41d37a09-2d2b-47b8-8fe2-4582cc0b8aed": "LSD stands for Lumpy Skin Disease.",
        "e5da4b6f-5a26-4cdd-a93d-ce4bbedd50a0": "A healthy cow is misidentified as LSD in the left example of Figure 3.",
        "f990e418-5c2d-4a4a-95de-ef3742f803a0": "False positives in disease identification for livestock can lead to unnecessary culling, increased veterinary costs, and disruption of trade. They may also cause farmers to misallocate resources and implement unwarranted biosecurity measures, ultimately affecting animal welfare and farm productivity.",
        "08f580ea-cdf3-4730-8a4d-6b847c941699": "FMD (Foot-and-Mouth Disease) is incorrectly predicted as LSD on the right side of Figure 3.",
        "542e0f43-871f-43e0-a052-62866b29c449": "The identification of a healthy cow as having LSD could lead to unnecessary culling, economic losses for farmers, and disruptions in livestock trade. It may also result in misallocation of veterinary resources and heightened public concern over livestock health.",
        "b14b98e4-eeb6-4f2e-ba08-51b8f9ea91bd": "False positives can lead to unnecessary culling or treatment of healthy livestock, increased costs for farmers, and misallocation of resources. They can also cause panic and disrupt trade, as healthy animals may be incorrectly labeled as diseased, impacting overall herd management and disease control efforts.",
        "c8622f0a-2281-49ee-a1c2-b0d83918d443": "Figure 3 presents visual evidence of false positives by showing a healthy cow incorrectly identified as having LSD on the left, and an instance of FMD being predicted as LSD on the right.",
        "fec2feaa-def0-4e24-a695-7cf64449942a": "Differentiating between LSD and other diseases like FMD in livestock is crucial to ensure accurate diagnosis and appropriate treatment. Misidentification can lead to unnecessary culling, misallocation of resources, and ineffective disease control measures, ultimately impacting animal health and agricultural productivity.",
        "cf0e9c45-9c05-4d2f-9e72-167a783a2bd4": "Misidentifying Foot-and-Mouth Disease (FMD) as Lumpy Skin Disease (LSD) in cattle could lead to inappropriate treatment protocols, delayed control measures for FMD, increased spread of the disease, and significant economic losses in the livestock industry.",
        "fc1e352f-c215-4778-b23f-b5771e787c61": "To improve the accuracy of disease identification and reduce false positives, it is essential to enhance diagnostic algorithms through better training data, implement advanced machine learning techniques, and incorporate additional clinical and environmental factors into the analysis. Regular validation and calibration of the diagnostic tools against a diverse set of samples can also help minimize misidentifications.",
        "f465a11b-ccbb-4662-8d57-b8143091f473": "LSD stands for Lumpy Skin Disease.",
        "8711dcb2-4723-4142-82cc-c0035803faa9": "A cow is identified as having LSD (Lumpy Skin Disease) through visual assessment, but in the examples provided, a cow with LSD is incorrectly identified as healthy, indicating a false positive.",
        "4d6ac606-e941-4b34-9dd6-e356ddf28f85": "The significance of the cow being incorrectly identified as healthy in the context of LSD (Lumpy Skin Disease) lies in the potential for disease spread, as false negatives can lead to unmonitored infected animals, undermining control measures and public health efforts.",
        "0003510f-268d-4fac-90ba-9ad910f500bb": "False positives in cow health identification can lead to mismanagement of healthy animals, unnecessary treatments, increased veterinary costs, and potential spread of disease due to incorrect assessments. This can also result in loss of trust in health monitoring systems and impact overall herd productivity.",
        "5def7186-405f-4148-8898-f3157994796d": "Visual characteristics that might lead to a cow being misidentified include similar body shape, color patterns, and overall size between the LSD cow and a healthy cow. Additionally, lighting conditions and angles in the images can affect perception, contributing to misidentification.",
        "427be915-dcd0-47db-b152-77a6d934741d": "The identification process differentiates between healthy cows and those with LSD by analyzing specific symptoms and indicators associated with LSD, ensuring accurate classification to minimize false positives.",
        "593a99c3-beff-4268-8c2d-0e1c3a5bae68": "False positives in livestock management can lead to unnecessary culling of healthy animals, increased costs for farmers, and misallocation of resources in disease control efforts. This can undermine trust in diagnostic tests and potentially allow actual disease outbreaks to go unchecked.",
        "bd3b502f-8a12-4f0e-95c3-f4a3022c8019": "Yes, specific indicators that could help reduce false positives in cow health assessments include monitoring vital signs, assessing behavioral changes, and utilizing advanced diagnostic tools such as blood tests or imaging techniques to confirm health status.",
        "efcfa463-7465-4524-b104-55c9eaa2af63": "Accurate identification is crucial for maintaining the overall health of cattle populations as it ensures that diseased animals, such as those with Lumpy Skin Disease (LSD), are correctly identified and managed, preventing the spread of illness and protecting the health of the herd.",
        "5ade2395-25e1-4f14-9f2b-a7ac5f67e4ec": "The examples in Figure 4 highlight the potential for misclassification in animal health monitoring, specifically the risk of false positives. This underscores the need for improved diagnostic accuracy and the implementation of more robust screening methods to ensure that healthy animals are not incorrectly identified as diseased. Future practices should focus on refining diagnostic criteria and utilizing advanced technologies to enhance the reliability of health assessments in livestock.",
        "39fc00bb-ce42-40cc-9454-3a34b542c5cc": "The key themes highlighted in the City of Adelaide's Strategic Plan for 2024-2028 include boldness, aspiration, and innovation.",
        "983cd2ea-2cc0-430b-951f-d37e1ffb644a": "The Strategic Plan aims to reflect the boldness of Adelaide by setting ambitious goals that promote innovation and aspiration, positioning the city as a leader in progressive urban development and community engagement.",
        "a8e77cc5-6f6c-4b5a-8a4a-ca7f137ed61d": "The Strategic Plan promotes innovation within the city by fostering a culture of creativity, investing in technology and infrastructure, encouraging collaboration between businesses and educational institutions, and supporting startups and entrepreneurs through funding and resources.",
        "47044ad4-ef23-4a39-8a5f-1efbd1fffc3b": "The City of Adelaide's aspirations for the future, as outlined in the Strategic Plan 2024-2028, include becoming a bold, aspirational, and innovative city that fosters growth, sustainability, and community engagement.",
        "8ad4c9c4-e88c-42d9-ac57-a4d8067302ce": "The Strategic Plan for 2024-2028 aligns with the city's identity as \"Adelaide\" by emphasizing bold initiatives, aspirational goals, and innovative solutions that reflect the unique character and values of the city.",
        "b9beaed1-2b93-47a9-9d6c-f1ed36394ff3": "The Strategic Plan for Adelaide (2024-2028) may include initiatives such as community engagement programs, local events and festivals, support for neighborhood associations, public art projects, and the development of shared public spaces to enhance social interaction and foster a sense of belonging among residents.",
        "3214fe78-7364-4d0d-8b60-9ef5076185d1": "The Strategic Plan for 2024-2028 addresses the challenges faced by the city by outlining targeted initiatives that focus on sustainability, economic growth, and community engagement. It emphasizes innovative solutions to enhance infrastructure, improve public services, and foster resilience against climate change, ensuring a vibrant and inclusive future for Adelaide.",
        "888a7b97-ae6f-4a8e-8041-4b60e148e1b9": "Stakeholders play a crucial role in the implementation of the Strategic Plan by providing input, resources, and support. They help ensure alignment with community needs, facilitate collaboration, and contribute to the plan's success through active engagement and feedback.",
        "f806f851-531b-4963-b10f-ae3938f13b09": "The success of the Strategic Plan will be measured through key performance indicators (KPIs), regular progress reviews, stakeholder feedback, and alignment with the plan's goals and objectives over its duration.",
        "a7ff8764-76fb-465e-9eb1-f10e1ae65cdf": "The anticipated outcomes of the Strategic Plan for the residents of Adelaide include enhanced urban livability, improved public services, increased economic opportunities, sustainable development, and a stronger sense of community engagement and inclusivity.",
        "75956fbf-dd21-4986-8dbc-3fd313b28cd9": "The key aspirations for the community in Adelaide over the next ten years include:\n\n1. **Vibrant Community**: A growing, thriving city with increased residents and visitors, year-round events, and world-class amenities that foster inclusivity and celebrate cultural diversity.\n\n2. **Resilient Environment**: A leading Green City with advanced green infrastructure, enhanced biodiversity, and a community resilient to climate change.\n\n3. **Innovative Economy**: A strong economic hub attracting global investment and talent, with diverse industries that build on existing strengths.\n\n4. **Purposeful Places**: Unique, accessible neighborhoods and public spaces designed for safety and liveliness, reflecting the city\u2019s history and identity.\n\n5. **High-Performing Corporation**: A trusted employer known for excellence, transparency, and financial sustainability.",
        "db006c33-63d0-4623-b651-8e325c680281": "Adelaide plans to enhance its environmental resilience and sustainability by 2034 by becoming a leading Green City in a Park, showcasing advanced green infrastructure, increasing biodiversity, and fostering a community that is more resilient to climate change.",
        "ac05aee7-654b-41a7-9a8d-1e8c3206569e": "The strategic plan aims to grow and innovate Adelaide's economy by positioning the city as a strong economic focal point that attracts global investment and talent. It emphasizes the development of new and diverse industries that build on existing economic strengths, fostering successful businesses connected to international opportunities.",
        "654127c4-e65e-49db-8577-01c2ff2d285d": "The vision for Adelaide's neighborhoods and public spaces in the next decade is defined by characteristics of vibrancy, inclusivity, and connectivity, fostering a thriving community. It emphasizes resilience and sustainability, positioning Adelaide as a leading Green City. The vision also highlights the importance of unique, safe, and accessible public spaces that reflect the city's history and identity, while supporting economic growth and innovation.",
        "a0e35414-64c5-47f7-aab1-414c964ec767": "By 2034, the Corporation of Adelaide aims to position itself as a trusted employer and partner by being recognized for excellence and achievement, prioritizing transparency, financial sustainability, and accountability. It will focus on being high-performing and customer-centric, attracting talent and partnerships through its innovative and bold approach.",
        "71b9cec2-90da-473d-987a-d92451eebd95": "Cultural celebration plays a crucial role in Adelaide's community development by fostering vibrancy, inclusivity, and connections among residents and visitors. It enhances the city's identity, showcases its heritage and diversity, and supports year-round events that contribute to a thriving and engaged community.",
        "fcc20327-eced-4bf2-bfbb-51bbf9d055d0": "Adelaide's green infrastructure will enhance its identity as a leading Green City by promoting increased biodiversity, sustainability, and resilience to climate change. This infrastructure will create vibrant public spaces, support community connections, and showcase the city's commitment to environmental protection, ultimately fostering a thriving urban ecosystem that attracts residents and visitors alike.",
        "dbb38ef9-0991-4349-8dba-c7630a1e50aa": "The proposed strategies to attract investment and talent to Adelaide's economy include fostering a vibrant community through year-round events and world-class amenities, promoting sustainability and resilience as a leading Green City, and developing diverse industries that leverage the city's economic strengths. Additionally, enhancing public spaces and ensuring a high-performing, customer-centric corporate environment will further position Adelaide as an appealing destination for investment and talent.",
        "b469ac5a-d6ca-48ec-94c5-ab8ce9f90cbb": "The strategic plan emphasizes inclusivity by highlighting the aspiration for a \"vibrant, connected and inclusive\" community, promoting year-round events that celebrate culture, heritage, and diversity. It envisions diverse neighborhoods that are accessible and safe, fostering connections among residents and visitors.",
        "1c5556d1-9d2a-45cd-b26e-b00e3e134695": "The vision for Adelaide reflects its historical and cultural identity in public space design by emphasizing vibrant, inclusive, and connected communities that celebrate the city's heritage and diversity. The design of public spaces aims to create safe, lively environments that showcase Adelaide's unique neighborhoods and cultural narratives, fostering a sense of belonging and community pride.",
        "897db248-564e-4533-ab77-67431161fc20": "The significance of the Kaurna people's relationship with the land, as acknowledged by the City of Adelaide, lies in the recognition of their cultural heritage, beliefs, and ongoing connection to the land. This acknowledgment emphasizes the importance of respecting and honoring the Kaurna people's traditions and their role in the cultural landscape of the Adelaide Plains, both historically and in contemporary society.",
        "89969883-054b-44e4-bbac-dc237d0ffeec": "The City of Adelaide expresses respect for the cultural heritage of the Kaurna people by acknowledging their traditional Country, paying respect to Elders past and present, and recognizing their ongoing cultural significance and relationship with the land. Additionally, the city extends this respect to other Aboriginal Language Groups and First Nations.",
        "b21904a4-f0e6-4801-9de8-5a5ffb6080b5": "The key components outlined in the Strategic Plan 2024-2028 for the City of Adelaide include:\n\n1. Vision\n2. Aspirations\n3. Principles\n4. Acknowledgment of Kaurna heritage\n5. Overview of the City and its opportunities\n6. Roles and responses of the Council\n7. Community engagement\n8. Environmental considerations\n9. Economic development\n10. Urban planning and place-making\n11. Strategic Planning Framework\n12. Resource Plan for 2024-2028",
        "2783d24d-3cec-4309-a490-11ae547a54eb": "The City of Adelaide extends respect to other Aboriginal Language Groups and First Nations by acknowledging their cultural heritage, beliefs, and ongoing relationship with the land, alongside recognizing the importance of these communities in the present day.",
        "1bedfab6-a34c-4b6a-9380-198072f79a31": "The Lord Mayor plays a pivotal role in the City of Adelaide's Strategic Plan by providing leadership, representing the community, and guiding the council in achieving the city's vision and aspirations. The Lord Mayor is instrumental in fostering relationships with stakeholders, ensuring the plan aligns with community needs, and promoting the cultural heritage of the Kaurna people.",
        "dde9fc20-c646-413a-adae-e2af55b7de4a": "The document emphasizes the importance of the Kaurna Elders by acknowledging their traditional Country, paying respect to their cultural heritage, and recognizing their ongoing significance to the Kaurna community today. It highlights the respect extended not only to the Kaurna Elders but also to other Aboriginal Language Groups and First Nations.",
        "036243db-a9be-41ca-ba5c-ca1a582cebe2": "The main aspirations mentioned in the Strategic Plan for the City of Adelaide include recognizing and respecting the cultural heritage of the Kaurna people, fostering community engagement, enhancing environmental sustainability, promoting economic growth, and improving the livability of urban spaces.",
        "ae5a17fa-84fc-496b-b83d-91e3d8fb3a91": "The City of Adelaide plans to engage with its community by acknowledging and respecting the cultural heritage and beliefs of the Kaurna people, as well as other Aboriginal Language Groups and First Nations. This engagement is reflected in their commitment to recognizing the importance of these communities in their strategic planning and decision-making processes.",
        "3975347a-a952-44b7-ae93-d89fee8e361c": "The Strategic Plan for the City of Adelaide includes environmental considerations such as the recognition of the cultural heritage and relationship of the Kaurna people with the land, sustainable management of natural resources, and initiatives aimed at preserving and enhancing the local environment.",
        "743eda07-0c4b-49ac-aa84-6fb22f778a36": "The purpose of the Resource Plan 2024-2028 is to outline the strategic allocation and management of resources to support the City of Adelaide's vision, aspirations, and initiatives over the specified period, ensuring sustainable development and effective service delivery to the community.",
        "a9f87895-86f9-474e-bed6-4cd45e1734b5": "The primary focus of the City of Adelaide\u2019s Strategic Plan for 2024\u20132028 is to achieve long-term goals across the economy, environment, and community, including improving streetscapes, enhancing economic viability for businesses, increasing residential access and affordability, maintaining assets, reducing waste, and addressing homelessness, while aiming for a population growth to 50,000 by 2036.",
        "86dd62f1-6919-471c-85a1-37c921a718f9": "The Council plans to improve the economic viability for businesses in Adelaide through its Strategic Plan 2024\u20132028, which aims to enhance streetscapes, support property owners in maximizing their investments, and boost residential access and affordability. The plan also focuses on providing certainty for business owners and potential investors, ensuring a commitment to deliver on promises made during the consultation process.",
        "b77d6b67-d69f-41c0-93f7-7a34fa22a459": "The Strategic Plan sets a specific goal to increase the population of Adelaide to 50,000 people by 2036.",
        "6610530a-38b3-4110-839e-bfed2964dc3e": "The Strategic Plan aims to address functional homelessness in the city by setting a goal to achieve zero functional homelessness by 2028. It includes initiatives to improve residential access, affordability, and amenity, which are essential for supporting vulnerable populations and ensuring that all residents have stable housing options.",
        "3a47550c-f127-46b0-ac4c-b9ccdc95c897": "The key stakeholders mentioned in the Strategic Plan consultation process are Council Members, residents, workers, and visitors.",
        "da43105c-372f-4a8a-86e8-5fbe73289f03": "The core responsibilities of the council referred to as \"roads, rates, and rubbish\" include maintaining and improving road infrastructure, managing property rates, and overseeing waste collection and management services.",
        "8b2a40fe-b653-4352-bd12-efe49596c6b1": "The Strategic Plan aims to enhance residential access and affordability by improving streetscapes, supporting property owners in maximizing their investments, and committing to achieve zero functional homelessness. It also includes a goal to increase the population to 50,000 by 2036, which will contribute to a more vibrant and accessible community.",
        "3db8e131-8420-4186-b0da-0d4386ba756d": "Community feedback plays a crucial role in shaping the Strategic Plan by ensuring that the needs and perspectives of residents, workers, and visitors are considered. This input helps the Council to align its long-term goals with the aspirations of the community, ultimately guiding decisions on economic viability, urban development, and social initiatives.",
        "43784e77-a294-4eab-b3e5-258ef022c235": "The Council aspires to enhance Adelaide's streetscapes by improving urban design, boosting economic viability for businesses, increasing residential access and amenity, and ensuring effective asset maintenance. Their vision aims to create a vibrant, accessible, and sustainable city that supports growth and community well-being.",
        "166bafb7-e6ba-4653-b91d-09cf302e6302": "The Strategic Plan aims to provide certainty for business owners and potential investors by outlining clear long-term goals for economic viability, improved streetscapes, and enhanced property utilization. It emphasizes a commitment to deliver on promises, ensuring a stable environment for investment and growth in Adelaide.",
        "b54729b1-1770-4a39-972a-422dad0146b1": "The main goals of the Strategic Plan for the City of Adelaide from 2024 to 2028 include improving streetscapes, enhancing economic viability for businesses, assisting property owners, boosting residential access and affordability, maintaining assets, reducing kerbside waste, achieving zero functional homelessness, and increasing the population to 50,000 by 2036. The plan also aims to provide certainty for business owners and residents while committing to deliver on its promises.",
        "ef511133-13a5-4b00-b84d-7093b1f72c82": "The Strategic Plan aims to improve economic viability for businesses in Adelaide by enhancing streetscapes, providing support for property owners to maximize their investments, and ensuring certainty for business owners and potential investors. This approach is designed to create a more attractive and profitable environment for businesses while boosting residential access and amenity.",
        "3c32be99-788a-4718-9c9f-f6ccaf63bfbf": "The Strategic Plan sets a target population size of 50,000 people for Adelaide by 2036.",
        "1f6e3fb1-1edc-4443-9efd-7bb10211d1f5": "The Strategic Plan proposes to address functional homelessness by aiming for zero functional homelessness through improved asset maintenance, enhanced residential access and affordability, and a commitment to deliver on promises made to the community.",
        "ecb97f3f-6507-470f-9b51-44a58e8ce392": "The Strategic Plan aims to enhance residential access and affordability by improving streetscapes, supporting economic viability for businesses, and helping property owners maximize their investments. It also includes initiatives to achieve zero functional homelessness and sensibly increase the population to 50,000 by 2036, thereby creating a more accessible and affordable living environment for residents.",
        "c3bed7d1-2631-49b5-97bd-22e46380d709": "Community feedback and consultation play a crucial role in the development of the Strategic Plan by ensuring that the perspectives and needs of residents, workers, and visitors are considered. This input helps shape the Plan's goals, such as improving streetscapes, enhancing economic viability, and addressing issues like homelessness and population growth, ultimately guiding the Council's commitments for the future of Adelaide.",
        "81b7572d-6419-413b-b012-be85cf83f609": "The Strategic Plan commits to providing certainty for business owners and investors by ensuring the delivery of promises related to economic viability, improved streetscapes, and support for property owners. It emphasizes a commitment to maintain assets, reduce waste, and manage population growth, all aimed at fostering a stable and supportive environment for businesses and investments.",
        "9d0bcd27-1bda-42c5-9550-3e226015d70f": "The Strategic Plan aims to reduce kerbside waste in the City of Adelaide by implementing measures to maintain assets and improve waste management practices, contributing to a cleaner environment and enhanced streetscapes.",
        "6d56d411-41d7-41e5-bb60-2105c6c85d0c": "The significance of maintaining assets in the Strategic Plan lies in ensuring the effective management and longevity of public resources, which supports economic viability, enhances community amenities, and fosters sustainable growth. This maintenance is crucial for delivering on commitments to residents, businesses, and investors, ultimately contributing to the overall improvement of the city's infrastructure and quality of life.",
        "e0a3b65b-d53b-4daf-963a-d2deef5b67ea": "The author of the Strategic Plan is Dr. Jane Lomax-Smith AM, who holds the title of Lord Mayor of the City of Adelaide.",
        "53cfef01-e5ff-4d94-8938-a2f796e17a17": "The key challenges currently facing the city and community include the post-pandemic environment, inflation, a housing crisis, and climate change. Additionally, uncertain global economic conditions, resource and labor shortages, disrupted supply chains, and geopolitical tensions are impacting local economies. These challenges necessitate a focus on sustainable development, social connectivity, and climate resilience while accommodating a growing and diverse population.",
        "20aa0dd0-89e3-474a-b90e-d0bc216a5122": "The projected population growth of 50,000 residents in the city will necessitate new housing developments to meet the increasing demand for quality housing. This growth will also require a focus on creating diverse and accessible neighborhoods, enhancing public spaces, and ensuring that housing solutions are sustainable and resilient to climate change.",
        "383b219e-0256-4be0-b7ce-ddd067ab3e00": "The Plan proposes to enhance social connectivity within the city by creating lively and accessible streets, designing public spaces that prioritize people and nature, and revitalizing precincts to host year-round events and quality amenities. This approach aims to foster an interconnected collection of unique neighborhoods that celebrate cultural diversity and promote community engagement.",
        "74fcc892-b1ed-487b-8479-ae402950585a": "The strategies mentioned for addressing climate change and promoting climate resilience include supporting adaptation measures for residents and visitors to protect against hazards like heatwaves, promoting a greener built environment through the reuse of old buildings, fostering a circular economy, and developing a low-carbon city. Additionally, the plan emphasizes the importance of social connectivity and designing public spaces that prioritize people and nature.",
        "15620429-2b63-4291-ac41-c2e66b770df6": "The Plan envisions the future layout of the city as an interconnected collection of unique neighborhoods and precincts, designed to offer diverse local experiences. It emphasizes vibrant, accessible streets that promote social connectivity and prioritize people and nature in public space design. The Plan also aims to support climate resilience and adapt to growth, providing quality housing for a projected 50,000 residents while revitalizing streets and amenities to celebrate the city's culture.",
        "0ad7236d-36f0-4251-9000-65bcb6b42468": "The revitalization of streets and precincts is central to the city's development strategy as it enhances vibrancy, promotes social connectivity, and supports the integration of diverse local experiences. By creating lively and accessible public spaces, the city aims to accommodate a growing and diverse population, foster community well-being, and celebrate its culture, all while addressing challenges such as climate change and economic uncertainty.",
        "4a94667f-524e-417d-a65d-f80a70f6a9b7": "Economic uncertainties are prompting the city to reevaluate its procurement strategies and workforce development initiatives. The challenges posed by post-pandemic recovery, resource shortages, and geopolitical tensions are leading to a focus on financial sustainability, local workforce enhancement, and partnerships with various sectors. This approach aims to adapt to changing economic conditions while fostering resilience and supporting emerging industries.",
        "70b00c79-da0c-4a55-abd3-8f4588cf926c": "The suggested initiatives to support a circular economy and low-carbon city include reusing old buildings, promoting green infrastructure, enhancing public spaces for social connectivity, and adapting to climate change through resilience planning. Additionally, the focus on sustainable procurement, developing the local workforce, and fostering partnerships across government and private sectors will further contribute to these goals.",
        "4b62324d-1d54-4fbb-b9d0-459552b12832": "The Plan addresses health, wellbeing, equity, and inclusion by recognizing the need for quality housing and vibrant public spaces to support a growing and diverse population. It emphasizes social connectivity through accessible streets and community events, while also prioritizing climate resilience to protect residents from environmental hazards. By fostering an interconnected city with diverse experiences, the Plan aims to create an inclusive environment that promotes overall wellbeing and equity for all community members.",
        "37c45db0-f9d0-4719-8a92-231b70de2310": "The significant emerging trends for the city's future economy include a focus on health, wellbeing, equity, and inclusion to support a diverse population, the development of quality housing for a growing number of residents, the promotion of social connectivity through vibrant public spaces, urgent action on climate change for resilience, and the ongoing digital transformation driven by artificial intelligence and cashless transactions. Additionally, the city will adapt its economic strategies in response to global uncertainties, resource shortages, and the need for sustainable partnerships.",
        "b0317dad-2f91-43e8-a269-c90b76fd42d2": "The proposed strategies to protect residents and visitors from heatwaves in Adelaide include enhancing the city's green spaces, reusing old buildings, and promoting a greener built environment. These initiatives aim to create a more sustainable and low-carbon city, which can help mitigate the impacts of extreme heat. Additionally, the city plans to focus on community preparedness and resilience in response to climate hazards.",
        "432a531b-27cf-4af7-bdc6-c37bbb365ab6": "The City of Adelaide plans to support a circular economy and low-carbon initiatives by reusing old buildings, promoting greener built forms, and fostering innovative, sustainable practices. The city aims to adapt to economic challenges by enhancing local workforce development, encouraging emerging industries, and leveraging digital transformation. Through bold responses to these challenges, Adelaide seeks to create transformative opportunities for its community and businesses, positioning itself as a leading Green City.",
        "1e5afa63-a390-40ac-9795-73b47155075b": "The economic challenges mentioned that have arisen from the COVID-19 pandemic include uncertain global economic conditions, resource and labor shortages, disrupted supply chains, interest rate rises, and international conflicts and geopolitical tensions.",
        "da84d1bf-bf78-4e3b-8317-0f7b408b17e6": "The Strategic Plan for the City of Adelaide suggests adaptation to emerging industries and digital transformation by focusing on developing a local workforce, supporting innovative and globally competitive businesses, and embracing technologies such as artificial intelligence and cashless transactions. It emphasizes a bold response to economic challenges, fostering an inclusive and thriving economy that leverages new opportunities for transformation in the city.",
        "d730fffc-a5d7-4b98-8dc6-d5e3b19edb7e": "The City of Adelaide aims to foster an inclusive and equitable economy by focusing on workforce development, supporting emerging industries, and promoting innovation through digital transformation. The city plans to adapt its procurement processes and collaborate with various stakeholders, including government and private enterprises, to create new opportunities that enhance competitiveness and sustainability. This approach is designed to address current economic challenges while ensuring that all residents and businesses can thrive.",
        "71c113b6-880a-4b9b-858c-7f4541225d22": "Colonel Light's planning of Adelaide in 1837 is historically significant as it established a city layout centered around an active city center and abundant open spaces, particularly the Park Lands surrounding the city. This design not only balanced urban development with natural elements but also set a precedent for sustainable urban planning. The Park Lands, now nationally heritage-listed, continue to play a crucial role in the city's identity and amenity, influencing contemporary efforts to create a greener, low-carbon urban environment.",
        "345dd26e-8c8b-4421-9dc0-67b6348a6422": "The City of Adelaide serves approximately 26,000 residents and plays a vital role in the broader South Australian community, which includes 1.7 million people. As the capital city, it is central to the state's civic, cultural, and commercial life, promoting sustainability, economic innovation, and community well-being.",
        "e1d9dea6-5ba4-41e9-81fb-123eb51f8272": "The significance of the Park Lands in Adelaide lies in their role as a nationally heritage-listed area that provides beautiful amenities, diverse uses, and serves as a gateway to the city. Designed by Colonel Light in 1837, they create a balance between the built and natural environment, reflecting the city's commitment to open space and community well-being.",
        "654439d8-a3ed-4232-a032-442f012e3499": "The document suggests that partnerships with private enterprises and government levels will be approached through a collaborative focus on financial sustainability, workforce development, and innovative procurement strategies. It emphasizes the need to be bold and adaptive in response to economic challenges, aiming to create transformative opportunities for the city and its businesses.",
        "2fb945b6-7e7c-41e8-a65d-1d3646cff911": "The overarching vision for the City of Adelaide, as outlined in the Strategic Plan, is to become a leading Green City that prioritizes sustainability, innovation, and inclusivity. This vision includes reusing old buildings, supporting a circular economy, and adapting to emerging economic challenges while fostering a thriving, equitable economy that empowers local businesses and enhances the community's resilience against hazards.",
        "cc27ef75-d350-4fd9-8c89-2f6c2802fbfd": "The population of the City of Adelaide is approximately 26,000 residents. In relation to the broader South Australian population, which totals around 1.7 million, the City of Adelaide represents a small but significant urban center within the state.",
        "86e50372-392a-4878-855d-0959dfa08d96": "The traditional custodians of the land on which Adelaide is built are the Kaurna people.",
        "69567d7a-f68a-4f89-8fca-ecb9b2569bdc": "Adelaide was planned in 1837 by Colonel Light.",
        "d01bcc39-f373-413c-878a-1942b3b55e9b": "Colonel Light's original plan for Adelaide featured an active city center, an abundance of open space, and the River Torrens as a central element. He designed the layout with streets surrounded by Park Lands, incorporating squares and gardens to balance the built and natural environment. The Park Lands are now heritage-listed and serve as vital green spaces for the community.",
        "cb62db43-e061-46a3-88ed-48bb457f346d": "The Park Lands of Adelaide include 29 parks and six squares.",
        "61a4d76a-8dac-4658-a0ca-8faeca610f77": "The Park Lands are significant to Adelaide's heritage as they embody Colonel Light's vision of a balanced city with ample open space, reflecting the city's commitment to integrating natural and built environments. They are nationally heritage-listed, serving as a vital amenity for residents and visitors, and play a crucial role in the city's cultural and social life, enhancing its identity and livability.",
        "d82e1efe-30f1-4012-95b7-030c9e9d316f": "Notable commercial and social spaces mentioned in the document include the Adelaide Central Market, Rundle Mall, and the Park Lands.",
        "86a4ce35-b09d-41d2-ba1d-701430e95b27": "The City of Adelaide aims to balance its cultural heritage with contemporary design by embracing quality design innovation while valuing its historical and built form heritage. This is reflected in the preservation of the Park Lands, which are nationally heritage-listed, and the integration of modern spaces like the Adelaide Central Market and Rundle Mall, all while maintaining the unique features of Colonel Light's original city plan.",
        "27e78579-4991-4b71-bb37-094130ecfd41": "The Gross Regional Product of the City of Adelaide is $21.9 billion.",
        "d21a3b8c-a358-43c7-a901-363f32e90ec8": "The City of Adelaide describes its spirit as bold, aspirational, and innovative, emphasizing resilience and progressiveness in the face of global challenges. This strong spirit has enabled the city to withstand social and economic disruptions, establishing it as a leading hub for commerce, knowledge sharing, and ideas exchange.",
        "d183e29e-0fc2-475e-af1a-a922864905c4": "The Gross Regional Product of the City of Adelaide represents 17.6% of the Gross State Product.",
        "9d859641-4be2-4fa5-9c75-e04f1084eb4f": "Adelaide's Park Lands include 29 parks and six squares.",
        "cd129655-2398-4720-9a3e-f9a2ca5ba30a": "The total land area of the City of Adelaide is 15.6 km\u00b2.",
        "af21a7c5-2a8c-4860-97e5-3be60ee0a7b8": "47% of Adelaide's residents are aged between 18 and 34.",
        "522bdd6f-298b-424b-95fd-69cf1fe7e2a9": "There are 12,265 local businesses reported in the City of Adelaide.",
        "d2ea477c-7b4c-4eaf-adfc-5d581451ecd9": "45% of Adelaide's population was born overseas.",
        "5a2062da-dac1-4cd2-84f2-aeac09ced6c6": "There are 14,660 private dwellings in the City of Adelaide.",
        "f2b6ed29-665c-4a44-9284-6af1d920a1e8": "The total number of jobs available in the City of Adelaide is 157,498.",
        "dabaa2fd-abcd-4a7f-a00a-5f6fac6d50e2": "50% of residents in Adelaide are renting their homes.",
        "87236c71-7417-4183-b987-218a13fbae2e": "Approximately 6,800 residents in Adelaide study at TAFE or University.",
        "02f4c8c9-3545-4447-9d49-95dc038a55de": "The development of the City of Adelaide's Strategic Plan is guided by the Local Government Act (SA) 1999 and the City of Adelaide Act 1998.",
        "383b1288-e107-48a7-8dd4-92fb5e79e595": "The primary stakeholders that the Strategic Plan is designed to benefit include ratepayers, residents, visitors, workers, and all key stakeholders in the City of Adelaide, as well as the broader South Australian community.",
        "de821ccb-13fe-4a5c-8d91-286920f4260c": "The City of Adelaide plans to collaborate with other levels of government by building strong partnerships with Federal, State, and Local Governments, as well as strategic non-government organizations. This collaboration aims to advocate for the city's interests, seek co-investment, and leverage relationships for grants and contributions, ultimately benefiting the community and shaping the future of the city.",
        "12aee59e-dd84-4952-a000-77d009357223": "The City of Adelaide acts as a custodian of community assets by managing and overseeing the assets entrusted to the Council, ensuring they are maintained and utilized effectively for the benefit of the community. This role involves developing strategies and policies that guide the management of these assets, while also advocating for their preservation and enhancement to support the city's growth and well-being.",
        "086343eb-f6f7-490a-935a-174934c57953": "The City of Adelaide acts as an advocate for its community by representing their interests to influence issues and opportunities that impact the city. It builds strong partnerships with Federal, State, and Local Governments, as well as non-government organizations, to leverage resources and seek co-investment for community benefits. Additionally, the City engages with various stakeholders to address local issues and ensure the community's voice is heard in decision-making processes.",
        "62a36f3a-95c4-4cd3-9724-ff7878c494d4": "The purpose of the Resource Plan is to guide the finance, infrastructure, and resources necessary for the delivery of the Strategic Plan over the next four years, while also supporting longer-term interconnected vision and economic plans.",
        "a95c57f6-162f-4e68-96dd-e1baf089440a": "The City of Adelaide intends to leverage partnerships for community benefit by collaborating with Federal, State, and Local Governments, as well as strategic non-government organizations. This approach aims to advocate for the city, seek co-investment, and secure grants and contributions that enhance community services and infrastructure. The City will also engage with various stakeholders to address local issues and implement effective strategies for the city's future.",
        "3a5d463d-2594-4d57-92e2-d640bcaf16cd": "The key roles identified for the City of Adelaide in implementing change are: \n\n1. **Leader**: Developing strategies and policies for the city.\n2. **Owner/Custodian**: Managing community assets.\n3. **Regulator**: Ensuring safety, cleanliness, and order under State legislation.\n4. **Information Provider**: Offering information to the community and stakeholders.\n5. **Advocate**: Representing community interests to influence relevant issues.\n6. **Facilitator/Initiator**: Engaging with various stakeholders to address city-related issues.",
        "6fdbebbb-045b-4ceb-81f5-8a0dd5a52e24": "The City of Adelaide fulfills its regulatory responsibilities by undertaking its role under State legislation to ensure the city remains safe, clean, and orderly. This includes developing and implementing strategies, policies, and programs that align with the Local Government Act and the City of Adelaide Act, while also managing community assets and providing information to stakeholders.",
        "23fc7659-1369-4f55-bd5b-847cc31ec14a": "The City of Adelaide engages with Federal, State, and Local Governments, as well as strategic non-government organizations, including private sector entities, community groups, and not-for-profit organizations, as part of its facilitation efforts.",
        "37c7290c-d66c-4a9d-99e3-75a1b48c87cf": "The City of Adelaide identifies several key roles in its approach to implementing and influencing change: \n\n1. **Leader** - Developing clear strategies and policies.\n2. **Owner/Custodian** - Managing community assets.\n3. **Regulator** - Ensuring safety and order under State legislation.\n4. **Information Provider** - Sharing information with the community and stakeholders.\n5. **Advocate** - Representing community interests to influence relevant issues.\n6. **Facilitator/Initiator** - Engaging with various stakeholders to address city issues.\n7. **Agent** - Providing services on behalf of third parties when beneficial to the community.\n8. **Direct Provider** - Delivering core services and programs.\n9. **Partner** - Collaborating with others to achieve service and project outcomes.",
        "d4220302-6177-4aed-8474-7c1e8f73ddda": "The City of Adelaide defines its role as a \"Leader\" in community development by developing clear strategies, policies, programs, and services that guide the city's growth while maintaining its livability. This leadership involves engaging with the community, advocating for their interests, and facilitating collaboration among various stakeholders to address urban challenges and opportunities.",
        "edcecf02-c3ea-4a27-b853-ad9323fa3e2a": "The City of Adelaide's strategy for maintaining liveability while supporting growth is underpinned by the following principles: \n\n1. **Exceptional Amenity** - Pursuing excellence in city development.\n2. **Quality Housing** - Ensuring liveability and affordability for residents.\n3. **Community Connection** - Fostering accessibility, diversity, and inclusivity.\n4. **Unique Experiences** - Creating engaging experiences for all city users.\n5. **Climate Resilience** - Integrating climate resilience into all initiatives.\n6. **Economic Growth** - Promoting innovation and investment in various sectors.\n7. **Budget Repair** - Delivering quality services while ensuring financial sustainability.",
        "a3604a30-942d-439d-8838-a9d73192eeaa": "The City of Adelaide acts as an \"Advocate\" for its community by representing their interests to influence issues and opportunities that affect the city. This includes engaging with stakeholders, promoting community needs, and ensuring that growth aligns with the principles of liveability, accessibility, and sustainability.",
        "3385eacc-a32d-482a-b769-35eac54ca58c": "The City of Adelaide plans to ensure \"Quality Housing\" for its residents by striving for liveability and affordability, which will help attract and retain residents. This commitment is part of a broader strategy that emphasizes exceptional amenity, community connection, and economic growth while maintaining the city's overall livability.",
        "8e0d7776-f862-4c47-a819-d99dd936ffa2": "The significance of \"Climate Resilience\" in the City of Adelaide's planning and development strategies lies in its commitment to integrating climate adaptation and sustainability into all aspects of urban growth. By embedding climate resilience, the city aims to protect its liveability, enhance community well-being, and ensure that development does not compromise environmental integrity. This principle guides decision-making to address climate-related challenges, fostering a sustainable and thriving urban environment for current and future generations.",
        "2480dbb3-2a60-4929-a71f-fa2de0cdd388": "The City of Adelaide aims to strengthen \"Community Connection\" among its residents by prioritizing accessibility, diversity, and inclusivity, ensuring that people are at the forefront of its initiatives. This involves engaging with individuals and community groups to foster relationships and enhance the overall sense of belonging within the city.",
        "ae0ae74e-1ef0-4288-9666-f0a09d03f3ee": "The City of Adelaide manages its community assets as an \"Owner/Custodian\" by developing strategies and policies that ensure the effective stewardship of these assets. This includes prioritizing exceptional amenity, quality housing, community connection, unique experiences, climate resilience, economic growth, and long-term financial sustainability to maintain the city's livability while supporting growth.",
        "c259ce8a-bf62-4df0-9d9b-2e02755f2f8c": "The City of Adelaide aims to balance economic growth with liveability by implementing principles that prioritize exceptional amenity, quality housing, community connection, unique experiences, climate resilience, and sustainable economic development. This approach ensures that growth enhances the city's livability rather than compromising it, while also focusing on long-term financial sustainability.",
        "2049e452-7007-44bb-ad53-08eac1f8dd35": "The City of Adelaide acts as a \"Facilitator/Initiator\" by bringing together and engaging various stakeholders, including individuals, community groups, industry, and government agencies, to collaboratively address community issues. This role involves fostering dialogue, coordinating efforts, and mobilizing resources to effectively tackle challenges impacting the city.",
        "8b12028b-6acf-4ba7-9922-d9cc4f9fb2bf": "The principle that emphasizes the importance of creating a high standard of living in the city is \"Quality Housing,\" which focuses on striving for liveability and affordability to attract and retain residents.",
        "024f1de2-567b-4d92-b737-3684714400b4": "The strategic plan aims to balance quality housing with affordability by striving for liveability and affordability to attract and retain residents, ensuring that housing options meet high standards while remaining accessible to a diverse population.",
        "2d46a10c-911d-44cd-b838-5694464397a9": "The plan proposes to strengthen community connection and inclusivity by prioritizing people first, enhancing accessibility, promoting diversity, and fostering a sense of belonging within the community.",
        "bd7d138e-dd8e-4469-9466-4ae0857afdcc": "The significance of \"Unique Experiences\" in the strategic plan is to enhance the attractiveness of the city by creating engaging and memorable activities for residents, workers, and visitors, thereby fostering community engagement and supporting overall growth and liveability.",
        "17d6025e-3ac2-4fe9-b399-6f15fa0f3a48": "The strategic plan addresses climate resilience by embedding it as a core principle in all initiatives, ensuring that climate considerations are integrated into decision-making processes to enhance the city's adaptability to climate change impacts.",
        "eb073d96-1c9b-4d61-8994-563866ecf680": "Economic growth in the City of Adelaide's strategic plan plays a crucial role by encouraging innovation, investment, and development in both current and emerging sectors, which supports overall liveability and sustainability.",
        "81595047-cc73-42ab-b1a4-0ac937091298": "The principle of \"Budget Repair\" is essential for providing quality services as it ensures long-term financial sustainability. By effectively managing the budget, resources can be allocated efficiently to maintain and enhance services that support liveability, community connection, and overall city excellence.",
        "0d3ff6ac-57bf-4a99-a801-37bdb225e51e": "The key areas of focus for innovation and investment according to the strategic plan are Economic Growth, Quality Housing, and Climate Resilience.",
        "13d0d920-84bb-4857-ab16-9b18028bca3f": "The plan aims to attract and retain residents by focusing on quality housing for liveability and affordability, fostering community connection through inclusivity and accessibility, and creating unique experiences that enhance the city's appeal. Additionally, it emphasizes exceptional amenity and climate resilience, ensuring a vibrant and sustainable environment for current and future residents.",
        "6252bc2d-a3dc-49e9-b01c-6734ea34995e": "The strategic plan supports residents and visitors by focusing on exceptional amenity and unique experiences, ensuring quality housing for liveability, fostering community connection and inclusivity, promoting climate resilience, and encouraging economic growth through innovation and investment.",
        "84563fb6-ef3a-4201-9b0a-aabec1da59fb": "The target number of affordable rental properties to be delivered by 2028 according to the Council\u2019s Housing Strategy is 600.",
        "558fb59c-7dd5-479d-a732-ba3e212f6e4b": "The Council plans to reduce rough sleeping and homelessness by working with partners to achieve Zero Functional Homelessness, increasing affordable housing supply, and attracting investment for 600 affordable rental properties by 2028. They aim to reduce incidences of homelessness to functional zero by 2026 and support 29 State Government housing outcomes per month for those experiencing homelessness.",
        "468de01c-a55b-4088-b295-bbe9e1f917f1": "The goal for increasing the city\u2019s population from 26,000 to 50,000 by 2036 is to support community growth, enhance housing affordability, and create a vibrant, inclusive environment that attracts and retains residents. This includes driving affordable housing outcomes, reducing homelessness, and fostering engaging community experiences.",
        "06650ce1-6b98-4083-abd8-8fb0a425530f": "The aim is to increase the share of family households living in the city from 12.5% to 15% by 2036, which represents a percentage increase of 20%.",
        "9b101ee0-ce2f-4753-b7e6-0e88e76c2d1e": "The Council aims to support 29 State Government housing outcomes per month for people experiencing homelessness until 2026.",
        "9025c776-a0f2-41bf-b120-6360c8de9e54": "Community-led services play a crucial role in enhancing social connections and active lifestyles by fostering engagement through locally-driven arts, cultural, and recreational activities. These services promote well-being, encourage participation in leisure and sports, and create vibrant experiences that strengthen community ties, ultimately contributing to a more connected and active population.",
        "9dfc8fe6-a500-402f-8364-a0f407589fb3": "The Council intends to elevate the city\u2019s reputation for arts and cultural experiences by encouraging and providing partnerships, grants, and sponsorship opportunities for arts, culture, and events.",
        "2ed9c1e1-ca57-461e-aa6f-5f2a39723476": "The city is implementing several strategies to increase housing supply and reduce rental pressures, including:\n\n1. **Partnerships and Advocacy**: Collaborating with partners to support residential growth and enhance housing affordability.\n2. **Investment Attraction**: Aiming to deliver 600 affordable rental properties by 2028 as part of the Council\u2019s Housing Strategy.\n3. **Incentive Utilization**: Increasing the use of City or State Government incentive schemes to promote diverse housing options and community facilities.\n4. **Population Growth Target**: Working to increase the city\u2019s population from 26,000 to 50,000 by 2036, which will help boost housing demand and supply.\n5. **Homelessness Reduction**: Striving for Zero Functional Homelessness by 2026 through targeted support for individuals experiencing homelessness.",
        "9b51d523-9443-44ca-a463-18e0f08ac77c": "The target year for achieving functional zero homelessness in the city is 2026.",
        "ec52c137-fb7a-407c-8032-b6d836899fc0": "The Council plans to celebrate and honor community cultures by driving social change through locally-led arts, cultural, and recreational activities, as well as by providing partnerships, grants, and sponsorship opportunities to elevate the city's reputation for unique arts and cultural experiences.",
        "1679081a-1610-4e83-aa87-f93718bdb129": "The expected percentage of the population living in the city is between 5% and 15%.",
        "24f834e4-1f37-4067-bec5-6f250cce8870": "The City of Adelaide aims to support 29 State Government housing outcomes for people experiencing homelessness by the year 2026.",
        "e4e43f64-1894-4db5-85fb-f5f7f2c17867": "The target increase in residents' life satisfaction is from 70% to 75%, which is a 5% increase.",
        "ce3cabb2-0e7c-42e6-9ed6-d7fea5523003": "The strategy to be reviewed by 2025 to enhance community engagement in active lifestyles is the Active City Strategy.",
        "c425e4f7-81a6-4925-989f-bb3e6606dfcc": "The City of Adelaide plans to amplify its status as a UNESCO City of Music by developing a Centre of Music, enhancing partnerships and grants for arts and cultural events, and increasing community participation in music-related activities. Additionally, the city aims to review its service delivery models and create a Community Wellbeing Plan by 2026 to better support the evolving needs of its residents.",
        "8d6e64f4-8f8f-4c5d-85a8-780f14ed2c0d": "One key action to support Aboriginal and Torres Strait Islander peoples and culture is to champion reconciliation and recognition by identifying opportunities to celebrate and elevate Kaurna culture and connection to Country.",
        "e7cd42a7-0030-4c16-9966-6e4f82e9cc37": "The overarching policy to be developed by 2025 is a grants policy aimed at supporting diversity in arts, culture, community development, recreation, and wellbeing.",
        "ca2cfd88-d290-49d7-9691-b2b94c86d2f7": "The goal for increasing volunteer participation in the community is to enhance social connections, improve community wellbeing, and support diverse opportunities for engagement in arts, culture, and recreational activities, ultimately fostering a sense of belonging and inclusivity among residents.",
        "c780d7dc-d030-4922-a4d2-ebd8c4151f3a": "A Community Wellbeing Plan is to be developed by 2026 to enhance community wellbeing in the City of Adelaide. This plan will focus on increasing social connections, participation in active lifestyles, and supporting diverse arts and cultural experiences, with the goal of raising residents' life satisfaction from 70% to 75%.",
        "cd9a2b5e-abc2-4a76-a9cf-1288c3a91bdb": "The document proposes to celebrate and elevate multicultural communities within the city by creating welcoming programs and services that recognize and promote community culture. It emphasizes championing reconciliation and the recognition of Aboriginal and Torres Strait Islander peoples, while also supporting initiatives that celebrate the profiles of diverse multicultural communities. Additionally, it aims to foster an inclusive environment that acknowledges diversity and enhances a sense of belonging for all residents and visitors.",
        "96c1877d-28fa-4499-8fe1-b6a641d6f6d8": "The primary goal of the new Stretch Reconciliation Action Plan to be established by 2024 in the City of Adelaide is to champion reconciliation and recognition of Aboriginal and Torres Strait Islander peoples and culture, while creating an equitable and welcoming community that celebrates diversity and promotes inclusion for all.",
        "f8aae89d-184e-4683-89da-f02874302e75": "The City of Adelaide plans to celebrate and elevate Kaurna culture and connection to Country by championing reconciliation, recognizing Aboriginal and Torres Strait Islander peoples, and creating inclusive opportunities for participation in cultural and social life. This includes establishing a new Stretch Reconciliation Action Plan by 2024, increasing Aboriginal and Torres Strait Islander-led community activities, promoting multicultural events, and developing a Cultural Policy that supports the city's unique cultural identity.",
        "0fa79790-3e48-4c69-9af2-5f3bab30e3a7": "The specific target set for increasing Aboriginal and Torres Strait Islander-led community reconciliation activities is to develop a target to increase the number of such activities.",
        "e878d333-b7b2-45fa-a45c-1a89a45f58e9": "The proposed initiatives to promote multicultural events and activities within the city include celebrating and elevating Kaurna culture, creating welcoming programs for multicultural communities, ensuring accessibility and inclusivity in services, establishing a new Diversity, Access and Inclusion Plan by 2024, and developing a Cultural Policy that supports the city\u2019s unique cultural identity. Additionally, there is a focus on promoting multicultural events and increasing Aboriginal and Torres Strait Islander-led community reconciliation activities.",
        "15509b6f-6300-4e27-a851-6058e78dba9b": "The City of Adelaide plans to ensure accessibility and inclusivity for all residents by implementing a new Diversity, Access and Inclusion Plan by 2024, establishing a Stretch Reconciliation Action Plan, promoting multicultural events, and developing policies that support social infrastructure and cultural identity. These initiatives aim to celebrate diversity, support Aboriginal and Torres Strait Islander communities, and create welcoming programs that encourage full participation from all backgrounds.",
        "a8b461a5-302b-4af3-8047-e71c897d67ab": "The target percentage for Aboriginal and Torres Strait Islander employment at the City of Adelaide is to be higher than 2%.",
        "16378ea8-3b2f-4bee-ba11-a0a05bac1e9a": "The key components of the new Diversity, Access and Inclusion Plan to be developed by 2024 include:\n\n1. Championing reconciliation and recognition of Aboriginal and Torres Strait Islander peoples and culture.\n2. Celebrating and elevating multicultural community profiles and creating welcoming programs.\n3. Supporting an inclusive community that recognizes diversity and accommodates people of all abilities.\n4. Ensuring accessibility and inclusivity in services and projects for diverse backgrounds.\n5. Establishing a new Stretch Reconciliation Action Plan.\n6. Increasing Aboriginal and Torres Strait Islander-led community reconciliation activities.\n7. Promoting higher employment rates for Aboriginal and Torres Strait Islander individuals within the City of Adelaide.\n8. Promoting multicultural events and activities.\n9. Developing a Social Infrastructure Policy to address community needs.\n10. Creating a Cultural Policy to support the City\u2019s unique cultural identity.",
        "e0299e73-82d4-4899-a5fb-b898f8ec8183": "The purpose of the Cultural Policy to be developed by 2024 is to promote and support the City of Adelaide's unique cultural identity, enhance community belonging, celebrate diversity, and ensure inclusive participation in cultural and social life for all residents, including Aboriginal and Torres Strait Islander peoples.",
        "390cf9bc-3234-49e3-a8a7-53442e44b20f": "The City of Adelaide plans to support belonging among people of diverse backgrounds by championing reconciliation with Aboriginal and Torres Strait Islander peoples, celebrating multicultural communities, and creating inclusive programs and services. They aim to establish a Stretch Reconciliation Action Plan and a Diversity, Access and Inclusion Plan by 2024, promote multicultural events, and ensure accessibility in their services. Additionally, they will develop policies to enhance cultural identity and support community needs, fostering full participation in the city's social and cultural life.",
        "2b8bfe31-5706-4cac-b3e6-c41a532e1223": "The Social Infrastructure Policy plays a crucial role in addressing current and emerging community needs by ensuring that services and projects are accessible and inclusive for all residents. It aims to create a welcoming environment that recognizes diversity, supports multicultural events, and promotes the participation of Aboriginal and Torres Strait Islander peoples. By establishing frameworks for reconciliation and inclusion, the policy fosters a sense of belonging and encourages full participation in the cultural and social life of the community.",
        "b36fec0f-0538-454f-8a04-7ec2163cb4d9": "The key objectives outlined for enhancing the Park Lands and open space are to protect, enhance, and activate these areas while being climate conscious and prioritizing sustainability in future decisions.",
        "0c754ff1-0327-4602-b220-b61c4ef2badb": "The document proposes to support the transition to a low carbon emissions city by implementing sustainable and renewable systems in projects, promoting circular economy activities, advocating for sustainable practices in development, increasing electric vehicle charging infrastructure, and setting targets for greenhouse gas emissions reduction. It also emphasizes collaboration with partners for innovation, community education on climate resilience, and the adaptation of buildings and industries to enhance resource efficiency.",
        "e4232091-81e0-4cb9-86b3-542acd594947": "The specific target set for reducing community greenhouse gas emissions by 2030 is a 50% reduction from the 2020 baseline.",
        "631f0f3d-aa2e-43bc-9b5f-db60bdafbfda": "Partnerships with universities and researchers play a crucial role in the city's sustainability efforts by fostering innovation and transforming carbon reliance. These collaborations enable the development and implementation of sustainable practices, support the circular economy, and enhance resource-use efficiency. Additionally, they provide access to data and expertise necessary for tracking progress and educating the community on climate resilience.",
        "baf900f8-d7c7-4edc-9d41-153a8d202eb8": "The document aims to increase the number of electric vehicle charging stations from 54.",
        "660c4723-0c4e-4193-969b-56689611b139": "The timeline for reviewing Procurement Policies and Guidelines to support Circular Economy outcomes is set for completion by 2024.",
        "a9f00af0-b7bb-4580-aab3-929c5a8f1ec7": "To improve resource-use efficiency in buildings and industries, the suggested measures include:\n\n1. Implementing sustainable, renewable, and green systems and materials in projects.\n2. Supporting circular economy activities to enhance sustainability.\n3. Advocating for increased use of sustainable practices and materials in development.\n4. Adopting clean and environmentally sound technologies and processes.\n5. Enhancing waste management and resource recovery services.\n6. Developing a Sustainability Governance and Reporting Framework to track progress and share data.",
        "41d1a569-3c75-477f-8b45-62b299b7fa6f": "The document aims to develop a Sustainability Governance and Reporting Framework by 2025.",
        "bac1947d-4db1-42cd-86a4-5afd208bb380": "The strategies mentioned for diverting waste from landfill in the community include partnering with the community to enhance waste management and resource recovery services, as well as implementing progressive waste management practices.",
        "b68cea8c-44e9-4404-8ffb-49e21cbf7217": "The document defines success in increasing green infrastructure in city assets as achieving a measurable target for enhancing and integrating sustainable practices and materials in development projects. This includes increasing the number of green upgrades or new buildings, implementing sustainable systems, and advocating for practices that support environmental resilience, ultimately contributing to a climate-conscious and low carbon emissions city.",
        "ed4cb43d-59f2-4e57-bcbc-24d2d6fd0959": "All new dwellings built from 2025 will be fully electric, with no internal gas supply, as part of the City of Adelaide's commitment to sustainability and climate resilience.",
        "d9673f44-1b6d-4b3f-9960-83250598213f": "The City of Adelaide plans to increase the diversion of residential kerbside waste from landfill to 80% by 2030 by providing progressive waste management and resource recovery services, partnering with the community to enhance waste diversion efforts, and establishing a baseline to measure circularity while setting targets for improved circular economy outcomes.",
        "99271d6f-87fe-4424-a5f8-d617d721d47a": "The goal for the adaptive reuse of underutilised buildings is to deliver 50 dwellings annually.",
        "a475e0b9-0797-4cf6-bef9-459944a3f577": "The framework being developed by 2025 to enhance sustainability governance and reporting is the Sustainability Governance and Reporting Framework.",
        "85bafa0b-e37f-4089-a578-28bd4aadd3bd": "The City of Adelaide Climate Strategy will support the community in reducing their climate impact by leading education on climate resilience, promoting sustainable building practices, enhancing waste management and resource recovery, and establishing a Sustainability Governance Framework. It aims to deliver 50 adaptive reuse dwellings annually, ensure all new homes are fully electric by 2025, increase landfill diversion from 50% to 80% by 2030, and protect and restore green spaces and biodiversity.",
        "46e487ae-8e50-4879-89bd-73ffaa588967": "The city employs several strategies to protect and restore native habitats, including advocating for no new development in the Park Lands, supporting the Kadaltilla/Adelaide Parklands Authority, and working with partners to convert underutilised areas into green spaces. Additionally, efforts are made to enhance the biodiversity and quality of existing green spaces, ensuring the protection and restoration of native habitats throughout the city.",
        "248ef9f6-ea02-4e45-8952-180e3341f9b8": "The City of Adelaide plans to measure and increase circular economy outcomes by establishing a baseline for circularity, setting targets for improvement, and enhancing waste diversion from landfill from 50% to 80% by 2030. They will also track green upgrades and new buildings, develop a Sustainability Governance and Reporting Framework by 2025, and support community initiatives to reduce climate impact.",
        "b3fc093d-419f-4e60-839a-2f8a5a995e49": "Partnerships play a crucial role in tracking green upgrades and new buildings in the community by facilitating access to data, enabling collaboration on sustainability initiatives, and supporting the implementation of climate-resilient practices. They help monitor progress, share best practices, and ensure that community goals for resource efficiency and environmental sustainability are met effectively.",
        "1a2f1290-471f-42d7-8dd0-ae5226110a4b": "The Kadaltilla Charter and Business Plans are significant as they guide the sustainable management and enhancement of the Park Lands, ensuring the protection of green spaces, biodiversity, and native habitats. They support community engagement in climate resilience efforts and advocate against new developments in these areas, promoting the restoration and effective use of underutilized spaces for environmental benefits.",
        "700d6a41-b85e-4eb5-90c3-9ab9b648dd53": "The actions being advocated to prevent new development in the Park Lands include: advocating for no new development in the Park Lands, returning previously alienated Park Lands, and leading efforts to protect and restore native habitats while enhancing the environmental value and biodiversity of these areas.",
        "1a2334a3-bfb2-42d5-9bdd-84242500696c": "The primary goal of the Kadaltilla/Adelaide Parklands Authority Subsidiary is to protect and enhance the environmental value, biodiversity, and quality of the Park Lands while advocating for no new development and achieving a net increase in green spaces and tree canopy cover by 2035.",
        "47934a43-4d15-439c-9080-29f3ca5ece36": "The document proposes to enhance biodiversity and ecosystem health within the City of Adelaide by 2030 through several key actions: protecting and restoring native habitats, advocating for no new developments in the Park Lands, achieving a net increase in biodiversity and habitats, supporting annual increases in street trees, and developing targets to expand green spaces. Additionally, it aims for world heritage listing of the Park Lands and the reclamation of alienated green spaces, all aligned with the Kadaltilla Strategic Plan.",
        "74d8d626-f083-4799-87df-89c199ca31e2": "The specific target set for tree canopy cover by 2035 is 40%.",
        "dd0d664b-34cb-4424-95f2-65a27aa2ee1b": "Strategies suggested for converting underutilized areas into green spaces include advocating for the environmental value of existing Park Lands, collaborating with partners to innovate green space creation, protecting and restoring native habitats, and pursuing a net increase in biodiversity and tree canopy cover. Additionally, there is a focus on reclaiming alienated Park Lands and implementing the Adelaide Park Lands Management Strategy.",
        "bd1d779f-8f35-4d63-816d-ddd3dfc58391": "Achieving world heritage listing for the Park Lands is significant as it ensures the protection and enhancement of their unique attributes, strengthens environmental and biodiversity efforts, and safeguards their national heritage status. This recognition promotes sustainable management and advocacy against development, ultimately contributing to the preservation and restoration of native habitats and green spaces within the city.",
        "73e69019-1208-4989-9514-a880425ae177": "The document addresses new development within the Park Lands by advocating for no new development, emphasizing the protection and restoration of green spaces, and seeking to reclaim alienated Park Lands. It aims to enhance biodiversity and maintain the integrity of the Park Lands through strategic management and partnerships.",
        "4a010339-76ae-4dd9-82a7-93820cdd3aa9": "The Kadaltilla Charter and Business Plans play a crucial role in the management of the Park Lands by guiding the protection and enhancement of green spaces, advocating for biodiversity and environmental quality, and ensuring no new developments occur within these areas. They support strategic initiatives aimed at increasing green spaces, restoring native habitats, and achieving specific targets for tree canopy cover and biodiversity by 2030. Additionally, they help in pursuing heritage listings to strengthen protections for the Park Lands.",
        "b357f262-8bc7-4a43-ba94-90d25c2fc3f7": "The proposed measures to protect and restore native habitats in the city include: \n\n1. Strengthening the protection of green spaces and Park Lands.\n2. Supporting the Kadaltilla/Adelaide Parklands Authority and its Charter.\n3. Advocating for the environmental value and biodiversity of Park Lands and open spaces.\n4. Working with partners to convert underutilized areas into green spaces.\n5. Opposing new developments in Park Lands and reclaiming alienated areas.\n6. Aiming for a net increase in biodiversity and ecosystem health by 2030.\n7. Increasing street trees annually to combat heat islands.\n8. Achieving 40% tree canopy cover by 2035.\n9. Developing targets to expand green spaces.\n10. Pursuing world heritage and state heritage listings for Park Lands to enhance protections.",
        "90f531c1-a2a1-4663-a701-8d0c526f25ee": "The document plans to support a net increase in street trees annually by aligning this goal with the Council\u2019s Climate Strategy, utilizing heat island data to inform tree planting efforts, and aiming for 40% tree canopy cover by 2035.",
        "271c845d-f7cf-4502-a591-f3426de16a92": "The intended outcome of the Adelaide Park Lands Management Strategy is to protect and enhance the attributes and character of the Park Lands, achieve a net increase in biodiversity and green spaces, support tree canopy cover, advocate against new developments, and secure heritage listings to strengthen protections for these areas.",
        "58098587-317a-40dd-8e8c-842573620942": "The primary objective of the economic strategy outlined in the document is to grow the economy in alignment with the community, support existing businesses in adapting to change, and create a strong skilled workforce.",
        "6f2c03ea-96d0-4e29-b99f-2639c6fa370e": "The strategy aims to support existing businesses in Adelaide by enhancing their agility and responsiveness to change, partnering with various stakeholders to upgrade precincts, and providing improved information to attract visitors. Key actions include supporting the Adelaide Central Market Authority and reinforcing Adelaide's reputation as a central business district, ultimately aiming to increase city visitation from 2.1 million to 2.5 million by 2028.",
        "ef1c8ce0-05f9-4005-9b22-cda17855b347": "The Adelaide Central Market Authority (ACMA) plays a crucial role in the economic growth plan by supporting the delivery of its Charter and Business Plans, which aim to attract visitors, stimulate investment, and enhance the city's reputation as a vibrant business and learning hub.",
        "24dbbe6d-be05-493b-90c7-80c5c77381ad": "The key partnerships mentioned for activating and upgrading precincts in Adelaide include the State Government, universities, associations, community groups, and advocacy groups.",
        "dbee2461-2268-4f58-b5b6-0f401a07a887": "The target increase in the number of visitors to the city by 2028 is from 2.1 million to 2.5 million.",
        "4aa1ba05-c07b-4666-8daa-e347f20c0b8a": "The strategy plans to enhance the information provided to visitors in Adelaide by refreshing the way information is delivered, partnering with various stakeholders to activate and upgrade precincts, and reinforcing Adelaide's reputation as a central business district. This approach aims to attract more visitors and improve their experience in the city.",
        "706aa352-c9bb-4b85-a54b-29bb23c1a531": "The document suggests reinforcing Adelaide's position as the State's central business district by supporting the Adelaide Central Market Authority, partnering with various stakeholders to enhance precincts, refreshing visitor information, and amplifying Adelaide's reputation as a hub for learning, work, and business startups. Additionally, it aims to increase city visitation from 2.1 million to 2.5 million by 2028.",
        "5eed5ff4-f82f-47e1-87e1-41dd1fe2c21f": "The proposed actions to stimulate investment and visitation in Adelaide include supporting the Adelaide Central Market Authority, partnering with various stakeholders to upgrade precincts, refreshing visitor information, and reinforcing Adelaide's reputation as a central business district. The goal is to increase city visitation from 2.1 million to 2.5 million by 2028.",
        "56b9c86f-a928-499e-9498-a73628644144": "The strategy aims to create a strong skilled workforce in the community by partnering with the State Government, universities, and local organizations to enhance education and training programs. This collaboration will ensure that the workforce is equipped with the necessary skills to meet the demands of existing and emerging businesses, ultimately fostering economic growth and adaptability.",
        "c1d879cf-8c6a-442a-848d-8600a19adaaa": "The success of the initiatives will be indicated by the increase in city visitation from 2.1 million to 2.5 million by 2028, effective support for the Adelaide Central Market Authority, and enhanced partnerships with government and community groups to stimulate investment and upgrade precincts.",
        "d2669ffe-7beb-48ec-8271-d36c72dbfabe": "The primary goal of the Adelaide Economic Development Strategy is to achieve a critical mass of jobs and investment, attract and retain businesses, and grow a dynamic, holistic economy by supporting various sectors and enhancing economic opportunities in the city.",
        "c0042bec-15b6-4bd4-a93e-7fd98760cf86": "The Council plans to support the Adelaide Economic Development Agency (AEDA) by continuing its financial and strategic backing, facilitating partnerships with stakeholders, and delivering key actions outlined in the AEDA Strategic Plan. This includes enhancing marketing strategies, providing economic data, and fostering investment in emerging sectors to boost job creation and economic growth in the city.",
        "156e0e0d-a4fa-429c-8409-431220dac5dc": "The sectors identified for growth and development in the City of Adelaide's economic strategy include medical, technology, creative, and professional services.",
        "b017cd18-641c-49ef-aee1-7579905d4ef7": "Partnerships with universities and businesses play a crucial role in attracting investment and improving employment opportunities by fostering collaboration to grow current and emerging sectors, such as medical, technology, and creative services. These partnerships help create a dynamic economy, support business development, and enhance the overall productivity of the city.",
        "20d45b19-3e29-4ce6-8f8e-89b28d4e5037": "The target year for developing a new City of Adelaide Economic Development Strategy is 2024.",
        "b81d42af-4840-4e75-a37e-f5bb5fa4034f": "The document suggests reducing barriers for businesses in the city by creating efficiencies and providing support for small, medium, and large-scale businesses to open and thrive. It emphasizes partnerships with key stakeholders to enhance economic development and the delivery of services and information that contribute to a high productivity economy.",
        "3c35f6e1-8218-4d70-aa5b-caab797ef790": "The indicators of success mentioned for measuring the effectiveness of the economic development initiatives include: \n\n1. Increase in foot traffic in key and emerging precincts annually.\n2. Increase in spending across the city.\n3. Achievement of a critical mass of jobs and investment.\n4. Attraction and retention of businesses.\n5. Growth in contribution to Gross State Product.\n6. Delivery of economic data and insights to the business community.",
        "e0c1eaf4-fcce-4647-9445-c6df3ac525f8": "The Council aims to increase spending across the city by enhancing foot traffic in key precincts, delivering targeted marketing strategies, supporting the Adelaide Economic Development Agency, attracting investment, creating partnerships in emerging sectors, reducing barriers for businesses, and developing a comprehensive Economic Development Strategy by 2024.",
        "243adf1a-3e6e-4934-8f05-08192cf75259": "The Council plans to deliver economic data and insights that include information on foot traffic trends, spending patterns across the city, and support for job creation and investment. This will be aimed at enhancing productivity, attracting businesses, and fostering growth in key sectors such as medical, technology, and creative industries.",
        "78d67856-973e-49c1-aec2-1494f8b7880b": "The document proposes to achieve a critical mass of jobs and investment in Adelaide by supporting the Adelaide Economic Development Agency (AEDA), enhancing partnerships with universities and businesses, creating efficiencies for businesses, and developing a comprehensive Economic Development Strategy by 2024. It aims to attract investment, improve employment opportunities, and promote emerging sectors such as medical, technology, and creative industries.",
        "810207f7-bfd2-4350-8069-66311eccb2c9": "75% of businesses now view the city as a good place to do business.",
        "a6ff0b73-63d1-49e7-96d3-9db6bd320ba0": "The City of Adelaide plans to increase the use of social enterprises and Aboriginal Torres Strait Islander owned businesses by enhancing procurement processes to prioritize these businesses, driving development opportunities through diverse commercial activities, and collaborating with partners on major development projects that focus on economic outcomes. Additionally, the council aims to review the Strategic Property Action Plan to manage community assets effectively.",
        "5193feb0-ee34-41cf-823d-a0ee4e056d12": "The major development projects mentioned are 88 O\u2019Connell Street, Market Square, and the former Bus Station, which focus on economic and housing outcomes.",
        "817770a0-a4e1-475f-9443-01aa5dd1c843": "The purpose of maintaining the Future Fund is to support investment in revenue-generating activities that reduce the financial burden on ratepayers.",
        "d65a760c-da91-4b9f-abd1-0ab23d361c35": "The City of Adelaide plans to review the Strategic Property Action Plan by 2024.",
        "9330c6d8-e629-46c7-a1b9-abcb42a79fe2": "The Strategic Property Action Plan mentions car parks and other commercial assets for management opportunities.",
        "315c34dc-ec06-41d4-9468-42ce9d0b8ca2": "The specific targets to be developed in relation to City of Adelaide housing developments include establishing sales and tenancy targets associated with these developments, as well as focusing on major projects like 88 O\u2019Connell Street, Market Square, and the former Bus Station to enhance economic and housing outcomes.",
        "6b6e95ef-4415-40a3-81bb-8fa406d6b2c3": "The council intends to support investment in revenue-generating activities by maintaining the Future Fund, reviewing the Strategic Property Action Plan by 2024, and developing sales and tenancy targets for housing developments. Additionally, they will focus on driving development opportunities and increasing the use of social enterprises and Aboriginal Torres Strait Islander owned businesses through procurement.",
        "8b63c842-754d-4ceb-822c-19d874b6dfa3": "The increase in the number of new businesses and investments in the city signifies a growing confidence in the local economy, which can lead to job creation, enhanced community development, and increased revenue for the city. This trend also supports diverse commercial activities and promotes social enterprises, contributing to a more resilient and inclusive economic environment.",
        "f422d89e-3af8-4bbc-9137-98b0b7c226c2": "The governance arrangements for managing the Future Fund include maintaining the fund to support investment in revenue-generating activities and reviewing the Strategic Property Action Plan by 2024.",
        "63182019-df9f-4b89-8f07-0d5739df1e7c": "The key objectives outlined for managing community assets are to: \n\n1. Manage assets to meet community needs.\n2. Encourage bold and purposeful development.\n3. Facilitate safe and accessible community spaces.\n4. Ensure adaptability and responsible maintenance of community assets.\n5. Support the creation of new assets for emerging community needs.\n6. Promote safer transport measures and road user behavior.\n7. Develop an Integrated Transport Strategy aligned with road safety goals.",
        "15f67438-55f2-4e1d-bcb2-5931cf113613": "The document proposes to enhance the safety and accessibility of places within the community by delivering quality upgrades to streets and laneways, creating new assets with a focus on safe design, and supporting diverse transport measures for drivers, cyclists, and pedestrians. It also emphasizes the importance of maintaining community assets responsibly and collaborating with partners to promote safer road user behavior. Specific projects, such as the upgrades of Hindley, Gouger, O\u2019Connell, Hutt, and Melbourne Streets, are planned to commence by 2024-2026, alongside the development of an Integrated Transport Strategy by 2024.",
        "cab66794-d2fc-49e5-a6ce-f7660eb424d4": "The specific street upgrade projects scheduled to commence by 2025/2026 include the design of the following: \n\n- Hindley Street (design by 2023/2024)\n- Gouger Street (design by 2023/2024)\n- O\u2019Connell Street (design by 2024/2025)\n- Hutt Street (design by 2024/2025)\n- Melbourne Street (design by 2025/2026)",
        "d28f0a11-6bc2-4985-8f59-a165599cde00": "The target year for developing and implementing an Integrated Transport Strategy is 2024.",
        "544c0523-4849-4a4c-9fdd-665819d60ad1": "The document plans to support the maintenance and development of community and cultural places by delivering quality upgrades to streets and public spaces, creating new assets to meet emerging community needs, and facilitating safe and accessible environments. It emphasizes collaboration with partners to enhance transport measures and ensure safe movement within the city, while also leading the development of a City Plan to guide growth and development in alignment with community needs.",
        "83fed39e-fc22-49cf-bc94-3787328ec3b1": "To encourage safer road user behavior, the suggested measures include:\n\n1. Delivering quality upgrades to streets and laneways to enhance safety and accessibility.\n2. Creating new community assets with a focus on safe design and maintenance.\n3. Collaborating with partners to promote active transport options for drivers, cyclists, and pedestrians.\n4. Designing specific street upgrade projects (e.g., Hindley, Gouger, O\u2019Connell, Hutt, and Melbourne Streets) to improve safety.\n5. Developing and implementing an Integrated Transport Strategy aligned with the South Australian Road Safety Strategy to minimize road incidents and fatalities.",
        "5b0e0b8a-45ba-48d2-ab2b-d5416f1d6089": "The significance of revising the Asset Management Plans by June 2024 lies in ensuring that community assets are effectively managed and maintained to meet evolving needs. This revision will facilitate the development of safe, adaptable infrastructure, support urban revitalization, and align with broader transport and safety strategies, ultimately enhancing the quality of life for residents and promoting sustainable growth in the city.",
        "b1d94630-89a1-4be2-a5bc-6a455898de22": "The document defines \"bold and interesting development\" as initiatives that support the changing needs of the community and city, focusing on creating unique, purposeful, and safe community, cultural, and civic places and infrastructure that align with residential growth.",
        "37fc4dd3-224f-42d3-8bc8-48fd1c220d7e": "Partnerships play a crucial role in achieving the objectives outlined in the document by facilitating collaboration on community asset management, enhancing transport measures, and supporting safer road user behavior. They enable the development of innovative and purposeful projects that meet the evolving needs of the community, ensuring that developments are well-designed, safe, and accessible.",
        "d9a63734-783d-4d2d-9606-295a6c1bc0de": "The indicators of success mentioned for the street and laneway upgrades include: \n\n1. Delivery of quality upgrades that make Adelaide well-designed, safe, and unique.\n2. Creation of new assets focused on safe design, construction, and maintenance.\n3. Increased active and diverse transport measures to ensure safe movement for drivers, cyclists, and pedestrians.\n4. Commencement of design projects for specific streets by set deadlines (e.g., Hindley Street by 2023/2024).\n5. Development and implementation of an Integrated Transport Strategy aligned with the South Australian Road Safety Strategy to 2031.",
        "8ad62d6a-b20e-48de-80bc-996076551adf": "The primary goal of the City Plan being developed for Adelaide by 2024 is to provide guidance on city growth and development, enhancing amenity and accessibility to create a liveable, walkable city that fosters community connection and inclusivity.",
        "969b8e6d-3a24-4537-bc91-948c60660254": "The plan aims to increase the number of dwellings in Adelaide by 2031 by setting a target to raise the total from 14,660 in 2021 to 22,770 by 2031. This will be achieved through the development of diverse and affordable housing options, repurposing existing buildings, and creating multi-use green spaces to enhance community connectivity. Additionally, 15% of new dwellings will be designated as affordable for low and moderate income earners, ensuring inclusivity in housing development.",
        "a21481e3-7e32-431d-b606-03b99ee55278": "15% of new dwellings are targeted to be affordable for low and moderate income earners.",
        "0d563f3d-9eb9-4e66-9146-7ba34fbdaba1": "The City Plan advocates for the development of multi-use green spaces, including open spaces, community gardens, and pocket parks, to promote shared use and community connection.",
        "94928ab3-5bfb-4263-830e-7d645a050b88": "The plan aims to review the heritage overlays for local heritage places by 2025.",
        "6ae6c002-0e19-46f1-93dc-3a7cc85c48b2": "The current percentage of people who agree that the city is a welcoming and dynamic place is 82%, with a target percentage of 90%.",
        "e16cc5fa-12ce-4018-95af-8f22bad3d6f6": "The plan proposes to support the adaptive reuse and improvement of existing buildings by encouraging repurposing and upgrading facilities, protecting heritage sites while maintaining their character, and advocating for diverse and affordable office spaces and housing. It aims to ensure that heritage places are preserved and integrated into development, with a review of heritage overlays and conservation management plans to be completed by 2025.",
        "b1f1c5b7-cc93-408e-8c63-181b47186d2a": "The specific measures mentioned to ensure access and inclusion for vulnerable or minority groups include maintaining and improving access for disability and LGBTQIA+ communities, as well as creating safe, inclusive, and healthy places for the community.",
        "96c8a9f7-60be-499c-b4b1-f9f889857d15": "The target number of heritage places to be maintained or increased in the city is to ensure no loss of the existing 1,850 heritage places and to consider options for increasing that number.",
        "bce30228-f7d5-4287-b768-8af1681bd9e1": "The timeline for delivering conservation management plans for heritage assets is by 2025.",
        "7049ce02-5fad-4cb3-aa3b-9ac892380878": "The target number of new dwellings is 17,780 by 2026 and 22,770 by 2031.",
        "5f08a1b2-85fb-4fcb-b15e-4d2685d0ebe7": "15% of new dwellings are designated for affordable purchase or rental for low and moderate income earners.",
        "041bcdb1-2df6-49eb-8551-6b4fced1f1bf": "The plan aims to review the heritage overlays by 2025.",
        "e39ca0b7-a0eb-4f4f-899b-2fdb18a9e544": "The goal is to increase the number of heritage places from the current 1,850 to 17,780 by 2026 and 22,770 by 2031.",
        "d8ebc361-887c-4fa9-990b-6ed4a2eb52e7": "The specific plans to be delivered for heritage assets by 2025 include: \n\n1. No loss of local heritage places and consideration of options to increase the current 1,850 heritage places.\n2. A review of heritage overlays to ensure heritage places are recognized and accommodated during development.\n3. Delivery of conservation management plans for heritage assets.",
        "365e4a5a-e965-41ea-9084-9009ddc8160c": "The strategic plan aims to enhance access and inclusion for vulnerable or minority groups by ensuring that 15% of new dwellings are affordable for low and moderate income earners, achieving Disability Access compliance in all new and upgraded infrastructure, and maintaining and improving access for disability, LGBTQIA+, and other vulnerable groups. Additionally, it includes reviewing the Disability Access and Inclusion Plan by 2024 and the Wellbeing (Public Health) Plan by 2026 to better address community needs.",
        "6955938f-caee-440d-a6e2-ca19aecaf34d": "To create sustained activation in the city, the following initiatives are suggested: \n\n1. Promote outdoor dining and manage parking, leases, and licenses effectively.\n2. Encourage unique experiences in public spaces through streamlined permit management.\n3. Support businesses in operating safely and responsibly.\n4. Enhance access and inclusion for disability, LGBTQIA+, and minority groups.\n5. Review and update relevant plans, including the Disability Access and Inclusion Plan, Wellbeing Plan, and Dog and Cat Management Plan, by their respective deadlines.",
        "b2cd2e00-d4fe-4be9-9eb4-a0b61a2ac4fc": "The Disability Access and Inclusion Plan is scheduled for review by 2024.",
        "4a7c002d-3b2b-49ef-9551-9781e05e14ee": "The Wellbeing (Public Health) Plan is scheduled for review by 2026.",
        "74415071-32ff-4404-9711-1644aad70e28": "The proposed action regarding the Dog and Cat Management Plan is to review it by 2024.",
        "fe462210-bd24-4985-9ab9-d6a3b5872e60": "The target date for implementing the Public Transparency Policy is June 2024.",
        "bdb2a4c5-8e8c-46e9-b1c9-96cb3313dd73": "The corporation plans to enhance customer experience by actively listening to community feedback and integrating their perspectives into decision-making processes. Key actions include promoting transparency through a Public Transparency Policy, achieving high scores in the Voice of the Customer Survey for satisfaction and ease, and ensuring that marketing and communication reflect current decisions and services.",
        "8c68714a-0b29-49ca-b402-4964dcf3b683": "To reduce the number of confidential Council decisions, the Corporation is implementing a Public Transparency Policy by June 2024 and is focused on enabling effective governance, risk management, and accountability in decision-making. Additionally, there will be a review and monitoring of the Governance Structure to ensure best practices in decision-making.",
        "d4ce8385-576f-4e7f-add9-0cc3e1b6aae6": "The goal related to the Voice of the Customer Survey scores is to achieve and maintain high levels of Customer Satisfaction and Customer Ease, ensuring that the experiences of customers align with their expectations and support informed decision-making.",
        "460bab6c-056e-4e64-91e8-32a129200577": "The corporation intends to achieve financial sustainability by focusing on responsible financial management, budget repair, and intergenerational equity while delivering quality services. Key actions include improving service efficiency, identifying new revenue streams, and ensuring high-value procurement aligned with relevant policies. Additionally, the corporation will review its Rating System and Procurement Policy to optimize outcomes and support community asset funding. Success will be measured through adherence to procurement policies and the achievement of targeted financial outcomes.",
        "dbe2305b-ab29-4d7e-8b4a-4ef70396d5b0": "The specific review planned for the Rating System is set to be completed by 2024.",
        "76ad8511-e9eb-471f-8671-49fde8e724c7": "The key components of the internal audit program mentioned in the document include:\n\n1. Alignment with service outcomes.\n2. Robust governance and risk management.\n3. Accountability and transparency in decision-making.\n4. Regular review and monitoring of the governance structure.\n5. Evaluation of Emergency Management Plans and responses.",
        "58f4d02a-f441-4f0a-8307-5da421caa8e1": "The corporation will ensure that 100% of procurement aligns with its relevant policies by implementing a comprehensive review of the Procurement Policy and Guidelines. This will include integrating strategies that support the Council\u2019s Climate, Diversity, Reconciliation, Workforce, and 'Buy Local' initiatives. Regular audits and monitoring will be conducted to ensure compliance and effectiveness in achieving these targets.",
        "ff10a404-8b6e-497e-ac72-eb0f6173205b": "The strategies outlined to improve service efficiency and identify new revenue streams include:\n\n1. **Reviewing the Rating System**: To ensure optimal financial outcomes by 2024.\n2. **High Value Procurement**: Achieving effective contracts management to enhance financial sustainability.\n3. **Identifying New Revenue Streams**: Creating opportunities for additional income through innovative approaches.\n4. **Conducting Procurement in Line with Policies**: Ensuring all procurement supports Council\u2019s strategic goals, including climate and local economy initiatives.",
        "c23a997c-b6b3-4e1e-a0f7-eb30b687a5ad": "The timeline for reviewing Emergency Management Plans and responses is set for completion by 2025.",
        "1b792e66-2854-4664-8253-8c438ab2f5ac": "The principle emphasized for responsible financial management in the City of Adelaide's Strategic Plan 2024-2028 is intergenerational equity.",
        "4db53b0b-0151-4423-bbd7-050c85540c3c": "The City of Adelaide aims to review its Rating System for optimum outcomes by 2024.",
        "0c55d2bc-fc15-400c-8799-eb35ca4070ed": "The target range for the Asset Renewal Funding Ratio, as outlined in the Long-Term Financial Plan, is between 90% and 110%.",
        "210e80f2-3e61-4dbe-9331-ed4a66b6cffc": "The specific employment target set for Aboriginal and Torres Strait Islander individuals within the City of Adelaide is to achieve greater than 2% employment.",
        "5642f44f-413e-499c-b7d4-1a380b3c90f2": "One of the key actions to improve service efficiency mentioned in the document is to identify new revenue streams and create new opportunities for income.",
        "27f4caea-0829-44f5-8bbf-2c0ed41eb32b": "The goal for the City of Adelaide's procurement practices is to ensure that 100% of procurement aligns with Council policies, supporting local sourcing, climate resilience, and other strategic targets, while also reviewing the Procurement Policy to enhance circular economy initiatives and Aboriginal and Torres Strait Islander employment by 2024.",
        "92bf4b96-20ca-4208-b149-552e0d64b06e": "The City of Adelaide plans to deliver a Workforce Strategy by 2024.",
        "1fe30c62-ac04-4b42-b3af-7cca812dab23": "The City of Adelaide is planning to implement a Graduate Program by 2025 to support workforce development.",
        "ff691d9b-7977-4ab0-97a8-8a228a306f2f": "The City of Adelaide intends to support informed decision-making and innovation by creating an organizational culture that fosters collaboration and agility, developing necessary skills and leadership, and implementing a Workforce Strategy by 2024. Additionally, they will utilize employee feedback to drive positive outcomes and establish a Graduate Program by 2025 to attract and retain talent aligned with their objectives.",
        "51b190a4-e57f-49fc-9a98-932be86ca5cc": "The desired outcome of the employee feedback tools and risk assessments is to generate positive employee outcomes that enhance engagement, support informed decision-making, and foster a high-performing organizational culture.",
        "8c33e3ff-8c86-4759-a72b-2d98045f76ec": "The target percentage for delivering Strategic and Capital Projects on time and on budget by 2024 is 75%.",
        "0ce31491-2d50-499c-992d-129ce10c7247": "The review of the Strategic Planning Framework is expected to be completed by 2024.",
        "5eee1ad6-9f5d-4fa0-94a9-9c995b994ad8": "The framework being developed to achieve best practice outcomes through partnerships is the Strategic Partnerships Framework, which aims to be implemented by 2024.",
        "87367a68-74cc-46b7-a015-6092b142fbcd": "Community feedback will be utilized to monitor, maintain, and adapt services, ensuring continuous improvement in value and efficiency. It will inform decision-making and guide the development of plans and policies, ultimately enhancing overall satisfaction with Council services.",
        "02e1bff7-138c-4da4-a056-2497bf7e8484": "The purpose of the Business Systems Roadmap is to support business efficiency by integrating technology and innovative solutions that enhance customer-focused performance improvements.",
        "b6bbd015-f1d0-4e88-bf5c-757a8d2a6bd3": "The planned upgrades for the Workforce Management System include delivering enhancements to improve business efficiency and customer-focused performance, as well as increasing staff awareness and engagement through better systems.",
        "92ef67ad-a5de-4063-b421-c3fc730c6d2e": "The review of the Community Engagement approach is scheduled to be completed by 2025.",
        "ea39905f-aeed-47e7-b977-e9d8e2f3504f": "Measures being taken to improve staff awareness and engagement include the implementation of better systems for communication and data integration, as well as the development of a Workforce Management System. These initiatives aim to enhance efficiency and provide staff with the necessary tools and insights to engage effectively with their roles.",
        "be4cffc7-9b80-4722-b8ce-e78f94b4b261": "The goal of implementing data integration solutions for Customer Insights is to improve efficiency outcomes by integrating customer data and insights, thereby enhancing decision-making and service delivery.",
        "b7a273a6-fbeb-4861-addb-a25bd66e7eb2": "Baseline data for relevant measures in the Strategic Plan is being developed by 2024.",
        "c2cc4817-3e26-4d0f-8822-d048515db468": "The primary focus of the Strategic Plan for the City of Adelaide for the years 2024\u20132028 is to outline a vision and aspirations for the city's future, guiding decision-making and shaping future policy positions, while ensuring long-term financial sustainability and effective resource management.",
        "fa9fdba0-8e15-4d50-ad63-086a44e65318": "The Long Term Financial Plan supports the overall Strategic Plan by ensuring the financial sustainability of the City of Adelaide over a ten-year horizon. It provides the necessary financial resources and framework to achieve the vision and aspirations outlined in the Strategic Plan, enabling effective implementation of key actions and objectives while maintaining a focus on long-term outcomes.",
        "4db0edf1-9039-4169-b640-b5c31eda3728": "The key components of the Resource Plan associated with the Strategic Plan include:\n\n1. **Financial Resources**: Budget allocations and funding required to support the implementation of the Strategic Plan.\n2. **Non-Financial Resources**: Human resources, infrastructure, and other assets necessary for execution.\n3. **Alignment with Objectives**: Ensuring resources are aligned with the objectives and key actions outlined in the Strategic Plan.\n4. **Support for Four-Year Delivery**: Resources specifically designated to enable the delivery of the Strategic Plan from 2024 to 2028.",
        "8ee68ef5-a15e-4ec2-a045-206cd85aa86a": "The aspirations articulated in the Strategic Plan influence future policy positions of the Council by providing a clear vision and defined outcomes that guide decision-making. These aspirations shape the Council's priorities, inform the development of specific objectives and actions, and ensure alignment with long-term goals for the city. As the Council refines related strategies and policies, the aspirations serve as a foundation for evaluating success and adapting future initiatives to meet community needs.",
        "691a54e4-8322-42dc-aeca-01bd7f9a66d8": "The purpose of the Indicators of Success/Measures/Targets section in the Strategic Plan is to define and clarify what long-term success looks like for the City of Adelaide, providing measurable criteria to assess progress and outcomes related to the plan's objectives.",
        "c368cdc5-422a-4042-bd7f-0611fcc9c5bf": "The Long Term Financial Plan is revised annually and has a time frame of ten years.",
        "db9c1a9b-17e7-4635-920a-c9bed57c8364": "The Principles play a crucial role in shaping the four-year plan of the Strategic Plan by informing the primary areas of focus that drive outcomes. They guide decision-making and help ensure that the objectives and actions align with the vision and aspirations for the City of Adelaide.",
        "13cc9c8b-358d-4ade-943b-50b1aec3478c": "The City Plan is integral to the overall vision for the future of Adelaide as it serves as a ten-year spatial plan that outlines future land uses and built form. It aligns with the Strategic Plan's long-term vision and aspirations, guiding decision-making and shaping future policies to ensure sustainable development and financial viability for the city.",
        "96b51eab-c536-4438-8770-4966b9e16324": "The suite of related Strategies, Plans, and Policies is significant in implementing the Strategic Plan as it provides a structured framework that aligns with the long-term vision and aspirations of the City of Adelaide. These documents ensure that actions are coordinated, resources are effectively allocated, and outcomes are measurable, thereby facilitating the successful delivery of the Strategic Plan over its four-year focus. They also allow for adaptability and refinement in response to changing needs and priorities, ensuring that the Strategic Plan remains relevant and impactful.",
        "0381d794-ed85-42b0-be9e-4652336b6f5b": "The expected outcomes described under the Objectives and Outcomes section of the Strategic Plan include the achievement of specific goals and the implementation of strategies that align with the Council's responsibilities. These outcomes are articulated to shape future policy positions and drive measurable success over the four-year delivery period from 2024 to 2028.",
        "4428d79d-9ee8-4ea1-be3d-26efc3300f60": "The key objectives outlined in the Strategic Plan for the City of Adelaide from 2024 to 2028 include:\n\n1. **Community Engagement**: Enhance community involvement and well-being through various strategies and policies.\n2. **Environmental Sustainability**: Promote sustainable practices and resilience against climate change.\n3. **Economic Development**: Foster economic growth and development through strategic initiatives and partnerships.\n4. **Urban Development**: Improve urban spaces and infrastructure to enhance livability and accessibility.\n5. **Corporate Governance**: Ensure effective governance and resource management to support the strategic objectives.\n\nThese objectives are supported by specific actions, measures of success, and a resource plan to facilitate their implementation.",
        "47746844-6941-4d9c-b404-5be4b9f52040": "The Council will measure the success of the Strategic Plan's implementation through specific indicators of success, which will include defined measures and targets for each objective. Progress will be assessed annually against these indicators, supported by a Resource Plan that outlines the necessary financial and non-financial resources. Additionally, the effectiveness of related strategies, plans, and policies will be evaluated to ensure alignment with the key outcomes and actions of the Strategic Plan.",
        "013291d1-5d96-4ec1-ada6-a55c92af4140": "The Resource Plan includes both financial and non-financial resources necessary for the Administration to support the Strategic Plan's delivery from 2024 to 2028. This encompasses funding allocations, staffing, infrastructure, and partnerships outlined in related strategies, plans, and policies across various sectors such as community, environment, economy, places, and corporate governance.",
        "aa71431b-9868-4e4f-ac79-2568dc8c7739": "Three related strategies or policies under the \"Our Community\" category are:\n\n1. Active City Strategy\n2. Cultural Strategy\n3. Wellbeing Plan (statutory)",
        "a17ef721-499b-495d-addc-7c3cff6339d0": "The \"Indicators of Success/Measures/Targets\" section in the Strategic Plan serves to define and clarify what long-term success looks like for the Council's objectives. It establishes specific criteria and benchmarks to evaluate the effectiveness of strategies and actions implemented, ensuring accountability and guiding future decision-making.",
        "8f53824d-05df-444f-9579-4efe7c17cedf": "The Strategic Plan for the City of Adelaide addresses environmental concerns through several key strategies, including the Integrated Biodiversity Management Plan, the Water Sensitive City Action Plan, and the Carbon Neutral Strategy. These initiatives aim to enhance biodiversity, promote sustainable water management, and achieve carbon neutrality. The plan outlines specific actions and measures of success to ensure long-term environmental sustainability, supported by a comprehensive Resource Plan to allocate necessary financial and non-financial resources.",
        "d5888a0c-cb18-43ad-88e1-59bec9e8af2f": "The Adelaide Economic Development Agency plays a crucial role in supporting the Strategic Plan by focusing on economic growth and development initiatives. It aligns with the plan's objectives by implementing strategies that enhance the local economy, attract investment, and promote sustainable business practices, thereby contributing to the overall success and measurable outcomes outlined in the Strategic Plan for 2024-2028.",
        "4bd24477-5741-4146-b1e5-9a8cb3e0f8d4": "The statutory plans mentioned in the context of \"Our Places\" are the Disability Access and Inclusion Plan, Community Land Management Plans, and the Annual Business Plan and Budget.",
        "752e3573-a20a-481a-842e-c50076b31103": "The Council will ensure the Strategic Plan remains relevant over time by regularly reviewing and updating related strategies, plans, and policies to align with key outcomes and measures of success. This will involve ongoing community engagement, monitoring indicators of success, and adapting the Resource Plan as needed to support the four-year delivery from 2024 to 2028.",
        "8742203a-8074-4fd1-8e12-c5921a953f24": "A complete list of the strategies, plans, and policies related to the Strategic Plan can be found on the City of Adelaide website at cityofadelaide.com.au/about-council/plans-reporting/strategies-plans-policies.",
        "a756754e-91d4-4878-b1a8-e4df84c85156": "The primary goal of the Council's Financial Principles is to ensure financial sustainability for current and future generations while delivering services and maintaining an operating surplus.",
        "c39bdf22-3968-443a-b3e6-3a3d31948d5a": "The Council plans to adjust fees and charges by applying equitable rates that respond to changing community needs, ensuring services are indexed to the Consumer Price Index (CPI), and considering new revenue streams. Adjustments will be made based on budget components, prioritizing funding for new or enhanced services while maintaining financial sustainability.",
        "8c40b587-bd59-4767-9837-79791bcc3f97": "Maintaining an operating surplus is significant for the Council as it ensures financial sustainability, allowing for the delivery of current services and assets while absorbing economic fluctuations. It supports the funding of new initiatives, reduces reliance on external revenue sources, and enables the Council to respond effectively to community needs and opportunities without incurring financial losses.",
        "a7fa1cd5-d912-4dd6-8ccc-5daad4e8df81": "The Council intends to capitalize on external funding opportunities by retiming projects to align with stakeholder objectives and recognizing the potential need for increased borrowings to respond to these opportunities. Additionally, they will explore new revenue streams to reduce reliance on existing sources.",
        "efbb711b-f268-4159-a969-392f6b696093": "The Council proposes to manage new or enhanced services requiring increased operating costs by adjusting priorities, increasing rate revenue, exploring other revenue sources, and implementing savings measures. This approach ensures financial sustainability while maintaining service delivery.",
        "01b850e8-37f4-47fa-a417-c54ee17215ef": "Asset management plans play a crucial role in the Council's capital renewal expenditure by providing a structured framework for prioritizing and allocating funds for the maintenance and replacement of assets. They ensure that capital renewal projects are aligned with the Council's financial principles, enabling effective budgeting and resource management to meet community needs while maintaining financial sustainability.",
        "dc094018-f2c5-474d-8539-0b3d112d96f2": "The Council considers using borrowings to fund projects when responding to external funding opportunities, for new or upgraded projects, and when it aligns with their financial principles, such as maintaining an operating surplus and ensuring financial sustainability.",
        "322ec5a3-b06c-44c8-9136-a9f074b79e34": "The Council ensures its financial resources can withstand economic fluctuations by maintaining an operating surplus, applying equitable fees and charges, capitalizing on external funding opportunities, and considering new revenue streams. Additionally, it adjusts rate revenue based on budget components, funds new services through priority adjustments, and bases capital expenditures on asset management plans. These principles collectively enhance financial sustainability and resilience against economic changes.",
        "c3e31b8c-8d74-40fe-8d13-c5133d9f6188": "The Council considers several factors when adjusting rate revenue, including the need to maintain an operating surplus, the impact of Consumer Price Index (CPI) on service delivery, equitable fees and charges, funding for new services and assets, and the alignment of budget components. Additionally, they evaluate external funding opportunities, the potential for increased borrowings, and the overall financial sustainability in relation to community needs and statutory obligations.",
        "bcdf8188-9ae7-4c9c-a52c-b32a211c06e4": "The Council approaches the disposal or repurposing of property assets by considering community outcomes while ensuring that such actions do not incur a financial loss. This process is guided by their financial principles, which emphasize maintaining an operating surplus and aligning decisions with asset management plans.",
        "33c9a5ac-117d-4263-b2ac-5bc01cd8453f": "The key components of the Council's Financial Principles for long-term financial sustainability include:\n\n1. **Capacity to Absorb Economic Fluctuations**: Ensuring financial resources can withstand economic cycles, social trends, and financial shocks.\n2. **Balanced Funding Decisions**: Making funding choices that support medium and long-term sustainability.\n3. **Revenue and Cost Stability**: Maintaining stable revenue streams and managing costs effectively.\n4. **Proportionality of Revenues and Benefits**: Aligning revenues with the benefits provided over time to the community.\n5. **Intergenerational Equity**: Spreading the costs of expenditures over time to benefit current and future communities.\n6. **Efficiency Improvements**: Continuously seeking efficiencies while maintaining existing service levels.\n7. **Integration with Strategic Plans**: Coordinating with the Long Term Financial Plan, Resource Plan, and other strategic documents to inform budgeting and service delivery.",
        "f12c850c-435a-460a-bab7-def3ec61b831": "The Council plans to achieve intergenerational equity in its financial decisions by ensuring that the costs of expenditures are distributed over time in relation to the benefits received by the community. This is supported by the Long Term Financial Plan, which maintains existing service levels while seeking efficiency improvements. Additionally, the Resource Plan outlines the necessary resources to meet strategic objectives, ensuring that financial sustainability is prioritized to absorb economic fluctuations and support future generations.",
        "1d84d626-62e3-461a-8cba-897909cd7252": "The purpose of the Resource Plan developed by the Council for 2024-2028 is to outline the financial and non-financial resources needed to achieve the Council's strategic objectives over the next four years, ensuring alignment with the Long-Term Financial Plan and other key documents to support effective decision-making and service delivery.",
        "72aef7a2-64ba-4d30-8fee-6e5dd5781f9f": "The Strategic Plan and Resource Plan interact with the Long-Term Financial Plan by ensuring that the financial and non-financial resources required to achieve strategic objectives are aligned with the Council's financial sustainability goals. The Resource Plan outlines the necessary resources for the next four years, while the Strategic Plan sets the overall direction. Together, they inform the Long-Term Financial Plan, which maintains existing service levels and seeks efficiency improvements, ensuring that funding decisions support intergenerational equity and the balanced provision of services over time. This integrated approach allows for coordinated planning and effective decision-making in the Annual Business Plan and Budget.",
        "6528fe2f-f82b-45ad-acf4-6257af865f96": "The Council ensures that its funding decisions contribute to financial sustainability by adhering to its Financial Principles, which focus on long-term capacity to absorb economic fluctuations and financial shocks. It emphasizes intergenerational equity by spreading costs over time relative to community benefits. The Long Term Financial Plan maintains existing service levels while seeking efficiency improvements. Additionally, the Resource Plan outlines necessary resources to achieve strategic objectives, and decision-making is guided by comprehensive strategies and plans that ensure coordinated service delivery and measurable progress.",
        "6295613c-4a36-48ca-93a4-e3b135e56449": "The Capital City Council plays a multifaceted role in delivering services to the community by acting as a leader, service provider, regulator, owner, facilitator, and advocate. It ensures financial sustainability through strategic planning and resource allocation, maintaining service levels while seeking efficiency improvements. The Council's decision-making is guided by various plans and policies, enabling coordinated delivery of services and programs. Additionally, it measures progress through targets and regular reporting, ensuring transparency and accountability to the community.",
        "738506d2-f417-48b4-8304-1255fd32e5e5": "The Council measures progress towards its strategic objectives through a combination of financial sustainability assessments, the implementation of a Resource Plan, and the use of targets. This includes tracking performance via quarterly reports and an Annual Report, which detail the delivery of objectives and key actions, ensuring transparency and accountability to the community.",
        "5c68c75a-3aea-41f1-8c77-a6e462e15278": "Maintaining existing service levels while seeking efficiency improvements is significant because it ensures financial sustainability and intergenerational equity. This approach allows the Council to absorb economic fluctuations and social trends while continuing to meet community needs. By balancing service delivery with efficiency, the Council can optimize resource allocation, enhance long-term planning, and ensure that the benefits of expenditures are equitably distributed over time. This strategy supports the achievement of strategic objectives and fosters community trust through transparent and accountable governance.",
        "02168750-9097-4a16-b8c0-f93c89b224ae": "The Council reports on its progress towards achieving its objectives through quarterly reports and an Annual Report each year.",
        "29d47367-6a08-40dc-b520-f9bf94015192": "The Council's financial sustainability ensures that it can effectively manage economic fluctuations and maintain service levels over the long term. This stability allows for consistent funding of community benefits, promotes intergenerational equity by spreading costs fairly, and supports strategic planning. As a result, the community can expect reliable services and programs that are well-coordinated and aligned with the Council's long-term objectives, ultimately enhancing overall community well-being.",
        "1abe8b0f-9ff0-4b06-92e3-f82085a0ba95": "The primary purpose of the Long Term Financial Plan developed by the Council is to provide a strategic framework for financial planning over a 10-year period, ensuring financial sustainability, alignment with the Strategic Plan, and adherence to financial principles and guidelines.",
        "ea07be02-41be-44ec-a3d1-2730c816f49f": "The Long Term Financial Plan ensures alignment with the Council's Strategic Plan by integrating financial sustainability assessments, maintaining high-priority expenditure programs, and aligning with service delivery standards, revenue guidelines, asset management plans, and other strategic initiatives. This comprehensive approach allows the Council to effectively plan and allocate resources in support of its long-term strategic goals.",
        "ff758077-bae5-4e24-9e10-fea6052e8768": "The Long Term Financial Plan emphasizes financial sustainability, alignment with strategic and asset management plans, adherence to revenue and financing guidelines, and the importance of cost assessments for proposed strategies. Key principles include managing rates and fees in line with inflation, forecasting salaries based on agreements, and ensuring capital expenditures align with asset management plans.",
        "1f0219f7-a650-4076-bad0-a2a261bd5976": "The plan addresses the Council's role and responsibilities by ensuring alignment with the Strategic Plan, maintaining high-priority expenditure programs, and adhering to financial principles. It considers the Council's appropriate functions, aligns with service delivery standards, and integrates with Revenue and Financing guidelines, Asset Management Plans, and other relevant strategies. Additionally, it emphasizes the importance of assessing the Council's financial position to achieve long-term sustainability.",
        "583d0c9a-789d-4795-989d-d61db08bbfae": "The assumptions made regarding rates revenue in the Long Term Financial Plan include that rates revenue will increase in line with forecast inflation, along with additional growth from new developments.",
        "51569fbd-d29c-4212-b928-663e451f4df1": "Salary and wage forecasts are determined based on enterprise agreements, and once these agreements expire, the Wage Price Index (WPI) is applied.",
        "210b2a2d-24ba-4c9a-b248-4ca65397ad6c": "The planned annual funding amount for capital enhancements during the current term of council is $15 million.",
        "0cab433e-6e5a-4dd5-9efe-2772070f5b5c": "The Long Term Financial Plan aligns with Asset Management Plans by ensuring that capital renewal expenditures are consistent with the identified needs and priorities outlined in the AMPs. This alignment supports the Council's financial sustainability and strategic objectives by integrating financial planning with asset management strategies, thereby facilitating effective service delivery and maintenance of infrastructure.",
        "221a8469-649f-4f17-9dd2-72c75282253e": "The plan proposes to manage fees and charges by aligning them with forecast inflation, ensuring that any increases reflect the anticipated rise in costs over time.",
        "cb5ee70e-4506-4015-920a-84baf0ebf205": "The Long Term Financial Plan considers interest rates relative to market expectations, ensuring that financial projections align with anticipated economic conditions.",
        "beb32353-48a4-4c11-a283-28d587dbcc52": "The key guidelines that the Long Term Financial Plan must align with are:\n\n1. Revenue and Financing guidelines, including Rating and Treasury Policies.\n2. Asset Management Plans.\n3. Other plans and strategies.\n4. Costing proposed strategies before agreement.\n5. Specific assumptions regarding revenue and expenditure growth in line with forecast inflation, interest rates, and capital renewal expenditures.",
        "e95d2fa4-2795-4302-99f0-060e5ba0cb49": "The Rates Revenue in the Long Term Financial Plan is projected to grow in line with forecast inflation, supplemented by additional revenue from new developments. This approach ensures alignment with various financial and asset management policies, contributing to the overall sustainability of the Council's financial position.",
        "1fb7f892-986b-4482-828d-6d9fba32ea3d": "The target range for the Operating Surplus Ratio is 0%\u201320%. The projected values for the years 2023-24 to 2027-28 are as follows: 0.9% for 2023-24, 1% for 2024-25, 0.9% for 2025-26, 2.8% for 2026-27, and 2.6% for 2027-28.",
        "b881ef2b-1f14-47d0-9b8c-29a291dfa506": "The Asset Renewal Funding Ratio is significant as it measures the adequacy of funding for the renewal of existing assets, ensuring that the council can maintain its infrastructure sustainably. The target range for this ratio is 90% to 110%.",
        "0093e75e-8be0-4ce2-92de-28a87c5e3910": "The Long Term Financial Plan ensures sustainability by aligning with Revenue and Financing guidelines, Asset Management Plans, and other strategic frameworks. It incorporates cost assessments for proposed strategies and adjusts based on recent Council decisions. Key assumptions include rates and fees in line with inflation, controlled salary forecasts, and capital expenditures aligned with Council funding commitments. Regular adjustments to the Plan maintain financial indicators within targeted ranges, ensuring operational surplus, manageable liabilities, and adequate asset renewal funding, thereby supporting the Council's strategic objectives.",
        "04dec1d3-dd4c-46fe-9183-943959b9b9a0": "Once enterprise agreements expire, it is assumed that salaries and wages forecasts will be adjusted to reflect the Wage Price Index (WPI) instead of the previous agreements.",
        "d254d053-2d05-4cbf-82e4-169ef79622ad": "The target for the Net Financial Liabilities ratio is less than 80%. The projected values for the upcoming years are as follows: 2023-24: 1%, 2024-25: 15%, 2025-26: 39%, 2026-27: 38%, and 2027-28: 39%.",
        "44196a38-8d82-4394-814e-dd4eb7a6a553": "The document defines the maximum allowable value for the Asset Test Ratio as 50%.",
        "5b39febf-92ae-4156-89f7-603c2ec5bcda": "The planned annual funding amount for capital enhancements, as per the Council's decision, is $15 million.",
        "25171f57-8659-45f6-a43b-4974686fada1": "The Cash Flow from Operations Ratio shows a positive trend over the four-year period, increasing from 101% in 2023-24 to 107% in both 2026-27 and 2027-28, consistently exceeding the target of less than 100%.",
        "0a629838-fb0f-4abe-90e7-f7f86857ddef": "Key Council priorities for investment include upgrades to several streets, partnerships with the State Government on major projects like the former Adelaide Aquatic Centre site, strategic property developments such as the Franklin Street Bus Station redevelopment, Market Square, and 88 O\u2019Connell Street, as well as significant renewal projects like Torrens Weir and King William Street Bridge.",
        "5caee24c-5365-4aa1-96b3-8c13343d1bc2": "The major project being developed in partnership with the State Government is the former Adelaide Aquatic Centre site.",
        "65bc5eb2-a5aa-44ba-b8ce-1ee5fbbd23f3": "The former Adelaide Aquatic Centre site is significant as it represents a key partnership between the Council and the State Government, highlighting the Council's commitment to major redevelopment projects that align with its strategic priorities and investments in urban renewal.",
        "895d6fbe-b021-4187-95c4-e962d11c8715": "One of the strategic property developments listed is the Franklin Street Bus Station redevelopment.",
        "383b2bac-6903-4d77-9f1b-1ae50f90728b": "The redevelopment of the Franklin Street Bus Station aligns with the Council's strategic plan by enhancing public transport infrastructure, supporting urban renewal, and fostering partnerships for major projects, thereby contributing to the overall investment in city improvements and core services.",
        "7af157ca-9407-47cc-ab51-3812f277266e": "The ongoing core services mentioned in relation to the Council's investment priorities include the delivery of essential municipal services.",
        "5e48f19e-13ec-4e26-8e1a-5d12615bf569": "The significant renewal projects highlighted are the Torrens Weir and the King William Street Bridge.",
        "55d06166-40d6-4813-ae58-68fcbc4fb561": "The King William Street Bridge project is a key component of the City of Adelaide's Strategic Plan 2024-2028, as it represents a significant renewal initiative that aligns with the Council's priorities for infrastructure upgrades and enhances connectivity within the city.",
        "4b584f65-e555-4f5d-be86-e20e8d42c6a0": "Market Square is a key component of the Council's strategic property developments, contributing to significant investment in urban renewal and enhancing public spaces in alignment with the Council's priorities.",
        "7ed0b33b-1692-46ee-b4fe-00c36af0327f": "The upgrades to several streets are likely to enhance connectivity, improve public transport access, and support economic development, aligning with the City of Adelaide's strategic goals of fostering sustainable growth, enhancing urban infrastructure, and improving community well-being.",
        "c043f972-cd78-4dbc-92f0-ddde9c19580c": "Rate revenue accounts for approximately 60% of the total annual revenue according to the Treasury Policy.",
        "62bbdf66-7999-41c1-b506-64a3572e3a67": "The Council assumes a 3% annual growth in rate income.",
        "e0909d3d-c988-40e0-9e5c-f04b7b6c01c3": "The facilities operated by the Council that generate fee-based revenue include the Adelaide Aquatic Centre, Adelaide Golf Links, UPark, Adelaide Town Hall, and the Property Portfolio (including Adelaide Central Market).",
        "b1ade058-9ae4-439b-a81e-25fdf5019e5e": "The projected rate revenue for the year 2025-26 is $145,177,000.",
        "8e3170e2-1bf6-4e29-931d-b4b1073776d0": "The Council generates income from statutory charges set by State Government legislation, which includes fees for services such as on-street parking and hire income for Council properties. These charges contribute to the overall revenue, alongside other income sources like rates and user charges.",
        "fb1ccb44-701a-4126-8f5a-4f1c69851ca1": "The total income projected for the year 2026-27 is $246,825,000.",
        "9158aa4f-96e6-4b7c-8d93-6ca2c5ff7379": "The two main components of the Council's income sources are rate revenue, which accounts for approximately 60% of total annual revenue, and user charges from fee-based facilities.",
        "093158ea-4c96-4bed-9e9d-c0aa289e43e4": "The budgeted amount for employee costs in the year 2024-25 is $83,050,000.",
        "46b4664c-931f-4864-9417-b2457bf2ef40": "The Council's Treasury Policy supports financial activities related to borrowing for strategic expenditures, cash flow management, budgeting, and investments.",
        "7e9cc301-a6dd-4361-82a1-42c61b0be2c5": "The expected income from investment for the year 2027-28 is $165,000.",
        "7cd218cc-eb5b-43fe-84ae-f34797a6b6bc": "The total income projected for the year 2027-28 is 254,516.",
        "40245ab1-9ddd-4ca7-85c4-b0192c36f0d8": "The statutory charges are expected to increase from 14,683 in 2023-24 to 16,132 in 2027-28, resulting in an increase of 1,449.",
        "ca958282-3b96-4eae-b8c8-315aaefb329c": "The operating surplus for the year 2026-27 is $6,598,000.",
        "f800adc8-3e0b-48c3-bfaa-1859b24a8523": "New borrowings are projected to be 20,921 in 2025-26.",
        "424ac2f2-3619-4ded-ad67-58642fd83611": "The trend in employee costs from 2023-24 to 2027-28 shows a gradual increase. Employee costs are projected to rise from 85,013 in 2023-24 to 90,929 in 2027-28, indicating an overall increase of 5,916 over the five-year period.",
        "41f5da4a-5ef9-453a-ba47-897e78b2d326": "The total amount of expenses projected for the year 2024-25 is $247,917,000.",
        "6dd1c568-aaef-4add-9e21-30c455d86dda": "The net borrowings figure increases from 30,184 in 2023-24 to 77,252 in 2027-28.",
        "fe44dd35-9e5e-4a2c-a0f8-87bb17c0b323": "The projected finance cost for the year 2026-27 is 3,970.",
        "06293891-038c-44b0-b03d-0e3d301cde4f": "The future fund is expected to remain constant at $39,967,000 over the five-year period.",
        "871e81bd-b492-4117-93b9-d3a55e50eab2": "The prudential borrowing limit for the year 2026-27 is 202,867.",
        "b7663140-d6c8-46b3-9082-eb68291ee91b": "The projected operating surplus for the year 2025-26 is $6,598,000.",
        "bfbb3d6e-e658-4176-a565-7e4582d4af84": "The allocation for major projects in the year 2023-24 is $36,386,000.",
        "111a0b81-466e-4bf2-acf6-10085fa32ff8": "The total capital expenditure projected for the year 2024-25 is $80,119,000.",
        "be54e310-49c5-44a2-9b22-4a418f0fb157": "The net borrowings expected to be in 2026-27 are $73,625,000.",
        "df466596-9fe1-4489-b138-80ea02d046d1": "The prudential borrowing limit increases from $157,628,000 in 2023-24 to $207,932,000 in 2027-28.",
        "b9768e03-c701-4929-ac32-4262aff73ec3": "The amount set aside for renewal capital expenditure in 2025-26 is $51,932,000.",
        "f100cb99-40ea-4cfa-a5bb-a96b000dff3a": "The Future Fund amount remains consistent over the five-year period at $39,967,000 due to stable projections and management strategies that maintain this level without fluctuations in funding or expenditures.",
        "83795b52-c140-4e13-bcc4-7e0e7886ae7f": "The total amount of new borrowings projected for the year 2024-25 is $17,515,000.",
        "5f55fbeb-f7a5-4030-9735-dbd36ee3ae21": "Asset Management Plans play a crucial role in the Council's financial planning by providing a structured approach to managing the asset portfolio. They ensure that the Council can deliver required services to the community while meeting strategic and legislative requirements. These plans inform capital expenditure decisions, particularly for renewal and replacement, by analyzing the optimal timing for asset replacement based on whole of life costing. Additionally, they support the Annual Business Plan and Budget through ongoing condition audits, ensuring that asset management aligns with financial projections and operational needs.",
        "9d3eb2e6-e132-4614-83d4-8007453c8b4e": "The Council ensures the ongoing improvement of its assets through the development of Asset Management Plans, which provide a comprehensive framework for managing its diverse asset portfolio. These plans include rolling condition audits that inform the Annual Business Plan and Budget, ensuring that renewal and replacement capital expenditures are based on optimal timeframes and whole of life costing.",
        "d043a745-4579-48a0-b04d-d38be8f341dc": "The purpose of the Asset Management Plans developed by the Council is to ensure effective and comprehensive management of the Council's diverse asset portfolio, delivering required service levels to the community while meeting strategic and legislative requirements over a three-year period. These plans guide capital expenditure decisions, optimize asset replacement timing, and inform the Annual Business Plan and Budget through ongoing condition audits.",
        "ba546fb9-6c94-43dd-8e9e-873edf6854c2": "The Council ensures asset management aligns with community service levels and legislative requirements through the development of comprehensive Asset Management Plans, which provide a three-year outlook for service delivery. Regular condition audits inform the Annual Business Plan and Budget, while capital expenditure is strategically managed to avoid disruptions. Additionally, the Property Strategy focuses on optimizing the property portfolio to meet growth objectives and maintain financial sustainability.",
        "2186b6c9-b259-4a8d-829f-6a5e32f9c5c3": "Rolling condition audits play a crucial role in the management of the Council's assets by providing essential information on the ongoing condition and performance of these assets. This data informs the Annual Business Plan and Budget, ensuring that renewal and replacement capital expenditures align with the Asset Management Plans. By assessing asset conditions, the Council can optimize replacement timelines based on whole of life costing, thereby enhancing service delivery and maintaining financial stability while meeting strategic and legislative requirements.",
        "96999606-fa0a-4f54-931c-db661755b67e": "Renewal and replacement capital expenditure is determined by the Asset Management Plans, which assess the optimal timeframe for asset replacement using whole of life costing. These plans incorporate data from rolling condition audits to ensure effective management of the asset portfolio while aligning with strategic and legislative requirements. Total capital expenditure is managed to minimize disruptions to activities and revenue generation.",
        "8855f61c-bce9-4b2d-b925-7a1f4e3729f2": "The Council's property portfolio aims to address strategic objectives for city growth, generate additional net revenue, protect asset value and returns, and ensure intergenerational equity. It focuses on optimizing performance through partnerships for property acquisition or repurposing and reinvesting proceeds from under-performing asset sales into new income-generating opportunities.",
        "2ceffc8e-bd6e-46d8-beef-21d607c1f05e": "It is important for the Council to protect the value and returns of its property portfolio to ensure sustainable revenue generation, support strategic growth objectives, and maintain intergenerational equity. By safeguarding these assets, the Council can effectively manage future expenditure commitments and avoid negative impacts on rates and community services.",
        "de5f26fe-c2d1-4c6f-a817-bde7ecf2f236": "The Property Strategy promotes a partnership approach to acquire or repurpose property assets with the private sector and other government tiers, aiming to optimize portfolio performance, meet strategic objectives, and reinvest proceeds from selling under-performing assets into new income-generating opportunities.",
        "029c34ea-12e9-4b28-8bc3-efdcc6d914dc": "The Council plans to leverage partnerships with the private sector and other government tiers by promoting a collaborative approach to acquire or repurpose property assets. This strategy aims to optimize the performance of the property portfolio, enhance value, and meet strategic objectives, while also allowing for the sale of under-performing assets to reinvest proceeds into new income-generating opportunities.",
        "0750ed9d-7ad4-4694-93b8-70b0898f83e3": "The significance of reinvesting proceeds from the sale of under-performing assets lies in optimizing the asset portfolio's performance and generating new income opportunities. This strategy helps maintain the value of the portfolio, supports strategic growth objectives, and ensures sustainable financial management for future community services and programs.",
        "4bd5179b-ceaf-4839-87f6-2a23feda1b2c": "The Council aims to avoid disruptive adjustments to its activities and revenue-raising efforts by managing total capital expenditure in alignment with Asset Management Plans, which focus on optimal asset replacement timing and whole of life costing. Additionally, the Property Strategy seeks to enhance the performance of the property portfolio through partnerships and strategic asset management, ensuring sustained revenue and minimizing adverse impacts on future financial commitments.",
        "7486f11d-6857-443d-afe3-de80ed057892": "The historical trend of the Local Government Price Index (LGPI) has typically tracked approximately 1% above the Consumer Price Index (CPI).",
        "9e763505-e17e-453f-ad33-3c0f2ea6b5d9": "Wages and salary increases for staff under the current Enterprise Agreements are projected to be 3% and 4% starting in 2024.",
        "7da5ca9f-ee2a-41c1-a4b3-4a2134c49919": "The specific focus areas highlighted for the maintenance and renewal of assets in the city include a stronger emphasis on renewals and maintenance of assets, particularly in mainstreets, to address the service and infrastructure needs of a growing and changing population.",
        "aaeb96ab-ee1f-4c15-8d9b-7489637bfda9": "The changing population in the city will likely increase demand for services and infrastructure, necessitating adjustments in resource allocation and planning. This includes expanding public services, enhancing transportation systems, and improving utility provisions to accommodate a larger and more diverse community. Additionally, the focus on asset maintenance and renewal will become more critical to ensure that infrastructure meets the evolving needs of residents.",
        "44821d26-a909-47af-9fe9-ee38633bf877": "Council revenue from commercial operations and fees is expected to decline due to fewer people working in the city post-COVID-19, impacting overall income from these sources.",
        "dbf6f743-fec1-43c1-84a5-096b72420281": "Increasing interest rates will lead to higher borrowing costs for the Council, which may strain its budget and limit funding for essential services and infrastructure projects. This could necessitate adjustments in service delivery, prioritization of projects, or increased reliance on alternative revenue sources to manage the financial impact.",
        "7606b94b-7db7-45a0-bf20-b7254b46ac2b": "The four key areas of focus in the Council's ongoing program of works for technology investment are: \n\n1. Customers at the centre: Understanding and meeting diverse customer needs.\n2. Secure and reliable: Enhancing safety and security for customers and their information.\n3. Data Driven: Utilizing data and insights to improve engagement and decision-making.\n4. Integrated solutions: Delivering technology solutions that streamline processes and encourage collaboration.",
        "9e523af4-3a15-463d-8671-4ad89bc67917": "The Council plans to ensure the security and reliability of its technology solutions by training staff and utilizing technology to enhance safety and security for customers and their information. This approach is part of a broader strategy outlined in the Business Systems Roadmap, which focuses on delivering integrated, secure, and customer-centered services.",
        "1a6fd3a8-29ce-46ae-805f-eb8cd1decfdf": "The Council intends to enhance customer engagement by utilizing data and insights to better understand customer needs, improve service delivery, and make informed decisions. This data-driven approach aims to create more tailored experiences for the community, ensuring that services meet diverse requirements effectively.",
        "917e4732-569f-45ea-b322-713f0d44713d": "The overarching goal of the Business Systems Roadmap for the Council over the next four years is to become a digitally enabled, integrated, innovative, secure, and inclusive organization that prioritizes customer-focused services, enhances data-driven decision-making, and ensures the safety and reliability of information and systems.",
        "c6a76e2d-ccb4-4bdb-b404-673f0e9f339e": "The four key areas of focus outlined in the Business Systems Roadmap for the Council's program of works over the next four years are:\n\n1. Customers at the centre\n2. Secure and reliable\n3. Data Driven\n4. Seamless",
        "3626e524-6739-4df5-9565-9f0d5d9d31db": "The Council plans to ensure that customers are at the center of its services by focusing on understanding their diverse needs, providing secure and reliable services, utilizing data-driven insights for improved engagement, and creating seamless, intuitive service experiences. This approach is outlined in the Business Systems Roadmap, which emphasizes a commitment to customer-centricity in all aspects of service delivery.",
        "3bfb386f-0b98-4709-9145-53dce87a9ad1": "The Council is enhancing the security and reliability of its services by implementing a comprehensive training program for staff and utilizing advanced technology to safeguard customer information. This initiative is part of the Business Systems Roadmap, which focuses on creating a secure and reliable environment for customers while ensuring that services are customer-centric and data-driven.",
        "5576d5a1-40b9-4ea7-9c3d-32dae8b084c3": "The Council intends to utilize data and insights to enhance customer engagement and decision-making by focusing on a data-driven approach. This involves analyzing customer data to better understand their needs, improving engagement and experiences, and enabling faster and more informed decision-making.",
        "1051dbbb-4be1-4a85-92a7-a5a8590c76b6": "In the context of the Council's service delivery, the term \"seamless\" refers to services that are simple, intuitive, purposeful, and provide a smooth experience for customers and communities.",
        "866dcc84-f69e-4a7c-bbf8-a33f7b7bcd50": "The projected number of full-time equivalent (FTE) positions for \"Our Community\" in the 2023-24 fiscal year is 95.7.",
        "9fd39684-e134-4cbe-8738-0ef00006ecbe": "The total number of FTE positions across all areas for the 2024-25 fiscal year is 761.3.",
        "18068d50-3f6f-486c-87d2-25808423809c": "Appropriate resourcing capacity and capability are critical for delivering on the Strategic Plan responsibilities because they ensure the organization can effectively attract, develop, and retain the necessary skills and knowledge to meet diverse customer needs and respond to emerging challenges. This alignment fosters a performance culture that supports the Council's vision and enhances service delivery, ultimately enabling the achievement of strategic goals.",
        "41ce924f-99ff-43da-83a8-839cc7649b9f": "Workforce planning enhances the Corporation's ability to meet new and emerging challenges by ensuring it has the right skills and capabilities in place. It facilitates the attraction, development, and retention of talent necessary to execute the Strategic Plan effectively. By aligning individual performance with organizational priorities, workforce planning fosters a culture of responsiveness and innovation, enabling the Corporation to adapt to changing needs and deliver high-quality services to the community.",
        "29d38709-a037-4f38-9349-272f6655e981": "The Corporation's operations must reflect the Council's vision by prioritizing customer-centric services, ensuring security and reliability, leveraging data for informed decision-making, and providing seamless, intuitive experiences. Additionally, it should focus on workforce planning to attract and retain necessary skills, fostering a performance culture aligned with organizational priorities, and supporting good governance.",
        "6e2d0bb8-5c90-47a5-a648-88bf30ad8b3d": "The primary goal of workforce planning within the Corporation, as outlined in the Strategic Plan, is to attract, develop, and retain the necessary skills and knowledge to effectively deliver on organizational priorities while fostering a performance culture aligned with the Council\u2019s vision.",
        "008bc7a8-3c65-4d7c-a659-19c58033f236": "The Corporation aims to align its operations with the Council\u2019s vision by fostering a performance culture that prioritizes organizational goals, ensuring responsiveness to community needs, and maintaining a focus on efficiencies and continuous improvement. This alignment is supported by workforce planning that attracts and develops necessary skills, adherence to core values, and a commitment to being an exceptional service provider and trusted partner.",
        "5cb1325e-eb34-4e66-a7f4-e74f8a1663aa": "The strategies mentioned for maintaining Full-Time Equivalent (FTE) numbers over the four-year period include focusing on efficiencies and continuous improvement, utilizing consultancy services, and employing additional contract or temporary staff as needed to ensure scalable service delivery.",
        "95cbadfa-93e5-4877-ba33-e1400466a299": "The Corporation may consider using consultancy services or temporary staff in situations where there is a need for specialized expertise, to manage peak workloads, to implement new projects or initiatives, or to ensure service delivery remains scalable while maintaining current full-time employee levels.",
        "e3f1d487-e416-44dd-b5b8-86e445af816a": "The five core values that guide the City of Adelaide's workplace culture are: \n\n1. Achievement\n2. Collaboration\n3. Customer Commitment\n4. Integrity\n5. Innovation",
        "7316aeb9-4c6e-4c29-a190-eaf64c0dc347": "The Corporation defines its purpose in service delivery and partnership as being an exceptional service provider and a reliable, trusted partner. It emphasizes the importance of aligning its operations with the Council's vision, being responsive to the needs of people and communities, and fostering a high-performing, inclusive workplace based on core values such as collaboration, customer commitment, and innovation.",
        "fdb617c6-1d73-430f-b3c4-6cf4c3c44dcc": "The significance of continuous improvement in the Corporation's workforce planning lies in its ability to enhance efficiency, maintain current staffing levels, and ensure responsiveness to the evolving needs of the community. By fostering a culture of continuous improvement, the Corporation can effectively align its workforce with strategic priorities, support service delivery, and adapt to future challenges, ultimately contributing to the achievement of the Strategic Plan.",
        "f1a7d869-18a0-49e3-8c34-bccbc8d1fadd": "The Corporation plans to ensure responsiveness to the changing needs of communities by maintaining a focus on workforce planning, which includes attracting and developing the necessary skills and knowledge. It emphasizes a commitment to continuous improvement and efficiency, allowing for scalable service delivery through the use of consultancy services or temporary staff when needed. Additionally, the Corporation aligns its operations with the Council\u2019s vision and values, fostering a high-performing and inclusive workplace that prioritizes customer commitment and innovation.",
        "28deb05d-fc36-4c47-bdf3-c99b49c98397": "Employee Values and Behaviours play a crucial role in shaping the Corporation's culture by establishing the standards for collaboration, accountability, and performance. They guide how employees interact with each other and with customers, ensuring alignment with the Corporation's strategic goals. By fostering values such as achievement, collaboration, customer commitment, integrity, and innovation, the Corporation creates a high-performing, inclusive, and sustainable workplace that supports its mission and enhances service delivery.",
        "971c4f84-2309-4898-9e20-067dc9eadad5": "The Corporation aspires to be recognized as a high achieving, best practice organization that is an exceptional service provider, a reliable and trusted partner, and a professional administrator.",
        "15acb2c2-36be-442f-817e-1764f82a4ba2": "The address of the City of Adelaide is 25 Pirie Street, Adelaide SA 5000.",
        "480e7c79-66f3-4249-8b2d-61460ca956ab": "The phone number for the City of Adelaide is 08 8203 7203.",
        "d3c1ca8d-9e24-4d98-9193-9de1677ea7e6": "The website for the City of Adelaide is cityofadelaide.com.au.",
        "c8e87315-ebcb-43af-a901-bab20c9d70db": "The City of Adelaide is located in Adelaide.",
        "8202e774-373c-4184-aeef-9fc9e74bb191": "The postal code for the City of Adelaide is 5000.",
        "a57d066a-6715-4887-8e77-bf13e0949926": "The organization referenced in the document is the City of Adelaide, a local government authority.",
        "a4ac6103-1ade-4fe8-9ab6-1e312218125e": "You can contact the City of Adelaide by phone at 08 8203 7203.",
        "96f438e6-a4a3-4c86-bbc7-ad089169d5c9": "The City of Adelaide is located on Pirie Street.",
        "60316bed-dcfb-4c7a-a237-223ae3794317": "The number \"25\" signifies the street number of the location, specifically 25 Pirie Street, in the City of Adelaide.",
        "e6e42b52-4594-4086-b4f0-1f96b7d8423b": "The City of Adelaide's website provides information about local services, events, community programs, council meetings, and resources for residents and visitors."
    },
    "corpus": {
        "node_0": "Count What You Want: Exemplar Identification and\nFew-Shot Counting of Human Actions in the Wild\nYifeng Huang1*, Duc Duy Nguyen2*, Lam Nguyen2, Cuong Pham2,3, Minh Hoai1,2\n1Stony Brook University, NY , USA\n2VinAI, Hanoi, Vietnam\n3Posts & Telecommunications Institute of Technology, Hanoi, Vietnam\nAbstract\nThis paper addresses the task of counting human actions of\ninterest using sensor data from wearable devices. We propose\na novel exemplar-based framework, allowing users to provide\nexemplars of the actions they want to count by vocalizing pre-\ndefined sounds \u201cone\u201d, \u201ctwo\u201d, and \u201cthree\u201d. Our method first\nlocalizes temporal positions of these utterances from the au-\ndio sequence. These positions serve as the basis for identify-\ning exemplars representing the action class of interest. A sim-\nilarity map is then computed between the exemplars and the\nentire sensor data sequence, which is further fed into a den-\nsity estimation module to generate a sequence of estimated\ndensity values. Summing these density values provides the\nfinal count. To develop and evaluate our approach, we intro-\nduce a diverse and realistic dataset consisting of real-world\ndata from 37 subjects and 50 action categories, encompassing\nboth sensor and audio data. The experiments on this dataset\ndemonstrate the viability of the proposed method in counting\ninstances of actions from new classes and subjects that were\nnot part of the training data. On average, the discrepancy be-\ntween the predicted count and the ground truth value is 7.47,\nsignificantly lower than the errors of the frequency-based and\ntransformer-based methods. Our project, code and dataset can\nbe found at https://github.com/cvlab-stonybrook/ExRAC.\nIntroduction\nCounting human actions of interest using wearable de-\nvices is a crucial task with applications in health monitor-\ning (e.g., Baghdadi et al. (2021)) and performance evalua-\ntion (e.g., O\u2019Reilly et al. (2018)).",
        "node_1": "The experiments on this dataset\ndemonstrate the viability of the proposed method in counting\ninstances of actions from new classes and subjects that were\nnot part of the training data. On average, the discrepancy be-\ntween the predicted count and the ground truth value is 7.47,\nsignificantly lower than the errors of the frequency-based and\ntransformer-based methods. Our project, code and dataset can\nbe found at https://github.com/cvlab-stonybrook/ExRAC.\nIntroduction\nCounting human actions of interest using wearable de-\nvices is a crucial task with applications in health monitor-\ning (e.g., Baghdadi et al. (2021)) and performance evalua-\ntion (e.g., O\u2019Reilly et al. (2018)). However, the majority of\nexisting counters are often designed for a limited set of ac-\ntion categories, such as walking and a few other physical ex-\nercises. These class-specific counters (e.g., Genovese, Man-\nnini, and Sabatini (2017)) are incapable of handling classes\nbeyond those they have been explicitly trained for. Conse-\nquently, relying solely on class-specific counters becomes\nimpractical and unscalable when dealing with a diverse set\nof action categories. For scalability, a promising alternative\nto class-specific counters is class-agnostic counters, capable\nof tallying repetitions from any arbitrary class, as long as\nthis class represents the dominant activity within the sensor\ndata being analyzed.\n*These authors contributed equally to this work.\nCopyright \u00a9 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.However, in many real-world scenarios, our interest might\nnot lie in counting actions from the dominant class. For in-\nstance, in sports training and skill evaluation, the objective\nis often to detect specific and infrequent mistakes within the\nprevalent data. As illustrated in Fig. 1, the action of inter-\nest may occur only briefly within the entire data sequence.\nThese factors pose significant challenges when applying ex-\nisting methods effectively.",
        "node_2": "For scalability, a promising alternative\nto class-specific counters is class-agnostic counters, capable\nof tallying repetitions from any arbitrary class, as long as\nthis class represents the dominant activity within the sensor\ndata being analyzed.\n*These authors contributed equally to this work.\nCopyright \u00a9 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.However, in many real-world scenarios, our interest might\nnot lie in counting actions from the dominant class. For in-\nstance, in sports training and skill evaluation, the objective\nis often to detect specific and infrequent mistakes within the\nprevalent data. As illustrated in Fig. 1, the action of inter-\nest may occur only briefly within the entire data sequence.\nThese factors pose significant challenges when applying ex-\nisting methods effectively.\nConfronting the challenge presented by real-world data,\nwhich often contains undesired actions, we propose to de-\nvelop an exemplar-based counting method, where an user\ncan provide exemplars of what they want to count. How-\never, the development of such a method poses two significant\ntechnical challenges. Firstly, devising a convenient exem-\nplar provision scheme is nontrivial. Secondly, once we have\nsome exemplars, the question remains how to effectively\nleverage them. In this paper, we address both of these chal-\nlenges to develop a novel exemplar-based counting method.\nFor the first challenge, we propose an intuitive and non-\nintrusive approach for specifying exemplars using vocal\nsounds. The exemplars are conveniently provided by ver-\nbally counting out loud \u201cone,\u201d \u201ctwo,\u201d \u201cthree\u201d at the onset\nof the counting process as shown in Fig. 1. Each utterance\ncorresponds to one repetition. To accurately detect the po-\nsitions of these counting utterances in the audio sequence,\nwe develop an efficient algorithm that solves a constrained\noptimization problem with the two constraints on the tempo-\nral ordering and the temporal distance between the identified\npositions. Once the positions of the counting utterances are\nidentified, we extract the exemplars from these locations.",
        "node_3": "Secondly, once we have\nsome exemplars, the question remains how to effectively\nleverage them. In this paper, we address both of these chal-\nlenges to develop a novel exemplar-based counting method.\nFor the first challenge, we propose an intuitive and non-\nintrusive approach for specifying exemplars using vocal\nsounds. The exemplars are conveniently provided by ver-\nbally counting out loud \u201cone,\u201d \u201ctwo,\u201d \u201cthree\u201d at the onset\nof the counting process as shown in Fig. 1. Each utterance\ncorresponds to one repetition. To accurately detect the po-\nsitions of these counting utterances in the audio sequence,\nwe develop an efficient algorithm that solves a constrained\noptimization problem with the two constraints on the tempo-\nral ordering and the temporal distance between the identified\npositions. Once the positions of the counting utterances are\nidentified, we extract the exemplars from these locations.\nFor the second challenge, we propose a novel model that\njointly processes the exemplars with the whole data se-\nquence as shown in Fig. 1. More concretely, we first gen-\nerate per-window embeddings for both the exemplars and\nthe whole data sequence. Subsequently, we compute a simi-\nlarity map between the exemplar and data sequence embed-\ndings, using Soft-DTW (Cuturi and Blondel 2017) and cor-\nrelation measures. This similarity map serves as the basis for\ngenerating a sequence of exemplar-infused embeddings for\nthe data sequence. The initial embedding sequence and the\nexemplar-infused embedding sequence are then fed into a\ndensity estimation module for moment-by-moment density\nestimation, from which the final count is obtained by sum-\nming the density values.\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10057",
        "node_4": "Temporal Density Map(1)Exemplar \nExtraction\n(2)Sliding Window \nFeature Embedding\nMulti -scale\nExemplars\n(3)Exemplar -Based \nSimilarity Estimation(4)Exemplar -\nInfused Feature \nEmbedding\n(5)Density  \nEstimation\n\u201cOne\u201d,\u201cTwo\u201d,\u201cThree\u201d\nOutputInput\n7 RepetitionsFigure 1: Processing pipeline of our method. The input consists of the sensor signal and the audio signal containing the ut-\nterances \u201cone,\u201d \u201ctwo,\u201d and \u201cthree,\u201d corresponding to three repetitions of the action of interest. The output is the total count,\nobtained by summing the values of the intermediate 1D density profile. This profile is better visualized as a 2D map as shown\nhere. This figure also shows the other processing steps, which will be explained in the forthcoming method section.\nRealizing the importance of a good similarity measure-\nment, we introduce a novel distance-preserving loss. This\nloss enforces the high-dimensional per-window embeddings\nto maintain local patterns, thereby preserving the similarity\nrelationships observable in the lower-dimensional space. In\naddition, considering the limited training data, we propose\nan exemplar-based data synthesis pipeline, which can syn-\nthesize training data and improve the result significantly.\nTo develop and evaluate the proposed method, we have\ncollected a dataset named Diverse Wearable Counting\ndataset (DWC). This dataset comprises sensor data se-\nquences accompanied by audio-specified exemplars col-\nlected from 37 subjects performing 50 distinct action cate-\ngories. What sets this dataset apart from many existing ones\nis the availability of synchronized audio data with vocal\nsounds for specifying exemplars. Furthermore, this dataset\nincludes instances where the action of interest may not be\nthe predominant action within the data sequence, providing\na more realistic representation of real-world scenarios.\nIn short, the main contributions of our paper are threefold.\nFirst, we introduce a novel strategy for using audio to specify\nexemplars of what needs to be counted.",
        "node_5": "In\naddition, considering the limited training data, we propose\nan exemplar-based data synthesis pipeline, which can syn-\nthesize training data and improve the result significantly.\nTo develop and evaluate the proposed method, we have\ncollected a dataset named Diverse Wearable Counting\ndataset (DWC). This dataset comprises sensor data se-\nquences accompanied by audio-specified exemplars col-\nlected from 37 subjects performing 50 distinct action cate-\ngories. What sets this dataset apart from many existing ones\nis the availability of synchronized audio data with vocal\nsounds for specifying exemplars. Furthermore, this dataset\nincludes instances where the action of interest may not be\nthe predominant action within the data sequence, providing\na more realistic representation of real-world scenarios.\nIn short, the main contributions of our paper are threefold.\nFirst, we introduce a novel strategy for using audio to specify\nexemplars of what needs to be counted. Second, we propose\na novel counting method that utilizes exemplars, incorporat-\ning a distance-preserving loss and an exemplar-based data\nsynthesis pipeline. Third, we introduce an unique dataset\nwith multiple data modalities to develop a practical count-\ning method for real-world scenarios.\nRelated Work\nAction counting through wearable devices is driven by its\ndiverse range of applications in health monitoring (Bagh-\ndadi et al. 2021; Lee et al. 2015; Nam, Kim, and Lee 2016;\nHatamie et al. 2020; Ramachandran and Liao 2022; Pa-\ntel et al. 2010), sports training (Chang, Chen, and Canny\n2007; O\u2019Reilly et al. 2018; Kranz et al. 2013; Ding et al.\n2015), and industrial contexts (Kong et al. 2019; Stiefmeier\net al. 2008). Existing counting methodologies have predomi-\nnantly focused on particular action categories, such as physi-\ncal exercises (Genovese, Mannini, and Sabatini 2017; Kupke\net al.",
        "node_6": "Related Work\nAction counting through wearable devices is driven by its\ndiverse range of applications in health monitoring (Bagh-\ndadi et al. 2021; Lee et al. 2015; Nam, Kim, and Lee 2016;\nHatamie et al. 2020; Ramachandran and Liao 2022; Pa-\ntel et al. 2010), sports training (Chang, Chen, and Canny\n2007; O\u2019Reilly et al. 2018; Kranz et al. 2013; Ding et al.\n2015), and industrial contexts (Kong et al. 2019; Stiefmeier\net al. 2008). Existing counting methodologies have predomi-\nnantly focused on particular action categories, such as physi-\ncal exercises (Genovese, Mannini, and Sabatini 2017; Kupke\net al. 2016; Pillai et al. 2020; Bian et al. 2019; Ishii et al.\n2021; Morris et al. 2014; Soro et al. 2019a; Oh, Olsen, and\nRamamurthy 2020). This specialization restricts their adapt-\nability, especially when faced with classes having no priortraining data. Consequently, relying on class-specific coun-\nters proves inadequate and unscalable in managing the wide\nrange of action categories encountered in real world.\nClass-agnostic counters is an alternative to class-specific\ncounters, but they can only count repetitions from the dom-\ninant class. Earlier strategies, based on Fourier analysis or\nwavelet transforms (Cutler and Davis 2000; Azy and Ahuja\n2008; Pogalin, Smeulders, and Thean 2008; Runia, Snoek,\nand Smeulders 2018), peak detection (Thangali and Sclaroff\n2005), and singular value decomposition (Chetverikov and\nFazekas 2006), have been explored.",
        "node_7": "2019a; Oh, Olsen, and\nRamamurthy 2020). This specialization restricts their adapt-\nability, especially when faced with classes having no priortraining data. Consequently, relying on class-specific coun-\nters proves inadequate and unscalable in managing the wide\nrange of action categories encountered in real world.\nClass-agnostic counters is an alternative to class-specific\ncounters, but they can only count repetitions from the dom-\ninant class. Earlier strategies, based on Fourier analysis or\nwavelet transforms (Cutler and Davis 2000; Azy and Ahuja\n2008; Pogalin, Smeulders, and Thean 2008; Runia, Snoek,\nand Smeulders 2018), peak detection (Thangali and Sclaroff\n2005), and singular value decomposition (Chetverikov and\nFazekas 2006), have been explored. More recently, signif-\nicant attention has been directed towards repetitive action\ncounting in videos (Levy and Wolf 2015; Zhang et al. 2020;\nZhang, Shao, and Snoek 2021; Fieraru et al. 2021; Hsu\net al. 2021; Hu et al. 2022; Dwibedi et al. 2020). Recent\nworks (Dwibedi et al. 2020; Hu et al. 2022) have achieved\npromising results by harnessing temporal self-similarity to\ncount repetitive actions from the dominant class.\nWhile exemplar-based counting is not a novel concept,\nour contribution stands as one of the few approaches de-\nsigned for wearable devices. Notably, it marks the pioneer-\ning effort in introducing a strategy for specifying exemplars\nthrough the act of uttering and subsequently detecting pre-\ndefined vocal sounds. This approach is innovative and dis-\ntinct from existing works in various fields. For instance, in\ncomputer vision, there are methods that utilize exemplars\nfor counting objects in images (Liu et al. 2022; Yang et al.\n2021; Ranjan et al.",
        "node_8": "2021; Hu et al. 2022; Dwibedi et al. 2020). Recent\nworks (Dwibedi et al. 2020; Hu et al. 2022) have achieved\npromising results by harnessing temporal self-similarity to\ncount repetitive actions from the dominant class.\nWhile exemplar-based counting is not a novel concept,\nour contribution stands as one of the few approaches de-\nsigned for wearable devices. Notably, it marks the pioneer-\ning effort in introducing a strategy for specifying exemplars\nthrough the act of uttering and subsequently detecting pre-\ndefined vocal sounds. This approach is innovative and dis-\ntinct from existing works in various fields. For instance, in\ncomputer vision, there are methods that utilize exemplars\nfor counting objects in images (Liu et al. 2022; Yang et al.\n2021; Ranjan et al. 2021; Ranjan and Hoai 2022b; Shi et al.\n2022; Lu, Xie, and Zisserman 2018; You et al. 2023; Nguyen\net al. 2022; Huang, Ranjan, and Hoai 2023; Ranjan and Hoai\n2022a). These methods require users to specify exemplars\nby drawing bounding boxes. However, when dealing with\ntime-series data, the natural provision of exemplars becomes\nnon-trivial. First, the visualization and semantic parsing of\nsensor data pose greater challenges compared to images.\nSecond, manually determining the temporal extents of hu-\nman actions in time series is more difficult compared to de-\nlineating object bounding boxes in images. Third, for sensor-\nbased counting, immediate results are often required, mak-\ning it crucial for the process of providing and identifying\nexemplars to be convenient and efficient, without involving\ntime-consuming procedures such as transmitting, visualiz-\ning, and drawing.\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10058",
        "node_9": "Sensor data sequence\nMulti -scale\nExemplars\n(1) Exemplar ExtractionPer-window \nEncoder Window \nsplittingWindow \nsplitting\nExemplar \nEmbedding\nSensor \nEmbedding\nTo-Exemplar \nSimilarity Map(3) Exemplar -Based Similarity Estimation\nSoft-DTW\nFlip & \nAs kernelN&R\nN&RPadding\n(2) Sliding Window \nFeature Embedding\nConv CGAP\n Conv\n Conv\nFused featureFPNDensity\nhead\n(4) Exemplar -Infused Feature EmbeddingTemporal\n Density Map\n(5) Density Estimation Stack K Blocks\nN&R Norm & ReLU CGAPChannel -wise \nGlobal Avg Pool\nConvolution\nElement -wise\nMultiplication\nElement -wise\nAdditionN&G Norm & GELUConv\nTemporal\nPositionInverse \nMax -Norm\nN&GAudio with utterances\nFigure 2: Main steps of our method. Our method begins with exemplar extraction, which is based on predefined utterance\ndetection in the audio data. Following this, per-window embeddings are extracted. Subsequently, we compute the similarity\nbetween the entire sensor sequence and the exemplars, which is then used for feature fusion. Finally, the temporal density map\nis estimated based on the fused features and the sensor embeddings.\nProposed Approach\nOur objective involves tallying the occurrences of a specific\naction class within a sequence of sensor data. Our method\ntakes as input both the sensor data sequence and an audio se-\nquence synchronized with it, featuring predetermined vocal\nsounds \u2013 one, two, three \u2013 corresponding to the initial three\nrepetitions of the action. As such, our approach comprises\ntwo fundamental stages: first, the identification of exem-\nplars, and subsequently, their utilization to derive the over-\nall count. These stages are executed using five modules, as\ndepicted in Fig. 2: (1) exemplar extraction, (2) sliding win-\ndow feature embedding, (3) exemplar-based similarity es-\ntimation, (4) exemplar-infused feature embedding, and (5)\ndensity estimation.",
        "node_10": "Finally, the temporal density map\nis estimated based on the fused features and the sensor embeddings.\nProposed Approach\nOur objective involves tallying the occurrences of a specific\naction class within a sequence of sensor data. Our method\ntakes as input both the sensor data sequence and an audio se-\nquence synchronized with it, featuring predetermined vocal\nsounds \u2013 one, two, three \u2013 corresponding to the initial three\nrepetitions of the action. As such, our approach comprises\ntwo fundamental stages: first, the identification of exem-\nplars, and subsequently, their utilization to derive the over-\nall count. These stages are executed using five modules, as\ndepicted in Fig. 2: (1) exemplar extraction, (2) sliding win-\ndow feature embedding, (3) exemplar-based similarity es-\ntimation, (4) exemplar-infused feature embedding, and (5)\ndensity estimation. In this section, we will elucidate these\nfive modules along with the training procedure.\nExemplar Extraction\nTo extract the exemplars for the action class of interest, we\nfirst identify three temporal positions corresponding to the\npredefined vocal sounds (one, two, three) in the audio. A\nnaive approach is to use a pre-trained classifier to greed-\nily select the window with the highest classification score.\nHowever, this fails to exploit two critical cues: (1) temporal\nordering, which requires the order of the sounds one, two,\nthrees to be preserved, and (2) temporal proximity, which\nensures that the distance between two predefined sounds is\nnot excessively large. Considering these two properties, we\nformulate the temporal position detection into a constrained\noptimization problem as follows:\ni\u2217, j\u2217, k\u2217=argmax\ni,j,kC1\niC2\njC3\nk, (1)\ns.t.1\u2264i < j < k \u2264Mandk\u2212i\u2264R. (2)\nHere, i, j, k denote the indices of a sliding window. Cu\ni\nis the classification score for the ithwindow to be the uth\nutterance.",
        "node_11": "However, this fails to exploit two critical cues: (1) temporal\nordering, which requires the order of the sounds one, two,\nthrees to be preserved, and (2) temporal proximity, which\nensures that the distance between two predefined sounds is\nnot excessively large. Considering these two properties, we\nformulate the temporal position detection into a constrained\noptimization problem as follows:\ni\u2217, j\u2217, k\u2217=argmax\ni,j,kC1\niC2\njC3\nk, (1)\ns.t.1\u2264i < j < k \u2264Mandk\u2212i\u2264R. (2)\nHere, i, j, k denote the indices of a sliding window. Cu\ni\nis the classification score for the ithwindow to be the uth\nutterance. Ris the upper bound for the temporal distance.The above optimization problem can be solved efficiently\nusing dynamic programming. We first divide the audio sig-\nnal into Moverlapping sliding windows, each with a du-\nration of one second and the step size being 0.1 seconds.\nWe then compute the classification scores (C1\ni, C2\ni, C3\ni)for\neach window using a pre-trained classifier, specifically the\nBCResNet (Kim et al. 2021) pretrained on Speech Com-\nmand (Warden 2018). For every group of Rconsecutive win-\ndows, we optimize C1\niC2\njC3\nksubject to the only constraint\ni < j < k with dynamic programming. The complexity of\nthis algorithm is O(R), and we have to run it M\u2212R+ 1\ntimes for M\u2212R+ 1 groups of Rconsecutive windows.\nThus, the overall complexity is O(R(M\u2212R+ 1)).\nLetX \u2208RN\u00d7ddenote the sensor data sequence, with N\nbeing the length and dthe number of sensor values at each\ntime step (d = 6 for data from the accelerometer and gyro-\nscope of a smartwatch).",
        "node_12": "2021) pretrained on Speech Com-\nmand (Warden 2018). For every group of Rconsecutive win-\ndows, we optimize C1\niC2\njC3\nksubject to the only constraint\ni < j < k with dynamic programming. The complexity of\nthis algorithm is O(R), and we have to run it M\u2212R+ 1\ntimes for M\u2212R+ 1 groups of Rconsecutive windows.\nThus, the overall complexity is O(R(M\u2212R+ 1)).\nLetX \u2208RN\u00d7ddenote the sensor data sequence, with N\nbeing the length and dthe number of sensor values at each\ntime step (d = 6 for data from the accelerometer and gyro-\nscope of a smartwatch). Upon solving the above optimiza-\ntion problem, we obtain i\u2217, j\u2217, k\u2217, which indicate the loca-\ntions of the three exemplars. To avoid noisy exemplars, we\nonly retain the two locations with the highest classification\nconfidence and let them be denoted as s1ands2. Unfortu-\nnately, we do not know the temporal extents of the exem-\nplars. To address this issue, we adopt a multi-scale approach\nas follows. For each position samong the two positions s1\nands2, we extract three exemplar sequences corresponding\nto three different scales: X[s\u221210 :s+10],X[s\u221220 :s+20] ,\nandX[s\u221240 :s+ 40]. With two locations and three scales,\nwe have a total of six exemplars. This strategy enables us to\ncount actions at various levels of granularity.\nSliding Window Feature Embedding\nAs sensor values at individual time steps carry limited in-\nformation, we learn and use window-level sensor represen-\ntation instead. To accomplish this, we partition a sensor data\nsequence into non-overlapping windows, with each window\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10059",
        "node_13": "comprising wsensor data points. We subsequently embed\neach window into a high-dimensional representation turning\nthe sequence of original sensor values X \u2208RN\nw\u00d7dinto a\nsequence of embedding vectors X\u2032\u2208RN\nw\u00d7d\u2032. Let\u03d5denote\nthis mapping, i.e., X\u2032=\u03d5(X), and \u03d5is implemented us-\ning temporal convolution. Specifically in our experiments,\nwis set to 10, and d\u2032is set to 64. Similarly, the exemplar\nsequence Eis transformed into E\u2032using \u03d5.\nExemplar-Based Similarity Estimation\nUtilizing per-window embedding, we estimate the similar-\nity map Sbetween the sensor embedding X\u2032and the exem-\nplar embedding E\u2032. Correlation and Dynamic Time Warping\n(DTW) are two widely-used methods for estimating simi-\nlarity between sequential data. However, directly applying\nthem to estimate the similarity between X\u2032andE\u2032is not ef-\nfective because correlation is sensitive to differences in scale\nand offset while DTW tends to overreact to static data. To\naddress these issues, we combine DTW and correlation to\nestimate the similarity as follows.\nWe first compute the correlation between the whole se-\nquence embedding and the exemplar embedding: Sc=\nReLU (Norm(X\u2032\u2297 E\u2032))where \u2297is correlation operation\nwith zero-padding to preserve the length of the signal (i.e.,\nScandX\u2032have the same length). Next, we calculate the\nSoft-DTW similarity (Cuturi and Blondel 2017) between the\nexemplar embedding and the sliding window on the whole\nsequence embedding. For the sliding window at location\ni, the resulting value is Sd\ni=Soft-DTW(X\u2032[i\u2212k\n2, i+\nk\n2],E\u2032), where kis the length of the exemplar E\u2032. Then,\nSdis fed into normalization and ReLU layers as Sd=\nReLU (Norm(Max(Sd)\u2212Sd)).",
        "node_14": "To\naddress these issues, we combine DTW and correlation to\nestimate the similarity as follows.\nWe first compute the correlation between the whole se-\nquence embedding and the exemplar embedding: Sc=\nReLU (Norm(X\u2032\u2297 E\u2032))where \u2297is correlation operation\nwith zero-padding to preserve the length of the signal (i.e.,\nScandX\u2032have the same length). Next, we calculate the\nSoft-DTW similarity (Cuturi and Blondel 2017) between the\nexemplar embedding and the sliding window on the whole\nsequence embedding. For the sliding window at location\ni, the resulting value is Sd\ni=Soft-DTW(X\u2032[i\u2212k\n2, i+\nk\n2],E\u2032), where kis the length of the exemplar E\u2032. Then,\nSdis fed into normalization and ReLU layers as Sd=\nReLU (Norm(Max(Sd)\u2212Sd)). Considering that Soft-DTW\nestimates the distance between two samples, we transform it\ninto a measure of similarity by taking the negative of the\ndistance and adding the maximum value, thereby ensuring a\nnon-negative similarity measure. The final similarity profile\nis obtained by computing S=Sc\u2299 Sd, where \u2299denotes\nelement-wise multiplication. Since we have two exemplars\nat three scales, the dimension of SisS \u2208RN\nw\u00d76.\nExemplar-Infused Feature Embedding\nUpon obtaining the similarity map S, we use it to generate a\nrefined representation that emphasizes exemplar-related fea-\ntures while suppressing irrelevant features. This can be im-\nplemented with a stack of Kfusion blocks, and the process\ncan be described as follows:\nF0=X\u2032,S0=S, (3)\nSi=CGAP(Conv(S i\u22121)), (4)\nFi=Conv(F i\u22121+GELU(Norm(Conv(F i\u22121\u2299 Si\u22121)))).\nHere, CGAP is the channel-wise (among exemplars) global\naverage pooling, and \u2299denotes element-wise multiplica-\ntion.",
        "node_15": "Since we have two exemplars\nat three scales, the dimension of SisS \u2208RN\nw\u00d76.\nExemplar-Infused Feature Embedding\nUpon obtaining the similarity map S, we use it to generate a\nrefined representation that emphasizes exemplar-related fea-\ntures while suppressing irrelevant features. This can be im-\nplemented with a stack of Kfusion blocks, and the process\ncan be described as follows:\nF0=X\u2032,S0=S, (3)\nSi=CGAP(Conv(S i\u22121)), (4)\nFi=Conv(F i\u22121+GELU(Norm(Conv(F i\u22121\u2299 Si\u22121)))).\nHere, CGAP is the channel-wise (among exemplars) global\naverage pooling, and \u2299denotes element-wise multiplica-\ntion. The final fused feature is F=FK\u2208RN\nw\u00d7d\u2032.\nDensity Estimation\nThe density estimation head comprises a Feature Pyramid\nNetwork (FPN) designed to extract multi-scale features anda temporal convolution counting head \u03c8to estimate the tem-\nporal densities. We extract multi-scale features as follows:\nFs1,Fs2,Fs3=FPN(F ), (5)\nX\u2032\ns1,X\u2032\ns2,X\u2032\ns3=FPN(Conv(X\u2032)), (6)\nwhere Fs1,Fs2,Fs3are multi-scale fused features from\nlow to high, and X\u2032\ns1,X\u2032\ns2,X\u2032\ns3are multi-scale sensor\nfeature for the sensor embedding. Using max-pooling,\nFs1,Fs2,X\u2032\ns1,X\u2032\ns2are down-sampled to have the same\nlength as Fs3andX\u2032\ns3. All of them are then concatenated\nand fed into a density estimation head \u03c8, implemented with\na temporal convolution network.\nTraining Loss\nThe counting loss over the predicted temporal density map\nis given by the squared error of the final count, expressed as:\nLc= (sum(T )\u2212\u02c6c)2, where \u02c6cis the ground truth count.",
        "node_16": "Using max-pooling,\nFs1,Fs2,X\u2032\ns1,X\u2032\ns2are down-sampled to have the same\nlength as Fs3andX\u2032\ns3. All of them are then concatenated\nand fed into a density estimation head \u03c8, implemented with\na temporal convolution network.\nTraining Loss\nThe counting loss over the predicted temporal density map\nis given by the squared error of the final count, expressed as:\nLc= (sum(T )\u2212\u02c6c)2, where \u02c6cis the ground truth count.\nThe success of our method largely depends on accurately\nestimating similarity between the exemplars and the query\ndata sequence. However, it\u2019s important to note that the sim-\nilarity relationship within the raw data space Xmay not\nbe fully preserved in the embedding space X\u2032. This is es-\npecially true when dealing with limited training data and\nthe lack of a robust pre-trained feature extractor. Inspired\nby Laplacian Eigenmaps (Belkin and Niyogi 2003), we pro-\npose to use a distance-preserving loss to encourage the per-\nwindow encoder to preserve the relationship of distance by\nenforcing the encoder to maintain the local patterns. We first\nbuild a k-nearest-neighbor graph over the raw window to\nrepresent the local pattern. To build it, we compute the ad-\njacency matrix W, where Wij= exp(\u2212||Xi\u2212Xj||2\n2\u03c32)repre-\nsents the similarity between the ithwindow and jthwin-\ndow. Then, for each node in the graph, we retain the top\nknearest neighbors in the adjacency matrix (k = 150 in\nour work). We compute the graph Laplacian: L=D \u2212 W ,\nwhere Dis the degree matrix with Dii=P\njWijand\nDij= 0 fori\u0338=j. Then the distance-preserving loss is\ndefined as Lpl=X\u2032TLX\u2032. The overall training loss is:\nLtrain =Lc+\u03bbLpl, where \u03bbis set to 0.01.",
        "node_17": "We first\nbuild a k-nearest-neighbor graph over the raw window to\nrepresent the local pattern. To build it, we compute the ad-\njacency matrix W, where Wij= exp(\u2212||Xi\u2212Xj||2\n2\u03c32)repre-\nsents the similarity between the ithwindow and jthwin-\ndow. Then, for each node in the graph, we retain the top\nknearest neighbors in the adjacency matrix (k = 150 in\nour work). We compute the graph Laplacian: L=D \u2212 W ,\nwhere Dis the degree matrix with Dii=P\njWijand\nDij= 0 fori\u0338=j. Then the distance-preserving loss is\ndefined as Lpl=X\u2032TLX\u2032. The overall training loss is:\nLtrain =Lc+\u03bbLpl, where \u03bbis set to 0.01.\nPretraining with Synthesis Data\nGiven the difficulty of collecting data from wearable de-\nvices, the amount of training data will always be limited,\nand it is possible that the model may overfit to the training\nset and subsequently underperform when faced with out-of-\ndistribution samples. To address the issue of dataset scarcity,\nwe propose a data synthesis method. This approach lever-\nages the predefined vocal sounds we previously discussed in\nthe exemplar extraction section, effectively augmenting our\nexisting dataset to bolster the model\u2019s robustness and ability\nto generalize. Our data synthesis approach consists of two\nmain steps. Firstly, we mine action templates from an ex-\nisting training set. Secondly, we randomly select a template\nand construct a sequence by aggregating multiple, randomly\naugmented versions of this template, interspersed with noise\nor repetitive irrelevant actions.\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10060",
        "node_18": "Categories\nDaily routines\n25%\nPhysical exercise23%\nRehab trainning\n14%\nFactory activities\n12%\nKitchen activities11%\nChores\n9%\nInstrumental\n5%\n1-10 10-25 25-50 50-75 75-100 >100\nRepetition count0100200300400500Number of Samples\n0 50 100 150 200 250 300\nSample duration (in seconds)0510152025Number of SamplesFigure 3: DWC dataset\u2019s statistics: The left figure displays the categories and the proportion of samples for each category in\nDWC. The two rightmost figures show the number of samples in various ranges of repetition count and duration.\nAction template mining. In the exemplar extraction, we\nobtain the temporal positions i\u2217, j\u2217, k\u2217of the predefined ut-\nterances in the feature embedding sequence. We then remap\nthese indexes to the time indexes \u02c6i,\u02c6j,\u02c6kof the original sen-\nsor data sequence. Different from that, we retain the position\nwith the minimum classification score during data synthesis.\nWe consider X[\u02c6i:\u02c6j]andX[\u02c6j:\u02c6k]as two template candidates.\nWe retain a candidate if it satisfies the following criteria: (1)\nStrong Confidence: the classification score of the temporal\nposition greater than 0.75. This threshold ensures that we\nonly select templates with a high degree of certainty, thus\navoiding ambiguous cases. (2) Moderate Length: we discard\ntemplate candidates that fall outside the established length\nbounds, thus avoiding excessively short or long templates\nthat may not represent typical actions. By iterating through\nall the samples in the original training data, we construct an\naction template database, which serves as a foundation for\nsynthesizing additional training data.\nAction sequence generation with template. To synthe-\nsize a training sample, we first randomly sample one action\ntemplate.",
        "node_19": "Different from that, we retain the position\nwith the minimum classification score during data synthesis.\nWe consider X[\u02c6i:\u02c6j]andX[\u02c6j:\u02c6k]as two template candidates.\nWe retain a candidate if it satisfies the following criteria: (1)\nStrong Confidence: the classification score of the temporal\nposition greater than 0.75. This threshold ensures that we\nonly select templates with a high degree of certainty, thus\navoiding ambiguous cases. (2) Moderate Length: we discard\ntemplate candidates that fall outside the established length\nbounds, thus avoiding excessively short or long templates\nthat may not represent typical actions. By iterating through\nall the samples in the original training data, we construct an\naction template database, which serves as a foundation for\nsynthesizing additional training data.\nAction sequence generation with template. To synthe-\nsize a training sample, we first randomly sample one action\ntemplate. Then we sample the count uniformly in the range\n[0.8C l,1.2C u], where ClandCurepresent the minimum\nand maximum counts within the training set, respectively.\nAfterward, we aggregate ctemplates, augmenting each one\nthrough the following procedures: (1) duration scaling: we\nstretch or compress the duration of the template with scal-\ning factor between 0.75 and 1.33; (2) time shifting: we shift\nthe temporal position of the stretched/compressed template\nby random value within between -10 and 10 time steps; (3)\nAmplitude scaling: we modify the amplitude of the template\nby a scaling factor randomly chosen between 0.75 and 1.33;\nand (4) random noise addition: we introduce Gaussian noise\nwith a standard deviation randomly chosen from 0 to 0.2.\nThrough these procedures, we ensure that each synthe-\nsized training sample embodies a diversity of temporal char-\nacteristics and amplitude variations, thus enriching the syn-\nthesized training sample. Upon aggregating ctemplates,\nwe incorporate one to two irrelevant action sequences (de-\nscribed earlier) or static noise into the training sample.",
        "node_20": "Through these procedures, we ensure that each synthe-\nsized training sample embodies a diversity of temporal char-\nacteristics and amplitude variations, thus enriching the syn-\nthesized training sample. Upon aggregating ctemplates,\nwe incorporate one to two irrelevant action sequences (de-\nscribed earlier) or static noise into the training sample. This\nintegration is performed to mimic real-world data condi-\ntions, ensuring that our synthesized training data encapsu-\nlates a range of possible scenarios.The DWC Dataset\nExisting datasets for action counting from wearable de-\nvices (Mortazavi et al. 2014; Nishino, Maekawa, and Hara\n2022; Zelman et al. 2020; Soro et al. 2019b; Prabhu,\nO\u2019Connor, and Moran 2020; Str \u00a8omb\u00a8ack, Huang, and Radu\n2020) often lack diversity in terms of both count values and\naction categories. Additionally, each data sample from these\ndatasets also lacks diversity in terms of the actions con-\ntained within the sample, with the actions of interest being\nthe predominant class. Considering these limitations, we in-\ntroduce a more diverse dataset named DWC, which stands\nfor Diverse and Wearable Counting. This dataset com-\nprises 1502 entries of wearable-device data from 37 subjects\nacross seven broad categories: kitchen activities, household\nchores, physical exercises, factory activities, daily routines,\ninstrument-involved activities, and rehabilitation training.\nThese broad categories encompass 50 distinct action classes,\noffering higher diversity compared to existing datasets.\nWe used a Samsung Galaxy Watch 4 for data collection.\nThe sampling frequency was 100 Hz for both the 3-axis ac-\ncelerometer and the 3-axis gyroscope, while the audio fre-\nquency was 16KHz. A total of 37 subjects were asked to\nwear the watch on their preferred hand while performing\nactivities. Subjects were provided with a list of activities\nto perform in their chosen order. Each activity was accom-\npanied by an illustrative guide and a brief textual descrip-\ntion.",
        "node_21": "This dataset com-\nprises 1502 entries of wearable-device data from 37 subjects\nacross seven broad categories: kitchen activities, household\nchores, physical exercises, factory activities, daily routines,\ninstrument-involved activities, and rehabilitation training.\nThese broad categories encompass 50 distinct action classes,\noffering higher diversity compared to existing datasets.\nWe used a Samsung Galaxy Watch 4 for data collection.\nThe sampling frequency was 100 Hz for both the 3-axis ac-\ncelerometer and the 3-axis gyroscope, while the audio fre-\nquency was 16KHz. A total of 37 subjects were asked to\nwear the watch on their preferred hand while performing\nactivities. Subjects were provided with a list of activities\nto perform in their chosen order. Each activity was accom-\npanied by an illustrative guide and a brief textual descrip-\ntion. The subjects were instructed to sequentially utter the\nwords \u201cone,\u201d \u201ctwo,\u201d \u201cthree\u201d while executing the first three\nrepetitions of the action, with each utterance corresponding\nto one repetition. During data collection, participants could\nperform other types of action or take intermittent breaks. We\nmanually inspected the collected data and annotated each\nsample with the number of repetitions of the action of in-\nterest. We also discarded samples in which the sensor and\naudio signals were not synchronized within 30ms. We de-\nveloped an Android application to initiate the recording of\nboth processes simultaneously, but since the audio stream\nwas controlled by a third-party program, there were still in-\nstances of temporal mismatch.\nThe data was collected in two phases. In the first phase, 31\nsubjects participated, and each subject was asked to perform\neach of the 50 actions once. However, some subjects were\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10061",
        "node_22": "MethodVal Set Test Set\nMAE RMSE MAE RMSE\nMean 17.18 21.91 14.80 17.49\nFrequency-based 28.10 45.31 28.65 45.39\nRepNet 11.95 17.33 10.82 14.75\nTransRAC 14.51 20.40 12.97 16.82\nProposed 7.66 12.25 7.47 13.09\nTable 1: Experiment results on DWC. The proposed method\nachieves the lowest counting errors. Note that the Test Set is\ncompletely disjoint from the Training Set.\nnot able to perform certain actions, such as push-ups, sit-ups,\nor jumping rope. The data collected in this phase containing\n1356 entries with the action of interest occupying from 50%\nto 90% of the temporal duration. Upon completing the first\nphase, we recognized that the collected data did not possess\nsufficient diversity to address various practical scenarios that\nrequire counting non-dominant actions. Consequently, we\nproceeded with a second phase involving six additional sub-\njects. We reviewed the list of 50 actions from the first phase\nand identified action classes that may not represent the pre-\ndominant actions in realistic situations. Specifically, we se-\nlected six actions: picking up, shaking the clothes, slicing,\ntennis racket swinging, drinking and eating, and stretching.\nEach subject in the second phase was requested to perform\neach activity five times, although in some cases it was not\nfeasible due to the lack of appropriate equipment. The data\ncollected during this phase consists of 146 entries. These en-\ntries encompass more challenging samples where the action\nof interest constitutes a significantly smaller proportion of\nthe temporal duration, ranging from only 10% to 20%. The\nfinal DWC dataset consists of 1502 entries, totaling 49,258\nrepetitions, and the statistics are shown in Fig. 3.\nExperiments\nTrain, validation, and test data.",
        "node_23": "We reviewed the list of 50 actions from the first phase\nand identified action classes that may not represent the pre-\ndominant actions in realistic situations. Specifically, we se-\nlected six actions: picking up, shaking the clothes, slicing,\ntennis racket swinging, drinking and eating, and stretching.\nEach subject in the second phase was requested to perform\neach activity five times, although in some cases it was not\nfeasible due to the lack of appropriate equipment. The data\ncollected during this phase consists of 146 entries. These en-\ntries encompass more challenging samples where the action\nof interest constitutes a significantly smaller proportion of\nthe temporal duration, ranging from only 10% to 20%. The\nfinal DWC dataset consists of 1502 entries, totaling 49,258\nrepetitions, and the statistics are shown in Fig. 3.\nExperiments\nTrain, validation, and test data. We conducted experi-\nments on the DWC dataset, using a partitioning scheme that\nguarantees the absence of shared subjects or action cate-\ngories between the training and testing data. We first divided\nthe data into two parts, containing 35 and 15 action cate-\ngories, respectively. Within each part, we further separated\nthe subjects into two groups, one containing 25 subjects and\nthe other 12. The combination of the 35 action categories\nwith 25 subjects became the training set, the 15 action cate-\ngories with 12 subjects formed the test set, and the remaining\ndata constituted the validation set.\nBaselines. We compared the proposed method against\nfour baseline models. Mean was a method that always out-\nputted the mean count of the samples in the training data.\nFrequency-based was a method that predicted the final count\nbased on the estimated the dominant frequency. We also\ncompared with two state-of-the-art repetitive action count-\ning methods, namely RepNet (Dwibedi et al. 2020) and\nTransRAC (Hu et al. 2022).",
        "node_24": "Within each part, we further separated\nthe subjects into two groups, one containing 25 subjects and\nthe other 12. The combination of the 35 action categories\nwith 25 subjects became the training set, the 15 action cate-\ngories with 12 subjects formed the test set, and the remaining\ndata constituted the validation set.\nBaselines. We compared the proposed method against\nfour baseline models. Mean was a method that always out-\nputted the mean count of the samples in the training data.\nFrequency-based was a method that predicted the final count\nbased on the estimated the dominant frequency. We also\ncompared with two state-of-the-art repetitive action count-\ning methods, namely RepNet (Dwibedi et al. 2020) and\nTransRAC (Hu et al. 2022). To adapt these two methods\nfor sensor data, we employed state-of-the-art feature extrac-\ntors (Wu et al. 2021; Zhou et al. 2021; Liu et al. 2021) thatComponents Combinations\nPretrain \u2717 \u2717 \u2717 \u2717 \u2713\nDist. Preserving Loss \u2717 \u2717 \u2717 \u2713 \u2713\nConstrained Detection \u2717 \u2717 \u2713 \u2713 \u2713\nSimilarity Estimation \u2717\u2713 \u2713 \u2713 \u2713\nMAE 11.30 10.87 10.32 10.05 7.66\nRMSE 16.15 15.23 14.96 14.72 12.25\nTable 2: Contributions of individual components\n0x 2x 4x 6x 8x 10x\nPretraining data proportion810121416Error\nMAE\nRMSE\n0.5 1.5 2.5 3.5\nK0.40.60.81.0OBK Error\nOurs\nGreedy\nFigure 4: Left: model\u2019s performance as the amount of pre-\ntraining data is increased; \u201c2x\u201d represents twice the size of\nthe real training set. Right: Quantitative result on temporal\nlocation detection.",
        "node_25": "Right: Quantitative result on temporal\nlocation detection. Off-By-K error under varying K.\nwere based on time-series forecasting and transfomers.\nEvaluation metrics. Following almost all previous count-\ning methods (e.g., Hu et al. (2022); Zhang, Shao, and\nSnoek (2021); Levy and Wolf (2015); Zhang et al. (2020);\nZhang, Shao, and Snoek (2021)), we used Mean Abso-\nlute Error (MAE) and Root Mean Squared Error (RMSE)\nas performance metrics, which are defined as: MAE =\n1\nnPn\ni=1|ci\u2212\u02c6ci|; RMSE =q\n1\nnPn\ni=1(ci\u2212\u02c6ci)2, where n\nis the number of test samples, and ciand\u02c6ciare the predicted\nand ground truth counts.\nImplementation details. The training of our model pro-\nceeded in two stages. In the first stage, the model was pre-\ntrained on the synthesized data, which was ten times the vol-\nume of the actual training set, for 30 epochs using Ltrain as\nthe loss function. We utilized the Adam optimizer with a\nlearning rate of 10\u22124and a batch size of one for this pre-\ntraining. After pre-training, the model was trained on the ac-\ntual training set for 30 epochs, using the same loss function,\noptimizer, and learning rate. The learning rate decay of 0.95\nwas applied at the end of each epoch.\nDuring these two stages, the audio window classifier used\nin the exemplar extraction module was BC ResNet (Kim\net al. 2021), which was trained on Speech Command (War-\nden 2018) data. The classifier was frozen and not updated\nduring the training stages. In our model, all input sensor data\nwas padded to a common length of 28,000. For the baseline\nmodels, the feature extraction process involved embedding\nthe sensor data into per-window embeddings, which were\nthen fed into the feature extractor.",
        "node_26": "We utilized the Adam optimizer with a\nlearning rate of 10\u22124and a batch size of one for this pre-\ntraining. After pre-training, the model was trained on the ac-\ntual training set for 30 epochs, using the same loss function,\noptimizer, and learning rate. The learning rate decay of 0.95\nwas applied at the end of each epoch.\nDuring these two stages, the audio window classifier used\nin the exemplar extraction module was BC ResNet (Kim\net al. 2021), which was trained on Speech Command (War-\nden 2018) data. The classifier was frozen and not updated\nduring the training stages. In our model, all input sensor data\nwas padded to a common length of 28,000. For the baseline\nmodels, the feature extraction process involved embedding\nthe sensor data into per-window embeddings, which were\nthen fed into the feature extractor. We standardized the win-\ndow size to 50 for all baseline feature extractors. Each fea-\nture extractor consisted of three layers with a specified hid-\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10062",
        "node_27": "den dimension of 256 and 8 attention heads. After feature\nextraction, the sensor features were passed through an adap-\ntive pooling layer of size 96 before entering the counting\nhead. The resulting temporal self-similarity map estimated\nby the counting head was then processed by an MLP to gen-\nerate the temporal density map.\nFor RepNet, the input sensor data was padded to have\nthe length of 28,000. TransRAC did not require padding.\nAll models underwent a training phase of 60 epochs using\nthe Adam optimizer with a learning rate of 10\u22125. The train-\ning process was conducted with a batch size of one, and the\ncount loss (L c) was used as the loss function. All experi-\nments were run on an RTX A5000 machine.\nQuantitative results. Table 1 shows a performance com-\nparison of various methods on the DWC dataset. The find-\nings highlight the superiority of the proposed method, con-\nsistently achieving a minimum 30% lower MAE compared\nto other approaches. Notably, RepNet and TransRAC are\nstrong baselines. For these baselines, extensive efforts were\ndedicated to optimizing their performance, tuning the piv-\notal feature extraction component of the methods, predom-\ninantly the time-series forecasting combined with a trans-\nformer architecture. In this pursuit, we explored a range\nof transformer variants, including the original transformer,\nAutoformer (Wu et al. 2021), Informer (Zhou et al. 2021),\nand Pyraformer (Liu et al. 2021). Specifically, the MAE\nvalues for RepNet on the test set, when using these trans-\nformer variants, are as follows: 10.82, 13.76, 11.99, 11.29,\nrespectively. Likewise, the corresponding MAE values for\nTransRAC with these transformer variants are: 12.97, 14.12,\n11.55, 12.99.",
        "node_28": "For these baselines, extensive efforts were\ndedicated to optimizing their performance, tuning the piv-\notal feature extraction component of the methods, predom-\ninantly the time-series forecasting combined with a trans-\nformer architecture. In this pursuit, we explored a range\nof transformer variants, including the original transformer,\nAutoformer (Wu et al. 2021), Informer (Zhou et al. 2021),\nand Pyraformer (Liu et al. 2021). Specifically, the MAE\nvalues for RepNet on the test set, when using these trans-\nformer variants, are as follows: 10.82, 13.76, 11.99, 11.29,\nrespectively. Likewise, the corresponding MAE values for\nTransRAC with these transformer variants are: 12.97, 14.12,\n11.55, 12.99. Despite extensive efforts to tune their perfor-\nmance, the resulting MAE values for these methods remain\nat least 30% higher than our proposed method\u2019s MAE.\nAblation studies. To assess the effectiveness of each\ncomponent in our proposed method, we conducted an abla-\ntion study using the validation data. The results of this anal-\nysis are presented in Table 2. The evaluated components in-\nclude: (1) Pretraining: Referring to pretraining on the syn-\nthesized dataset; (2) Dist. Preserving Loss: Indicating the\nutilization of our distance-preserving loss; (3) Constrained\nDetection: Representing the use of our dynamic program-\nming algorithm to detect the temporal locations of counting\nutterances under the temporal ordering and temporal prox-\nimity constraints. In its absence, we would employ a naive\nsolution that selects the audio window with the highest clas-\nsification score; and (4) Similarity Estimation: Indicating the\nproposed method for exemplar similarity estimation. In its\nabsence, we use a naive correlation to estimate the similar-\nity. The results presented in Table 2 demonstrate the benefi-\ncial impact of all proposed components on the overall per-\nformance.",
        "node_29": "The results of this anal-\nysis are presented in Table 2. The evaluated components in-\nclude: (1) Pretraining: Referring to pretraining on the syn-\nthesized dataset; (2) Dist. Preserving Loss: Indicating the\nutilization of our distance-preserving loss; (3) Constrained\nDetection: Representing the use of our dynamic program-\nming algorithm to detect the temporal locations of counting\nutterances under the temporal ordering and temporal prox-\nimity constraints. In its absence, we would employ a naive\nsolution that selects the audio window with the highest clas-\nsification score; and (4) Similarity Estimation: Indicating the\nproposed method for exemplar similarity estimation. In its\nabsence, we use a naive correlation to estimate the similar-\nity. The results presented in Table 2 demonstrate the benefi-\ncial impact of all proposed components on the overall per-\nformance. Particularly noteworthy is the significant contri-\nbution of pretraining on the synthesized dataset, which had\nthe most substantial effect on the final result.\nGiven that pretraining is the most crucial component, we\nconducted further analysis to examine the impact of differ-\nent amounts of pretraining data. In our default setting, we\nadopted an aggressive strategy, incorporating a large volume\nof synthesized training data, which is ten times the size of\nthe real training data. However, we wanted to investigateOne exemplar Two exemplars Three exemplars\nMAE RMSE MAE RMSE MAE RMSE\n9.08 14.88 8.74 14.29 7.66 12.25\nTable 3: Experiment results on the proposed DWC validation\nset with different numbers of audio exemplars.\n(a) Predict: 9.7, GT: 8 (b) Predict: 60.7, GT: 60\n(c) Predict: 40.7, GT: 40 (d) Predict: 48.0, GT: 50\nFigure 5: Qualitative results. Four prediction examples.",
        "node_30": "In our default setting, we\nadopted an aggressive strategy, incorporating a large volume\nof synthesized training data, which is ten times the size of\nthe real training data. However, we wanted to investigateOne exemplar Two exemplars Three exemplars\nMAE RMSE MAE RMSE MAE RMSE\n9.08 14.88 8.74 14.29 7.66 12.25\nTable 3: Experiment results on the proposed DWC validation\nset with different numbers of audio exemplars.\n(a) Predict: 9.7, GT: 8 (b) Predict: 60.7, GT: 60\n(c) Predict: 40.7, GT: 40 (d) Predict: 48.0, GT: 50\nFigure 5: Qualitative results. Four prediction examples. Each\nexample shows the input sensor data, the estimated density\nmap, the predicted count, and the ground truth value.\nwhether a smaller amount of synthesized data could still\nyield significant improvements, resulting in faster pretrain-\ning. The results of this experiment are shown in Fig. 4(a),\nwhere different proportions of the default synthesized data\nwere used (with random selection). Specifically, \u201c2x\u201d rep-\nresents twice the size of the real training set, and \u201d4x\u201d in-\ndicates four times the size. Intriguingly, our results reveal\nthat even a synthesized dataset only twice the size of the\nreal training data leads to a marked improvement in perfor-\nmance. Additionally, we assessed the effectiveness of using\na different number of exemplars, as presented in Table 3.\nQuantitative analysis for exemplar localization. Our\napproach relies heavily on the temporal localization of the\npredefined utterances. To evaluate its efficacy, we conducted\nan experiment on the validation set, and the result is shown\nin Fig. 4. For evaluation, we used the Off-By-K Error (OBK)\nmetric, defined as: OBK =1\nNPN\ni=1\u03b4(|ti\u2212\u02c6ti| \u2264K).",
        "node_31": "Specifically, \u201c2x\u201d rep-\nresents twice the size of the real training set, and \u201d4x\u201d in-\ndicates four times the size. Intriguingly, our results reveal\nthat even a synthesized dataset only twice the size of the\nreal training data leads to a marked improvement in perfor-\nmance. Additionally, we assessed the effectiveness of using\na different number of exemplars, as presented in Table 3.\nQuantitative analysis for exemplar localization. Our\napproach relies heavily on the temporal localization of the\npredefined utterances. To evaluate its efficacy, we conducted\nan experiment on the validation set, and the result is shown\nin Fig. 4. For evaluation, we used the Off-By-K Error (OBK)\nmetric, defined as: OBK =1\nNPN\ni=1\u03b4(|ti\u2212\u02c6ti| \u2264K). Here,\n\u03b4is the Diract delta function, Nrepresents the total num-\nber of temporal locations, tiis the predicted temporal loca-\ntion, and \u02c6tiis the ground truth temporal location. This met-\nric measures the temporal discrepancy in seconds, between\na predicted location and its corresponding ground truth lo-\ncation. We set a naive greedy scheme as the baseline for\ncomparison. The results of our experiment underscored the\neffectiveness of our approach.\nQualitative results. Qualitative results shown in Fig. 5\ndemonstrate our method\u2019s ability to accurately leverage the\nexemplars for counting the actions of interest.\nConclusions\nWe propose a few-shot method for counting actions in real-\nworld settings, utilizing vocal sounds from audio data to\ngather exemplars. These exemplars efficiently estimate ac-\ntion frequency over time. Our approach, validated by a com-\nprehensive dataset, has proven effective in evaluations.\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10063",
        "node_32": "Acknowledgements\nThis project was partially supported by US National Sci-\nence Foundation Award NSDF DUE-2055406 and AFOSR\nAward FA2386-23-1-4058.\nReferences\nAzy, O.; and Ahuja, N. 2008. Segmentation of periodically\nmoving objects. In Proceedings of the International Confer-\nence on Pattern Recognition.\nBaghdadi, A.; Cavuoto, L. A.; Jones-Farmer, A.; Rigdon,\nS. E.; Esfahani, E. T.; and Megahed, F. M. 2021. Monitor-\ning worker fatigue using wearable devices: A case study to\ndetect changes in gait parameters. Journal of quality tech-\nnology, 53(1): 47\u201371.\nBelkin, M.; and Niyogi, P. 2003. Laplacian Eigenmaps for\nDimensionality Reduction and Data Representation. Neural\nComput., 1373\u20131396.\nBian, S.; Rey, V . F.; Hevesi, P.; and Lukowicz, P. 2019. Pas-\nsive capacitive based approach for full body gym workout\nrecognition and counting. In Proceedings of the Interna-\ntional Conference on Pervasive Computing and Communi-\ncations.\nChang, K.-h.; Chen, M. Y .; and Canny, J. 2007. Tracking\nfree-weight exercises. In Proceedings of the ACM interna-\ntional joint conference on Pervasive and Ubiquitous Com-\nputing.\nChetverikov, D.; and Fazekas, S. 2006. On Motion Period-\nicity of Dynamic Textures. In Proceedings of the British\nMachine Vision Conference.\nCutler, R.; and Davis, L. S. 2000. Robust Real-Time Peri-\nodic Motion Detection, Analysis, and Applications. IEEE\nTrans. Pattern Anal. Mach. Intell., 22(8): 781\u2013796.\nCuturi, M.; and Blondel, M.",
        "node_33": "In Proceedings of the Interna-\ntional Conference on Pervasive Computing and Communi-\ncations.\nChang, K.-h.; Chen, M. Y .; and Canny, J. 2007. Tracking\nfree-weight exercises. In Proceedings of the ACM interna-\ntional joint conference on Pervasive and Ubiquitous Com-\nputing.\nChetverikov, D.; and Fazekas, S. 2006. On Motion Period-\nicity of Dynamic Textures. In Proceedings of the British\nMachine Vision Conference.\nCutler, R.; and Davis, L. S. 2000. Robust Real-Time Peri-\nodic Motion Detection, Analysis, and Applications. IEEE\nTrans. Pattern Anal. Mach. Intell., 22(8): 781\u2013796.\nCuturi, M.; and Blondel, M. 2017. Soft-DTW: a Differen-\ntiable Loss Function for Time-Series. In Proceedings of the\nInternational Conference on Machine Learning.\nDing, H.; Shangguan, L.; Yang, Z.; Han, J.; Zhou, Z.; Yang,\nP.; Xi, W.; and Zhao, J. 2015. Femo: A platform for free-\nweight exercise monitoring with rfids. In Proceedings of the\nACM conference on embedded networked sensor systems.\nDwibedi, D.; Aytar, Y .; Tompson, J.; Sermanet, P.; and Zis-\nserman, A. 2020. Counting Out Time: Class Agnostic Video\nRepetition Counting in the Wild. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.\nFieraru, M.; Zanfir, M.; Pirlea, S. C.; Olaru, V .; and\nSminchisescu, C. 2021. AIFit: Automatic 3D Human-\nInterpretable Feedback Models for Fitness Training. In Pro-\nceedings of the IEEE Conference on Computer Vision and\nPattern Recognition.\nGenovese, V .",
        "node_34": "2015. Femo: A platform for free-\nweight exercise monitoring with rfids. In Proceedings of the\nACM conference on embedded networked sensor systems.\nDwibedi, D.; Aytar, Y .; Tompson, J.; Sermanet, P.; and Zis-\nserman, A. 2020. Counting Out Time: Class Agnostic Video\nRepetition Counting in the Wild. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.\nFieraru, M.; Zanfir, M.; Pirlea, S. C.; Olaru, V .; and\nSminchisescu, C. 2021. AIFit: Automatic 3D Human-\nInterpretable Feedback Models for Fitness Training. In Pro-\nceedings of the IEEE Conference on Computer Vision and\nPattern Recognition.\nGenovese, V .; Mannini, A.; and Sabatini, A. M. 2017. A\nsmartwatch step counter for slow and intermittent ambula-\ntion. Ieee Access, 5: 13028\u201313037.\nHatamie, A.; Angizi, S.; Kumar, S.; Pandey, C. M.; Sim-\nchi, A.; Willander, M.; and Malhotra, B. D. 2020. Textile\nbased chemical and physical sensors for healthcare monitor-\ning. Journal of the electrochemical society, 167(3): 037546.Hsu, Y .; Zhang, Q.; Tsougenis, E.; and Tsui, K. 2021.\nViewpoint-Invariant Exercise Repetition Counting. CoRR.\nHu, H.; Dong, S.; Zhao, Y .; Lian, D.; Li, Z.; and Gao, S.\n2022. TransRAC: Encoding Multi-scale Temporal Correla-\ntion with Transformers for Repetitive Action Counting. In\nProceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition.\nHuang, Y .; Ranjan, V .; and Hoai, M. 2023.",
        "node_35": "2020. Textile\nbased chemical and physical sensors for healthcare monitor-\ning. Journal of the electrochemical society, 167(3): 037546.Hsu, Y .; Zhang, Q.; Tsougenis, E.; and Tsui, K. 2021.\nViewpoint-Invariant Exercise Repetition Counting. CoRR.\nHu, H.; Dong, S.; Zhao, Y .; Lian, D.; Li, Z.; and Gao, S.\n2022. TransRAC: Encoding Multi-scale Temporal Correla-\ntion with Transformers for Repetitive Action Counting. In\nProceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition.\nHuang, Y .; Ranjan, V .; and Hoai, M. 2023. Interactive Class-\nAgnostic Object Counting. In Proceedings of the Interna-\ntional Conference on Computer Vision (ICCV).\nIshii, S.; Nkurikiyeyezu, K.; Luimula, M.; Yokokubo, A.;\nand Lopez, G. 2021. Exersense: real-time physical exercise\nsegmentation, classification, and counting algorithm using\nan imu sensor. Activity and Behavior Computing, 239\u2013255.\nKim, B.; Chang, S.; Lee, J.; and Sung, D. 2021. Broad-\ncasted Residual Learning for Efficient Keyword Spotting. In\nProceedings of the Annual Conference of the International\nSpeech Communication Association.\nKong, X. T.; Luo, H.; Huang, G. Q.; and Yang, X. 2019.\nIndustrial wearable system: the human-centric empowering\ntechnology in Industry 4.0. Journal of Intelligent Manufac-\nturing, 30: 2853\u20132869.\nKranz, M.; M \u00a8oller, A.; Hammerla, N.; Diewald, S.; Pl \u00a8otz,\nT.; Olivier, P.; and Roalter, L. 2013. The mobile fitness\ncoach: Towards individualized skill assessment using per-\nsonalized mobile devices.",
        "node_36": "Activity and Behavior Computing, 239\u2013255.\nKim, B.; Chang, S.; Lee, J.; and Sung, D. 2021. Broad-\ncasted Residual Learning for Efficient Keyword Spotting. In\nProceedings of the Annual Conference of the International\nSpeech Communication Association.\nKong, X. T.; Luo, H.; Huang, G. Q.; and Yang, X. 2019.\nIndustrial wearable system: the human-centric empowering\ntechnology in Industry 4.0. Journal of Intelligent Manufac-\nturing, 30: 2853\u20132869.\nKranz, M.; M \u00a8oller, A.; Hammerla, N.; Diewald, S.; Pl \u00a8otz,\nT.; Olivier, P.; and Roalter, L. 2013. The mobile fitness\ncoach: Towards individualized skill assessment using per-\nsonalized mobile devices. Pervasive and Mobile Computing,\n9(2): 203\u2013215.\nKupke, J.; Willemsen, T.; Keller, F.; and Sternberg, H. 2016.\nDevelopment of a step counter based on artificial neural net-\nworks. Journal of Location Based Services, 10(3): 161\u2013177.\nLee, H. J.; Hwang, S. H.; Yoon, H. N.; Lee, W. K.; and Park,\nK. S. 2015. Heart rate variability monitoring during sleep\nbased on capacitively coupled textile electrodes on a bed.\nSensors, 15(5): 11295\u201311311.\nLevy, O.; and Wolf, L. 2015. Live Repetition Counting. In\nProceedings of the IEEE International Conference on Com-\nputer Vision.\nLiu, C.; Zhong, Y .; Zisserman, A.; and Xie, W. 2022.\nCounTR: Transformer-based Generalised Visual Counting.\nInProceedings of the British Machine Vision Conference.\nLiu, S.; Yu, H.; Liao, C.; Li, J.; Lin, W.; Liu, A. X.; and Dust-\ndar, S.",
        "node_37": "Lee, H. J.; Hwang, S. H.; Yoon, H. N.; Lee, W. K.; and Park,\nK. S. 2015. Heart rate variability monitoring during sleep\nbased on capacitively coupled textile electrodes on a bed.\nSensors, 15(5): 11295\u201311311.\nLevy, O.; and Wolf, L. 2015. Live Repetition Counting. In\nProceedings of the IEEE International Conference on Com-\nputer Vision.\nLiu, C.; Zhong, Y .; Zisserman, A.; and Xie, W. 2022.\nCounTR: Transformer-based Generalised Visual Counting.\nInProceedings of the British Machine Vision Conference.\nLiu, S.; Yu, H.; Liao, C.; Li, J.; Lin, W.; Liu, A. X.; and Dust-\ndar, S. 2021. Pyraformer: Low-complexity pyramidal atten-\ntion for long-range time series modeling and forecasting. In\nProceedings of the International conference on learning rep-\nresentations.\nLu, E.; Xie, W.; and Zisserman, A. 2018. Class-Agnostic\nCounting. In Proceedings of the Asian Conference on Com-\nputer Vision.\nMorris, D.; Saponas, T. S.; Guillory, A.; and Kelner, I. 2014.\nRecoFit: using a wearable sensor to find, recognize, and\ncount repetitive exercises. In Proceedings of the SIGCHI\nConference on Human Factors in Computing Systems.\nMortazavi, B. J.; Pourhomayoun, M.; Alsheikh, G.; Alshu-\nrafa, N.; Lee, S. I.; and Sarrafzadeh, M. 2014. Determin-\ning the Single Best Axis for Exercise Repetition Recognition\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10064",
        "node_38": "and Counting on SmartWatches. In Proceedings of the In-\nternational Conference on Wearable and Implantable Body\nSensor Networks.\nNam, Y .; Kim, Y .; and Lee, J. 2016. Sleep monitoring based\non a tri-axial accelerometer and a pressure sensor. Sensors,\n16(5): 750.\nNguyen, T.; Pham, C.; Nguyen, K.; and Hoai, M. 2022. Few-\nShot Object Counting and Detection. In Proceedings of the\nEuropean Conference on Computer Vision.\nNishino, Y .; Maekawa, T.; and Hara, T. 2022. Few-Shot and\nWeakly Supervised Repetition Counting With Body-Worn\nAccelerometers. In Frontiers in Computer Science.\nOh, M.-h.; Olsen, P.; and Ramamurthy, K. N. 2020. Crowd\ncounting with decomposed uncertainty. In Proceedings of\nthe AAAI conference on artificial intelligence.\nO\u2019Reilly, M.; Caulfield, B.; Ward, T.; Johnston, W.; and Do-\nherty, C. 2018. Wearable inertial sensor systems for lower\nlimb exercise detection and evaluation: a systematic review.\nSports Medicine, 48: 1221\u20131246.\nPatel, S.; Hughes, R.; Hester, T.; Stein, J.; Akay, M.; Dy,\nJ. G.; and Bonato, P. 2010. A novel approach to monitor\nrehabilitation outcomes in stroke survivors using wearable\ntechnology. Proceedings of the IEEE, 98(3): 450\u2013461.\nPillai, A.; Lea, H.; Khan, F.; and Dennis, G. 2020. Per-\nsonalized step counting using wearable sensors: A do-\nmain adapted LSTM network approach. arXiv preprint\narXiv:2012.08975.\nPogalin, E.; Smeulders, A. W. M.; and Thean, A. H. C. 2008.",
        "node_39": "Sports Medicine, 48: 1221\u20131246.\nPatel, S.; Hughes, R.; Hester, T.; Stein, J.; Akay, M.; Dy,\nJ. G.; and Bonato, P. 2010. A novel approach to monitor\nrehabilitation outcomes in stroke survivors using wearable\ntechnology. Proceedings of the IEEE, 98(3): 450\u2013461.\nPillai, A.; Lea, H.; Khan, F.; and Dennis, G. 2020. Per-\nsonalized step counting using wearable sensors: A do-\nmain adapted LSTM network approach. arXiv preprint\narXiv:2012.08975.\nPogalin, E.; Smeulders, A. W. M.; and Thean, A. H. C. 2008.\nVisual quasi-periodicity. In Proceedings of the IEEE Con-\nference on Computer Vision and Pattern Recognition.\nPrabhu, G.; O\u2019Connor, N. E.; and Moran, K. 2020. Recogni-\ntion and Repetition Counting for Local Muscular Endurance\nExercises in Exercise-Based Rehabilitation: A Comparative\nStudy Using Artificial Intelligence Models. Sensors, 20.\nRamachandran, B.; and Liao, Y .-C. 2022. Microfluidic wear-\nable electrochemical sweat sensors for health monitoring.\nBiomicrofluidics, 16(5): 051501.\nRanjan, V .; and Hoai, M. 2022a. Exemplar Free Class Ag-\nnostic Counting. In Proceedings of the Asian Conference on\nComputer Vision (ACCV).\nRanjan, V .; and Hoai, M. 2022b. Vicinal Counting Net-\nworks. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition Workshops.\nRanjan, V .; Sharma, U.; Nguyen, T.; and Hoai, M. 2021.\nLearning To Count Everything. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.",
        "node_40": "Sensors, 20.\nRamachandran, B.; and Liao, Y .-C. 2022. Microfluidic wear-\nable electrochemical sweat sensors for health monitoring.\nBiomicrofluidics, 16(5): 051501.\nRanjan, V .; and Hoai, M. 2022a. Exemplar Free Class Ag-\nnostic Counting. In Proceedings of the Asian Conference on\nComputer Vision (ACCV).\nRanjan, V .; and Hoai, M. 2022b. Vicinal Counting Net-\nworks. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition Workshops.\nRanjan, V .; Sharma, U.; Nguyen, T.; and Hoai, M. 2021.\nLearning To Count Everything. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.\nRunia, T. F. H.; Snoek, C. G. M.; and Smeulders, A. W. M.\n2018. Real-World Repetition Estimation by Div, Grad and\nCurl. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition.\nShi, M.; Lu, H.; Feng, C.; Liu, C.; and Cao, Z. 2022. Repre-\nsent, Compare, and Learn: A Similarity-Aware Framework\nfor Class-Agnostic Counting. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.Soro, A.; Brunner, G.; Tanner, S.; and Wattenhofer, R.\n2019a. Recognition and repetition counting for complex\nphysical exercises with deep learning. Sensors, 19(3): 714.\nSoro, A.; Brunner, G.; Tanner, S.; and Wattenhofer, R.\n2019b. Recognition and Repetition Counting for Complex\nPhysical Exercises with Deep Learning. Sensors, 714.\nStiefmeier, T.; Roggen, D.; Ogris, G.; Lukowicz, P.; and\nTr\u00a8oster, G.",
        "node_41": "2022. Repre-\nsent, Compare, and Learn: A Similarity-Aware Framework\nfor Class-Agnostic Counting. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition.Soro, A.; Brunner, G.; Tanner, S.; and Wattenhofer, R.\n2019a. Recognition and repetition counting for complex\nphysical exercises with deep learning. Sensors, 19(3): 714.\nSoro, A.; Brunner, G.; Tanner, S.; and Wattenhofer, R.\n2019b. Recognition and Repetition Counting for Complex\nPhysical Exercises with Deep Learning. Sensors, 714.\nStiefmeier, T.; Roggen, D.; Ogris, G.; Lukowicz, P.; and\nTr\u00a8oster, G. 2008. Wearable activity tracking in car manu-\nfacturing. IEEE Pervasive Computing, 7(2): 42\u201350.\nStr\u00a8omb\u00a8ack, D.; Huang, S.; and Radu, V . 2020. MM-Fit:\nMultimodal Deep Learning for Automatic Exercise Logging\nacross Sensing Devices. Proc. ACM Interact. Mob. Wearable\nUbiquitous Technol., 4.\nThangali, A.; and Sclaroff, S. 2005. Periodic Motion Detec-\ntion and Estimation via Space-Time Sampling. In Proceed-\nings of the Applications of Computer Vision Workshop.\nWarden, P. 2018. Speech Commands: A Dataset for\nLimited-V ocabulary Speech Recognition. CoRR.\nWu, H.; Xu, J.; Wang, J.; and Long, M. 2021. Autoformer:\nDecomposition transformers with auto-correlation for long-\nterm series forecasting. In Advances in Neural Information\nProcessing Systems.\nYang, S.; Su, H.; Hsu, W. H.; and Chen, W. 2021. Class-\nagnostic Few-shot Object Counting. In Proceedings of the\nIEEE Winter Conference on Applications of Computer Vi-\nsion.",
        "node_42": "ACM Interact. Mob. Wearable\nUbiquitous Technol., 4.\nThangali, A.; and Sclaroff, S. 2005. Periodic Motion Detec-\ntion and Estimation via Space-Time Sampling. In Proceed-\nings of the Applications of Computer Vision Workshop.\nWarden, P. 2018. Speech Commands: A Dataset for\nLimited-V ocabulary Speech Recognition. CoRR.\nWu, H.; Xu, J.; Wang, J.; and Long, M. 2021. Autoformer:\nDecomposition transformers with auto-correlation for long-\nterm series forecasting. In Advances in Neural Information\nProcessing Systems.\nYang, S.; Su, H.; Hsu, W. H.; and Chen, W. 2021. Class-\nagnostic Few-shot Object Counting. In Proceedings of the\nIEEE Winter Conference on Applications of Computer Vi-\nsion.\nYou, Z.; Yang, K.; Luo, W.; Lu, X.; Cui, L.; and Le, X. 2023.\nFew-shot Object Counting with Similarity-Aware Feature\nEnhancement. In Proceedings of the IEEE Winter Confer-\nence on Applications of Computer Vision.\nZelman, S.; Dow, M. M.; Tabashum, T.; Xiao, T.; and Albert,\nM. V . 2020. Accelerometer-Based Automated Counting of\nTen Exercises without Exercise-Specific Training or Tuning.\nJournal of Healthcare Engineering.\nZhang, H.; Xu, X.; Han, G.; and He, S. 2020. Context-\nAware and Scale-Insensitive Temporal Repetition Counting.\nInProceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition.\nZhang, Y .; Shao, L.; and Snoek, C. G. M. 2021. Repetitive\nActivity Counting by Sight and Sound. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recogni-\ntion.\nZhou, H.; Zhang, S.; Peng, J.; Zhang, S.; Li, J.; Xiong, H.;\nand Zhang, W.",
        "node_43": "Zelman, S.; Dow, M. M.; Tabashum, T.; Xiao, T.; and Albert,\nM. V . 2020. Accelerometer-Based Automated Counting of\nTen Exercises without Exercise-Specific Training or Tuning.\nJournal of Healthcare Engineering.\nZhang, H.; Xu, X.; Han, G.; and He, S. 2020. Context-\nAware and Scale-Insensitive Temporal Repetition Counting.\nInProceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition.\nZhang, Y .; Shao, L.; and Snoek, C. G. M. 2021. Repetitive\nActivity Counting by Sight and Sound. In Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recogni-\ntion.\nZhou, H.; Zhang, S.; Peng, J.; Zhang, S.; Li, J.; Xiong, H.;\nand Zhang, W. 2021. Informer: Beyond efficient transformer\nfor long sequence time-series forecasting. In Proceedings of\nAAAI Conference on Artificial Intelligence.\nThe Thirty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (AAAI-24)\n10065",
        "node_44": "\u2018Fouling\u2019 \u2013 significant deposition of sulphur (Photos in  Nov  2021)\nThis is how the absorber vessel normally looks like after 12+ days of \noperations => require 2 -day mechanical clean. \n\u2018Clean\u2019  \u2013 very minimal deposition of sulphur (Two dream runs in Dec 2021)\nThis is how the plant & vessel are  designed to look like, and  have been \nachieved only two times over  the 4-year  history.  \u2022 Company : Cooper Energy (Adelaide -based) (ASX: COE) \n\u2022 Asset : Orbost Gas Plant in Victoria\n\u2022Proposed Project title: \u201c The Application of Machine Learning to Reduce the Fouling of Absorber Vessels at Orbost Gas Processing Plant\u201d\n\u2022 Background : Orbost Gas Plant (OGP) processes raw gas from nearly gas field to export sales gas into the pipeline (which is then used fo r \ncommercial, industrial and power generation purposes). The export sales gas must meet several strict specifications such as t he concentrations of \nsolids particle, water, mercury, oxygen and hydrogen sulphide (H2S).   Two absorber vessels were installed at OGP to remove the H2S concentration of \nuntreated gas. These absorber vessels are designed to run for months/years without any fouling. However, since operating in 2 020 , these vessels \nhave been having fouling issues, which requires each absorber vessel to be opened and mechanically cleaned every 12 \u2013 15 days. \n\u2022 Key  questions: What were the differences in operational data that resulted in the two dream runs in Dec 2021? And how do we replicate it for\nthe going -forward operation? This could potentially be answered by the application of ML based on the time series data of pressure, temperature, \nflowrate, injection rate\u2026 of the related equipment in the process at OGP. \n\u2022 Note: The real -time data at OGP are measured by the local device/gauges then transmitted to the AVEVA PI system for data storage, visualisation and \nsimple analysis. The  AVEVA PI system is very commonly used in industrial operations in Australia and over the world.",
        "node_45": "However, since operating in 2 020 , these vessels \nhave been having fouling issues, which requires each absorber vessel to be opened and mechanically cleaned every 12 \u2013 15 days. \n\u2022 Key  questions: What were the differences in operational data that resulted in the two dream runs in Dec 2021? And how do we replicate it for\nthe going -forward operation? This could potentially be answered by the application of ML based on the time series data of pressure, temperature, \nflowrate, injection rate\u2026 of the related equipment in the process at OGP. \n\u2022 Note: The real -time data at OGP are measured by the local device/gauges then transmitted to the AVEVA PI system for data storage, visualisation and \nsimple analysis. The  AVEVA PI system is very commonly used in industrial operations in Australia and over the world. Therefore, the  quality, format \nand structure of the data are expected to be good quality for machine learning purposes.",
        "node_46": "Think Digital  \nAI Roadmap",
        "node_47": "Prepared by  \n \nAustralian Institute for Machine Learning  \nNovember 2023",
        "node_48": "Project Background  \nThe Australian Institute of Machine Learning (AIML) regularly engages with South Australian agencies \nand businesses to help to develop new or improved services based on machine learning. AIML works \nwith agencies to iteratively define, prove, and demonstrate the feasibility of machine learning \nsolutions and provide a bedrock of technology for further developme nt. \n \nThink Digital is a South Australian business specializing  in the creation of immersive  and interactive \ncontent that transforms training and education for agriculture, food  and fiber . They have recently \nlaunched an application with PIRSA and Animal Hea lth Australia to help educate producers about \nemergency animal diseases in sheep  (Sheep Emergency Disease AR Tool).  \n \nThink Digital is looking to incorporate AI & ML into a  new product that helps pastoralists to identify \nEmergency Animal diseases in cattle.  \nDocument Purpose  \nThis document outline s a roadmap for the Think Digital  to develop and integrate emerging AI \ntechnology in  support of their vision, providing both high -level guiding principles and a concrete plan \nfor taking the next steps.",
        "node_49": "Project Background  3 \nDocument Purpose  3 \nThink Digital Today  5 \nSWOT Analysis  6 \nVision for AI and Machine Learning  7 \nRoadmap Principles  7 \nAI Maturity Model  7 \nBecoming a machine learning organisation  8 \nModel development roadmap  10 \nMachine learning engineering principles  11 \nThink Digital in 1 year  12 \nOrganisational alignment  12 \nInfrastructural alignment  13 \nTaking it for a test run  14 \nAI maturity advancement  15 \nThink Digital in 3 years  16 \nPilot studies into AI Platform  16 \nContinued organisational alignment  16 \nData collection  18 \nAI maturity advancement  19 \nAppendices  20 \nAppendix A:  Current Work Summary  20 \nAppendix B:  Recommendations  21 \nAppendix C:  Examples of problems with the current model  22",
        "node_50": "Think Digital  Today  \nThink Digital is looking to incorporate AI & ML into an augmented reality product that helps \npastoralists to identify Emergency Animal diseases in cattle. The y want to develop a  tool that uses AI \n& ML to detect emergency animal diseases like Foot and Mouth Disease (FMD) and Lumpy Skin \nDisease (LSD) . \n \nIn North Australia, the cattle industry faces significant challenges due to diseases like Lumpy S kin \nDisease (LSD) and Foot -And-Mouth Disease (FMD).  LSD affects cattle and water buffalo, leading to \nskin nodules, reduced milk production, and sometimes death. FMD, on the other hand, is a highly \ncontagious ailment affecting cloven -hoofed animals, includi ng cattle, sheep, and pigs. It doesn't affect \nhumans but can have severe consequences for Australia's animal health and trade.  \n \nIn the initial engagement with AIML Researchers (lead by Yifan Liu), the AIML Research team \ndeveloped a data pre -processing solu tion and trained a model. The custom model that was developed \nclassified images in to one of three classes; 1. Foot and Mouth Disease (FMD), 2. Lumpy Skin Disease \n(LSD), and 3. Healthy. The research concluded with the establishment of an API endpoint and t he \ndeployment of the model. For the small training dataset, the validation accuracy was high, but the \nmodel accuracy was unreliable when tested with previously unseen images (Appendix A:  Examples of \nproblems with the current model, page 19).  \n \nFollowing t he project handover from the research team, the AIML Engineering team engaged to \nimprove the preliminary work. Initial steps involved verification checks and a review of the codebase \nprovided by Akide Liu et. al., the engineering team refined the project d ocumentation, including \nupdating READMEs, to make it easier for Think Digital to use the work.  \n  \nThe current work has limitations. Most notably, the model does not generalize well  and t he main \ncause for this is a lack of training data that is suitably dive rse.",
        "node_51": "Healthy. The research concluded with the establishment of an API endpoint and t he \ndeployment of the model. For the small training dataset, the validation accuracy was high, but the \nmodel accuracy was unreliable when tested with previously unseen images (Appendix A:  Examples of \nproblems with the current model, page 19).  \n \nFollowing t he project handover from the research team, the AIML Engineering team engaged to \nimprove the preliminary work. Initial steps involved verification checks and a review of the codebase \nprovided by Akide Liu et. al., the engineering team refined the project d ocumentation, including \nupdating READMEs, to make it easier for Think Digital to use the work.  \n  \nThe current work has limitations. Most notably, the model does not generalize well  and t he main \ncause for this is a lack of training data that is suitably dive rse. The machine learning model \ndevelopment process demands quality training data on the scale of 100K to 1 million images to \nperform in real world scenarios.  \n \nToday, the Think Digital is in early stages of building a generalized AI model and deploying in  the real -\nworld delivering value to end users. We have defined a strategic roadmap to show important \nmilestones required to develop and maintain AI systems.",
        "node_52": "SWOT Analysis  \nStrengths  \n \n\u25cf Think Digital has a strong rural network \nin Australia  through its  educational \nprograms.  \n\u25cf Established  partnerships  \n- veterinary experts  \n- farmers /photographers  \n- DAF QLD  Weaknesses  \n \n\u25cf Insufficient training data . \n\u25cf Lack of  internal technical expertise.  \n\u25cf Lack  of technology infrastructure to test \nand deploy AI models  \nOpportunities  \n \n\u25cf Partner with more data providers ( farms , \nveterinary clinics , etc) . \n\u25cf Lead the market and gain traction with in \nit. \n\u25cf Become a trusted leader  with the best \ndata t hat is being leveraged to have the \nbest models  for disease detection . Threats  \n \n\u25cf Competitor (s) getting  better data . \n\u25cf Competitor (s) building better models.  \n\u25cf Competit or(s)  building internal \ncapabilities and IP . \n\u25cf Competitor(s) building stronger \nrelationships with target market and /or \nstrategic partners . \n\u25cf Regulatory changes in data collection, \nprivacy, and AI usag e. \n \nThink Digital \u2019s greatest strength is a strong rural network in Australia built via their educational \nprograms  and a know -how  of the animal diseases . They can leverage th is network  to create \nnationwide partnerships to collect and source data from cattle farms  crucial to develop ing and \nmaintaining leading  AI models . \n \nThe business\u2019 strengths also suggest  opportunities  in address ing the need s of the biosecurity \ngovernment  to prevent disease outbreak in Northern Australia. Later, the tool can be expand ed to \nbroader use cases to classify other diseases.  \n \nSimilarly, the business\u2019 weaknesses suggest opportunities. The lack of quality training data is the \nbiggest bottleneck in the AI model development that presents an opportunity in creating a propriety \ndataset  and create a unique edge before competition enters in the market.  Furthermore, lack of \ninternal technical expertise will elevate the risks  generally and increase the likelihood of a competitor \ntaking a strong alternative  to the market .  \n \nIt is crucial  to create large , high -quality  datasets to addressing current limitations .",
        "node_53": "They can leverage th is network  to create \nnationwide partnerships to collect and source data from cattle farms  crucial to develop ing and \nmaintaining leading  AI models . \n \nThe business\u2019 strengths also suggest  opportunities  in address ing the need s of the biosecurity \ngovernment  to prevent disease outbreak in Northern Australia. Later, the tool can be expand ed to \nbroader use cases to classify other diseases.  \n \nSimilarly, the business\u2019 weaknesses suggest opportunities. The lack of quality training data is the \nbiggest bottleneck in the AI model development that presents an opportunity in creating a propriety \ndataset  and create a unique edge before competition enters in the market.  Furthermore, lack of \ninternal technical expertise will elevate the risks  generally and increase the likelihood of a competitor \ntaking a strong alternative  to the market .  \n \nIt is crucial  to create large , high -quality  datasets to addressing current limitations . Leveraging the data \nand streamlining data collection processes will add momentum and improve opportunities to train \nand deploy better models. By develop ing a strong  internal technology team , Think Digital will improve \ntheir ability to; efficiently capture high -quality data , build high quality AI models , and deploy the m in an \nengaging and effective end-user -experience .",
        "node_54": "Vision for AI and Machine Learning  \nThink Digital  aims to he lp cattle farm owners to embrace emerging AI technologies to help detect \ncattle diseases such as Foot -And-Mouth (FMD) and Lumpy Skin Disease (LSD) . \n \nMachine Learning (ML) can play a transformative role in the classification of cattle diseases using \nimages.  By analyzing vast datasets, AI can help in early detection, prediction of disease spread, and \nformulation of effective containment strategies. Moreover , ML algorithms can assist in classifying \nand differentiating between various cattle diseases based on s ymptoms, ensuring timely and \nappropriate interventions.  \nRoadmap Principles  \nThe following models and principles are referenced throughout as a way for a company to progress \non an AI journey.  \nAI Maturity Model  \nMost companies today would fall into the Level 1  category of AI maturity.  They are aware of it, and \nare indirectly benefiting from companies that are at Level 4 and 5.   \n \n \nAI Maturity Model.",
        "node_55": "Level 1 - Awareness  \n \nAt level 1, companies will be aware of AI, but not yet applying it to their business problems.  They talk \nof AI more than they know of it (e.g., be led by hype and fear of missing out).  There are ideas being \nformed, but no strategies in how these ideas ca n be realised and applied.  \n \nLevel 2 - Prototyping  \n \nAt level 2 companies will be prototyping systems informally. The code produced will be of research \nquality (e.g., Jupyter notebooks, ad -hoc, unorchestrated).  This will be used to inform the company \nabout  how they might become operational in AI. What data do I need? How many beefy computers do \nI need?  Some companies here may be experimenting with AWS, Azure and Google Cloud \u201coff the \nshelf models\u201d to see where they could get an easy win (often coming up sh ort when the generic \nsolutions don't solve their unique business problems).  \n \nLevel 3 - Operational  \n \nAt level 3 a company will have graduated a prototype into an operational environment that they use  in \ntheir day to day business functions.  They will likely  have or be hiring machine learning engineers, \ncreating data pipelines, keeping versioned datasets, and undertaking some level of machine learning \n\u201cops\u201d.  At least 1 feature in their application stack, or information processing tasks will be utilising AI \nto offer more value to their customers or to internal stakeholders.  \n \nLevel 4 - Systemic  \n \nAt level 4 companies will be using machine learning to disrupt their existing business processes in a \nnovel way.  This will likely be more than simple application of re search off the shelf models (e.g., \nobject detection models are not disruptive) - which is the \u201chype\u201d we see with level 1 companies.  \nRather they will be building custom models, processes, pipelines, and new functionality that has not \nyet been available in the market.  Very few companies will reach this stage.  \n \nLevel 5 - Transformational  \n \nAt level 5 companies are using machine learning pervasively. At this stage AI is the value they are \nproviding to their customers.",
        "node_56": "At least 1 feature in their application stack, or information processing tasks will be utilising AI \nto offer more value to their customers or to internal stakeholders.  \n \nLevel 4 - Systemic  \n \nAt level 4 companies will be using machine learning to disrupt their existing business processes in a \nnovel way.  This will likely be more than simple application of re search off the shelf models (e.g., \nobject detection models are not disruptive) - which is the \u201chype\u201d we see with level 1 companies.  \nRather they will be building custom models, processes, pipelines, and new functionality that has not \nyet been available in the market.  Very few companies will reach this stage.  \n \nLevel 5 - Transformational  \n \nAt level 5 companies are using machine learning pervasively. At this stage AI is the value they are \nproviding to their customers.  Each component of their systems will prov ide value to (or revenue \nderived from customers) from AI (e.g., TikTok, Facebook, Google and friends).  \nBecoming a machine learning organisation  \nBefore an organisation commits to increasing their AI maturity from Level 1, they must commit to \nimproving many core values. Only then can they successfully drive significant business value from \nmachine learning. Most companies could reach Level 3 with a fair amount of investment and \ncommitment .",
        "node_57": "Organisational alignment  \n \nMachine learning isn\u2019t a \u201cbolt on\u201d feature t hat can be added to a business with the expectation that it \nwill just work. The company must align itself to make machine learning a part of its core business, \nremoving traditional boundaries and ensuring that initiatives have support and representation at  every \nlevel of the business. New teams and roles may need to be created.  \n \nMulti -disciplinary teams  \n \nBuilding machine learning models requires more than just machine learning experts. Multi -disciplinary \nteams are necessary, embedding subject matter experti se with veterinary  experts, cattle farm owners, \ndata engineers , software engineers etc. Furthermore, you must give them the resources, the capability \nand the mandate to deliver on the company\u2019s AI and machine learning vision.  \n \nData engineering as a core activity  \n \nEvery machine learning project starts with data.  You will need to build comprehensive labelled data to \ntrain machine learning models and to evaluate them.  This data will need to be acquired, cleaned, \norganised, stored and made available to the teams and systems that need it.  \n \nThe data required for machine learning may be larger, more complex, more sensitive, or more volatile \nthan your existing production systems, and require new methods of management.  \n \nModel training and evaluation as a core ac tivity  \n \nModel training and validation is the heart of machine learning applications. It requires an investment \nin computers (GPUs in particular) in either the cloud, or in dedicated machine learning hardware.  Data \nscientists and engineers  will be identify ing the modes and measures, and engineers will be \nimplementing the data loading, model training, and model checkpointing / evaluation code.  \n \nModels are typically not \u201ctrain once and forget\u201d - but need to be constantly maintained as you would \nany component of a system.  \n \nContinuous deployment  \n \nThe best machine learning products provide frictionless mechanisms to launch a model into a \nproduction environment, where it can be used for its intended purpose. Continuous integration, \ntesting, and delivery of models i s critical.",
        "node_58": "Model training and evaluation as a core ac tivity  \n \nModel training and validation is the heart of machine learning applications. It requires an investment \nin computers (GPUs in particular) in either the cloud, or in dedicated machine learning hardware.  Data \nscientists and engineers  will be identify ing the modes and measures, and engineers will be \nimplementing the data loading, model training, and model checkpointing / evaluation code.  \n \nModels are typically not \u201ctrain once and forget\u201d - but need to be constantly maintained as you would \nany component of a system.  \n \nContinuous deployment  \n \nThe best machine learning products provide frictionless mechanisms to launch a model into a \nproduction environment, where it can be used for its intended purpose. Continuous integration, \ntesting, and delivery of models i s critical.  \n \nA gold standard dataset needs to be developed to act as a \u201cgatekeeper\u201d for models - in this case a set \nof known \u201c verified\u201d  data labels  and \u201cdiverse\u201d cattle disease images  covering all kinds of real-world  \nscenarios in the cattle disease test dataset .  This sets the bar for what the model must be able to \npredict  to be useful for customers.  This is usually a hand -built  dataset that is kept away from model \ntraining, and provides quality assurance and confidence to any models that are pushed into  a live app. \nYou would typically ensure that only models that \u201cpass\u201d the gold standard are pushed into the \nproduction environment.",
        "node_59": "Monitoring  \n \nYou need to keep an eye on the models once they are running in production. Data changes over time, \nand customer  behaviour may also shift as time moves on.  You will need to define and measure \nmetrics that can tell you how the model is performing in the product.  You should also ask for \ncustomer feedback on the predictions that a model is generated. You will then be  able to identify if \nquality is dropping, or customers are using the models for unexpected annotations or on areas that \nhave had no training data associated with them (e.g., if you have trained on specific  cattle data  in a \ngiven region , and a user not from  that region is trying to use the model - you would want to warn them, \nor be aware that the model may fail to produce useful results).  \nModel development roadmap  \n \nEach new model will start as a feasibility study and many of the models and prototypes develop ed \nearly on will fail and not launch into a production environment.  \n \nThese early studies will be instrumental in determining what is possible for the Think  Digital AI \nassisted cattle disease tool . \n \nFrom the early work on model development, we realise that  the model has severe limitations in \ngeneralizing well over unseen data.  Think Digital is in the feasibility  stage where they have collected \ndata, trained a model and realised its limitations.  \n \nAn example is shown below, of the possible \u201cflow\u201d of activities that Think  Digital could take to mature \nfrom their current setup to one with an MVP machine learning product.  \n \n \nExample of how Think Digital  might mature a n AI model.  \n \nYou will repeat this process for many models as it is the only way you can gain the organisational \nknowledge  you\u2019ll need to develop a complete  Platform.",
        "node_60": "For instance - the following will be unknown to you unless you\u2019ve deployed several models into \nproduct ion settings:  \n \n\u25cf Performance requirements (e.g., for running the model in production) and what \u201chit\u201d you can \ntake in terms of inference time (e.g., does it need to be real-time ? Or does batching requests \nand inferring them later is an option ?) \n\u25cf Training hard ware requirements (e.g., how much GPU ram does our data need? How big is the \nclassification  model  architecture ? Where do we host this? On cloud? On Prem? What\u2019s the \ntotal cost of ownership in either case?)  \n\u25cf Data labelling costs for training and evaluation ( e.g., how similar is each cattle  farm\u2019s data? \nDoes the model generalise over different cattle dat a? Does it work on cattle  data in Australia \nand Globally? How much data per cattle disease  is required to achieve good performance?)  \n\u25cf Data labelling costs for g old standard - (e.g., what are specifications for each disease and \nhow to ensure  data labelling quality?  Think more \u201cintegration testing\u201d for the model vs. \nevaluation data which is \u201cunit testing\u201d for the model.)  \nMachine learning engineering principles  \nMost of the problems you will encounter on this journey are, in fact, engineering  problems.  Even with \nall the resources of great machine learning experts (such as those at AIML or those that you hire \ninternally), most of the gains come from great data (an d labels) , not \u201cstate of the art\u201d machine \nlearning algorithms.  \nThe basic approach the be taken for each model is almost always:  \n1. Make sure your training, evaluation, gold -standard testing and deployment pipeline is reliable  \nend to end and can be run by anyo ne easily and is fully automated.  \n2. Start with a reasonable objective (e.g., classifying may be only disease instead of two)  \n3.",
        "node_61": "Think more \u201cintegration testing\u201d for the model vs. \nevaluation data which is \u201cunit testing\u201d for the model.)  \nMachine learning engineering principles  \nMost of the problems you will encounter on this journey are, in fact, engineering  problems.  Even with \nall the resources of great machine learning experts (such as those at AIML or those that you hire \ninternally), most of the gains come from great data (an d labels) , not \u201cstate of the art\u201d machine \nlearning algorithms.  \nThe basic approach the be taken for each model is almost always:  \n1. Make sure your training, evaluation, gold -standard testing and deployment pipeline is reliable  \nend to end and can be run by anyo ne easily and is fully automated.  \n2. Start with a reasonable objective (e.g., classifying may be only disease instead of two)  \n3. Add common\u00ad -sense data and labels one at a time (e.g., focus on one classification only \nregional data  at a time, train small models i nitially, add other classes and regions one at a \ntime, always measure, only continue if precision and recall stays high for each class and \nagainst the gold standard, train small specific models otherwise).  \n4. Make sure that your pipeline always stays reliable  (e.g., having suitable fail -safe checks in \nplace, thorough testing before roll out is crucial)  \nThis approach will work well for a long period of time. Mature and established computer vision deep \nlearning methods will get you an initial massive lift (e.g . training an  established classification  model \nsuch as Efficient Net  from the PyTorch Torchvision library will be sufficient  for most use cases , \npossibly for many years).1  \nThe biggest gains will typically be found in higher quality (e.g., different viewpoin ts, lighting \nconditions, types, of cattle ) input data and higher quality labels  for each disease  verified by the \nveterinary experts . It\u2019s not uncommon for commercial datasets to contain hundreds of thousands or \n                                                           \n1 https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html",
        "node_62": "even millions  of well labelled  data points. Y ou will find that these become the company\u2019s crown \njewels  and provide a competitive edge in the market . \nStart with a simple use case of three class problem (FMD, LSD and healthy). Adding complexity in the \ninitial phase of development will slow down the future releases. The most important thing is to take a \nthin wedge of a model (e.g., only 3 class es) all the way into production.  \nThink Digital  in 1 year \n \nThink Digital  defines its key priorities for machine learning - and identifies the problems that need to \nbe solved to get there (organisationally and infrastructurally).  \n \nIn the first year you will need to undertake several transformations within the company. These inc lude:  \n \n\u25cf Organisational alignment  \n\u25cf Infrastructural alignment  \n\u25cf And, commencing one or more pilot machine learning projects  \nOrganisational alignment  \nYou will need to ensure that as a company you are aligned to a machine learning goal.  To do this you \nwill need t o hire appropriate staff and established processes (governance, steering committees) to \nshift the culture.  \n \nGovernance  \n \nYou will need to establish the system by which your machine learning projects are controlled, how \nthey operate, and the mechanisms by wh ich the teams involved are held to account.  You will need to \nensure that models are compliant with appropriate privacy and data protection legislation.  \n \nThe key concerns for governance are in naming a person or team that is responsible for building, \nmaint aining and monitoring models, ensuring they report to the Chief Data Officer or equivalent.  \n \nSteering committee  \n \nYou will need to establish a machine learning steering committee that acts as the advisory body for \nthe machine learning team.  Members should include customer advocates, senior stakeholders in the \nproject or organisation, experts in the field, etc. There can be internal or external members.  \n \nThe key concerns for this group will be in overseeing the direction, scope, budget, timelines and \nmethods  used in the machine learning products developed by Think Digital .",
        "node_63": "Chief Data Officer / Head of AI & Data  \n \nChief Data Officer - a fantastic hire at this point would be a data & AI leader, someone who can lead \nthe change internally, hire the right people to help them, and understand the changes that need to be \nmade internally to enable the team to succeed.  \n \nThe key concerns of the CDO are to build a machine learning culture, hire the right engineers , and set \nup the strategic roadmap with the steering commi ttee. They should be adept at understanding the \ncompany\u2019s data holdings, how they can be leveraged for machine learning and where the \nopportunities lay.  \n \nIt is important to realise the need of key external partnerships with data collection agencies, data \nlabelling services, cattle farm owners, veterinary experts to address current data limitations and \nidentify right market opportunities.  \nInfrastructural alignment  \nYou will need to provision appropriate infrastructure in support of your machine learning initi atives. \nThis will need to be right sized to handle the spatial resolution of the training data and labels, \ninference performance requirements and so on. Some possible scenarios follow.  \n \nLocal development, local model rollout, cloud inference  \n \nIf your organ isation is largely utilising on -prem development, with minimal cloud infrastructure the \nfollowing (very brief) set of technologies may be appropriate.  \n \n1. Training data storage on local NAS  \n2. Training and model development using local deep learning workstations  (e.g., $ 8000 AUD \nworkstations)  \n3. Via CI/CD agent conduct model rollout using a larger lab workstation (e.g., lambda labs 4x \nGPU machines, approx $20,000 AUD)  \na. E.g. train fully quantized and optimised model for CPU prediction  \n4. Cloud for CPU -based inference - pay per usage (CPU time)  \na. Or, Cloud for GPU -based inference  \n \nLocal development, cloud training, cloud inference  \n \nIf your organisation is more cloud -savvy you can spin out training nodes, utilise AI platforms, and so \non. \n \n1. Training data storage in cloud  \n2.",
        "node_64": "1. Training data storage on local NAS  \n2. Training and model development using local deep learning workstations  (e.g., $ 8000 AUD \nworkstations)  \n3. Via CI/CD agent conduct model rollout using a larger lab workstation (e.g., lambda labs 4x \nGPU machines, approx $20,000 AUD)  \na. E.g. train fully quantized and optimised model for CPU prediction  \n4. Cloud for CPU -based inference - pay per usage (CPU time)  \na. Or, Cloud for GPU -based inference  \n \nLocal development, cloud training, cloud inference  \n \nIf your organisation is more cloud -savvy you can spin out training nodes, utilise AI platforms, and so \non. \n \n1. Training data storage in cloud  \n2. Training and model development using local deep learning workstations (e.g., $6000 AUD \nworkstations)  \n3. Via CI/CD agent to spin up GPU nodes and train model in cloud - pay per usage (GPU and CPU \ntime)  \na. E.g., spin up GPU node in AWS to train then shutdown",
        "node_65": "b. E.g., use off the shelf AI platforms (e.g., AWS SageMaker, Google Colab, Google API \nplatform, and so on).  \n4. Cloud for CPU -based inference - pay per usage (CPU time)  \na. Or, Cloud for GPU -based inference  \n \nImportant note  \n \nDevelopers will need a workstation capable  of running a subset of the data through the model locally \nto test that it is working.  The right tools are needed.  \nTaking it for a test run  \nThe best way to validate your organisational processes and infrastructure is to build a machine learnt \nsystem inter nally.  We have detailed summary of the current  work and its limitations  (described in the \nAppendices at the end of this document).  \n \nThe initial phase of the project undertaken with the AIML research team helped Think Digital in going \nthrough the first ite ration of machine learning model development lifecycle process. We feel this is a \ngood first starting point  as it will stress multiple aspects of the infrastructure and organisational \nprocesses.   \n \nCurrent work signifies the importance of addressing several  challenges related to building and \ndeploying robust Machine Learning based systems. Undertaking this task as an organisation will help \nyou understand that if you have adequate provisioned infrastructure, and whether your organisational \nprocesses are align ed enough to make it a reality.   \n \nSpecifically, it will help you test your:  \n\u25cf Training infrastructure - is the system large enough to handle the training imagery you have \nacquired?  \n\u25cf Production infrastructure - is the serving host large enough to predict at t he cadence you \nrequired? Real time? Batch operations?  \n\u25cf Staffing - do you have the appropriate expertise in house to develop and troubleshoot the \ncomputer vision techniques being applied to the satellite imagery?  \n\u25cf Deployment processes - is the deployment of t he model frictionless? Are you able to watch it \nin production? How do you measure its accuracy and performance?  \n\u25cf Usefulness - does the model actually provide value to the customers? How are you measuring \nthis?  \n\u25cf Steering committee - does the committee underst and the model?",
        "node_66": "Specifically, it will help you test your:  \n\u25cf Training infrastructure - is the system large enough to handle the training imagery you have \nacquired?  \n\u25cf Production infrastructure - is the serving host large enough to predict at t he cadence you \nrequired? Real time? Batch operations?  \n\u25cf Staffing - do you have the appropriate expertise in house to develop and troubleshoot the \ncomputer vision techniques being applied to the satellite imagery?  \n\u25cf Deployment processes - is the deployment of t he model frictionless? Are you able to watch it \nin production? How do you measure its accuracy and performance?  \n\u25cf Usefulness - does the model actually provide value to the customers? How are you measuring \nthis?  \n\u25cf Steering committee - does the committee underst and the model? Does it have the required \nexpertise for the team internally to lean on to get the model built and deployed?  \n\u25cf Governance - are you appropriately applying privacy laws? Do users have the ability to access \nand delete information stored about the m? Are you informing customer before collecting or \nusing their data ? \n \nYou will be in a better position to answer questions as you go about building the organization and \ninfrastructure.",
        "node_67": "AI maturity advancement  \nWe would expect that Think Digital  would reach an AI maturity level of 2 by starting to adopt some of \nthese practices in the first year of adopting this roadmap.  \n \nIn particular you would expect to see Think Digital \u2019s engineering team developing prototypes, \nexperimenting with research -level code and prototypes.  Think Digital  will have developed \ndemonstrator -level applications that use static datasets extracted from the platform.  \n \nThe organisation will be learning about the possibilities by applying a hands -on approach, trying out \nmodel s, seeing what works and what doesn't.  If a pilot study shows particular promise, we could \nexpect that Think Digital  may adopt it into the platform as a beta or hidden tool that some customers \nmay access.",
        "node_68": "Think Digital  in 3 years  \nThink Digital  is transitioning into becoming an active ML  organisation  - they have several pilot studies \nunderway and they start to collapse these into an AI tool appropriate to their company. They are aiming \nto have at least one model running in production and providing va lue to customers.  \nPilot studies into AI Platform  \nAt the start of the 2nd year into our roadmap, we would expect to have at least 1 or multiple  pilot \nstud ies underway (e.g., automatically classifying cattle diseases ( i.e. FMD , LSD and healthy )).  This \npilot  study will now be maturing into a demonstrable application.  \n \nThink Digital has already worked with the AIML research and engineering team to develop  first version \nof dataset and model. The pilot  study  code still needs  a lot of  work in terms of generalizing, \nproductionizing and reliable deployment  infrastructure (both code level  and hardware level) of the AI \nmodel.  \n \nThink Digital  should be looking at how they can take this model, and operationalise it (with a view to \nhitting a Level 3 AI maturity  level). Specifically , they will need to take the pilot study code, and:  \n\u25cf Orchestrate retraining of the model  \n\u25cf Orchestrate deployment of the model into a service that is used by the app/website  \n\u25cf Roll out the model into the production setting, monitoring its impact, and measuring customer \n\u201cuplift\u201d based on the use of the model (e.g., does the model provide a useful automation that \nis bringing people back to the app?) \n \nAdditional pilot studies should now be undertaken.  Specifically, once a first model is deploy ed, \nmonitored, and easily updatable in response to bugs and new data versions.  \n \nAs each of these pilot studies mature into demonstrable capabilities, they should be folded into the \n\u201cAI Platform\u201d that has been developed to support the first pilot study. The  first few pilots that are \nfolded in may require updates, rework and tweaking of the overall system - as the organisation learns \nto adopt AI components into its existing feature set.",
        "node_69": "Additional pilot studies should now be undertaken.  Specifically, once a first model is deploy ed, \nmonitored, and easily updatable in response to bugs and new data versions.  \n \nAs each of these pilot studies mature into demonstrable capabilities, they should be folded into the \n\u201cAI Platform\u201d that has been developed to support the first pilot study. The  first few pilots that are \nfolded in may require updates, rework and tweaking of the overall system - as the organisation learns \nto adopt AI components into its existing feature set.  \nContinued organisational alignment  \nThink Digital  will need to continue it s ongoing organisation realignment if it wishes to continue to gain \nAI maturity.  \n \nProcesses will need to be developed for automated data collection, labelling, and quality control  \n \nThe cohort of people employed within the company will also need to shift - it is at this stage that a \nmachine learning engineering team, data scientists, and possibly a chief data officer should be \nconsidered.  This team will be the \u201ccore\u201d of features that are developed and integrated into the \nplatform moving forward.",
        "node_70": "The follow ing diagram explores a possible layout of tasks, data and people might look like at Think \nDigital  in 3 or more years.  \n \nFigure 1: Possible structure of an AI Processes at Think Digital.  \n \nWe can see that we have the existing user faci ng application at the head of the processes . This will be \ninstrumented to capture customer data, in the form of labels (e.g., manual annotation of cattle",
        "node_71": "images ), analytics (e.g., how long they spend in the app, where they fail, where they succeed), and \nmodel feedback (e.g., ranking / rating on how good a prediction was for a new map).  \n \nThe data will be fed into a \u201cdata lake\u201d - e.g., untransformed, unstructured data placed typically in date \nbins left in raw form.   \n \nData engineers will then convert this r aw data into usable datasets for machine learning and analytics \nsuch as by transforming into queryable forms (e.g., in a database, or columnar storage formats such \nas Parquet).  \n \nMachine learning engineers will review, visualise and explore these datasets t o implement new \nmachine learning models.  They will work with data scientists to understand which techniques are \napplicable and performant.  They will feed up to the data engineers to ensure the data being captured \nand ETL processes are adequate (and often  help out in this process, wearing two hats typically).  \n \nFinally , the machine learning team (e.g., ML engineers and data scientists) will iterate on, expand, test \nand validate machine learning products, and deploy them into the user facing application.  \nData collection  \nTo improve the AI  models for cattle disease identification, Think Digital must focus on collecting \ndiverse and comprehensive data. This is crucial because diseases can appear differently in cattle \nfrom different regions, such as Indonesia and  Northern Australia.  \n \nDiverse Data Collection: The company should gather data on all symptom variations, emphasizing the \ninclusion of images from multiple cattle breeds, especially those like the target breeds. It's important \nto document diseases on variou s body parts, especially where symptoms are most prominent. The \ncollection should also account for different environmental conditions, such as varying cleanliness \nlevels and types of dirt exposure.  \n \nEnvironmental and Contextual Factors: Collect  data under a wide array of conditions. This includes \ncapturing images in different lighting conditions, both indoors and outdoors, clean and muddy, and at \nvarious times of the day. Data should also be gathered across seasons to reflect different weather \nconditions li ke sun, rain, and cloudiness.",
        "node_72": "This is crucial because diseases can appear differently in cattle \nfrom different regions, such as Indonesia and  Northern Australia.  \n \nDiverse Data Collection: The company should gather data on all symptom variations, emphasizing the \ninclusion of images from multiple cattle breeds, especially those like the target breeds. It's important \nto document diseases on variou s body parts, especially where symptoms are most prominent. The \ncollection should also account for different environmental conditions, such as varying cleanliness \nlevels and types of dirt exposure.  \n \nEnvironmental and Contextual Factors: Collect  data under a wide array of conditions. This includes \ncapturing images in different lighting conditions, both indoors and outdoors, clean and muddy, and at \nvarious times of the day. Data should also be gathered across seasons to reflect different weather \nconditions li ke sun, rain, and cloudiness. Including a range of cattle ages and genders, particularly if \nsymptoms vary between them, is also essential.  \n \nDetailed Imaging and Comparative Analysis: Using macro photography will provide detailed images of \nsymptoms, crucial  for accurate disease identification. Images should cover different cattle body parts \nand viewpoints. Comparing these images with those of healthy cattle will help distinguish between \nhealthy and diseased states more effectively.  \n \nBy implementing these strategies, Think Digital can enhance the robustness  and adaptability of its AI \nmodels. This approach ensures that the models are trained on data that closely aligns with the end -\nuser's needs and can adapt to changing disease presenta tions and environmental factors.",
        "node_73": "AI maturity advancement  \nWithin 3 years Think Digital  should be aiming to hit a maturity level of 3.  This means that they should \nhave at least 1 operational application feature, integrated into the customer facing (interna l or \nexternal) aspects of their business, that is completely leveraging a machine learning approach.   \n \nMonitoring models, data versioning, mature data pipelines, and frictionless model deployment into the \nproduction environment should now be common practi ce.  The existing platform can seamlessly \nutilise the machine learning models and code, without impacting performance or previous \nfunctionality. Customers should be able to derive value from the machine learnt feature - for example, \nfarm owners having thei r cattle  diagnosed for different diseases using an app.  \n \nDuring this phase, with a steady machine learning operation  footing, Think Digital  should be applying \nfunding into researching disruptive ways they could apply machine learning within their tools, \nincluding development of new models if they have access to appropriate machine learning expertise.",
        "node_74": "Appendices  \n \nAppendix A:  Current Work Summary  \n \nIn the initial phase of the project  with AIML Researchers (lead by Yifan Liu), the AIML Research team \ndeveloped a data pre -processing solution and trained a model. The custom model that was developed \nclassified images in to one of three classes; 1. Foot and Mouth Disease (FMD), 2. Lumpy Skin Disease \n(LSD), and 3. Healthy. The research concluded with the esta blishment of an API endpoint and the \ndeployment of the model. For the small training dataset  of roughly 5000 images , the validation \naccuracy was high, but the model accuracy was unreliable when tested with previously unseen \nimages (Appendix B:  Examples of  problems with the current model, page 1 7).   \n \nFollowing the project handover from the research team, the AIML Engineering team engaged to \naugment the preliminary work. Initial steps involved verification checks and a review of the codebase \nprovided by Aki de Liu et. al., the engineering team refined the project documentation, including \nupdating READMEs, to make it easier for Think Digital to use the work.    \n \nThe AIML engineering team also added Docker2 support for easier setup of the development \nenvironmen t.  Multiple Docker images were set up for; 1. Model training, 2. Backend API hosting, and \n3. The Front -end. Additionally, Docker Compose support was added to simplify testing and \ndevelopment of the Docker images. These were deployed onto cloud infrastruct ure using Terraform \nscripts via Kubernetes.  These deployments were used by the engineering team to test system \ncomponents and provide essential information about model performance and hardware requirements \nfor different use cases of the components.  \n \n  \n                                                           \n2 https://www.docker.com/",
        "node_75": "Appendix B:  Recommendations  \n \nTo train a robust classification model for cattle diseases like Foot and Mouth Disease (FMD) and \nLumpy Skin Disease (LSD), it is essential to collect and annotate  a large  dataset. This dataset should \ninclude images of various cattle breeds from different locations, showcasing a range of health \nconditions and disease stages. The images must capture diverse environmental conditions, including \nvariations in lighting and perspective, and should focus on specific regions of interest , such as body \nparts where diseases are typically observed. The conditions of the cattle, whether muddy, wet, dry, \nclean, dirty, or dusty, should also be represented in the dataset. A minimum scale of 100,000 to 1 \nmillion images is recommended to ensure th e model's effectiveness and accuracy in real -world \nscenarios.  \n \nData labelling is a next logical step after collecting data. It should be taken care in parallel with the \ndata collection process, where the  incoming data is constantly labelled  and verifi ed. It is crucial to \nestablish precise and detailed data annotation guidelines. For LSD, annotations must focus on the \ncharacteristics of nodules, including their size, shape, and texture. It is important to document the \nprogression of these nodules from early stages, where they may appear small and firm, to later stages \ncharacterized by necrosis or ulceration. Additionally, annotators should pay attention to changes in \nskin texture and signs of inflammation around the nodules, such as reddened skin or rough pat ches.  \n \nFor FMD, the guidelines should emphasize the annotation of lesion locations, especially around the \nmouth, feet, and teats, and the condition of these lesions, whether they are blisters, ulcerations, or raw \nareas. Annotators must also record secondar y symptoms and behavioural  changes, including \nexcessive drooling, swelling, redness, and signs of lameness or reluctance to move. These \nannotations should be made in collaboration with veterinary experts to ensure accuracy and reliability, \nproviding the mo del with comprehensive and nuanced data for effective disease identification.",
        "node_76": "Appendix C:  Examples of problems with the current model  \n \n  \nFigure 2.  Calf Examples of False Positives: Healthy cow being identified as LS D (left), and FMD (right)",
        "node_77": "Figure 3: Examples of False Positives: Healthy cow being identified as LSD (left), and FMD predicted as LSD (right)",
        "node_78": "Figure 4: Examples of False Positives: LSD cow being identified as Healthy (left), and Healthy cow",
        "node_79": "Our Adelaide.\nBold.\nAspirational.\nInnovative.City of Adelaide\nStrategic Plan  \n2024  \u20132028",
        "node_80": "Vision Aspirations Principles\nAs the capital city of South Australia,  \nAdelaide has a vital role to play in shaping the future of our state.\nOur Adelaide.  \nBold.  \nAspirational.  \nInnovative.Achieving our vision for the future will be guided by our long term aspirations:\nOur Community:  \nVibrant, connected and inclusive\nIn ten years Adelaide will be a growing and thriving \nCapital City with more residents and visitors. Year-\nround events and world-class amenities will create \nvibrancy, support community development and \nconnections, and celebrate our culture, heritage and \ndiversity.\nOur Environment:  \nResilient, protected and sustainable\nIn ten years Adelaide will be a nation leading Green \nCity in a Park showcasing our advanced green \ninfrastructure, increased biodiversity and \nsustainability and a community that is more resilient \nto climate change.Our Economy:  \nGrowing, innovative and responsive\nIn ten years Adelaide will be the strong economic \nfocal point of the state, attracting investment and \ntalent from around the world. New and diverse \nindustries will complement and build on our \neconomic strengths and city businesses will be \nsuccessful and connected to global opportunities.\nOur Places:  \nInteresting, purposeful and safe\nIn ten years Adelaide will be a diverse collection of \nunique or distinctive neighbourhoods and precincts \nthat are connected and accessible. Our public spaces \nwill be designed for people, making them safe and \nlively and a reflection of our history and identity.\nSupported by:\nOur Corporation:  \nHigh performing, customer-centric and bold\nIn ten years people will seek us out as an exciting and trusted employer and partner of choice with a reputation \nfor excellence and achievement. The Corporation will be sector leading in transparency, financial sustainability \nand accountability.\n3 2\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_81": "City of Adelaide tampendi, ngadlu Kaurna \nyertangga banbabanbalyarnendi (inbarendi). \nKaurna meyunna yaitya mattanya Womma \nTarndanyako.\nParnako yailtya, parnuko tappa purruna, parnuko \nyerta ngadlu tampendi. Yellaka Kaurna meyunna \nitto yailtya, tappa purruna, yerta kuma burro \nmartendi, burro warriappendi, burro tangka \nmartulyaiendi. Kumarta yaitya miyurna iyangka \nyalaka ngadlu tampinthi.\nCity of Adelaide acknowledges the traditional \nCountry of the Kaurna people of the Adelaide Plains \nand pays respect to Elders past and present. We \nrecognise and respect their cultural heritage, beliefs \nand relationship with the land. We acknowledge that \nthey are of continuing importance to the Kaurna \npeople living today. And we also extend that respect \nto other Aboriginal Language Groups and other \nFirst\u00a0Nations.Kaurna \nAcknowledgementContents\nVision  ................................................................................................................................. 2\nAspirations  .................................................................................................................. 3\nPrinciples  ....................................................................................................................... 3\nKaurna Acknowledgement  .................................................................... 4\nContents  ........................................................................................................................ 5\nLord Mayor Introduction  .......................................................................... 6\nCouncil Members  ............................................................................................... 7\nOur City  .......................................................................................................................... 8\nOur Opportunities  ............................................................................................ 9\nOur Role  ......................................................................................................................... 10\nOur Response  .......................................................................................................... 11\nOur Community  .................................................................................................. 12\nOur Environment  ................................................................................................ 14\nOur Economy  .......................................................................................................... 16\nOur Places  ................................................................................................................... 18\nOur Corporation  .................................................................................................. 20\nStrategic Planning Framework  .......................................................... 24\nResource Plan 2024\u20132028  ........................................................................ 26\n5 4\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_82": "Council Members\nFrom left to right:\nCouncillor Mary Couros (North Ward), Councillor Arman Abrahimzadeh OAM (Area), Deputy Lord Mayor Keiran \nSnape (South Ward), Councillor Simon Hou (Central Ward), The Right Honourable Lord Mayor of Adelaide Dr Jane \nLomax-Smith AM, Councillor David Elliott (Central Ward), Councillor Carmel Noon (Central Ward), Councillor \nHenry Davis (South Ward), Councillor Phillip Martin (North Ward), Councillor Janet Giles (Area), Councillor Dr Mark \nSiebentritt (South Ward), Councillor Jing Li (Central Ward)Our Council Members for the 2022\u20132026 term of Council:Lord Mayor Introduction\nShaping the future of a city requires bold thinking \nand long-term planning.\nThe capital city council is custodian of the heart of \nour state and it\u2019s up to us to be both aspirational and \naudacious in our vision for Adelaide\u2019s CBD.\nBut we also need to deliver on the core business of \ncouncil \u2013 roads, rates, and rubbish \u2013 if we want to be \nbold in other areas and live in a city of which we can \nbe proud.\nThe City of Adelaide\u2019s Strategic Plan 2024\u20132028 \ncharts a course for our Council to achieve its long-\nterm goals across the economy, the environment and \nthroughout our community.\nThis Strategic Plan aspires to improve our \nstreetscapes, deliver economic viability for \nbusinesses, help property owners to better utilise and \nprofit from their investment and boost residential \naccess, affordability and amenity.\nThe Plan also maps out how Council can maintain its \nassets, reduce kerbside waste, achieve zero functional \nhomelessness, and sensibly increase our population \nto 50,000 people by 2036.\nIt\u2019s also about providing certainty for business \nowners, potential investors, and residents \u2013 matched \nby a commitment to deliver on our promises.\nOur residents, workers, and visitors are also an \nimportant part of our Strategic Plan, and we valued \nyour feedback during the consultation period.\nThe Strategic Plan gives us an opportunity to choose \na different trajectory for Adelaide, and its future over \nthe next four years.",
        "node_83": "This Strategic Plan aspires to improve our \nstreetscapes, deliver economic viability for \nbusinesses, help property owners to better utilise and \nprofit from their investment and boost residential \naccess, affordability and amenity.\nThe Plan also maps out how Council can maintain its \nassets, reduce kerbside waste, achieve zero functional \nhomelessness, and sensibly increase our population \nto 50,000 people by 2036.\nIt\u2019s also about providing certainty for business \nowners, potential investors, and residents \u2013 matched \nby a commitment to deliver on our promises.\nOur residents, workers, and visitors are also an \nimportant part of our Strategic Plan, and we valued \nyour feedback during the consultation period.\nThe Strategic Plan gives us an opportunity to choose \na different trajectory for Adelaide, and its future over \nthe next four years.\nBut importantly, it will be our promise to deliver on \nour commitments.\nDr Jane Lomax-Smith AM  \nLord Mayor City of Adelaide\n7 6\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_84": "Our Opportunities\nThis Plan has been developed in a time of change and \nuncertainty for our city and community \u2013 the post \npandemic environment, inflation forecasts, housing \ncrisis and climate change are at the top of Council\u2019s \nagenda. These challenges bring new opportunities. \nOver the next decade our population will grow and \nbecome more diverse. Health, wellbeing, equity and \ninclusion will continue to play important roles in \nsupporting a changing population. We will need new \ndevelopments to provide quality housing for a \nprojected 50,000 residents in the near future. Our \nCity Plan will guide where this growth should occur, \ncomplemented by revitalisation of our streets and \nprecincts where year-round events and quality \namenities will create vibrancy and celebrate our \nrich\u00a0culture. \nOur city in the future will be an interconnected \ncollection of unique neighbourhoods and precincts \nwhich offer diverse local experiences. We will \npromote social connectivity by making sure our \nstreets are lively and accessible and putting people \nand nature first when we design our public spaces.\nAction on climate change has become more urgent \nand we will support our city to adapt and be climate \nresilient. We will ensure that our residents and visitors \nare prepared, and where possible protected, from hazards such as heatwaves. Adelaide can be a nation \nleading Green City in a Park with new ways to re-use \nold buildings and a greener built form, supporting a \ncircular economy and low-carbon city.\nUncertain global economic conditions generated \nfrom COVID-19 recovery, resource and labour \nshortages, disrupted supply chains, interest rate rises, \ninternational conflicts and geo-political tensions, are \nlikely to continue impacting national and local \neconomies. These challenges have encouraged us to \nre-consider how we procure, how we develop our \nlocal workforce, how we can be financially \nsustainable and how we partner across all levels of \ngovernment and with private enterprises.\nWe will focus on our economy and how people are \nchoosing to work, emerging industries and the \nongoing digital transformation through artificial \nintelligence and cashless transactions.",
        "node_85": "We will ensure that our residents and visitors \nare prepared, and where possible protected, from hazards such as heatwaves. Adelaide can be a nation \nleading Green City in a Park with new ways to re-use \nold buildings and a greener built form, supporting a \ncircular economy and low-carbon city.\nUncertain global economic conditions generated \nfrom COVID-19 recovery, resource and labour \nshortages, disrupted supply chains, interest rate rises, \ninternational conflicts and geo-political tensions, are \nlikely to continue impacting national and local \neconomies. These challenges have encouraged us to \nre-consider how we procure, how we develop our \nlocal workforce, how we can be financially \nsustainable and how we partner across all levels of \ngovernment and with private enterprises.\nWe will focus on our economy and how people are \nchoosing to work, emerging industries and the \nongoing digital transformation through artificial \nintelligence and cashless transactions. We will \nsupport an inclusive, equitable and thriving economy, \nenabling current and emerging businesses to be \ninnovative and globally competitive.\nBy being bold in how we respond to the challenges \nthat will unfold over the coming years, we will create \nnew opportunities that will have a transformative \nimpact on our city, community and businesses. Our City\nThe City of Adelaide is the capital of South Australia \nand the heart of the state\u2019s civic, cultural and \ncommercial life. This Strategic Plan acknowledges \nthat as a capital city council we need to manage our \nresponsibilities to our 26,000 residents and to all 1.7 \nmillion South Australians.\nWe are bold, aspirational \nand innovative.\nBuilt on the traditional lands of the Kaurna people \nwith a rich and deep Aboriginal heritage, Colonel \nLight planned Adelaide in 1837 with an inspired idea: \nan active city centre and an abundance of open space \nwith the River Torrens at its heart. Colonel Light laid \nout the streets surrounded by Park Lands with \nsquares and gardens to create balance in our built \nand natural form. The Park Lands are now nationally \nheritage-listed and are cherished for their beautiful \namenity, array of uses and unique role as a gateway \nto the city.",
        "node_86": "Our City\nThe City of Adelaide is the capital of South Australia \nand the heart of the state\u2019s civic, cultural and \ncommercial life. This Strategic Plan acknowledges \nthat as a capital city council we need to manage our \nresponsibilities to our 26,000 residents and to all 1.7 \nmillion South Australians.\nWe are bold, aspirational \nand innovative.\nBuilt on the traditional lands of the Kaurna people \nwith a rich and deep Aboriginal heritage, Colonel \nLight planned Adelaide in 1837 with an inspired idea: \nan active city centre and an abundance of open space \nwith the River Torrens at its heart. Colonel Light laid \nout the streets surrounded by Park Lands with \nsquares and gardens to create balance in our built \nand natural form. The Park Lands are now nationally \nheritage-listed and are cherished for their beautiful \namenity, array of uses and unique role as a gateway \nto the city.\nOur iconic Adelaide Central Market, Rundle Mall and \nPark Lands provide commercial, social and green \nspaces for people to meet, play and relax. Adelaide is \nan attractive, contemporary city which embraces \nquality design innovation while recognising and \nvaluing the city\u2019s cultural and built form heritage and \nthe unique features of Colonel Light\u2019s plan. \nAdelaide is known for being progressive, resilient, \nbold, trailblazing and enterprising. This strong \nAdelaide spirit has seen us withstand the times of \nglobal social and economic disruption, and emerge \nwith a reputation for being a leading commercial, \nknowledge sharing and ideas exchange city. \nWe aspire to strengthen what we know makes \nAdelaide one of the world\u2019s most liveable cities. We \nare leveraging our past and looking to the future to \ngrow an exceptional Capital City that all South \nAustralians can be proud of.Our City\n760ha\nPark Lands  including 29 parks and six squares\n15.6km2\ntotal land area\n14,660\nprivate dwellings\n12,265\nlocal businesses\n$21.9 Billion \nCity of Adelaide Gross Regional Product.",
        "node_87": "Adelaide is known for being progressive, resilient, \nbold, trailblazing and enterprising. This strong \nAdelaide spirit has seen us withstand the times of \nglobal social and economic disruption, and emerge \nwith a reputation for being a leading commercial, \nknowledge sharing and ideas exchange city. \nWe aspire to strengthen what we know makes \nAdelaide one of the world\u2019s most liveable cities. We \nare leveraging our past and looking to the future to \ngrow an exceptional Capital City that all South \nAustralians can be proud of.Our City\n760ha\nPark Lands  including 29 parks and six squares\n15.6km2\ntotal land area\n14,660\nprivate dwellings\n12,265\nlocal businesses\n$21.9 Billion \nCity of Adelaide Gross Regional Product.  \n17.6% of Gross State Product\n157,498\njobs\nOur Community\n26,120\nresidents\n47%\naged between 18 and 34\n20% \naged 60 and over\n45%\nborn overseas\n36%\nspeak a language other than English\n26%\nstudy at Tafe or University\n50%\nrenting\n9 8\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_88": "Our Role\nThe City of Adelaide has developed this Strategic Plan \n(the Plan) as guided by the  Local Government Act \n(SA) 1999 , which requires councils to develop and \nadopt plans for the management of its area, informed \nby the provisions of the City of Adelaide Act 1998 . \nThis Plan is supported by a Resource Plan which \nguides the finance, infrastructure and resources that \nunderpin delivery over the next four years, as well as \na suite of longer-term interconnected vision and \neconomic plans.\nThis Plan is not only for Council, it is a Plan for our \nratepayers, residents, visitors, workers and all key \nstakeholders. As the Capital City Council for all South \nAustralians, we need to be outward looking, to work \ncollaboratively with Federal, State and Local \nGovernments and to demonstrate excellence, \ninnovation and exceptional service provision.\nThis Plan reflects our commitment to working with \nothers to shape the future of our City for the benefit \nof the whole State. We will continue to build strong \npartnerships to advocate for the benefit of the city \nand leverage our relationships to seek co-investment, \ngrants and contributions to the benefit of our \ncommunity. Key partnerships include those with the \nFederal, State and Local Government sectors, and \nstrategic non-government (private sector, community \ngroups and not-for-profit) organisations.\nIn developing this Plan we have considered our \ndiverse and complex roles and the levers we can use \nto implement and influence change.The City of Adelaide is a:\n\u2022 Leader: Developing strategies, policies, programs \nand services that chart a clear course for Adelaide. \n\u2022 Owner/Custodian: Managing community assets \nthat are entrusted to Council.\n\u2022 Regulator: Undertaking our role under State \nlegislation to keep the city safe, clean and orderly.\n\u2022 Information Provider: Providing information about \nCouncil and the city to the general community and \nstakeholders.\n\u2022 Advocate: Representing the interests of our \ncommunity to influence issues/opportunities that \nimpact our city.\n\u2022 Facilitator/Initiator: Bringing together and \nengaging with individuals, community groups, \nindustry, government agencies and other \nstakeholders to address issues impacting the city.",
        "node_89": "In developing this Plan we have considered our \ndiverse and complex roles and the levers we can use \nto implement and influence change.The City of Adelaide is a:\n\u2022 Leader: Developing strategies, policies, programs \nand services that chart a clear course for Adelaide. \n\u2022 Owner/Custodian: Managing community assets \nthat are entrusted to Council.\n\u2022 Regulator: Undertaking our role under State \nlegislation to keep the city safe, clean and orderly.\n\u2022 Information Provider: Providing information about \nCouncil and the city to the general community and \nstakeholders.\n\u2022 Advocate: Representing the interests of our \ncommunity to influence issues/opportunities that \nimpact our city.\n\u2022 Facilitator/Initiator: Bringing together and \nengaging with individuals, community groups, \nindustry, government agencies and other \nstakeholders to address issues impacting the city.\n\u2022 Agent: Providing of services to the community on \nbehalf a third party (e.g. State or Federal \nGovernment) where there is demonstrated need \nand significant benefit to the community.\n\u2022 Direct Provider: Delivering our core services, \nprojects or programs.\n\u2022 Partner: Working with others to deliver services, \nprograms or projects outcomes. Our Response\nOver the past decade, we have heard from our \ncommunity that our city must grow if we want to \nthrive, but this growth should not come at the \nexpense of what has made our city one of the most \nliveable in the world.\nTo ensure we maintain our liveability and to support \ngrowth, these principles will underpin everything \nwe\u00a0do:\n\u2022 Exceptional Amenity \u2013 Be bold and courageous in \nour pursuit of excellence for our city.\n\u2022 Quality Housing \u2013 Strive for liveability and \naffordability to attract and retain residents.\n\u2022 Community Connection \u2013 Strengthen connection, \naccessibility, diversity and inclusivity by putting \npeople first.\n\u2022 Unique Experiences \u2013 Create interesting \nexperiences for our residents, workers and visitors.\n\u2022 Climate Resilience \u2013 Embed climate resilience in all \nthat we do.\n\u2022 Economic Growth \u2013 Encourage innovation, \ninvestment and development in current and \nemerging sectors. \n\u2022 Budget Repair \u2013 Provide quality services and ensure \nlong-term financial sustainability.",
        "node_90": "To ensure we maintain our liveability and to support \ngrowth, these principles will underpin everything \nwe\u00a0do:\n\u2022 Exceptional Amenity \u2013 Be bold and courageous in \nour pursuit of excellence for our city.\n\u2022 Quality Housing \u2013 Strive for liveability and \naffordability to attract and retain residents.\n\u2022 Community Connection \u2013 Strengthen connection, \naccessibility, diversity and inclusivity by putting \npeople first.\n\u2022 Unique Experiences \u2013 Create interesting \nexperiences for our residents, workers and visitors.\n\u2022 Climate Resilience \u2013 Embed climate resilience in all \nthat we do.\n\u2022 Economic Growth \u2013 Encourage innovation, \ninvestment and development in current and \nemerging sectors. \n\u2022 Budget Repair \u2013 Provide quality services and ensure \nlong-term financial sustainability.\n11 10\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_91": "Our Community\nVibrant, connected and inclusive\nOur Objective is to:\n\u2022 Support our communities to thrive\n\u2022 Create fun, lively and interesting experiences\n\u2022 Celebrate and honour community and cultures\nOutcome Key Actions Indicator of Success/Measures/Targets\nDrive affordable, \nsafe and quality \nhousing outcomes \nthat attract and \nretain residents in \nour cityWork with partners to identify new and \ninnovative ways to reduce rough sleeping \nand\u00a0homelessness\nContribute towards achieving Zero \nFunctional\u00a0Homelessness\nSupport increased residential growth and \nhousing affordability through partnerships and \nadvocacy\nReduce rental pressures by increasing housing \nsupply and unlocking properties for long-\nterm\u00a0tenantsAttract investment to deliver 600 affordable \nrental properties by 2028 in line with Council\u2019s \nHousing Strategy\nIncrease the use of the City of Adelaide or \nState Government incentive schemes or grants \nto increase diversity in housing, public realm, \nsustainability and community facilities in line \nwith Council\u2019s Housing\u00a0Strategy\nIncrease the number of people living in the city \nfrom 26,000 to 50,000 by 2036\nReduce the incidences of people sleeping \nrough or experiencing homelessness to \nfunctional zero by 2026 in line with Council\u2019s \nHomelessness Strategy\nIncrease the share of family households from \n12.5% to 15% living in the city\nSupport 29 State Government housing \noutcomes per month in the City of Adelaide for \npeople experiencing homelessness to 2026 in \nline with Council\u2019s Homelessness StrategyOutcome Key Actions Indicator of Success/Measures/Targets\nAn interesting and \nengaging place to \nlive, learn and\u00a0visitEnable community-led services which increase \nwellbeing, social connections and participation \nin active lifestyles, leisure, recreation and sport\nDrive social change and strengthen \ncommunities through locally-led arts, cultural \nand recreational activities\nElevate the City\u2019s reputation for exceptional \nand unique arts and cultural experiences by \nencouraging and providing arts, culture and \nevents partnerships, grants and \nsponsorship\u00a0opportunities\nLead and create opportunities for people to \nexpand knowledge, learn,",
        "node_92": "5% to 15% living in the city\nSupport 29 State Government housing \noutcomes per month in the City of Adelaide for \npeople experiencing homelessness to 2026 in \nline with Council\u2019s Homelessness StrategyOutcome Key Actions Indicator of Success/Measures/Targets\nAn interesting and \nengaging place to \nlive, learn and\u00a0visitEnable community-led services which increase \nwellbeing, social connections and participation \nin active lifestyles, leisure, recreation and sport\nDrive social change and strengthen \ncommunities through locally-led arts, cultural \nand recreational activities\nElevate the City\u2019s reputation for exceptional \nand unique arts and cultural experiences by \nencouraging and providing arts, culture and \nevents partnerships, grants and \nsponsorship\u00a0opportunities\nLead and create opportunities for people to \nexpand knowledge, learn, and master new\u00a0skillsIncrease in residents\u2019 wellbeing from 70% to \n75% life satisfaction\nDevelop a target for increasing participation in \narts, events and cultural experiences facilitated \nor supported by the City of Adelaide \nReview the Active City Strategy by 2025\nDevelop an overarching grants policy to \nsupport diversity in arts, culture, community \ndevelopment, recreation and wellbeing by 2025\nAmplify Adelaide\u2019s status as a UNESCO City \nof\u00a0Music \nInvestigate opportunities for a Centre of\u00a0Music\nReview library and community centre service \ndelivery model to better meet the evolving \ncommunity\u2019s need by 2025\nDevelop a Community Wellbeing Plan by\u00a02026\nIncrease the diverse opportunities for volunteer \nparticipation in line with the Volunteering \nAustralia national standards\nAn inclusive, \nequitable and \nwelcoming \ncommunity where \npeople feel a sense \nof belongingChampion Reconciliation and recognition of \nAboriginal and Torres Strait Islander peoples \nand culture by identifying opportunities to \ncelebrate and elevate Kaurna culture and \nconnection to Country\nCelebrate and elevate our community culture \nand the profiles of multicultural communities \nand create welcoming programs and services\nSupport belonging through an inclusive and \nwelcoming community that recognises \ndiversity and enables people of all abilities \nliving, working and visiting the city\nCreate sustained, respectful,",
        "node_93": "equitable and \nwelcoming \ncommunity where \npeople feel a sense \nof belongingChampion Reconciliation and recognition of \nAboriginal and Torres Strait Islander peoples \nand culture by identifying opportunities to \ncelebrate and elevate Kaurna culture and \nconnection to Country\nCelebrate and elevate our community culture \nand the profiles of multicultural communities \nand create welcoming programs and services\nSupport belonging through an inclusive and \nwelcoming community that recognises \ndiversity and enables people of all abilities \nliving, working and visiting the city\nCreate sustained, respectful, and inclusive \nopportunities that encourage full participation \nof people from diverse backgrounds in the \ncultural and social life of the City by ensuring \nour services and projects are accessible and \ninclusive for allEstablish and deliver a new Stretch \nReconciliation Action Plan by 2024\nDevelop a target to increase the number of \nAboriginal and Torres Strait Islander-led \ncommunity reconciliation activities\nSupport Aboriginal and Torres Strait Islander \nemployment at the City of Adelaide to be \nhigher than 2%\nPromote multicultural events and activities in \nour city \nEstablish a new Diversity, Access and Inclusion \nPlan by 2024\nDevelop a Social Infrastructure Policy by 2024 \nto support our current and emerging \ncommunity needs\nDevelop a Cultural Policy by 2024 that \npromotes and supports the City\u2019s unique \ncultural identity and opportunities\n13 12\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_94": "Our Environment\nResilient, protected and sustainable\nOur Objective is to:\n\u2022 Protect, enhance, and activate our Park Lands and open space\n\u2022 Be climate conscious and resilient\n\u2022 Prioritise sustainability in our decisions for the future\nOutcome Key Actions Indicator of Success/Measures/Targets\nLead as a Low \nCarbon \nEmissions\u00a0City  Implement sustainable, renewable and green \nsystems, infrastructure, practices and materials \nin our projects and services\nGenerate, lead and support new circular \neconomy activities to support sustainability \nand economic outcomes\nWork with partners including universities, and \nresearchers to innovate and transform \ncarbon\u00a0reliance \nAdvocate for an increase in sustainable \npractices and materials in all development, \noffset by tree and renewal energy\u00a0integration\nMake public electric vehicle charging \ninfrastructure available for all users, including \nmicro-mobility, catalysing the uptake of \nelectric vehicles in Adelaide and improving \nCouncil and community performance on \ntransport emissionsDevelop a target to increase green \ninfrastructure in our assets to support and \nenhance our environment\nIncrease the number of electric vehicle \ncharging stations from 54 in line with Council\u2019s \nClimate Strategy\nReview Procurement Policies and Guidelines by \n2024 to include requirements that support \nCircular Economy outcomes\nSupport a 50% reduction in the city\u2019s \ncommunity greenhouse gas emissions by 2030 \nfrom the 2020 baseline with an ambition to be \nnet zero by 2035Outcome Key Actions Indicator of Success/Measures/Targets\nA sustainable city \nwhere climate \nresilience is \nembedded in all \nthat we doWork with our partners to plan for, lead and \neducate our community on a climate \nresilient\u00a0future\nSupport the adaptation of buildings and \nindustries to make them sustainable, with \nincreased resource-use efficiency and greater \nadoption of clean and environmentally sound \ntechnologies and\u00a0processes\nWork with partners to access data to track the \nnumber of green upgrades or new\u00a0buildings\nProvide progressive waste management and \nresource recovery services\nPartner with the community to divert more \nwaste from landfillDevelop a Sustainability Governance and \nReporting Framework by 2025 and capture and \nshare data and learnings\nAll asset investment (design,",
        "node_95": "lead and \neducate our community on a climate \nresilient\u00a0future\nSupport the adaptation of buildings and \nindustries to make them sustainable, with \nincreased resource-use efficiency and greater \nadoption of clean and environmentally sound \ntechnologies and\u00a0processes\nWork with partners to access data to track the \nnumber of green upgrades or new\u00a0buildings\nProvide progressive waste management and \nresource recovery services\nPartner with the community to divert more \nwaste from landfillDevelop a Sustainability Governance and \nReporting Framework by 2025 and capture and \nshare data and learnings\nAll asset investment (design, construct and \nmaintenance) considers and embeds \nappropriate climate resilient measures\nSupport the community to reduce their \nclimate impact through the new City of \nAdelaide Climate Strategy \n50 dwellings are delivered annually through \nadaptive reuse of underutilised\u00a0buildings\nAll new dwellings built from 2025 are fully \nelectric (no internal gas supply)\nEstablish a baseline to measure circularity in \nthe City of Adelaide and initiate targets to \nincrease circular economy outcomes\nIncrease diversion from landfill for residential \nkerbside waste from 50% (2020) to 80% \nby\u00a02030 \nThe status, \nattributes and \ncharacter of our \ngreen spaces and \nthe Park Lands are \nprotected and \nstrengthenedContinue the support for the Kadaltilla/\nAdelaide Parklands Authority Subsidiary and \nthe delivery of the Kadaltilla Charter and \nBusiness Plans\nLead and advocate for the environmental \nvalue, productivity, quality and biodiversity of \nthe Park Lands, squares, open space \nand\u00a0streetscapes\nProtect and restore native habitat in our\u00a0city \nWork with partners to create innovative ways \nto create or convert underutilised areas to \ngreen space \nAdvocate for no new development in the Park \nLands and returning Park Lands that have \nbeen\u00a0alienated Achieve a net increase in biodiversity, habitats,",
        "node_96": "attributes and \ncharacter of our \ngreen spaces and \nthe Park Lands are \nprotected and \nstrengthenedContinue the support for the Kadaltilla/\nAdelaide Parklands Authority Subsidiary and \nthe delivery of the Kadaltilla Charter and \nBusiness Plans\nLead and advocate for the environmental \nvalue, productivity, quality and biodiversity of \nthe Park Lands, squares, open space \nand\u00a0streetscapes\nProtect and restore native habitat in our\u00a0city \nWork with partners to create innovative ways \nto create or convert underutilised areas to \ngreen space \nAdvocate for no new development in the Park \nLands and returning Park Lands that have \nbeen\u00a0alienated Achieve a net increase in biodiversity, habitats, \nand ecosystems health within the City of \nAdelaide by 2030\nSupport a net increase in street trees annually \naligned to heat island data within Council\u2019s \nClimate Strategy\nSupport 40% tree canopy cover by 2035 \nDevelop a target to increase green spaces to \nsupport our environment\nAchieve world heritage listing of our Park \nLands, and protect their national heritage \nlisting status and pursue State Heritage listing \nto strengthen protections\nNo loss of Park Lands and seek to reclaim Park \nLands green space in line with the Kadaltilla \nStrategic Plan \nDeliver the Adelaide Park Lands \nManagement\u00a0Strategy\n15 14\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_97": "Our Economy\nGrowing, innovative and responsive \nOur Objective is to:\n\u2022 Continue to grow our economy in alignment with the community\n\u2022 Support existing businesses to be agile and responsive to change\n\u2022 Create strong skilled workforces\nOutcome Key Actions Indicator of Success/Measures/Targets\nAdelaide\u2019s unique \nexperiences and \nopportunities \nattract visitors to \nour cityContinue the support for the Adelaide Central \nMarket Authority (ACMA) Subsidiary and the \ndelivery of the ACMA Charter and \nBusiness\u00a0Plans\nPartner with the State Government, \nuniversities, associations, community and \nadvocacy groups to activate and upgrade \nprecincts to stimulate investment, visitation \nand maximise opportunities\nRefresh the way in which information is \nprovided to visitors to the city\nReinforce the position of Adelaide as the \nState\u2019s central business district and amplify \nAdelaide\u2019s reputation as a place to learn, work \nand start a business Support the delivery of key actions of ACMA\nIncrease the number of people who visit the \ncity from 2.1 million to 2.5 million by 2028 \nthrough local, interstate and \ninternational\u00a0visitation.",
        "node_98": "Increase in foot traffic in key and emerging \nprecincts annually in line with the Council\u2019s \nEconomic Development Strategy\nIncrease spending across the city\nDeliver marketing and promotion strategies to \nshare Adelaide\u2019s unique attributes and \nemerging opportunities Outcome Key Actions Indicator of Success/Measures/Targets\nAchieve a critical \nmass of jobs and \ninvestment and \nattract and retain \nbusinesses by \ngrowing a dynamic, \nholistic\u00a0economyContinue the support for the Adelaide \nEconomic Development Agency (AEDA) \nSubsidiary and the delivery of the AEDA \nCharter and Business Plans \nProvide services and information that \ncontribute towards a high \nproductivity\u00a0economy\nWork with partners, universities and businesses \nto attract investment and improve \nemployment opportunities\nCreate partnerships to grow and develop \ncurrent and emerging sectors such as medical, \ntechnology, creative and professional \nservices\u00a0sectors\nCreate efficiencies and reduce barriers to \nsupport small, medium and large-scale \nbusinesses to open and thrive in our cityCouncil and AEDA to partner with key \nstakeholders to progress economic \ndevelopment and growth outcomes across all \nsectors in the City to increase city contribution \nto Gross State Product\nDevelop a City of Adelaide Economic \nDevelopment Strategy by 2024 to drive\u00a0growth \nSupport the delivery of the key actions of the \nAEDA Strategic Plan to support investors, \nemerging sectors, entrepreneurs and business \nowners to be successful, innovative and \nresponsive to a changing business environment\nDeliver economic data and insights to our \nbusiness community.",
        "node_99": "An increase of businesses who think the city is \na good place to do business from 64% to 75%\nAn increase in the number of new businesses \nand investment in the city\nIncrease the use of social enterprises and \nAboriginal Torres Strait Islander owned \nbusinesses through City of \nAdelaide\u00a0procurement\nCouncil is driving \ndevelopment \nopportunities for \nour community via \ndiverse commercial \nactivitiesWork with partners on the completion of major \ndevelopment outcomes that focus on \neconomic and housing outcomes such as \n88\u00a0O\u2019Connell Street, Market Square and the \nformer Bus Station\nMaintain the Future Fund to support \ninvestment in revenue generating activities to \nreduce ratepayer burdenReview the Strategic Property Action Plan by \n2024 to manage opportunities including car \nparks and other commercial assets for \nour\u00a0community \nDevelop sales and tenancy targets associated \nwith City of Adelaide housing\u00a0developments\nManage the governance arrangements for the \nFuture Fund\n17 16\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_100": "Our Places\nInteresting, purposeful and safe\nOur Objective is to:\n\u2022 Manage assets to meet the needs of our community\n\u2022 Encourage bold, interesting and purposeful development\n\u2022 Facilitate and activate our places in a safe  \nand accessible way for our community\nOutcome Key Actions Indicator of Success/Measures/Targets\nCommunity assets \nare adaptable and \nresponsibly \nmaintained Deliver quality street and laneway upgrades, \nmainstreets, precincts, and neighbourhood \nrevitalisation and improvements that make \nAdelaide well-designed, safe and unique\nCreate new assets to meet emerging \ncommunity needs with a focus on safe design, \nconstruction and maintenance \nSupport the maintenance and development of \nbold and interesting community, cultural and \ncivic places and infrastructure in step with \nresidential growth, enabling connections into \nand out of the city\nWork with partners to increase active and \ndiverse transport measures to ensure drivers, \ncyclists and pedestrians can safely and easily \nmove within the city with a goal to minimise \nroad incidents and decrease\u00a0fatalities\nWork with partners to support safer road \nuser\u00a0behaviour Commence the design of the Hindley Street \nupgrade project by 2023/2024\nCommence the design of the Gouger Street \nupgrade project by 2023/2024\nCommence the design of the O\u2019Connell Street \nupgrade project by 2024/2025\nCommence the design of the Hutt Street \nupgrade project by 2024/2025\nCommence the design of the Melbourne Street \nupgrade project by 2025/2026\nDevelop and implement an Integrated \nTransport Strategy and establish associated \ntargets by 2024 that aligns to the South \nAustralian Road Safety Strategy to 2031\nRevise the Asset Management Plans by \nJune\u00a02024Outcome Key Actions Indicator of Success/Measures/Targets\nEncourage bold, \ninteresting and \npurposeful \ndevelopment that \nsupports the \nchanging needs of \nour community \nand\u00a0cityLead the development of a City Plan that \nprovides guidance on city growth, \ndevelopment,",
        "node_101": "interesting and \npurposeful \ndevelopment that \nsupports the \nchanging needs of \nour community \nand\u00a0cityLead the development of a City Plan that \nprovides guidance on city growth, \ndevelopment, amenity needs and accessibility \nto make Adelaide a liveable and walkable city \nthat people are proud to call home\nCreate and advocate for multi-use green spaces \nsuch as open space, community gardens and \npocket parks that enable shared use and \ncommunity connection\nEncourage repurposing, adaptive reuse and \nimprovement of buildings and facilities\nSupport the development or conversion of \ndiverse and affordable office spaces \nand\u00a0housing \nProtect, share and elevate our heritage and \nculturally significant places, maintaining the \ncharacter while encouraging adaptive reuse, \nrepurposing and upgrading buildings Develop the City Plan by 2024\nIncrease in the number of people who agree \nthat the city is a welcoming and dynamic place \nfull of rich and diverse experiences from 82% \nto 90%\nIncrease in the number of dwellings in our city \nfrom 14,660 (2021) to 17,780 by 2026 and 22,770 \nby 2031\n15% of new dwellings are available as \naffordable purchase or rental to low and \nmoderate income earners\nNo loss of local heritage places and consider \noptions to increase the 1,850 places\nReview the heritage overlays to ensure our \nheritage places are known and accommodated \nduring development by\u00a02025\nDeliver conservation management plans for \nheritage assets by 2025\nCreate safe, \ninclusive and \nhealthy places for \nour communityMaintain and improve disability, LGBTQIA+ and \nvulnerable or minority group access \nand\u00a0inclusion.",
        "node_102": "660 (2021) to 17,780 by 2026 and 22,770 \nby 2031\n15% of new dwellings are available as \naffordable purchase or rental to low and \nmoderate income earners\nNo loss of local heritage places and consider \noptions to increase the 1,850 places\nReview the heritage overlays to ensure our \nheritage places are known and accommodated \nduring development by\u00a02025\nDeliver conservation management plans for \nheritage assets by 2025\nCreate safe, \ninclusive and \nhealthy places for \nour communityMaintain and improve disability, LGBTQIA+ and \nvulnerable or minority group access \nand\u00a0inclusion.\nCreate opportunities for sustained activation in \nthe city through outdoor dining, parking, \nleases and licences \nEncourage interesting and unique experiences \nin public spaces through permit management\nSupport businesses to operate safely\nProvide services that encourage responsible \npet\u00a0ownershipAchieve Disability Access compliance in all new \nand upgraded infrastructure\nReview the Disability Access and Inclusion Plan \nby 2024\nReview the Wellbeing (Public Health) Plan \nby\u00a02026\nReview the Dog and Cat Management Plan \nby\u00a02024\nReview and implement by-laws which respond \nto community needs by 2025\n19 18\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_103": "Our Corporation\nHigh performing, customer-centric and bold\nOur Objective is to:\n\u2022 Effective Leadership and Governance \n\u2022 Exceptional Customer Experience \n\u2022 Financial Sustainability\n\u2022 People Engagement\n\u2022 Strategy, Value and Efficiency\n\u2022 Technology and Information\nOutcome Key Actions Indicator of Success/Measures/Targets\nEffective Leadership \nand GovernanceDemonstrate bold capital city leadership and \nrobust governance with our community at the \nheart of our decisions\nEnable effective governance, risk management, \naccountability and transparency at all times in \ndecision\u00a0makingImplement a Public Transparency Policy by \nJune 2024\nReduce the number of items and Council \ndecisions considered and held in\u00a0confidence\nDeliver a robust internal audit program that \naligns to service outcomes\nReview and monitor the Governance Structure \nto ensure best practice decision making and \nenable effective advice for \nCouncil\u2019s\u00a0undertakings\nReview Emergency Management Plans and \nresponse by 2025\nExceptional \nCustomer \nExperienceListen and respond to our community, \nembedding their perspective to support \ndecision-making\nFocus on the experience of our customers to \nensure outcomes meet expectations \nPromote and communicate the work of\u00a0CouncilAchieve and maintain Voice of the Customer \nSurvey scores for Customer Satisfaction and \nCustomer Ease \nReview marketing and communication policies \nand practices to ensure website and social \nmedia content is reflective of current decisions, \nprojects and servicesOutcome Key Actions Indicator of Success/Measures/Targets\nFinancial \nSustainabilityFocus on budget repair and ensure responsible \nfinancial management through the principle of \nintergenerational equity while delivering \nquality services \nAchieve high value procurement and contracts \nmanagement outcomes \nImprove service efficiency by identifying new \nrevenue streams and creating new \nopportunities for incomeReview the Rating System to ensure optimum \noutcomes by 2024\nDetermine future funding requirements for \ncommunity assets such as Torrens Weir \nenhancement and replacement/strengthening \nof Adelaide Bridge\n100% of procurement is conducted in line with \nrelevant Council policies and supports \nCouncil\u2019s Climate, Diversity, Reconciliation, \nWorkforce and \u2018Buy Local\u2019 strategies \nand\u00a0targets \nReview the Procurement Policy and Guidelines \nto support circular economy, climate resilience,",
        "node_104": "projects and servicesOutcome Key Actions Indicator of Success/Measures/Targets\nFinancial \nSustainabilityFocus on budget repair and ensure responsible \nfinancial management through the principle of \nintergenerational equity while delivering \nquality services \nAchieve high value procurement and contracts \nmanagement outcomes \nImprove service efficiency by identifying new \nrevenue streams and creating new \nopportunities for incomeReview the Rating System to ensure optimum \noutcomes by 2024\nDetermine future funding requirements for \ncommunity assets such as Torrens Weir \nenhancement and replacement/strengthening \nof Adelaide Bridge\n100% of procurement is conducted in line with \nrelevant Council policies and supports \nCouncil\u2019s Climate, Diversity, Reconciliation, \nWorkforce and \u2018Buy Local\u2019 strategies \nand\u00a0targets \nReview the Procurement Policy and Guidelines \nto support circular economy, climate resilience, \nAboriginal and Torres Strait Islander \nemployment and local sourcing by 2024\nFinancial indicators are in line with annual \ntargets (as outlined in the Long-Term Financial \nPlan) with a focus on Asset Renewal Funding \nRatio between 90% and\u00a0110%\nGrow the share of non-rates based revenue\nPeople Engagement Attract and retain people with skills and \nbehaviours which align with our organisational \nobjectives and values \nCreate an organisational culture that enables \nbold and experienced leadership, where our \npeople thrive and are proud to work, making \nthe City of Adelaide an employer of choice\nIdentify and develop the skills, capabilities, and \nleadership needed to support a high \nperforming organisation\nSupport ways of working, which enable \ninformed decision-making and enable agility, \ncollaboration, and innovationAboriginal and Torres Strait Islander \nEmployment at the City of Adelaide to be \ngreater than 2%\nDeliver and maintain a Workforce Strategy by \n2024\nDeliver a City of Adelaide Graduate Program \nby 2025 \nAction recommendations arising from \nemployee feedback tools and risk assessment \nto generate positive employee outcomes\n21 20\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_105": "Outcome Key Actions Indicator of Success/Measures/Targets\nStrategy, Value and \nEfficiencyWork with local, national and international \npartners to deliver the outcomes of the \nStrategic Management Framework to move our \ncity into the future\nCreate, maintain and integrate plans and \npolicies that reflect and guide decision making \nand support our city and our community \nto\u00a0thrive\nUse community feedback, data and research to \nmonitor, maintain and adapt our range of \nquality services to continuously improve the \nvalue and\u00a0efficiencyDevelop and implement a Strategic \nPartnerships Framework to achieve best \npractice outcomes including benchmarking \nopportunities by 2024\nComplete a review of the Strategic Planning \nFramework by 2024\nStrategic and Capital Projects are delivered on \ntime and on budget (target 75%)\nBusiness, Resident and City User Surveys \nidentify overall satisfaction with \nCouncil\u00a0services \nReview the Community Engagement approach \nby 2025\nDevelop baseline data for relevant measures in \nthe Strategic Plan by 2024\nTechnology and \nInformationFocus on integration, digital opportunities and \ninnovative solutions to support business \nefficiency and customer focused \nperformance\u00a0improvements \nContinue to efficiently maintain the rich \nhistorical significance of our archival and \ncivic\u00a0collectionDeliver and maintain Business Systems \nRoadmap to support business efficiency\nDeliver Workforce Management \nSystem\u00a0upgrades\nImplement data integration solutions for \nCustomer Insights to drive efficiency\u00a0outcomes \nIncrease awareness and engagement of staff \nthrough the use of better systems\nImprove and drive efficiency outcomes \nthrough the integration of customer data \nand\u00a0insights\n23 22\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_106": "Strategic Planning Framework\nThis Plan forms part of the City of Adelaide\u2019s suite of Strategic Management Plans.\nStrategic Plan  \nCommunityLong Term with a four year delivery focus.  \nPlanning for the vision and aspirations of the Adelaide Capital City.\nLong Term Financial Plan  \nFinancialTen year Plan, revised annually to ensure a ten year view is maintained. \nPlanning for the long term financial sustainability of the City of Adelaide. \nAsset Management Plans  \nInfrastructureSuite of ten year Plans.  \nPlanning for the sustainable renewal and maintenance of Council assets\nCity Plan  \nDevelopment/ Built FormTen year Spatial Plan.  \nPlanning for the future land uses and built form of the Adelaide Capital City.\nStructure of the Strategic Plan 2024\u20132028 and supporting documents:\nLong Term Considerations\nVision  \nA vision for the future of Adelaide. A leading aspirational statement summarising the focus of the plan and \nguiding decision-making on the future of the city.\nAspirations  \nThat help articulate the vision, expressed as outcomes which help shape future policy positions of Council.\nShort Term Considerations\nPrinciples \nInform primary areas of focus to drive outcomes across the four-year plan. \nObjectives and Outcomes  \nDescribe what will be achieved and the strategies employed.\nKey Actions  \nWhat is being delivered under each objective relevant to Council\u2019s responsibilities (How we will do it)\nIndicators of Success/Measures/Targets  \nProvide an understanding of what long term success looks like (Measures of Success)\nResource Plan\nThe Strategic Plan is supported by a Resource Plan \u2013 the financial, and non-financial resources required for the \nAdministration to enable and support the Strategic Plan\u2019s four year delivery over 2024\u20132028.List of related Strategies, Plans and Policies\nTo bring our Strategic Plan to life, Council has a suite \nof related Strategies, Plans and Policies. These will be \nchanged and refined over time to reflect the key \noutcomes, actions and measures of success outlined \nin this Strategic Plan. The list below highlights the \nprimary relationship of each related strategy, plan or policy, noting that some of these have multiple \nrelationships to the aspirations.",
        "node_107": "Objectives and Outcomes  \nDescribe what will be achieved and the strategies employed.\nKey Actions  \nWhat is being delivered under each objective relevant to Council\u2019s responsibilities (How we will do it)\nIndicators of Success/Measures/Targets  \nProvide an understanding of what long term success looks like (Measures of Success)\nResource Plan\nThe Strategic Plan is supported by a Resource Plan \u2013 the financial, and non-financial resources required for the \nAdministration to enable and support the Strategic Plan\u2019s four year delivery over 2024\u20132028.List of related Strategies, Plans and Policies\nTo bring our Strategic Plan to life, Council has a suite \nof related Strategies, Plans and Policies. These will be \nchanged and refined over time to reflect the key \noutcomes, actions and measures of success outlined \nin this Strategic Plan. The list below highlights the \nprimary relationship of each related strategy, plan or policy, noting that some of these have multiple \nrelationships to the aspirations. For a complete list of \nstrategies, plans and policies, please visit the City of \nAdelaide website cityofadelaide.com.au/about-\ncouncil/plans-reporting/strategies-plans-policies\nOur Community\n\u2022 Active City Strategy \n\u2022 Adelaide Events Guidelines\n\u2022 Adelaide Parklands Leasing and Licencing Policy\n\u2022 Adelaide Parklands Management Strategy \n(statutory)\n\u2022 Cultural Strategy\n\u2022 Dog and Cat Management Plan (statutory)\n\u2022 Smart Move Transport and Movement Strategy\n\u2022 Stretch Reconciliation Action Plan\n\u2022 Wellbeing Plan (statutory)\nOur Environment\n\u2022 Kadaltilla/Adelaide Park Lands Authority Subsidiary \nCharter \n\u2022 Integrated Biodiversity Management Plan\n\u2022 Resilient East Regional Climate Change Action Plan\n\u2022 Water Sensitive City Action Plan\nOur Economy\n\u2022 Adelaide Economic Development Agency \nSubsidiary Charter\n\u2022 Carbon Neutral Strategy\n\u2022 Waste Resource Recovery Strategy\n\u2022 Property StrategyOur Places\n\u2022 Adelaide Central Market Authority \nSubsidiary\u00a0Charter\n\u2022 Heritage Strategy and Action Plan\n\u2022 Disability Access and Inclusion Plan (statutory)\n\u2022 Homelessness, Social Housing and Affordable \nHousing Policy\nOur Corporation \n\u2022 By-Laws\n\u2022 Community Land Management Plans (statutory)\n\u2022 Annual Business Plan and Budget (statutory)\n\u2022 Procurement Policy\n\u2022 Consultation Policy\n25 24\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_108": "Financial\nFinancial Principles\nTo deliver on our priorities and ensure financial \nsustainability for current and future generations, the \nbelow Financial Principles have been applied:\nCouncil will:\n\u2022 Continue to deliver current services and assets, \nindexed in line with Consumer Price Index (CPI)\n\u2022 Apply fees and charges that are equitable and \nresponsive to changing community needs\n\u2022 Ensure an effective rating system \n\u2022 Maintain an operating surplus \n\u2022 Capitalise on external funding opportunities \nthrough retiming projects to align to stakeholder \nobjectives, recognising the potential need for \nincreased borrowings in order to respond \nto\u00a0opportunities \n\u2022 Consider new and different revenue streams to \nreduce reliance on existing revenue sources \n\u2022 Adjust rate revenue after consideration of all other \nbudget components and use growth in rate \nrevenue to partly fund servicing new rateable \nproperties and to service new borrowings\n\u2022 Fund new or enhanced services, assets or \nmaintenance requiring an increase in operating \ncosts from the adjustment of priorities, rate \nrevenue or other revenue increases and/or \nthrough\u00a0savings \n\u2022 Base all capital renewal expenditure on our asset \nmanagement plans \n\u2022 Consider the disposal, purchase and/or repurposing \nof property assets to support community \noutcomes, without incurring a financial loss \n\u2022 Use borrowings to fund new and upgrade projects \nwhere appropriate (which include major projects) \n\u2022 Ideally, fund operations, expenses or renewal \nprojects from within the budget.When considering these principles, Council considers \nthe service or project in the context of\u00a0Council\u2019s:\n\u2022 Roles and responsibilities;\n\u2022 Statutory obligations;\n\u2022 Ability to give effect to an adopted strategy, policy \nor plan;\n\u2022 Levers and discretion to intervene to address \nmarket challenges, opportunities or failure; or\n\u2022 Ability to gain value, efficiency or effectiveness in \nrelation to dollars spent.\nCouncil\u2019s Financial Principles ensure that Council\u2019s \nmeasures and targets can be met over the \nlonger\u00a0term. \nFinancial Sustainability\nThe Council\u2018s financial resources have the capacity to \nabsorb cyclical economic factors, social trends and \nfinancial shocks.",
        "node_109": "Council\u2019s Financial Principles ensure that Council\u2019s \nmeasures and targets can be met over the \nlonger\u00a0term. \nFinancial Sustainability\nThe Council\u2018s financial resources have the capacity to \nabsorb cyclical economic factors, social trends and \nfinancial shocks. Funding decisions are an important \nmethod of providing the capacity to meet financial \nsustainability in the medium and long term, along \nwith planning, stability of revenue and costs, \nproportionality of revenues with benefits over time \nand a \u2018balanced\u2019 operating result.\nFinancial sustainability is also central to supporting \nintergenerational equity (or fairness), which ensures \nthat the costs associated with expenditure are spread \nover time relevant to the communities that will draw \nbenefit. Council\u2019s Long Term Financial Plan has \nassumed that existing service levels will be \nmaintained, while seeking efficiency improvements in \nline with appropriate planning, measures \nand\u00a0benchmarks.\nResource Plan 2024  \u20132028\nCouncil has developed a Resource Plan which \nunderpins this Plan. It outlines the financial and \nnon-financial resources required to achieve our \nstrategic objectives over the next four years. The \nStrategic Plan and the Resource Plan will work in \nconcert with the Long-Term Financial Plan, Asset \nManagement Plans and City Plan to inform the \nAnnual Business Plan and Budget. Council\u2019s decision \nmaking is informed by strategies, plans and policies \nthat articulate the provision of services, programs \nand projects. Program Plans ensure all work is \nplanned and delivered in a coordinated way.The role of a Capital City Council is diverse and \ncomplex, which impacts the way we deliver services. \nWe are a leader, a service provider, a regulator, an \nowner, a facilitator and an advocate. By measuring \nthe delivery of our objectives and key actions, our \ncommunity will know what we have achieved. \nTargets provide further direction to ensure we are \ndelivering on our vision for the future, while allowing \nCouncil to measure and track progress through \nquarterly reports and an Annual Report each year.\n27 26\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_110": "Long Term Financial Plan\nA high level 10-year Long Term Financial Plan has \nbeen developed as part of Council\u2019s ongoing \nfinancial planning to assist Council to plan within a \nlonger term strategic framework. The key \ncomponents of the plan are:\n\u2022 Assessment of Council\u2019s current financial position \nand achieving longer term financial sustainability.\n\u2022 Ensuring Financial Principles are met.\n\u2022 Consideration of Council\u2019s appropriate role \nand\u00a0responsibilities.\n\u2022 Ensuring alignment with the Strategic Plan and \nmaintenance of high priority \nexpenditure\u00a0programs.\n\u2022 Ensuring alignment with agreed service provision \nand delivery standards.\n\u2022 Ensuring alignment with Revenue and Financing \nguidelines, including Rating and Treasury Policies.\n\u2022 Ensuring alignment with Asset Management Plans.\n\u2022 Ensuring alignment with other plans and\u00a0strategies.\n\u2022 Costing proposed strategies before they \nare\u00a0agreed.\u2022 The specific assumptions and outcomes \nunderpinning the Long Term Financial Plan are:\n\u2022 Rates Revenue in line with forecast inflation (in \naddition to growth from new developments).\n\u2022 Fees and charges in line with forecast inflation.\n\u2022 Salaries and wages forecasts based on enterprise \nagreements; once expired, Wage Price Index \n(WPI)\u00a0applied.\n\u2022 Other revenue and expenditure growth, in general, \nin line with forecast inflation.\n\u2022 Interest rates relative to market expectations.\n\u2022 Capital renewal expenditure in line with Asset \nManagement Plans (AMPs).\n\u2022 Capital enhancements (new and upgrade) in line \nwith Council Decision to fund $15 million per \nannum over current term of council and \nassumed\u00a0continuation.",
        "node_111": "\u2022 Ensuring alignment with Revenue and Financing \nguidelines, including Rating and Treasury Policies.\n\u2022 Ensuring alignment with Asset Management Plans.\n\u2022 Ensuring alignment with other plans and\u00a0strategies.\n\u2022 Costing proposed strategies before they \nare\u00a0agreed.\u2022 The specific assumptions and outcomes \nunderpinning the Long Term Financial Plan are:\n\u2022 Rates Revenue in line with forecast inflation (in \naddition to growth from new developments).\n\u2022 Fees and charges in line with forecast inflation.\n\u2022 Salaries and wages forecasts based on enterprise \nagreements; once expired, Wage Price Index \n(WPI)\u00a0applied.\n\u2022 Other revenue and expenditure growth, in general, \nin line with forecast inflation.\n\u2022 Interest rates relative to market expectations.\n\u2022 Capital renewal expenditure in line with Asset \nManagement Plans (AMPs).\n\u2022 Capital enhancements (new and upgrade) in line \nwith Council Decision to fund $15 million per \nannum over current term of council and \nassumed\u00a0continuation.\nThe Long Term Financial Plan will be periodically \nadjusted to reflect the recent decisions of Council to \nensure sustainability is maintained.Indicators 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nOperating Surplus Ratio \u2013 Target: 0%\u201320% 0.9% 1% 0.9% 2.8% 2.6%\nNet Financial Liabilities \u2013 Target: Less than 80% (1%) 15% 39% 38% 39%\nAsset Renewal Funding Ratio \u2013 Target: 90%-110% 90% 93% 95% 98% 100%\nAsset Test Ratio \u2013 Target: Maximum 50% 10% 13% 18% 18% 19%\nInterest Expense Ratio \u2013 Target: Maximum 10% 0.4% 1.3% 1.7% 2.0% 2.3%\nLeverage Test Ratio \u2013 Target: Maximum 1.5 years 0.2 0.3 0.5 0.5 0.5\nCash Flow from Operations Ratio \u2013 Target:  \n< than 100%101% 100% 102% 107% 107%\nBorrowings 20% 26% 36% 36% 37%Four Year (Long Term) Financial Plan\nCouncil\u2019s four year financial view, taken from the \nLong Term Financial Plan, provides the funding for \nCouncil\u2019s Strategic Plan.",
        "node_112": "This period sees significant \ninvestment in Council priorities including upgrades to \nseveral streets, partnerships with the State \nGovernment on major projects such as the former \nAdelaide Aquatic Centre site, Strategic Property \ndevelopments including the Franklin Street Bus \nStation redevelopment, Market Square and \n88\u00a0O\u2019Connell Street and ongoing delivery of core \nservices. Significant renewal projects including \nTorrens Weir and King William Street Bridge influence \nfuture year.\n29 28\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_113": "Treasury Policy\nThe Long Term Financial Plan identifies borrowing as \nan important funding source particularly for \nstrategic expenditure relating to new and upgraded \nprojects and strategic property activities. Borrowing is undertaken in accordance with Council\u2019s Treasury \nPolicy which underpins decision making for the \nfunding of Council\u2019s operations in the context of \ncash flow, budgeting, borrowings and investments.General Operating\nOperating Position\nRate revenue\nRates are an important source of revenue, \naccounting for approximately 60% of the total \nannual revenue. Council assumes a 3% growth in \nfuture rate income, primarily from valuation reviews \nand new properties.Other revenue\nThe Council operates a number of fee based facilities \nincluding the Adelaide Aquatic Centre, Adelaide Golf \nLinks, UPark, Adelaide Town Hall and the Property \nPortfolio (including Adelaide Central Market). Each \nfee based facility provides valued services for \nratepayers and visitors and is an important source of \nrevenue. Council generates income from statutory \ncharges, set by State Government legislation, in \naddition to the charging of fees for Council services \nincluding on-street parking-machine tickets and hire \nincome for Council properties.$\u2019000s 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nIncome\nRates Revenues 135,395 139,809 145,177 151,533 156,845\nStatutory Charges 14,683 14,990 15,356 15,739 16,132\nUser Charges 70,002 64,926 66,509 74,101 75,951\nGrants, Subsidies and Contributions 4,449 4,547 4,318 4,426 4,536\nInvestment Income 150 154 157 161 165\nReimbursements 338 346 355 364 373\nOther Income 465 477 488 500 513\nTotal Income 225,481 225,249 232,361 246,825 254,516\nExpenses\nEmployee Costs 85,013 83,050 85,581 88,215 90,929\nMaterials,",
        "node_114": "395 139,809 145,177 151,533 156,845\nStatutory Charges 14,683 14,990 15,356 15,739 16,132\nUser Charges 70,002 64,926 66,509 74,101 75,951\nGrants, Subsidies and Contributions 4,449 4,547 4,318 4,426 4,536\nInvestment Income 150 154 157 161 165\nReimbursements 338 346 355 364 373\nOther Income 465 477 488 500 513\nTotal Income 225,481 225,249 232,361 246,825 254,516\nExpenses\nEmployee Costs 85,013 83,050 85,581 88,215 90,929\nMaterials, Contracts & Other Expenses 81,672 80,569 82,199 86,191 88,343\nDepreciation, Amortisation & Impairment 56,040 56,835 59,353 62,012 64,675\nFinance Costs 835 2,525 3,117 3,502 3,970\nTotal Expenses 223,561 222,980 230,250 239,920 247,917\nOperating Surplus 1,920 2,268 2,111 6,905 6,598$\u2019000s 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nProjections\nNew Borrowings 20,285 17,515 20,921 5,005 3,626\nPrincipal Paid - - - - -\nGross Borrowings 70,568 87,666 108,587 113,592 117,219\nFuture Fund 40,384 39,967 39,967 39,967 39,967\nNet Borrowings 30,184 47,699 68,620 73,625 77,252\nPrudential Borrowing Limit 157,628 181,387 191,951 202,867 207,",
        "node_115": "980 230,250 239,920 247,917\nOperating Surplus 1,920 2,268 2,111 6,905 6,598$\u2019000s 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nProjections\nNew Borrowings 20,285 17,515 20,921 5,005 3,626\nPrincipal Paid - - - - -\nGross Borrowings 70,568 87,666 108,587 113,592 117,219\nFuture Fund 40,384 39,967 39,967 39,967 39,967\nNet Borrowings 30,184 47,699 68,620 73,625 77,252\nPrudential Borrowing Limit 157,628 181,387 191,951 202,867 207,932\nInfrastructure and Property\nAsset Management\n$\u2019000s 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nMajor Projects 36,386 30,917 21,100 15,920 15,820\nNew and Upgrades 13,932 520 320 320 320\nRenewal 50,416 48,682 51,932 52,739 54,922\nTotal Capital 100,734 80,119 73,352 68,979 71,062\nThe Council owns, and is responsible for the \nmanagement, operation and maintenance of a \ndiverse asset portfolio that provides services and \nfacilities for city users. Asset Management Plans have \nbeen developed to provide effective and \ncomprehensive management of Council\u2019s asset \nportfolio, with a three year view to deliver the \nrequired levels of service for the community and \nmeet strategic and legislative requirements.  \nRolling condition audits provide information on the \nongoing improvement of assets to ensure they \ninform the Annual Business Plan and Budget.\nRenewal and replacement capital expenditure is \nbased on Asset Management Plans which consider \nthe optimal timeframe for asset replacement based \non whole of life costing.",
        "node_116": "932 520 320 320 320\nRenewal 50,416 48,682 51,932 52,739 54,922\nTotal Capital 100,734 80,119 73,352 68,979 71,062\nThe Council owns, and is responsible for the \nmanagement, operation and maintenance of a \ndiverse asset portfolio that provides services and \nfacilities for city users. Asset Management Plans have \nbeen developed to provide effective and \ncomprehensive management of Council\u2019s asset \nportfolio, with a three year view to deliver the \nrequired levels of service for the community and \nmeet strategic and legislative requirements.  \nRolling condition audits provide information on the \nongoing improvement of assets to ensure they \ninform the Annual Business Plan and Budget.\nRenewal and replacement capital expenditure is \nbased on Asset Management Plans which consider \nthe optimal timeframe for asset replacement based \non whole of life costing. Total capital expenditure \nshall be managed in a way which avoids disruptive \nadjustments to activities, programs and revenue \nraising efforts.Property and New and Upgraded Assets\nCouncil\u2019s property portfolio seeks to address \nstrategic objectives for growth in the city and \nprovides additional net revenue to Council,  \nassisting to manage expenditure commitments.  \nConsequently, it is important that both the value  \nof the portfolio, and its returns (both net of \nborrowings), are protected to avoid adverse impacts \nwith regard to intergenerational equity, rates and \nexpenditure programs in the future.\nThe Property Strategy aims to optimise the \nperformance of the property portfolio. It promotes  \na partnership approach to acquire or repurpose \nproperty assets with the private sector and other \ntiers of government to leverage their value, to meet \nstrategic objectives or to sell under-performing \nassets with sale proceeds reinvested into new income \ngenerating opportunities.\n31 30\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_117": "Resources\nService Delivery Influences\nInfluences which may impact on the scope and level \nof services to be provided over the next four \nyears\u00a0include:\n\u2022 Local Government Price Index increases on \nrelevant goods and services, which has historically \ntracked at approximately 1% above the CPI.\n\u2022 Current Enterprise Agreements for most staff \nprovide for wages and salary increases of 3% and \n4% from 2024.\n\u2022 Increase in utility charges with indications that \nsustainability premiums will continue into \nthe\u00a0future.\n\u2022 A stronger focus on renewals and maintenance  \nof assets, specifically to mainstreets.\n\u2022 Service and infrastructure needs for a growing \nand changing population in the city.\n\u2022 Commitments to major projects and \npartnership\u00a0initiatives. \n\u2022 Council revenue from commercial operations and \nother fees and charges expected to be impacted \ndue to fewer people working in the city post-\nCOVID-19.\n\u2022 Impact of increasing interest rates on \nCouncil\u2019s\u00a0borrowings.Information Technology\nCouncil recognises the strategic importance of \ntechnology investment to deliver integrated \ntechnology solutions that improve access to \ninformation, streamline processes, safeguard \ninformation and systems and encourage \ncollaboration across the organisation, to enable the \ndelivery of customer focused services to our \ncommunity. The Business Systems Roadmap sets out \nthe program of works over the next four years in \nCouncil\u2019s ongoing journey to be a digitally enabled, \nintegrated, innovative, secure and inclusive Council. \nCouncil has an ongoing program of works that \nfocusses on four key areas:\n\u2022 Customers at the centre: We understand our \ncustomers and provide services to meet their \ndiverse needs.\n\u2022 Secure and reliable: We train our staff and use \ntechnology to increase safety and security for our \ncustomers and their information.\n\u2022 Data Driven: We use data and insights to improve \nour engagement and experiences with our \ncustomers and communities to make better and \nfaster decisions.",
        "node_118": "The Business Systems Roadmap sets out \nthe program of works over the next four years in \nCouncil\u2019s ongoing journey to be a digitally enabled, \nintegrated, innovative, secure and inclusive Council. \nCouncil has an ongoing program of works that \nfocusses on four key areas:\n\u2022 Customers at the centre: We understand our \ncustomers and provide services to meet their \ndiverse needs.\n\u2022 Secure and reliable: We train our staff and use \ntechnology to increase safety and security for our \ncustomers and their information.\n\u2022 Data Driven: We use data and insights to improve \nour engagement and experiences with our \ncustomers and communities to make better and \nfaster decisions.\n\u2022 Seamless: Our services are simple, intuitive, with \npurpose and seamless for a better experience for \nour customers and communities.Our People\nFTE 2023\u201324 2024\u201325 2025\u201326 2026\u201327 2027\u201328\nOur Community 95.7 69.4 69.4 69.4 69.4\nOur Environment 40.2 39.2 39.2 39.2 39.2\nOur Economy 157 157 157 157 157\nOur Places 321.3 321.3 321.3 321.3 321.3\nOur Corporation 160.6 174.4 170.4 170.4 170.4\nTOTAL 774.8 761.3 757.3 757.3 757.3\nAppropriate resourcing capacity and capability is \ncritical to deliver on the Strategic Plan responsibilities \nand be responsive to new and emerging challenges. \nWorkforce planning enables the Corporation to \nattract, develop and retain the skills, knowledge and \nexperience required to deliver across the duration of \nthe Strategic Plan, and creating a performance \nculture in which individuals are aligned to delivering \norganisational priorities. \nThe Corporation, in the way it supports customers, \nconducts business, delivers services, develops its \npeople and supports good governance must reflect \nthe Council\u2019s vision and enable its achievement.",
        "node_119": "Workforce planning enables the Corporation to \nattract, develop and retain the skills, knowledge and \nexperience required to deliver across the duration of \nthe Strategic Plan, and creating a performance \nculture in which individuals are aligned to delivering \norganisational priorities. \nThe Corporation, in the way it supports customers, \nconducts business, delivers services, develops its \npeople and supports good governance must reflect \nthe Council\u2019s vision and enable its achievement. The \nCorporation\u2019s commitment to be genuinely \nresponsive to the changing needs of people, business \nand communities is paramount to the delivery of the \nStrategic Plan, requiring effective delivery now, and \nclear plans for the future.\nA focus on efficiencies and continuous improvement \nwill enable FTE numbers to be maintained at current \nlevels over the four-year period. At times, consultancy \nservices or additional contract or temporary staff will \nbe required to ensure our service delivery and people \nresources are scalable. Employee Values and Behaviours\nAt City of Adelaide our values provide the context for \nhow we work together and with others. They are the \nstandard against which we hold ourselves and others \naccountable. We are committed to building a high \nperforming, inclusive and sustainable workplace for \nthe future that is based on and fosters these values \nand recognises alignment to them is integral to \nour\u00a0culture.\n\u2022 Achievement\n\u2022 Collaboration\n\u2022 Customer Commitment\n\u2022 Integrity \n\u2022 Innovation\nOur Corporation\u2019s Purpose \nAs an organisation we will be:\n\u2022 An exceptional service provider\n\u2022 A reliable and trusted partner\n\u2022 A professional administrator\n\u2022 A high achieving, best practice organisation \n33 32\nCity of Adelaide | Strategic Plan 2024 \u20132028",
        "node_120": "SAI23-004\nCity of Adelaide  \n25 Pirie Street  \nAdelaide SA 5000\nP 08 8203 7203  \nW cityofadelaide.com.au"
    },
    "relevant_docs": {
        "32ef6672-1ec0-4c10-8b27-4007f4f32a16": [
            "node_0"
        ],
        "d4756049-0274-41a6-8de3-259c35d78d4f": [
            "node_0"
        ],
        "31118474-50d4-45ab-8ce5-c6b89fb29922": [
            "node_0"
        ],
        "7e3bdbe6-39a7-4796-9215-8b77c9249223": [
            "node_0"
        ],
        "9f97711d-0189-463a-a8cf-dc255d002c03": [
            "node_0"
        ],
        "d5adabb2-fb49-4dde-808b-f86a31604ba4": [
            "node_0"
        ],
        "4d9d0fff-4184-4d22-a932-fdc8a9ea7920": [
            "node_0"
        ],
        "cd34e354-e25a-4929-9d8e-080fae574a1c": [
            "node_0"
        ],
        "c90facf1-f70c-405c-8ea5-b494dec103e4": [
            "node_0"
        ],
        "f8a2cad3-1094-43e7-82b3-00b8408217a8": [
            "node_0"
        ],
        "17f21610-189d-4395-9c26-d3066513e95d": [
            "node_1"
        ],
        "396baf08-f8f0-43ca-a885-b9d05e287d82": [
            "node_1"
        ],
        "4804a4e8-7c8f-4753-81c8-dd6410a6ff67": [
            "node_1"
        ],
        "d87bf991-9905-4953-a684-db1638e60f7d": [
            "node_1"
        ],
        "35b0531e-82ee-46c0-80c8-50dee2b02866": [
            "node_1"
        ],
        "d12a4877-43db-44fc-8486-6b789839cb26": [
            "node_1"
        ],
        "0b648d23-10d6-451a-8a7b-846aed9d42e8": [
            "node_1"
        ],
        "24c7a67b-81a8-4c3d-8740-17ef880d2245": [
            "node_1"
        ],
        "a463daee-df6d-4b46-9101-8bae1a7fe898": [
            "node_1"
        ],
        "e629843b-9292-4cd7-bed8-16a53eb62f83": [
            "node_1"
        ],
        "017bc1ce-58df-4187-94e2-114be35a1912": [
            "node_2"
        ],
        "24ca969e-7de9-4466-9172-b000cf1decb4": [
            "node_2"
        ],
        "8c12a405-2fcc-4248-bd3c-d462742cc606": [
            "node_2"
        ],
        "0d8325ce-9322-4099-8344-c10f47e3488e": [
            "node_2"
        ],
        "d29316ca-531d-4a08-84d3-156d1c281f6a": [
            "node_2"
        ],
        "08924186-7ca0-4773-879c-d846f86683ca": [
            "node_2"
        ],
        "acdadf88-978e-40f8-a276-f11bfc83bc49": [
            "node_2"
        ],
        "99055101-e570-448b-bdef-249baed6f62d": [
            "node_2"
        ],
        "142eb68a-4f28-4e7c-a847-5d4f6c9019d5": [
            "node_2"
        ],
        "e8d4ec23-7fa4-4c1f-a19e-6de98e448f3c": [
            "node_2"
        ],
        "537a9fcf-baf6-403e-9de3-e7372482e696": [
            "node_3"
        ],
        "8391f1c0-61b6-4cfd-9479-a7dc201d2ec0": [
            "node_3"
        ],
        "f309a7fc-9de7-431f-8167-8ace994d5e48": [
            "node_3"
        ],
        "0100ff21-a16a-43ec-9a59-42af403370d0": [
            "node_3"
        ],
        "3e1baaaf-cef2-473e-8faa-dc358d646afe": [
            "node_3"
        ],
        "21114822-a751-4b72-992c-3c2f04594ffa": [
            "node_3"
        ],
        "bc6b1104-7488-40cf-a9db-1d0dd795bb5c": [
            "node_3"
        ],
        "30c18b74-87aa-479b-a62a-20074e3e15ca": [
            "node_3"
        ],
        "53d1f24b-1c16-47fa-a0e8-7c9d2639b1cc": [
            "node_3"
        ],
        "242727fc-3fac-4472-8e2b-1ea0a1b174c1": [
            "node_3"
        ],
        "f698506d-0fb2-4da3-991a-f05e6ad1f02f": [
            "node_4"
        ],
        "5a23c71e-b658-4492-9f01-5544c1f427e4": [
            "node_4"
        ],
        "05c6f495-cae9-4b7d-a88e-46ce3823db21": [
            "node_4"
        ],
        "70ebd277-49cb-4741-9de3-692a0f15fc28": [
            "node_4"
        ],
        "7060d59a-e35e-4bd8-9799-c9a1b1b58520": [
            "node_4"
        ],
        "88cf8cd9-54dd-4eb1-bd8f-750cc245c24d": [
            "node_4"
        ],
        "dcdef816-1b37-4a44-a4e0-bc9e63e5bb19": [
            "node_4"
        ],
        "b6e022d1-0e9c-441b-b16b-6f6aacacc2c1": [
            "node_4"
        ],
        "a979903a-b7c9-4bc6-927c-74f19c4edec6": [
            "node_4"
        ],
        "a1af9298-f041-450e-af96-1993f63b1429": [
            "node_4"
        ],
        "14a2c33e-6d72-4826-8600-d5fa253b2511": [
            "node_5"
        ],
        "1828396e-fcf5-4f0c-ad4c-6a94c846d908": [
            "node_5"
        ],
        "8c367593-e86d-4e58-874f-cd357bdf6259": [
            "node_5"
        ],
        "c0bb2eb9-d688-4789-96cf-be3979ed60ff": [
            "node_5"
        ],
        "6f4c5b68-30f7-45be-bdaa-27fc7929a5bf": [
            "node_5"
        ],
        "ac7bfebf-ba58-4cf5-af0f-159f69147f33": [
            "node_5"
        ],
        "5c96930b-bbd8-401c-86d6-b8f50710ff50": [
            "node_5"
        ],
        "b2154a7a-f683-42f9-a6f8-780050a47bf2": [
            "node_5"
        ],
        "61235bc4-851f-4727-8d62-b36870755f53": [
            "node_5"
        ],
        "80b6718f-eca2-4500-af26-3a8b45a2fe91": [
            "node_5"
        ],
        "d2576825-e3c4-4e61-a6e7-e37cb7c74c2f": [
            "node_6"
        ],
        "f6ab131b-1888-4ea4-9c39-c7e58bf56a51": [
            "node_6"
        ],
        "b769e1ad-a02d-4d9e-a179-59e9e14f116e": [
            "node_6"
        ],
        "9cc59700-8178-4109-b65b-220eedd470ea": [
            "node_6"
        ],
        "f0c023a3-f5ea-4af8-a584-b1b293e6cf6e": [
            "node_6"
        ],
        "e2078f35-f926-4230-9393-c4925b93df05": [
            "node_6"
        ],
        "20763859-94ad-4eaa-82f0-67bca78e6d99": [
            "node_6"
        ],
        "d8aa77a9-7cbd-4cc7-a8b0-70eb4a49532c": [
            "node_6"
        ],
        "a515ef64-fe94-43c2-815f-5db2a4f68a22": [
            "node_6"
        ],
        "2b639641-8fbe-448c-b5ea-89cc04c2593f": [
            "node_6"
        ],
        "73cffc64-c393-4eda-82e0-0322934017eb": [
            "node_7"
        ],
        "4e33a1ac-6dc5-468c-a266-7b5d951e764f": [
            "node_7"
        ],
        "6a45ede6-d08d-4447-a162-efa21db60a59": [
            "node_7"
        ],
        "befdce95-fc7a-462d-850d-4e240940cb1a": [
            "node_7"
        ],
        "b1b011d7-4517-430c-a7d4-dbe5639a5deb": [
            "node_7"
        ],
        "0e1df606-13d4-4b62-9e46-aff3f4cee9bd": [
            "node_7"
        ],
        "9b99f917-04ca-4173-bb89-f4883c658507": [
            "node_7"
        ],
        "380df8b9-3bb2-41b5-9669-1c010a4d97f6": [
            "node_7"
        ],
        "015208fa-edde-449b-8125-a413945e0008": [
            "node_7"
        ],
        "e45338c9-1e51-476d-87bb-8f4901865d0f": [
            "node_7"
        ],
        "c40cdd23-6925-4ce3-be1c-d819bed4dba6": [
            "node_8"
        ],
        "517ced69-702a-4e7d-b3c7-aa8185f77351": [
            "node_8"
        ],
        "bd388b07-a98e-49fd-9af3-9e76f10f448d": [
            "node_8"
        ],
        "bbd2f1da-054b-41e9-8f63-476d98da5a57": [
            "node_8"
        ],
        "66339a42-ae2e-46a3-b420-9358f18f1807": [
            "node_8"
        ],
        "b838dfc2-8851-428d-9662-03edc7322e06": [
            "node_8"
        ],
        "70152abf-d7ea-4d50-b6f3-6db11ea8b7b3": [
            "node_8"
        ],
        "07f904a8-7e75-4dbf-8e99-3de01e0a9a23": [
            "node_8"
        ],
        "b05e9879-10e8-4591-8fb0-065447a32d99": [
            "node_8"
        ],
        "04ae64de-9127-4d90-9610-21a508cf4547": [
            "node_8"
        ],
        "49c3497a-71ce-4331-b8be-5af1ae6c50e7": [
            "node_9"
        ],
        "e2ab869e-2c87-403f-b360-04e720221bb0": [
            "node_9"
        ],
        "bd0b9ac3-3791-4fa6-8f40-1a6def1a8ee8": [
            "node_9"
        ],
        "946ccf15-b763-46fc-ab4d-b0187cd14475": [
            "node_9"
        ],
        "c137fdb2-76eb-4995-981d-31ff2a489ae2": [
            "node_9"
        ],
        "69d7584b-0121-4862-8033-1df168161a02": [
            "node_9"
        ],
        "556b4a95-a7f9-4e27-9ba2-d4843635ea77": [
            "node_9"
        ],
        "367c6a07-c583-4f1c-ba56-51ed35c516c7": [
            "node_9"
        ],
        "eb796dcc-92e9-4604-a7e3-d3739ceeda4a": [
            "node_9"
        ],
        "3ef4cf8c-ca18-479b-8d75-1ed28afe5200": [
            "node_9"
        ],
        "80a3361e-ddef-45b6-99e1-90845e6da645": [
            "node_10"
        ],
        "05041635-0cc2-4940-a2de-be5765a2a325": [
            "node_10"
        ],
        "36b4d303-78d7-42f5-93f7-0cee0b55ac01": [
            "node_10"
        ],
        "350c71f0-e836-4018-ae46-8698d3b1b7c8": [
            "node_10"
        ],
        "246317a3-ddca-40cc-b4a2-4292950f7980": [
            "node_10"
        ],
        "dd4795bd-88e4-4f86-9ede-d70d6ba9e700": [
            "node_10"
        ],
        "476f98c0-d31b-4067-9ea7-4634021d325d": [
            "node_10"
        ],
        "c5e1f2d3-4eef-40e3-8178-b92e16acda3c": [
            "node_10"
        ],
        "1af061f6-fe86-41d8-89d6-4bcbddb3c1f7": [
            "node_10"
        ],
        "c15538e5-c88c-46a5-99a0-4dea7dddffbf": [
            "node_10"
        ],
        "98e401e1-6cd8-4241-b2ce-4fee1fededad": [
            "node_11"
        ],
        "eeff8a66-f604-4d0a-bb14-55e50371846d": [
            "node_11"
        ],
        "8f9d996d-2451-47c5-ab29-6176282bacd2": [
            "node_11"
        ],
        "5299e242-86aa-45c0-b712-257b3fe3d865": [
            "node_11"
        ],
        "df915e88-3f55-4dfd-97a5-9afe5a97d999": [
            "node_11"
        ],
        "c720134c-ba2c-4a43-9b18-4f2f1beab78d": [
            "node_11"
        ],
        "95b912d6-9abe-496b-aa66-363413928b07": [
            "node_11"
        ],
        "c456d235-d773-4c79-8603-bf8b692c445a": [
            "node_11"
        ],
        "58a13bfe-ad05-48c7-959c-e5f33d63cba5": [
            "node_11"
        ],
        "c450e1b8-5a58-4b4d-a331-0ce09b91752e": [
            "node_11"
        ],
        "8e6e7af4-b69c-4b22-8644-fabcda5c7646": [
            "node_12"
        ],
        "483221a6-b0b8-447f-a8dd-1244f4dcf198": [
            "node_12"
        ],
        "a59690f5-4631-4106-9a0c-5526ebd6205e": [
            "node_12"
        ],
        "30623bd6-d264-4efc-acc1-552b3a655392": [
            "node_12"
        ],
        "6ff143c6-a24f-4dd9-b731-e70a883c2a4e": [
            "node_12"
        ],
        "1d1aee13-bf19-49c6-9be7-069a15dc1646": [
            "node_12"
        ],
        "2d54e7be-535e-4a68-8c7d-04af5e87f33e": [
            "node_12"
        ],
        "3bea9d5a-0eed-4902-bc6c-8e0fc1c4fa0e": [
            "node_12"
        ],
        "5f2a753b-e3e4-4050-a93a-e6c646a294a0": [
            "node_12"
        ],
        "a2ea2a49-7188-4bdb-bf6f-fd4e6bd589ee": [
            "node_12"
        ],
        "3110c4eb-667d-4d4a-8b03-8225d004266c": [
            "node_13"
        ],
        "9012e63a-280f-433f-9928-14a41be8b88c": [
            "node_13"
        ],
        "8afd0699-7468-4a87-8518-c4a2944b4007": [
            "node_13"
        ],
        "efde1447-dd29-44eb-823e-30e1357ba185": [
            "node_13"
        ],
        "e2048f62-dbad-4c5f-8eb1-646c46548ec1": [
            "node_13"
        ],
        "0095dfdf-14d8-4f55-831d-7a4e2dc615ee": [
            "node_13"
        ],
        "ab4a9239-e66f-4f6e-9644-5b4cc697da31": [
            "node_13"
        ],
        "04fa9c87-3f32-4a8a-9838-7209ea5bc835": [
            "node_13"
        ],
        "0d19cc03-5689-4d32-babb-99233f357659": [
            "node_13"
        ],
        "897e844a-8466-491d-98aa-746a83f32979": [
            "node_13"
        ],
        "1f940636-44a7-4f7a-ae8a-5cdb8bbde226": [
            "node_14"
        ],
        "1faf8f2d-ab0c-4aa7-a07c-fd0b787b9c80": [
            "node_14"
        ],
        "35232c5f-8914-41a8-97f1-76bf609352d5": [
            "node_14"
        ],
        "73164304-b3e6-4bb3-a835-e01950134883": [
            "node_14"
        ],
        "6cafddf0-6db5-48e5-89db-ea2cfd4d1aa6": [
            "node_14"
        ],
        "2901bb6a-fd15-43f9-b967-15d537bc3a14": [
            "node_14"
        ],
        "1e8aaeaa-0dc9-4e0c-9129-e1656fadc275": [
            "node_14"
        ],
        "9a5ba4b0-1775-47b4-a064-3a65ba7817c7": [
            "node_14"
        ],
        "19f6c104-ac22-414c-8b52-4cba6436039a": [
            "node_14"
        ],
        "faf81f50-7638-4b1b-a4ce-f06f2da5076e": [
            "node_14"
        ],
        "6d261c39-1728-465b-92e8-29db9c97db43": [
            "node_15"
        ],
        "d0d09cc4-4b96-4aed-8d2c-8509b6a6d902": [
            "node_15"
        ],
        "a5e77c0f-d512-4458-81d9-44bc73d0366b": [
            "node_15"
        ],
        "ed6c23ce-33a2-4f26-92fc-09f65aa15369": [
            "node_15"
        ],
        "ce2b3592-b917-4b07-9572-7ba567b4d46b": [
            "node_15"
        ],
        "cac9e37f-bc69-4f81-ae5c-3d612ea9b066": [
            "node_15"
        ],
        "3701f14d-6c94-48eb-81de-83699be772fc": [
            "node_15"
        ],
        "add1f92d-b4c1-4b0d-b3a0-eeee3f06865b": [
            "node_15"
        ],
        "cd4238e4-6194-4cc7-9a08-6dec7799463b": [
            "node_15"
        ],
        "8d098a55-1c32-4774-afcf-245eaa0dd0f8": [
            "node_15"
        ],
        "fd3d1def-29c9-4fde-83fe-92acddb6b624": [
            "node_16"
        ],
        "09be4db5-7cb3-4065-9ffb-21efd72a60b2": [
            "node_16"
        ],
        "2da81443-35ec-4670-a69e-8c5578ce51a2": [
            "node_16"
        ],
        "f64cd801-63f4-43e4-bc18-654a9cd3e26f": [
            "node_16"
        ],
        "5042da7d-2f29-4d25-97ec-1b4f898de79b": [
            "node_16"
        ],
        "202d3e14-f7a4-492e-8da8-36c5426a02b7": [
            "node_16"
        ],
        "a9706704-a3f1-4b95-9f7c-2bb4052e4dda": [
            "node_16"
        ],
        "8187a927-f361-4ce2-9755-31e844fc0782": [
            "node_16"
        ],
        "9be74f5d-1287-4ad8-9f50-009c7356e268": [
            "node_16"
        ],
        "a7c699e8-c46b-4a73-957a-a60aa47069a2": [
            "node_16"
        ],
        "e07ceab4-17b0-4a7f-a1c2-3c95b601d357": [
            "node_17"
        ],
        "ca9117dc-3338-481f-9755-6ea96268fea4": [
            "node_17"
        ],
        "71dc74f5-20f5-4d15-9274-7499b3582322": [
            "node_17"
        ],
        "fbd06c1f-e0a3-49d1-b5af-46c640ad0ce2": [
            "node_17"
        ],
        "e36dfa05-2039-4b53-9fe9-8e3c301f1137": [
            "node_17"
        ],
        "429343a1-bf8e-4542-a709-01bdea0b33df": [
            "node_17"
        ],
        "eec9db1c-74e8-44b0-8901-93bfe18206e2": [
            "node_17"
        ],
        "0cdd3f68-76da-41cb-b215-3a5f0db7d2ec": [
            "node_17"
        ],
        "444d987a-6eb0-47bb-b8ba-e83eec1755a5": [
            "node_17"
        ],
        "ed7072f2-ff28-44d8-8e76-e189e7a23f6f": [
            "node_17"
        ],
        "22144f80-8269-42fb-9ea0-61d99f1cc564": [
            "node_18"
        ],
        "6efc2d56-3745-4154-8c0d-a78521254a84": [
            "node_18"
        ],
        "0a2814cb-a237-4670-bb18-7b5bedf00e7a": [
            "node_18"
        ],
        "fc3ebf70-80ad-4c9e-83c8-0d7c03585751": [
            "node_18"
        ],
        "a78829a9-1824-4266-ae66-301154b95f23": [
            "node_18"
        ],
        "f62c9926-24ae-49fb-a5da-6e167184ad33": [
            "node_18"
        ],
        "067d7606-d82f-40bd-8255-1c0ca15145fd": [
            "node_18"
        ],
        "2c5d8014-57fd-4a47-83e4-3c14bc9abac5": [
            "node_18"
        ],
        "14e31a02-3887-433f-b94c-107ff02a516c": [
            "node_18"
        ],
        "b0984b59-d397-4227-8e32-b7065fbc94cf": [
            "node_18"
        ],
        "711226d3-170d-4abf-9216-15d329dfc433": [
            "node_19"
        ],
        "aae819d8-fd80-43c8-aa99-e3445ab85907": [
            "node_19"
        ],
        "f30fa86d-69de-4d97-aa6b-9424356318f3": [
            "node_19"
        ],
        "c61c1322-5146-4626-8a51-b0ee8f736a94": [
            "node_19"
        ],
        "12d66e93-3234-42fe-a606-811946d7e142": [
            "node_19"
        ],
        "8f1a071b-339a-42b0-872c-f293f6dcb929": [
            "node_19"
        ],
        "d042d265-2abc-4f40-bcfb-60d3d7aef523": [
            "node_19"
        ],
        "7f2584d3-2277-48b4-9c3d-324ffafdf289": [
            "node_19"
        ],
        "71002515-4d2d-4208-b8d1-28ebe6ea3333": [
            "node_19"
        ],
        "de696dbf-cabb-4e7a-a56e-92a3fe005ad0": [
            "node_19"
        ],
        "d6a81ba0-e13e-4af4-bf48-881a3b101162": [
            "node_20"
        ],
        "987327dc-a3a2-4ade-b4c5-a5503901ec7b": [
            "node_20"
        ],
        "ef1b57f7-95a8-4d3d-9ba6-675f9974886c": [
            "node_20"
        ],
        "60a92707-5074-44be-947a-a22bbe7e11fa": [
            "node_20"
        ],
        "205891f4-1f24-4c32-9c4d-109b6aa3f44c": [
            "node_20"
        ],
        "b303aa46-3f0a-4f60-b915-757ed7451a7d": [
            "node_20"
        ],
        "6cb99cb5-77d7-42c0-a053-7b061c04017f": [
            "node_20"
        ],
        "7ad9c395-9748-4a4b-a799-7a1b49700ed3": [
            "node_20"
        ],
        "37891ae1-ee80-4d33-8665-f467b1085685": [
            "node_20"
        ],
        "7262c8cf-df8e-4ca9-8db9-5d95928b1237": [
            "node_20"
        ],
        "80eab700-07eb-4db7-b7c0-88c08b6180e2": [
            "node_21"
        ],
        "7f312939-0cda-4344-8d63-b21fe01eae2b": [
            "node_21"
        ],
        "cc1311bb-b7eb-4473-a6c2-7922e033cd5e": [
            "node_21"
        ],
        "a34b37bb-32fa-42e6-b469-ebfce20664e6": [
            "node_21"
        ],
        "6fc09c10-4a87-4fc4-bb36-b716d1eddec5": [
            "node_21"
        ],
        "293b5d7c-bc8f-4f5d-ac34-ef71f06accf4": [
            "node_21"
        ],
        "75f1bdea-87b4-4bcc-b78e-774e9b49fe73": [
            "node_21"
        ],
        "3bbfabb3-c28d-414e-8b30-050bfb456725": [
            "node_21"
        ],
        "77f40012-2e34-408b-a95f-fd486fa0b9a8": [
            "node_21"
        ],
        "dad155f2-4824-47d9-9b95-c0918c503040": [
            "node_21"
        ],
        "53a1cd19-150f-4e5d-9193-34be2b39f658": [
            "node_22"
        ],
        "c38fb9fc-5881-4cca-ac9c-4c13c4959b17": [
            "node_22"
        ],
        "191a7e43-88fd-48fa-8726-2fecd6c09de6": [
            "node_22"
        ],
        "137eca49-d40b-4c78-829d-7fb6cb1a03b9": [
            "node_22"
        ],
        "85c11b2d-1913-45a0-a98e-2dd805cb0d5e": [
            "node_22"
        ],
        "897ff4de-ce26-4e6b-82e3-fce974d3c54b": [
            "node_22"
        ],
        "210e9863-3484-4c60-90ff-632d5f257e99": [
            "node_22"
        ],
        "897771c9-8970-455b-8ea9-a979e9b44d27": [
            "node_22"
        ],
        "db5db884-1b8b-44f7-af86-008fff892617": [
            "node_22"
        ],
        "4da3c4a1-17b0-45e1-9dce-97227f6484f4": [
            "node_22"
        ],
        "079d4cb1-5473-400b-a1b6-7ef02ad534a6": [
            "node_23"
        ],
        "2ef95125-c84b-443c-bc21-d91fc74e58ab": [
            "node_23"
        ],
        "6ba58817-f124-4663-b2f5-3c182357b8b7": [
            "node_23"
        ],
        "03c5d38e-d9a6-451a-980f-451fbc389ee2": [
            "node_23"
        ],
        "4e132014-802e-4181-ae91-b5dc122cb3a6": [
            "node_23"
        ],
        "95b69604-61f8-4ce2-8002-a55a09b67962": [
            "node_23"
        ],
        "85ac2c3b-0c9d-44af-b390-1d6d49fd9b11": [
            "node_23"
        ],
        "1fdf033d-27c3-46e8-81b2-d2d979834d49": [
            "node_23"
        ],
        "82704c7b-139c-4eb1-aa68-0c83386ccbc2": [
            "node_23"
        ],
        "85b7d179-e80c-4e4c-94ca-680094e1aeab": [
            "node_23"
        ],
        "1e9c0cf8-8f47-4d85-afda-75c28cf6ec8a": [
            "node_24"
        ],
        "6d86a937-49ca-4832-8309-a6437ad88a86": [
            "node_24"
        ],
        "7b0a342f-8602-4079-8333-b67d81e787c6": [
            "node_24"
        ],
        "435fa0dc-248d-4262-a065-31cf823645fa": [
            "node_24"
        ],
        "6c67ecd6-3abb-49bb-a44a-1600be5699b0": [
            "node_24"
        ],
        "6e55442e-d9f6-4e89-8c2a-f649a38ca72a": [
            "node_24"
        ],
        "2e6a029e-d1f6-45ae-ac90-d45c27ebe765": [
            "node_24"
        ],
        "6979dfc8-5285-4692-a80d-aa978ee53d7a": [
            "node_24"
        ],
        "be6343fb-3fc0-4bee-a1ba-e34121795c72": [
            "node_24"
        ],
        "61bb61ba-a521-45c7-9eeb-9f451ce18aaa": [
            "node_24"
        ],
        "dba5f537-0930-4b7e-b36d-b87b29b64259": [
            "node_25"
        ],
        "90e3a682-d395-4a67-a97e-4aba90a18e06": [
            "node_25"
        ],
        "f7d176e5-00a9-4941-8416-45f46036fad4": [
            "node_25"
        ],
        "5b9f423e-b862-481b-8063-c57bc2c9060f": [
            "node_25"
        ],
        "37963767-5d41-41dc-b79e-4d68f1ad5e69": [
            "node_25"
        ],
        "d7635981-5dc3-4562-8fac-189219bcca36": [
            "node_25"
        ],
        "b235e45f-d358-408c-b7ca-81a355becffa": [
            "node_25"
        ],
        "d849ac2f-e3d9-4bff-98b2-1e3e0833aa01": [
            "node_25"
        ],
        "d612f036-3aaa-4ebb-a90b-52cce6766348": [
            "node_25"
        ],
        "9535781d-0120-4335-abd3-362c07045071": [
            "node_25"
        ],
        "5a2d2bef-6bf6-47e5-a806-25eb94a8e916": [
            "node_26"
        ],
        "b0fd5e83-7bab-4c05-beaa-f4d39ea3c821": [
            "node_26"
        ],
        "bc058fa5-13bc-408e-a4d3-8c8f612d501d": [
            "node_26"
        ],
        "09d13c7c-dc84-433d-9b3a-887df63b4f64": [
            "node_26"
        ],
        "915a63ab-97bc-4427-b8cb-e741d6663993": [
            "node_26"
        ],
        "f7e6dbbc-d0ad-4ff7-a24e-5103e0a8f756": [
            "node_26"
        ],
        "5c9031d6-2826-4aef-9388-a367721b8bcd": [
            "node_26"
        ],
        "962d2649-29f4-4ea0-89af-b275aafab75f": [
            "node_26"
        ],
        "370cabbf-ba53-4173-9f02-e48978dc988e": [
            "node_26"
        ],
        "63ae2029-248f-4045-8c04-a8777216de44": [
            "node_26"
        ],
        "bc0e01c3-cca4-48fc-9b84-a01bf23f409f": [
            "node_27"
        ],
        "18ad6860-3b6d-4c19-9729-71b38c234d86": [
            "node_27"
        ],
        "95a1d7a6-181a-4123-ac9b-db5761dd60d9": [
            "node_27"
        ],
        "1c38225f-63fd-4866-8b96-59c1584288a8": [
            "node_27"
        ],
        "0b1fecb2-9955-4409-b879-99b81bd2835c": [
            "node_27"
        ],
        "bff2baf9-5611-4285-a755-6a8144ae03ab": [
            "node_27"
        ],
        "2d63357a-dfb4-488a-99a0-ba8777497b4f": [
            "node_27"
        ],
        "2858c379-00df-446b-ab2f-4d4b4995fb27": [
            "node_27"
        ],
        "c04ab6c4-7c71-4005-8d51-aeab17955d53": [
            "node_27"
        ],
        "325d7364-45dd-4596-b4b6-6ea432fb4275": [
            "node_27"
        ],
        "5578250b-e131-437b-a957-e863e93b87e5": [
            "node_28"
        ],
        "d26d206b-400e-4b22-9055-9d0392663c44": [
            "node_28"
        ],
        "00fb8a56-6fd7-447f-b6df-985594dacf64": [
            "node_28"
        ],
        "94a6a0d0-55e1-494c-8c0a-eb726abf63ee": [
            "node_28"
        ],
        "379afce7-e083-4540-a524-2fc41aaf166c": [
            "node_28"
        ],
        "9dbb5521-7625-48da-836c-f7230b7f3926": [
            "node_28"
        ],
        "d791d85e-164f-4b28-811e-4dde5a3af255": [
            "node_28"
        ],
        "bfa6aad5-0688-43f3-b97b-4fca073df622": [
            "node_28"
        ],
        "799e7cbd-aa03-4cc7-a248-1a4760fa7361": [
            "node_28"
        ],
        "5dd43a48-9bba-4ad5-9b77-cab587c2488b": [
            "node_28"
        ],
        "255102ac-2bde-43ad-b193-f9dc8d28578f": [
            "node_29"
        ],
        "f728f884-ac71-4563-a860-bfff00536fe3": [
            "node_29"
        ],
        "adb75412-48d0-4eed-ad27-6372d4418968": [
            "node_29"
        ],
        "32d9c621-eca1-493d-883c-6cfb4782a1f7": [
            "node_29"
        ],
        "e1800faf-084a-4fba-8928-57ca17dc2663": [
            "node_29"
        ],
        "db376112-e2ee-4674-a152-101c912d0abe": [
            "node_29"
        ],
        "f61d850f-e72d-4a09-82ee-11dd4c2a692a": [
            "node_29"
        ],
        "1d40761a-625f-45f0-aadb-1118555b7663": [
            "node_29"
        ],
        "17279fa2-33bf-4c8b-a1a9-328314f835ad": [
            "node_29"
        ],
        "4eda790b-30d1-4256-94fa-a638f04baeef": [
            "node_29"
        ],
        "a82ba857-c310-42a1-a59c-d7d7b6553e9e": [
            "node_30"
        ],
        "4c3aa6a6-f97e-4252-b7d1-4276cdec53d2": [
            "node_30"
        ],
        "7a2d69b3-ccb1-4a10-9b5a-afad00cda9cf": [
            "node_30"
        ],
        "98834c17-f59a-4088-97e8-052a701365f6": [
            "node_30"
        ],
        "aa0e8886-917f-4733-8041-b132238c351e": [
            "node_30"
        ],
        "a37778c6-4e27-4c43-8104-f4966fc82a8c": [
            "node_30"
        ],
        "2fd6feee-fb7b-4173-a9c4-446de82b9df5": [
            "node_30"
        ],
        "ce848f8c-c992-4369-bc50-fe2162c5f301": [
            "node_30"
        ],
        "5216a93e-793d-442a-aa8f-ddc506067b40": [
            "node_30"
        ],
        "8142bb3c-f3c1-4c5d-93ff-77d3c23a1151": [
            "node_30"
        ],
        "51a4195e-9561-4b1a-8c8a-52d916d6769a": [
            "node_31"
        ],
        "0087e472-bfb2-4143-ab4c-7ada02246122": [
            "node_31"
        ],
        "a4821c94-d56a-4e90-9a12-ed22ae0c2e5f": [
            "node_31"
        ],
        "de4bc384-4776-4b68-b157-9a6aa430a0bd": [
            "node_31"
        ],
        "4049f5fc-a198-472a-92ac-5d473b541069": [
            "node_31"
        ],
        "2d0e1c04-ec2b-45de-ac53-269d21a79b5f": [
            "node_31"
        ],
        "024097d3-c09a-47ed-850a-7216417ccfb2": [
            "node_31"
        ],
        "14389a39-3fdc-4503-8d87-cc0ade307536": [
            "node_31"
        ],
        "a8cc42af-0cb7-4d7d-8e99-13252337d276": [
            "node_31"
        ],
        "407d9916-c33c-46f4-b8e7-f08ed3ac17db": [
            "node_31"
        ],
        "e4107144-1df1-4948-a90a-4f7455059f5a": [
            "node_32"
        ],
        "74bbddc8-6791-4e00-8c69-b790d2fc3a51": [
            "node_32"
        ],
        "b5708334-dece-492b-9e1b-0e642eb80d74": [
            "node_32"
        ],
        "dc1dab7e-d88d-4a30-a995-51f874996335": [
            "node_32"
        ],
        "77e1a87c-c704-4ec0-9234-596db37a247b": [
            "node_32"
        ],
        "f2800580-6cd9-407b-8850-583a9d9daf44": [
            "node_32"
        ],
        "44ab95d7-484e-4c6a-96ef-3f27654706c0": [
            "node_32"
        ],
        "d3bb8ceb-5e36-4707-9131-5f321b13c5bb": [
            "node_32"
        ],
        "9cc5990a-11e4-4f92-96d9-b9a73ce8ddf6": [
            "node_32"
        ],
        "48e39a7e-63da-4dd5-b1c5-acc960a75574": [
            "node_32"
        ],
        "8ba5cdff-48e8-4ece-a02e-6652f26e6a72": [
            "node_33"
        ],
        "e178ab76-9f90-4e3c-bc06-797d546674da": [
            "node_33"
        ],
        "65708399-a9d1-40d9-a8ba-a146fdb500ad": [
            "node_33"
        ],
        "aee3b5b5-969d-4b26-b784-fa46c3d62c7a": [
            "node_33"
        ],
        "69d23bee-1fa1-45c4-9c75-64c36294315a": [
            "node_33"
        ],
        "c52c6e5f-7dd2-490f-a254-b00f5a7f63ee": [
            "node_33"
        ],
        "5d460895-f4f0-49b7-b3a9-38605687d8ae": [
            "node_33"
        ],
        "0708dcf0-48f9-4f77-94ff-acf5861751ef": [
            "node_33"
        ],
        "6b1f886e-6742-4c4c-903e-b32d6338b3eb": [
            "node_33"
        ],
        "c27ce862-d36c-4327-97e7-7b84d95d609f": [
            "node_33"
        ],
        "ccafc552-b69d-419b-b3c3-b416e15fd4bc": [
            "node_34"
        ],
        "58a7cc59-8473-4c65-bf4a-a5b51d53dc05": [
            "node_34"
        ],
        "8aaf26ba-ca33-4c33-b947-1b66c4b113fb": [
            "node_34"
        ],
        "450e5730-e86b-4e38-81fa-97e49e03a3db": [
            "node_34"
        ],
        "e2d966c1-d6f5-4c38-aec3-c517ce9e86ec": [
            "node_34"
        ],
        "157d1fbd-5455-49c0-a4fa-d2578af6ff93": [
            "node_34"
        ],
        "c4537e4c-eb14-477f-b98f-b3e5d96095a7": [
            "node_34"
        ],
        "19f582e0-c90c-4d45-b951-b96c7dc85ac1": [
            "node_34"
        ],
        "6380e54c-b3c3-405c-8fd8-cd933e6ec022": [
            "node_34"
        ],
        "2646dffd-0aee-4ad7-8404-15f3d59e9bf8": [
            "node_34"
        ],
        "4cf115c7-c09a-4706-b375-e19a42de41ef": [
            "node_35"
        ],
        "52580674-8937-4538-823e-24cda4e031d5": [
            "node_35"
        ],
        "7fa02457-9c47-40aa-99c8-9523971c066c": [
            "node_35"
        ],
        "8655ad91-3ef2-438e-ae74-d962d7cda4cf": [
            "node_35"
        ],
        "6229b471-5690-4d14-9fcf-26d99946a9a1": [
            "node_35"
        ],
        "faf0cb8c-b32a-42ac-8c77-4823f9b4e3c9": [
            "node_35"
        ],
        "521dda53-c2d7-44dd-86b8-d35886ffd020": [
            "node_35"
        ],
        "bf7cf49c-3cd5-436b-b4e2-b2fe933a577d": [
            "node_35"
        ],
        "75cc895e-5dd5-438d-9238-752d0110f256": [
            "node_35"
        ],
        "6a5f857c-9040-43a0-8d12-70bba5daffe6": [
            "node_35"
        ],
        "20042e21-0c6b-4fd9-a666-b20f8604f6f9": [
            "node_36"
        ],
        "b0abdf95-fe1c-448c-8993-56576c89873d": [
            "node_36"
        ],
        "6b963fb1-5002-4611-88f1-bf7e73b7d21e": [
            "node_36"
        ],
        "b11c55d4-87c6-4c65-865e-db6ac36d8080": [
            "node_36"
        ],
        "ab4b6f74-b2eb-4498-a7ee-5d66ee9bf1bf": [
            "node_36"
        ],
        "2a6a908d-3971-4b8a-a484-bbfce0e34c3d": [
            "node_36"
        ],
        "f16d8396-b250-4ca9-a635-73c164cd928b": [
            "node_36"
        ],
        "6a889b61-c417-4539-a289-d6a425d59b01": [
            "node_36"
        ],
        "2f1a3906-1b0b-40a4-98bb-ad01ebe7ac0e": [
            "node_36"
        ],
        "02971c7b-6dce-4190-a328-278407fca76e": [
            "node_36"
        ],
        "a5cb8a48-dc9e-4ac2-8313-7d97c0580150": [
            "node_37"
        ],
        "528f7464-e29f-4246-8258-0d308254ac66": [
            "node_37"
        ],
        "8d797cc5-80de-4e35-bab7-eb7b5d518e1c": [
            "node_37"
        ],
        "4db61cc5-0f71-4233-a133-31b7212bb88d": [
            "node_37"
        ],
        "d20d74fb-d0ec-4063-9f06-137449896cc6": [
            "node_37"
        ],
        "98b813b8-ff16-4e98-a381-50d1285ef2ab": [
            "node_37"
        ],
        "0e3abdcc-41ed-4d8c-a3bb-f4f5710cefa6": [
            "node_37"
        ],
        "71edf93f-4d99-47df-837f-c52ce8b9d05f": [
            "node_37"
        ],
        "bfb4b3ed-118f-4ed3-b41b-36eb2461bbea": [
            "node_37"
        ],
        "3a060707-c2cb-4044-9645-cca6b771ff23": [
            "node_37"
        ],
        "30c3a0fa-21d4-4594-9dc0-880a5f668232": [
            "node_38"
        ],
        "0641b149-b720-4799-b76a-4ad01f7dd0ff": [
            "node_38"
        ],
        "29700f68-9d24-45f7-91e2-c42e5610d0cd": [
            "node_38"
        ],
        "296b921a-4c40-4b72-a49a-db8a43a841f8": [
            "node_38"
        ],
        "91807a6f-aeb1-42df-94ab-354c396c799e": [
            "node_38"
        ],
        "c6066936-d334-43c2-a645-ede960ac6299": [
            "node_38"
        ],
        "b8c474e1-efac-4c9d-9f63-5c99bbe85d0f": [
            "node_38"
        ],
        "8b9ecc38-552f-4acd-a1a4-9d926b6d19ff": [
            "node_38"
        ],
        "9feca725-2a9b-4fdf-93d4-80f67cb4ce54": [
            "node_38"
        ],
        "e6abc7bf-0e90-4f81-960c-a7bee91f0b18": [
            "node_38"
        ],
        "5e672913-a547-452d-8e8a-8f1bec0a73ff": [
            "node_39"
        ],
        "7d1a6894-784c-42a4-baf9-f0b74ef92ff7": [
            "node_39"
        ],
        "6a67dd1b-17d7-4c20-be4b-666b44f3b676": [
            "node_39"
        ],
        "eb62eca9-8838-4647-8c76-2cb875f05074": [
            "node_39"
        ],
        "5637dc15-bb1a-404e-87dd-23a95fde2a51": [
            "node_39"
        ],
        "7378b489-d667-496e-a6d2-263ffc33eb15": [
            "node_39"
        ],
        "32b198b7-ada9-4f01-9f9a-94c8bc025446": [
            "node_39"
        ],
        "65a792ad-328f-475c-a437-7c5437162d82": [
            "node_39"
        ],
        "c45587fb-df14-4f37-b2eb-94d87b524e54": [
            "node_39"
        ],
        "9b4d141e-a5e2-4b38-8e2d-e85449e1869e": [
            "node_39"
        ],
        "12c043d3-224c-4a84-a73a-d4ecee6c0d6a": [
            "node_40"
        ],
        "9ea842f1-e275-4b96-81f1-5f0cc0e63774": [
            "node_40"
        ],
        "78f3b38f-733c-4c1f-965f-638daecad005": [
            "node_40"
        ],
        "4ef0f299-accf-4832-b4f2-f8e7eb397171": [
            "node_40"
        ],
        "7d6f7196-b820-4392-91f9-16159c6c50ea": [
            "node_40"
        ],
        "6fd56408-e666-489b-bab3-d2914d6db6b9": [
            "node_40"
        ],
        "e7157f3a-f92d-42e1-919e-124a511811a8": [
            "node_40"
        ],
        "30ed34de-ede5-4581-9cbb-2d5a2979e874": [
            "node_40"
        ],
        "c1d21903-6664-43d5-9a1e-887a51c8278b": [
            "node_40"
        ],
        "fccbb184-aa2b-4efa-ac04-59f6e50776fe": [
            "node_40"
        ],
        "d9922c52-7546-4b3e-8adf-d4a557b84ff7": [
            "node_41"
        ],
        "ddbfe30c-7cb5-4c17-bfca-7c98247defb2": [
            "node_41"
        ],
        "108c70fb-1311-4d80-84c8-311aa4310cf8": [
            "node_41"
        ],
        "95aa0e69-5845-43de-afaa-003cbc62149a": [
            "node_41"
        ],
        "45f36e38-8c78-45fa-8bf9-eb191ac76d93": [
            "node_41"
        ],
        "46751dcf-0fc8-4ddf-aa97-b7907e24d2ae": [
            "node_41"
        ],
        "23747377-55b9-4d69-950c-3ea9951b3b8f": [
            "node_41"
        ],
        "63d8162f-d116-43f0-ba34-12914b64b55d": [
            "node_41"
        ],
        "8b54deb0-d651-4146-9e8d-4cdd0b51b458": [
            "node_41"
        ],
        "1019ae12-2f1d-4c74-b4c7-399d74e5cd2a": [
            "node_41"
        ],
        "9c071fee-76cf-43ec-8c92-f9a1209e0e60": [
            "node_42"
        ],
        "7cda54c5-b76e-4ba6-a4d5-b68feb094c66": [
            "node_42"
        ],
        "df479ad9-de53-4d9e-958c-f12a1fc064f3": [
            "node_42"
        ],
        "02ab81b7-7a24-4c0b-a0a3-eadff47dfd2a": [
            "node_42"
        ],
        "76d76e0a-c83d-4a17-8f63-33e1020d1a8c": [
            "node_42"
        ],
        "79e0273c-19a2-4daf-9c98-75970c0d642a": [
            "node_42"
        ],
        "b759dd77-0296-4a23-b4f3-e0361d074f3e": [
            "node_42"
        ],
        "0dd0fc90-a281-4e35-a271-036856d87213": [
            "node_42"
        ],
        "8afe2f15-fc7e-4456-8322-aaf508641097": [
            "node_42"
        ],
        "3e6e8112-e36c-423c-bd4f-a4b15559cf80": [
            "node_42"
        ],
        "301fb51c-9c0d-414a-a18a-4842875a53a9": [
            "node_43"
        ],
        "b8d89b08-f577-436e-a369-07ac5d2c93c2": [
            "node_43"
        ],
        "b73b053e-333c-4f15-8ac5-0d45fade1608": [
            "node_43"
        ],
        "a075bac8-a9a7-4724-ac3a-d2687f22457e": [
            "node_43"
        ],
        "1c4afe35-cf39-4aec-988c-c4925b178794": [
            "node_43"
        ],
        "396b4099-f60c-4bc6-9c41-d758393ba287": [
            "node_43"
        ],
        "41238ccc-9c35-4f50-ac64-2da2536c68b5": [
            "node_43"
        ],
        "63a811ad-326c-44b9-850a-ce66e24c3394": [
            "node_43"
        ],
        "20f71ec6-76b0-4aa5-81cd-062a67d240cb": [
            "node_43"
        ],
        "676831e7-918b-47d6-b4c1-1ff574f1dd5b": [
            "node_43"
        ],
        "0496e41b-fd02-484d-af79-87c14e1d4b36": [
            "node_44"
        ],
        "cda54acb-c04d-4707-b933-7b44aa00b0e2": [
            "node_44"
        ],
        "2d287c93-8731-4ff9-9d7a-f6f7ee145ebe": [
            "node_44"
        ],
        "915a5b7b-72d0-42c6-81ab-dd40048c72b4": [
            "node_44"
        ],
        "269575e8-4317-4ba0-9cf4-838b954ff0df": [
            "node_44"
        ],
        "7e5c1569-30fc-49ef-b75c-60ececb99a66": [
            "node_44"
        ],
        "301e1066-b928-41f5-ad47-5a4ce3a469e1": [
            "node_44"
        ],
        "a580fdfe-b92a-43fc-91b2-edc508cf7d62": [
            "node_44"
        ],
        "668cd2d3-67a2-4cd1-9e13-924194560b21": [
            "node_44"
        ],
        "2b824f4e-9ec5-4759-9df1-ffee66432ce1": [
            "node_44"
        ],
        "bc3ede22-0728-4a99-988e-b7df30f1d95b": [
            "node_45"
        ],
        "632a96f9-0565-4814-885e-2a1118da52ed": [
            "node_45"
        ],
        "30719dd5-1d3e-4f73-a858-df0c1b1b2abf": [
            "node_45"
        ],
        "ee1c3c27-202c-4e20-90b6-5e91581c20c2": [
            "node_45"
        ],
        "152d711d-93f7-42c7-bc29-d0cad37ee7c0": [
            "node_45"
        ],
        "d6686972-b4a3-4d33-8a04-4fccfed984b5": [
            "node_45"
        ],
        "98577014-759b-415e-b40c-5caa0b274f65": [
            "node_45"
        ],
        "a47d5af1-cada-429b-818e-1798fe75ba3b": [
            "node_45"
        ],
        "266016ff-ebda-49b9-8006-ac14c9b886ab": [
            "node_45"
        ],
        "fc03e389-97fa-4d6a-bbda-d6b15a0a5697": [
            "node_45"
        ],
        "dd566266-806a-4016-8354-a31c689e3495": [
            "node_46"
        ],
        "33188237-b8b9-49f5-b73b-4588dd1ca068": [
            "node_46"
        ],
        "1a784ec3-fef0-4abc-a959-1bfea9cd2928": [
            "node_46"
        ],
        "6ac6e1ca-10e3-41fa-bf1d-793c06eecb7a": [
            "node_46"
        ],
        "50d737e2-0b34-485c-a43d-010845bad93b": [
            "node_46"
        ],
        "a480c106-ab76-4546-9a78-5b5d1fb6a260": [
            "node_46"
        ],
        "5e544ff9-b5c4-412e-80bc-4ebe7cabbe43": [
            "node_46"
        ],
        "7b8de721-3bcc-478a-b5e7-c8fe05ef3751": [
            "node_46"
        ],
        "820d6895-9298-4fa0-80ba-371ecd6b9dc1": [
            "node_46"
        ],
        "20801477-55da-4808-a335-c04614343dab": [
            "node_46"
        ],
        "050cd8f2-8b81-4087-8042-50025fc4cb88": [
            "node_47"
        ],
        "47c6f4ee-8c59-459b-916b-4a719081cf35": [
            "node_47"
        ],
        "e74ed6ad-693e-4881-b2c7-1e9f73b77116": [
            "node_47"
        ],
        "d5b98505-cbfe-433e-9755-5b538bcff6dc": [
            "node_47"
        ],
        "741e187d-2f24-436d-a74e-fa054e51cbc7": [
            "node_47"
        ],
        "531a0432-a71f-4e54-92a8-3609b2a2e062": [
            "node_47"
        ],
        "ec755e46-4f5f-4ce7-8301-6870ca1001fb": [
            "node_47"
        ],
        "46fd0cf6-d4c8-4b98-93c2-efbf0e8247b1": [
            "node_47"
        ],
        "58d1cd06-f9e4-429b-8c7c-4e606795af41": [
            "node_47"
        ],
        "f7d0d81f-ade2-4f66-a092-087799550401": [
            "node_47"
        ],
        "f84bc2d4-36be-47e9-9a1f-00b70c5b8064": [
            "node_48"
        ],
        "8f5bac99-5799-4ae3-a61d-6c2e7f4054ea": [
            "node_48"
        ],
        "4a21bd8a-60a0-4c7c-9ca8-02f62a864c7f": [
            "node_48"
        ],
        "5da9fe6e-a447-42b5-a6ba-77ad894ced2d": [
            "node_48"
        ],
        "6c512976-50e3-4fe3-a476-977818a18c47": [
            "node_48"
        ],
        "5910176c-a236-44f6-a6ad-acba811eb949": [
            "node_48"
        ],
        "9c73d7c4-144d-4cac-9aa1-ee56489fc93f": [
            "node_48"
        ],
        "1c5d9011-ce47-4273-b059-ffb9d3043221": [
            "node_48"
        ],
        "a0814b19-8f04-482e-ab53-098131fca33c": [
            "node_48"
        ],
        "a78117c8-a1db-4a11-912d-f8591997d44d": [
            "node_48"
        ],
        "e57a0b2b-f823-4eb8-9fe8-ddb31a5bf741": [
            "node_49"
        ],
        "ff045dfe-7694-4eb7-a03d-13bc80ef4dbd": [
            "node_49"
        ],
        "e85b0190-668e-4c1d-8148-9badec727e1e": [
            "node_49"
        ],
        "2347dde2-feaa-44ff-ab68-5b532e6d7e38": [
            "node_49"
        ],
        "7b91d845-ea81-45d9-8cdb-cd1a59575a48": [
            "node_49"
        ],
        "513e9e56-c0ba-438c-9de4-e644f5e5a6a8": [
            "node_49"
        ],
        "88e275bb-f4a0-4faf-a169-8ff5aabd89c0": [
            "node_49"
        ],
        "a41380d6-83c8-4142-8262-ca1e7eae3b96": [
            "node_49"
        ],
        "9c310f28-1cfc-4726-93cb-42cc65732466": [
            "node_49"
        ],
        "b654f81f-93bc-4088-a207-7330ee06990a": [
            "node_49"
        ],
        "9817bb16-8dd3-45d8-85fc-56a118037805": [
            "node_50"
        ],
        "3f38517c-bb69-41d8-9b27-c8821161b76c": [
            "node_50"
        ],
        "c7af7534-6da7-4017-af2d-d80b09ca9f36": [
            "node_50"
        ],
        "554ac857-b079-4b24-b2e9-4c0e80ce4f19": [
            "node_50"
        ],
        "82646a36-5aca-417d-b72c-95c78d282fd4": [
            "node_50"
        ],
        "04f63b07-dd4e-4821-b6e0-b72b330bd42c": [
            "node_50"
        ],
        "b8752331-021a-4dce-91b9-9ea76ac62a53": [
            "node_50"
        ],
        "2c773019-2046-4896-a95e-97042891a472": [
            "node_50"
        ],
        "100fd2e6-488c-45c3-a334-1fa994ff0479": [
            "node_50"
        ],
        "b3aaddcd-58a0-4167-86f6-e70cd718dd76": [
            "node_50"
        ],
        "35744457-25c2-47d3-ab93-f910699af25b": [
            "node_51"
        ],
        "5baf4ae9-1f70-4773-bcfc-5877958f2a12": [
            "node_51"
        ],
        "fc48afad-c6d6-4bca-9ac7-72ac598709b6": [
            "node_51"
        ],
        "c0e3188e-158a-4c21-9ff4-b7e8cc54225e": [
            "node_51"
        ],
        "17d4da66-36db-4227-be1a-e595e59a8f39": [
            "node_51"
        ],
        "90290b87-5f40-4b35-a7fe-e80866f7aa83": [
            "node_51"
        ],
        "cddd7c73-c194-4b00-a92d-4c5859ec4963": [
            "node_51"
        ],
        "264b89e5-9127-45e5-921f-a21cb7e1d9a5": [
            "node_51"
        ],
        "eae11695-ea17-4c27-9b01-eab59b1080e0": [
            "node_51"
        ],
        "8a9d2b96-e751-449d-ad21-27976a7fe4db": [
            "node_51"
        ],
        "da894833-9991-4d84-8fd3-7c80555570cb": [
            "node_52"
        ],
        "50a1f411-4439-4052-bd63-ac6815682a8a": [
            "node_52"
        ],
        "647b8f74-694a-44ee-be06-1b2a7b2a1e13": [
            "node_52"
        ],
        "b0a73431-cdbd-46f8-a45f-92b6c9f6a013": [
            "node_52"
        ],
        "b4b7b8df-54e7-4759-af8f-2e26d3f8d143": [
            "node_52"
        ],
        "979c6aed-31e4-402b-9190-16364b0926c8": [
            "node_52"
        ],
        "cc8c79e7-5431-4430-8864-7066ba054674": [
            "node_52"
        ],
        "2c16a947-68b1-49bd-95a3-dc30f7b75d6a": [
            "node_52"
        ],
        "cb16663e-be2e-400d-9c6a-84cfcf48b86e": [
            "node_52"
        ],
        "c4d3ab23-5ac2-4209-a577-276fe819b848": [
            "node_52"
        ],
        "b995ab73-c543-4f76-82cf-737762c9d4ec": [
            "node_53"
        ],
        "efacece0-c6f0-4565-a006-b24fcce5e7ed": [
            "node_53"
        ],
        "faecd854-324d-4ecb-8245-022a738a62fe": [
            "node_53"
        ],
        "05b8b2e5-f320-4063-9c35-120e80f0d1e1": [
            "node_53"
        ],
        "0924d57d-4a57-4d5a-abde-977aed1e8195": [
            "node_53"
        ],
        "b1d2225c-5262-40be-9435-3cd80f2244f0": [
            "node_53"
        ],
        "aeab0052-4806-4d32-90aa-831f47c0e49d": [
            "node_53"
        ],
        "cf170467-f49b-49c0-80d2-3665f69b2d4a": [
            "node_53"
        ],
        "4fec6935-e1a3-4fe3-badb-244060650ce7": [
            "node_53"
        ],
        "fe71de98-5739-4d7a-99ec-f2944b25c822": [
            "node_53"
        ],
        "4a1b6539-f0bb-4894-bd5c-16d28515a710": [
            "node_54"
        ],
        "efe31c8b-c3d9-448a-be10-06be88443a50": [
            "node_54"
        ],
        "69bc6eb4-07a9-401d-b3ff-fcdb41d716ee": [
            "node_54"
        ],
        "98fe575f-8bb3-4741-943c-5205a989f7b1": [
            "node_54"
        ],
        "f1c23dc2-2234-42cf-a67a-8a0889606d8d": [
            "node_54"
        ],
        "bf3ad9c9-b64a-4e2c-8dd8-c2c6bf943c63": [
            "node_54"
        ],
        "4e377d7f-bd74-4db3-80b1-0a3ff0b4b440": [
            "node_54"
        ],
        "13eca91f-1457-4104-9c72-eac3c46c0826": [
            "node_54"
        ],
        "403098a1-bfda-4360-80e4-33b5f6b583ec": [
            "node_54"
        ],
        "5ca5549d-b2cc-466f-b7e2-f2fbd8ff7dec": [
            "node_54"
        ],
        "8e949f80-11cd-4c50-a932-5cce502c4cc6": [
            "node_55"
        ],
        "9fa0e53d-fa89-4d6b-a8ec-a9913e942371": [
            "node_55"
        ],
        "215a6744-8504-42a3-a93d-18aedf76576e": [
            "node_55"
        ],
        "137b609e-2536-4295-b77e-20922c5fadd4": [
            "node_55"
        ],
        "d026d46b-06d1-4808-8e82-1f8d90f4ea11": [
            "node_55"
        ],
        "410accbc-71e9-441e-9cf4-0df35475709b": [
            "node_55"
        ],
        "d60d8a8f-b638-4d3d-ae07-1afb31ef14fd": [
            "node_55"
        ],
        "b14c1b83-6f23-4067-be06-c7de8ae337bf": [
            "node_55"
        ],
        "acf55019-de39-4305-8c46-03046ba28f1d": [
            "node_55"
        ],
        "7d822587-80e3-45fc-91c9-e2a8cedd2437": [
            "node_55"
        ],
        "8719f682-d5f8-43c9-8c9b-6c07073cc125": [
            "node_56"
        ],
        "f693b61e-d27f-470d-8157-4dc5f9bbbf62": [
            "node_56"
        ],
        "57190111-3957-4d61-aabd-bed690343209": [
            "node_56"
        ],
        "98940bde-49d9-4394-b2a2-9b6317adcfb6": [
            "node_56"
        ],
        "40589171-7f97-4c80-9fbf-5a04feb5d3ac": [
            "node_56"
        ],
        "46952c14-aca2-4d3a-bdb1-540a3538a6f5": [
            "node_56"
        ],
        "6a1eef83-30d8-4c10-972f-21a9b9c4465f": [
            "node_56"
        ],
        "6c74a967-d83d-4055-b91c-33836ee2544d": [
            "node_56"
        ],
        "9ce6dd33-583c-48c1-b862-7470363d924b": [
            "node_56"
        ],
        "6641ca23-4e2e-4a67-bd0e-c261e45374f4": [
            "node_56"
        ],
        "115b5ff0-8c32-4cc2-8999-5121167b9b16": [
            "node_57"
        ],
        "94ef122d-e7a7-4a86-8bcf-d5f3218be311": [
            "node_57"
        ],
        "71635b99-612c-454d-ae04-e63e4a510897": [
            "node_57"
        ],
        "95768618-782f-4857-8bd0-3c86ae48da37": [
            "node_57"
        ],
        "8c8984f1-fe09-4a30-a907-b274d2e8c1ad": [
            "node_57"
        ],
        "cf21dc2f-7d4e-4094-95f8-0f15ce19ca35": [
            "node_57"
        ],
        "9137ac31-5994-4f81-8257-d34f8910f912": [
            "node_57"
        ],
        "a57142fb-949d-4ad0-863c-73ad9e12ff73": [
            "node_57"
        ],
        "266fb45d-979d-41f3-9195-4eae191cb4f3": [
            "node_57"
        ],
        "8843a731-248a-4a86-8715-4c34e5bfd12d": [
            "node_57"
        ],
        "e987bffb-652c-41fa-b638-03a325cbd452": [
            "node_58"
        ],
        "ee73687e-6781-415a-8192-14785c57489f": [
            "node_58"
        ],
        "8063b733-1ce1-4816-a135-6ceafa861132": [
            "node_58"
        ],
        "5da8b13e-80aa-43de-aebf-77667ecfb24e": [
            "node_58"
        ],
        "9199ec4c-4bec-4abe-bbe5-e2b18cd69aa9": [
            "node_58"
        ],
        "c3911101-90e4-4431-8377-0c24d78268dd": [
            "node_58"
        ],
        "1612c074-7a13-4dd8-87a9-ffec252042b1": [
            "node_58"
        ],
        "ea3a0533-1770-4f6a-ab71-dc0c7192be07": [
            "node_58"
        ],
        "3c5400a5-9f38-4f40-84cf-caae47225b45": [
            "node_58"
        ],
        "851cfaac-08a3-4c97-9b2a-021488404c4a": [
            "node_58"
        ],
        "8878b0ca-be25-430f-93c4-15cb6efa036e": [
            "node_59"
        ],
        "1c7ada10-2764-467c-a16b-c912b758b916": [
            "node_59"
        ],
        "53d2e073-98d3-4e4f-af71-5aefaac61a33": [
            "node_59"
        ],
        "cb80e657-bf0a-41e6-8722-a6f3229ff554": [
            "node_59"
        ],
        "98a43352-73ff-4967-a15d-f7712f0c73ff": [
            "node_59"
        ],
        "a75c04f7-b6e1-4ff4-bbbb-f5637731e3cf": [
            "node_59"
        ],
        "07eed9b8-51c5-4c83-8d30-6a2405cc208b": [
            "node_59"
        ],
        "090c33bb-8c23-40cd-bd15-317a31780cd9": [
            "node_59"
        ],
        "2c8d73d9-cad6-41ea-adb0-b5e956d40232": [
            "node_59"
        ],
        "98b628d4-59f5-4398-8490-e2c4809fd2df": [
            "node_59"
        ],
        "0d906c68-2c27-44b0-bb99-3b06f10020b8": [
            "node_60"
        ],
        "b677fc86-2f80-4dea-8c28-f2caa30e6256": [
            "node_60"
        ],
        "a46ab7a7-fba0-4bc2-82f0-13f430b7d274": [
            "node_60"
        ],
        "5a6286ee-525a-471f-87ac-bff7f24dd3e1": [
            "node_60"
        ],
        "832da1a3-1b60-448e-a168-abcf97805a54": [
            "node_60"
        ],
        "35483409-15cd-4913-a756-a3a7962c026c": [
            "node_60"
        ],
        "1f333cbe-9531-471c-ba0f-17a47a064ddb": [
            "node_60"
        ],
        "fdbeb963-107a-4a23-8196-47d9769f93d6": [
            "node_60"
        ],
        "087b78b1-72be-4365-a2f7-d547cb2e5254": [
            "node_60"
        ],
        "97d6bfe3-2991-4bca-a24d-20a697e89d20": [
            "node_60"
        ],
        "39fb1fdb-c4b8-4ffd-8c96-d965389f9c36": [
            "node_61"
        ],
        "ab6edc73-d6e7-4ce9-a8c4-08106e29181d": [
            "node_61"
        ],
        "2f9318fb-8ee0-4372-aa4f-9d14512bfa57": [
            "node_61"
        ],
        "6ab111ad-b43d-4009-9c11-4aaee888823b": [
            "node_61"
        ],
        "eda3a1ca-ff49-4ffc-b25d-927cbf736863": [
            "node_61"
        ],
        "93ca92bb-ced6-4090-a4fc-a1d62b575a25": [
            "node_61"
        ],
        "cdd4f520-05a2-4e2b-8ed2-854fd1194e3e": [
            "node_61"
        ],
        "20a5234a-c43c-4311-bf17-80e780a4893b": [
            "node_61"
        ],
        "9a7a8957-10e3-49a3-b4df-bf757c163f54": [
            "node_61"
        ],
        "0e521319-8694-4a2b-9d54-a66b892c83ac": [
            "node_61"
        ],
        "5c970110-e1d0-4e6f-953c-adaff361aa98": [
            "node_62"
        ],
        "8faa885f-4180-48e5-aef9-aaa48a4eab41": [
            "node_62"
        ],
        "520b007f-b46b-4555-9ac3-02437dbe6999": [
            "node_62"
        ],
        "32352e0a-8833-4216-ac20-b4cd9ad397aa": [
            "node_62"
        ],
        "d5936a06-0467-4388-a999-c41ecf7309cc": [
            "node_62"
        ],
        "bb64e96b-a915-418f-86eb-4b725968698b": [
            "node_62"
        ],
        "3c87f087-40e5-404d-b315-0eb5f4c5ecb8": [
            "node_62"
        ],
        "3b48fb75-ef22-4b35-bec1-b0c13fce7c4b": [
            "node_62"
        ],
        "1154b7f2-0cf4-4470-bcc0-f05a4da2dc1f": [
            "node_62"
        ],
        "491372a9-b2b0-497f-839b-21596170ee3d": [
            "node_62"
        ],
        "ff8bc7ac-7d1f-4865-9e7a-e740cc5363eb": [
            "node_63"
        ],
        "df417cc5-735e-4349-a23b-bede7f426b63": [
            "node_63"
        ],
        "3ab71da5-e1a6-41e4-8312-957e4307830e": [
            "node_63"
        ],
        "3fffc918-343b-4440-aa2c-27be55b96093": [
            "node_63"
        ],
        "e142641f-3b9b-40fc-baba-ab7f1de239de": [
            "node_63"
        ],
        "b2182f46-7f9a-4e6c-99bb-381e53501a78": [
            "node_63"
        ],
        "3e895da7-aece-4144-83b4-d235bb5b883f": [
            "node_63"
        ],
        "916c98e7-ad14-47ac-9bdd-c402a71150dd": [
            "node_63"
        ],
        "a072dc53-e437-454a-beec-6033cbde1814": [
            "node_63"
        ],
        "3f2f9a07-b1c5-4304-b1ea-2ac73cfedb2b": [
            "node_63"
        ],
        "213a9eb6-111d-4e11-ba28-797348d6438f": [
            "node_64"
        ],
        "07ac3d26-8943-4cae-8a77-3c3b19e53514": [
            "node_64"
        ],
        "c86e0d13-d5fa-4243-ac7b-89992750db91": [
            "node_64"
        ],
        "f4767c8d-6a38-498a-84a1-4ccac23a3aec": [
            "node_64"
        ],
        "a5826f46-cd52-4cce-919a-4e48c2d338cd": [
            "node_64"
        ],
        "d043400c-4b2e-401b-8095-797552adca10": [
            "node_64"
        ],
        "3f7ebf54-a4f8-496a-a6f7-b651936ea394": [
            "node_64"
        ],
        "9fdda640-b941-4f84-a90d-74ddda41d0ab": [
            "node_64"
        ],
        "55f76b95-e508-4a9a-8a85-41e3cd7f7156": [
            "node_64"
        ],
        "f23cb140-903a-44f8-bf20-fee32d70bf26": [
            "node_64"
        ],
        "b328b745-a2e1-4ade-9975-8bb2decf667e": [
            "node_65"
        ],
        "dfeaca4e-a891-4160-8bbb-65794be3d018": [
            "node_65"
        ],
        "c505fc92-7a53-4252-a948-87aee7b26cd5": [
            "node_65"
        ],
        "7897be73-ada0-4f01-b46e-f6e958451de0": [
            "node_65"
        ],
        "d5804a0b-3a8e-432d-8527-14255dc81b94": [
            "node_65"
        ],
        "0158ebff-cc19-4ad6-948c-8db3b1b3358c": [
            "node_65"
        ],
        "1be747ec-8da9-4e70-8122-9020f3655b2e": [
            "node_65"
        ],
        "f087f0d3-72f7-45a4-9a19-f4bacb31e5b2": [
            "node_65"
        ],
        "38f18a2d-e7e9-4b76-afdc-7b946265380e": [
            "node_65"
        ],
        "77761402-5b9f-4ae6-9049-15f59d6dadbb": [
            "node_65"
        ],
        "8f590244-5633-459e-85ae-bafefda116ac": [
            "node_66"
        ],
        "a11b2bcb-1c6d-470c-a615-05386dbe927e": [
            "node_66"
        ],
        "23bec182-cb85-4e58-a151-85cd9a281ae3": [
            "node_66"
        ],
        "c9cd09f3-e2cd-474d-b7af-39c1657a03c5": [
            "node_66"
        ],
        "a4c7ad53-a551-4e2e-9520-b9619535a72d": [
            "node_66"
        ],
        "ec79734a-d0f9-426a-aa41-7b8393f106cd": [
            "node_66"
        ],
        "6d14b842-7104-489c-a49e-bbcb9df1377b": [
            "node_66"
        ],
        "1934cc08-fe3a-4d0b-95f6-2c33bd279084": [
            "node_66"
        ],
        "17d6d808-d31a-44b3-b248-a7ace5dabd8a": [
            "node_66"
        ],
        "eeac5187-1101-4874-bd43-ca2f04434316": [
            "node_66"
        ],
        "8799af57-3e50-4081-915c-9ac84c4a1c94": [
            "node_67"
        ],
        "b1236e6a-5e22-471d-b7c5-b995832737ef": [
            "node_67"
        ],
        "733de9fb-236a-4904-a3bc-30b13cd55c30": [
            "node_67"
        ],
        "82ceb96f-f224-4df7-830d-ede76b800592": [
            "node_67"
        ],
        "97f3bc2a-1254-4a77-8b17-ac40e09aba1a": [
            "node_67"
        ],
        "957a6d50-03c1-46a1-ab91-d01bb2a1648d": [
            "node_67"
        ],
        "634af046-ac90-4d10-9531-db8586afcf27": [
            "node_67"
        ],
        "b50bad86-754f-49ed-be8b-f74fd7f3acc5": [
            "node_67"
        ],
        "09d91749-ffbf-4bf2-b136-e7027448bdb7": [
            "node_67"
        ],
        "5ff058e6-900f-45d7-a090-ef273e397f39": [
            "node_67"
        ],
        "da6c366a-f264-4853-9174-a8d152164749": [
            "node_68"
        ],
        "c4d4d471-8064-4bbc-964e-9513afb5ef2d": [
            "node_68"
        ],
        "a37407c6-9b8d-48a2-a8d2-f78fc096ab98": [
            "node_68"
        ],
        "3759fef7-c249-4c5a-bf11-7037391087ff": [
            "node_68"
        ],
        "5cf94c08-1c2e-4194-bac2-d07bc3b8b2d2": [
            "node_68"
        ],
        "2524c742-8962-4ec5-8fdf-c025ff16ad2a": [
            "node_68"
        ],
        "a1ccdc82-dfa7-4a5d-bb8d-9642b23006cd": [
            "node_68"
        ],
        "0039ce0c-ef5e-4792-a2c0-476baf48723d": [
            "node_68"
        ],
        "a74318c8-42b5-4556-99cc-eb9708a7c633": [
            "node_68"
        ],
        "c53bfaa8-9da1-4ab1-bb2d-2e1d94916b7a": [
            "node_68"
        ],
        "c35aea2b-b918-4361-815e-523640c5cb6c": [
            "node_69"
        ],
        "3e726180-04fe-407b-8392-3c8e55ebad25": [
            "node_69"
        ],
        "f343d49b-34ef-4f26-acd7-56b8da7b33c5": [
            "node_69"
        ],
        "d27ef022-0ccc-4bcd-8df9-8deed985454f": [
            "node_69"
        ],
        "103434b1-97d6-47a8-a5f6-07342abe6755": [
            "node_69"
        ],
        "ba793b4e-2549-49a5-bb33-870e32b76bc6": [
            "node_69"
        ],
        "2f8c40a2-abf7-4b42-9f19-dcb53cd08674": [
            "node_69"
        ],
        "8380f09f-bcee-442a-afa7-46177d014369": [
            "node_69"
        ],
        "49b3274d-3bbb-4a22-ae2e-7c09e0956ad6": [
            "node_69"
        ],
        "b966899b-893c-407b-83ed-fffc631c4553": [
            "node_69"
        ],
        "705005f8-c859-4727-add6-4f796fb2b63a": [
            "node_70"
        ],
        "57d85b38-90ed-49da-9f79-ed5873267c47": [
            "node_70"
        ],
        "fb7482d8-e44c-4807-a30c-700f03e560aa": [
            "node_70"
        ],
        "a8421188-09ee-4e6f-9934-142527ffa4a6": [
            "node_70"
        ],
        "1c7c683b-e4a6-4d87-a850-107ebe313bcd": [
            "node_70"
        ],
        "f65de762-c7c1-4483-8f2e-8779d7a62471": [
            "node_70"
        ],
        "a669a841-7163-4431-9afb-f357c2c6450b": [
            "node_70"
        ],
        "767647d7-8b92-4d49-8f06-394da4376c48": [
            "node_70"
        ],
        "3df7f878-d0c2-4642-8554-a7eb499a572e": [
            "node_70"
        ],
        "ac12b4d4-9372-4dc0-9ee1-c2961f8344bb": [
            "node_70"
        ],
        "14406418-5e3e-43b2-bdfe-fccbbcb00ad1": [
            "node_71"
        ],
        "46ae7457-1b27-408a-80f1-8b8d5c7b8007": [
            "node_71"
        ],
        "cf2ce19d-d248-46b7-aad3-732b10c46436": [
            "node_71"
        ],
        "7266b78a-d51d-4b23-afcf-278d88e6f49c": [
            "node_71"
        ],
        "d7c85143-4745-4972-aade-0fbe25af3562": [
            "node_71"
        ],
        "4453c603-ad5e-4a6f-8047-7bb91a1de59e": [
            "node_71"
        ],
        "948b9224-ade2-4cd2-b23b-bae20ab1110f": [
            "node_71"
        ],
        "bf5bbff6-3be8-49b7-bcc8-8ba87d0a62d1": [
            "node_71"
        ],
        "a5a4db33-48f5-439c-a9b1-3534b1dce410": [
            "node_71"
        ],
        "95e2bc15-da51-4b0e-813d-64fd087ca5a8": [
            "node_71"
        ],
        "0b478b73-6dc8-4996-bc5a-c7c00480fb1c": [
            "node_72"
        ],
        "31fc4dda-af03-4ef0-85d8-2a6b3f8dff67": [
            "node_72"
        ],
        "e109b4b8-0a7c-44a1-a1f2-240301d27627": [
            "node_72"
        ],
        "3a86fb5a-6e28-4d86-80ff-22190e1df88a": [
            "node_72"
        ],
        "733ad948-9a20-492d-a20f-0147a8d9c976": [
            "node_72"
        ],
        "b7a54960-cfec-4e3f-a819-e972714d0bc5": [
            "node_72"
        ],
        "567b9e9c-41c6-4c95-842c-6f72dba76490": [
            "node_72"
        ],
        "b738e10a-0664-4063-a8b3-a11eee9745d7": [
            "node_72"
        ],
        "5d5f75c6-1c19-4c4d-8352-4823cb116898": [
            "node_72"
        ],
        "6da4870b-96c0-48bb-b810-6daa87deab69": [
            "node_72"
        ],
        "aa25506b-9f1a-46d0-8852-c8640af39fad": [
            "node_73"
        ],
        "e38797f9-0780-4ec2-a9f6-c632685f241f": [
            "node_73"
        ],
        "1270291d-fb52-4129-8a9d-14199320422e": [
            "node_73"
        ],
        "875b12f4-7a56-4790-9ac6-925a6e44fbc1": [
            "node_73"
        ],
        "a87607e8-af71-40b4-96f9-0e525e656ee0": [
            "node_73"
        ],
        "7957918d-e98b-463c-b8b7-6a3c89eff592": [
            "node_73"
        ],
        "a77b3c98-7f9f-4ac4-a159-025ece9182ec": [
            "node_73"
        ],
        "c1e4d188-466f-4937-9dbb-363c9cd4ded2": [
            "node_73"
        ],
        "1eb6c2d7-b94e-42a8-b9af-f939853ddb1b": [
            "node_73"
        ],
        "5e3a47d5-9f67-4d47-917e-0c829061fde1": [
            "node_73"
        ],
        "8f4d1f09-f1f6-447d-981c-54a308947a34": [
            "node_74"
        ],
        "17547cd3-30de-4a13-98cc-d21cac2f720b": [
            "node_74"
        ],
        "0d944071-33f5-4a84-89b8-e557d0365de9": [
            "node_74"
        ],
        "f468a687-bf30-4588-9b92-af9efd845f93": [
            "node_74"
        ],
        "eee41968-1e05-418a-b0ab-fb55d08cca50": [
            "node_74"
        ],
        "630de532-f03e-4604-bf62-430d9211766a": [
            "node_74"
        ],
        "d5ed6de3-b48a-40bf-8c97-1269e463d002": [
            "node_74"
        ],
        "a2c80258-43e2-4ebd-8935-e84535619c98": [
            "node_74"
        ],
        "4eb7fa56-cb2f-4524-8b2b-d58168a73a51": [
            "node_74"
        ],
        "f87227c0-94dc-43d7-9bdf-234466f4914b": [
            "node_74"
        ],
        "83f99077-bf3b-4649-955b-dad4f7dfccb0": [
            "node_75"
        ],
        "fef23ab4-b05e-4ef0-a491-4c51e117f626": [
            "node_75"
        ],
        "277a78d3-0e36-4769-826c-403303a65936": [
            "node_75"
        ],
        "96270adc-645b-4022-9732-eec60efb84bb": [
            "node_75"
        ],
        "6d5d184b-81a4-42fa-af50-3007bc97f9e4": [
            "node_75"
        ],
        "1a3baa7f-f8d2-45c3-8028-3ab6c30c528b": [
            "node_75"
        ],
        "4302263d-0c50-47d0-b5f9-38963a432f2e": [
            "node_75"
        ],
        "22ade6b1-93e8-4027-adf3-6c0a4b86ccc3": [
            "node_75"
        ],
        "9c942fd9-2dd9-46bc-b424-f98523dd3f9d": [
            "node_75"
        ],
        "da653ff8-d3a7-4e8a-8f48-c760c266e48b": [
            "node_75"
        ],
        "7fc5d684-5961-419b-aae1-e4b2515ac839": [
            "node_76"
        ],
        "4ef3151c-647a-4243-86f8-6934f1cb4303": [
            "node_76"
        ],
        "ff9f394c-2dac-416f-9af4-93913057f344": [
            "node_76"
        ],
        "ce5832b5-0cfa-4810-8ec4-d95dc227705b": [
            "node_76"
        ],
        "e324fdd5-fc57-4d16-8b75-a16d73726cae": [
            "node_76"
        ],
        "fd9e57ce-d7b3-47b1-ad7d-27761722dc84": [
            "node_76"
        ],
        "8f2d4d42-f0a7-4c1b-8c8b-a22291ac4f4e": [
            "node_76"
        ],
        "cbd6a2ef-cb21-4f1d-83f3-f2918873b2fd": [
            "node_76"
        ],
        "20c11819-aa1a-4e37-b7cb-8d8ac1e55f52": [
            "node_76"
        ],
        "5a04b49f-3cb1-428a-b490-54ac456aa8e8": [
            "node_76"
        ],
        "41d37a09-2d2b-47b8-8fe2-4582cc0b8aed": [
            "node_77"
        ],
        "e5da4b6f-5a26-4cdd-a93d-ce4bbedd50a0": [
            "node_77"
        ],
        "f990e418-5c2d-4a4a-95de-ef3742f803a0": [
            "node_77"
        ],
        "08f580ea-cdf3-4730-8a4d-6b847c941699": [
            "node_77"
        ],
        "542e0f43-871f-43e0-a052-62866b29c449": [
            "node_77"
        ],
        "b14b98e4-eeb6-4f2e-ba08-51b8f9ea91bd": [
            "node_77"
        ],
        "c8622f0a-2281-49ee-a1c2-b0d83918d443": [
            "node_77"
        ],
        "fec2feaa-def0-4e24-a695-7cf64449942a": [
            "node_77"
        ],
        "cf0e9c45-9c05-4d2f-9e72-167a783a2bd4": [
            "node_77"
        ],
        "fc1e352f-c215-4778-b23f-b5771e787c61": [
            "node_77"
        ],
        "f465a11b-ccbb-4662-8d57-b8143091f473": [
            "node_78"
        ],
        "8711dcb2-4723-4142-82cc-c0035803faa9": [
            "node_78"
        ],
        "4d6ac606-e941-4b34-9dd6-e356ddf28f85": [
            "node_78"
        ],
        "0003510f-268d-4fac-90ba-9ad910f500bb": [
            "node_78"
        ],
        "5def7186-405f-4148-8898-f3157994796d": [
            "node_78"
        ],
        "427be915-dcd0-47db-b152-77a6d934741d": [
            "node_78"
        ],
        "593a99c3-beff-4268-8c2d-0e1c3a5bae68": [
            "node_78"
        ],
        "bd3b502f-8a12-4f0e-95c3-f4a3022c8019": [
            "node_78"
        ],
        "efcfa463-7465-4524-b104-55c9eaa2af63": [
            "node_78"
        ],
        "5ade2395-25e1-4f14-9f2b-a7ac5f67e4ec": [
            "node_78"
        ],
        "39fc00bb-ce42-40cc-9454-3a34b542c5cc": [
            "node_79"
        ],
        "983cd2ea-2cc0-430b-951f-d37e1ffb644a": [
            "node_79"
        ],
        "a8e77cc5-6f6c-4b5a-8a4a-ca7f137ed61d": [
            "node_79"
        ],
        "47044ad4-ef23-4a39-8a5f-1efbd1fffc3b": [
            "node_79"
        ],
        "8ad4c9c4-e88c-42d9-ac57-a4d8067302ce": [
            "node_79"
        ],
        "b9beaed1-2b93-47a9-9d6c-f1ed36394ff3": [
            "node_79"
        ],
        "3214fe78-7364-4d0d-8b60-9ef5076185d1": [
            "node_79"
        ],
        "888a7b97-ae6f-4a8e-8041-4b60e148e1b9": [
            "node_79"
        ],
        "f806f851-531b-4963-b10f-ae3938f13b09": [
            "node_79"
        ],
        "a7ff8764-76fb-465e-9eb1-f10e1ae65cdf": [
            "node_79"
        ],
        "75956fbf-dd21-4986-8dbc-3fd313b28cd9": [
            "node_80"
        ],
        "db006c33-63d0-4623-b651-8e325c680281": [
            "node_80"
        ],
        "ac05aee7-654b-41a7-9a8d-1e8c3206569e": [
            "node_80"
        ],
        "654127c4-e65e-49db-8577-01c2ff2d285d": [
            "node_80"
        ],
        "a0e35414-64c5-47f7-aab1-414c964ec767": [
            "node_80"
        ],
        "71b9cec2-90da-473d-987a-d92451eebd95": [
            "node_80"
        ],
        "fcc20327-eced-4bf2-bfbb-51bbf9d055d0": [
            "node_80"
        ],
        "dbb38ef9-0991-4349-8dba-c7630a1e50aa": [
            "node_80"
        ],
        "b469ac5a-d6ca-48ec-94c5-ab8ce9f90cbb": [
            "node_80"
        ],
        "1c5556d1-9d2a-45cd-b26e-b00e3e134695": [
            "node_80"
        ],
        "897db248-564e-4533-ab77-67431161fc20": [
            "node_81"
        ],
        "89969883-054b-44e4-bbac-dc237d0ffeec": [
            "node_81"
        ],
        "b21904a4-f0e6-4801-9de8-5a5ffb6080b5": [
            "node_81"
        ],
        "2783d24d-3cec-4309-a490-11ae547a54eb": [
            "node_81"
        ],
        "1bedfab6-a34c-4b6a-9380-198072f79a31": [
            "node_81"
        ],
        "dde9fc20-c646-413a-adae-e2af55b7de4a": [
            "node_81"
        ],
        "036243db-a9be-41ca-ba5c-ca1a582cebe2": [
            "node_81"
        ],
        "ae5a17fa-84fc-496b-b83d-91e3d8fb3a91": [
            "node_81"
        ],
        "3975347a-a952-44b7-ae93-d89fee8e361c": [
            "node_81"
        ],
        "743eda07-0c4b-49ac-aa84-6fb22f778a36": [
            "node_81"
        ],
        "a9f87895-86f9-474e-bed6-4cd45e1734b5": [
            "node_82"
        ],
        "86dd62f1-6919-471c-85a1-37c921a718f9": [
            "node_82"
        ],
        "b77d6b67-d69f-41c0-93f7-7a34fa22a459": [
            "node_82"
        ],
        "6610530a-38b3-4110-839e-bfed2964dc3e": [
            "node_82"
        ],
        "3a47550c-f127-46b0-ac4c-b9ccdc95c897": [
            "node_82"
        ],
        "da43105c-372f-4a8a-86e8-5fbe73289f03": [
            "node_82"
        ],
        "8b2a40fe-b653-4352-bd12-efe49596c6b1": [
            "node_82"
        ],
        "3db8e131-8420-4186-b0da-0d4386ba756d": [
            "node_82"
        ],
        "43784e77-a294-4eab-b3e5-258ef022c235": [
            "node_82"
        ],
        "166bafb7-e6ba-4653-b91d-09cf302e6302": [
            "node_82"
        ],
        "b54729b1-1770-4a39-972a-422dad0146b1": [
            "node_83"
        ],
        "ef511133-13a5-4b00-b84d-7093b1f72c82": [
            "node_83"
        ],
        "3c32be99-788a-4718-9c9f-f6ccaf63bfbf": [
            "node_83"
        ],
        "1f6e3fb1-1edc-4443-9efd-7bb10211d1f5": [
            "node_83"
        ],
        "ecb97f3f-6507-470f-9b51-44a58e8ce392": [
            "node_83"
        ],
        "c3bed7d1-2631-49b5-97bd-22e46380d709": [
            "node_83"
        ],
        "81b7572d-6419-413b-b012-be85cf83f609": [
            "node_83"
        ],
        "9d0bcd27-1bda-42c5-9550-3e226015d70f": [
            "node_83"
        ],
        "6d56d411-41d7-41e5-bb60-2105c6c85d0c": [
            "node_83"
        ],
        "e0a3b65b-d53b-4daf-963a-d2deef5b67ea": [
            "node_83"
        ],
        "53cfef01-e5ff-4d94-8938-a2f796e17a17": [
            "node_84"
        ],
        "20aa0dd0-89e3-474a-b90e-d0bc216a5122": [
            "node_84"
        ],
        "383b219e-0256-4be0-b7ce-ddd067ab3e00": [
            "node_84"
        ],
        "74fcc892-b1ed-487b-8479-ae402950585a": [
            "node_84"
        ],
        "15620429-2b63-4291-ac41-c2e66b770df6": [
            "node_84"
        ],
        "0ad7236d-36f0-4251-9000-65bcb6b42468": [
            "node_84"
        ],
        "4a94667f-524e-417d-a65d-f80a70f6a9b7": [
            "node_84"
        ],
        "70b00c79-da0c-4a55-abd3-8f4588cf926c": [
            "node_84"
        ],
        "4b62324d-1d54-4fbb-b9d0-459552b12832": [
            "node_84"
        ],
        "37c45db0-f9d0-4719-8a92-231b70de2310": [
            "node_84"
        ],
        "b0317dad-2f91-43e8-a269-c90b76fd42d2": [
            "node_85"
        ],
        "432a531b-27cf-4af7-bdc6-c37bbb365ab6": [
            "node_85"
        ],
        "1e5afa63-a390-40ac-9795-73b47155075b": [
            "node_85"
        ],
        "da84d1bf-bf78-4e3b-8317-0f7b408b17e6": [
            "node_85"
        ],
        "d730fffc-a5d7-4b98-8dc6-d5e3b19edb7e": [
            "node_85"
        ],
        "71c113b6-880a-4b9b-858c-7f4541225d22": [
            "node_85"
        ],
        "345dd26e-8c8b-4421-9dc0-67b6348a6422": [
            "node_85"
        ],
        "e1d9dea6-5ba4-41e9-81fb-123eb51f8272": [
            "node_85"
        ],
        "654439d8-a3ed-4232-a032-442f012e3499": [
            "node_85"
        ],
        "2fb945b6-7e7c-41e8-a65d-1d3646cff911": [
            "node_85"
        ],
        "cc27ef75-d350-4fd9-8c89-2f6c2802fbfd": [
            "node_86"
        ],
        "86e50372-392a-4878-855d-0959dfa08d96": [
            "node_86"
        ],
        "69567d7a-f68a-4f89-8fca-ecb9b2569bdc": [
            "node_86"
        ],
        "d01bcc39-f373-413c-878a-1942b3b55e9b": [
            "node_86"
        ],
        "cb62db43-e061-46a3-88ed-48bb457f346d": [
            "node_86"
        ],
        "61a4d76a-8dac-4658-a0ca-8faeca610f77": [
            "node_86"
        ],
        "d82e1efe-30f1-4012-95b7-030c9e9d316f": [
            "node_86"
        ],
        "86a4ce35-b09d-41d2-ba1d-701430e95b27": [
            "node_86"
        ],
        "27e78579-4991-4b71-bb37-094130ecfd41": [
            "node_86"
        ],
        "d21a3b8c-a358-43c7-a901-363f32e90ec8": [
            "node_86"
        ],
        "d183e29e-0fc2-475e-af1a-a922864905c4": [
            "node_87"
        ],
        "9d859641-4be2-4fa5-9c75-e04f1084eb4f": [
            "node_87"
        ],
        "cd129655-2398-4720-9a3e-f9a2ca5ba30a": [
            "node_87"
        ],
        "af21a7c5-2a8c-4860-97e5-3be60ee0a7b8": [
            "node_87"
        ],
        "522bdd6f-298b-424b-95fd-69cf1fe7e2a9": [
            "node_87"
        ],
        "d2ea477c-7b4c-4eaf-adfc-5d581451ecd9": [
            "node_87"
        ],
        "5a2062da-dac1-4cd2-84f2-aeac09ced6c6": [
            "node_87"
        ],
        "f2b6ed29-665c-4a44-9284-6af1d920a1e8": [
            "node_87"
        ],
        "dabaa2fd-abcd-4a7f-a00a-5f6fac6d50e2": [
            "node_87"
        ],
        "87236c71-7417-4183-b987-218a13fbae2e": [
            "node_87"
        ],
        "02f4c8c9-3545-4447-9d49-95dc038a55de": [
            "node_88"
        ],
        "383b1288-e107-48a7-8dd4-92fb5e79e595": [
            "node_88"
        ],
        "de821ccb-13fe-4a5c-8d91-286920f4260c": [
            "node_88"
        ],
        "12aee59e-dd84-4952-a000-77d009357223": [
            "node_88"
        ],
        "086343eb-f6f7-490a-935a-174934c57953": [
            "node_88"
        ],
        "62a36f3a-95c4-4cd3-9724-ff7878c494d4": [
            "node_88"
        ],
        "a95c57f6-162f-4e68-96dd-e1baf089440a": [
            "node_88"
        ],
        "3a5d463d-2594-4d57-92e2-d640bcaf16cd": [
            "node_88"
        ],
        "6fdbebbb-045b-4ceb-81f5-8a0dd5a52e24": [
            "node_88"
        ],
        "23fc7659-1369-4f55-bd5b-847cc31ec14a": [
            "node_88"
        ],
        "37c7290c-d66c-4a9d-99e3-75a1b48c87cf": [
            "node_89"
        ],
        "d4220302-6177-4aed-8474-7c1e8f73ddda": [
            "node_89"
        ],
        "edcecf02-c3ea-4a27-b853-ad9323fa3e2a": [
            "node_89"
        ],
        "a3604a30-942d-439d-8838-a9d73192eeaa": [
            "node_89"
        ],
        "3385eacc-a32d-482a-b769-35eac54ca58c": [
            "node_89"
        ],
        "8e0d7776-f862-4c47-a819-d99dd936ffa2": [
            "node_89"
        ],
        "2480dbb3-2a60-4929-a71f-fa2de0cdd388": [
            "node_89"
        ],
        "ae0ae74e-1ef0-4288-9666-f0a09d03f3ee": [
            "node_89"
        ],
        "c259ce8a-bf62-4df0-9d9b-2e02755f2f8c": [
            "node_89"
        ],
        "2049e452-7007-44bb-ad53-08eac1f8dd35": [
            "node_89"
        ],
        "8b12028b-6acf-4ba7-9922-d9cc4f9fb2bf": [
            "node_90"
        ],
        "024f1de2-567b-4d92-b737-3684714400b4": [
            "node_90"
        ],
        "2d46a10c-911d-44cd-b838-5694464397a9": [
            "node_90"
        ],
        "bd7d138e-dd8e-4469-9466-4ae0857afdcc": [
            "node_90"
        ],
        "17d6025e-3ac2-4fe9-b399-6f15fa0f3a48": [
            "node_90"
        ],
        "eb073d96-1c9b-4d61-8994-563866ecf680": [
            "node_90"
        ],
        "81595047-cc73-42ab-b1a4-0ac937091298": [
            "node_90"
        ],
        "0d3ff6ac-57bf-4a99-a801-37bdb225e51e": [
            "node_90"
        ],
        "13d0d920-84bb-4857-ab16-9b18028bca3f": [
            "node_90"
        ],
        "6252bc2d-a3dc-49e9-b01c-6734ea34995e": [
            "node_90"
        ],
        "84563fb6-ef3a-4201-9b0a-aabec1da59fb": [
            "node_91"
        ],
        "558fb59c-7dd5-479d-a732-ba3e212f6e4b": [
            "node_91"
        ],
        "468de01c-a55b-4088-b295-bbe9e1f917f1": [
            "node_91"
        ],
        "06650ce1-6b98-4083-abd8-8fb0a425530f": [
            "node_91"
        ],
        "9b101ee0-ce2f-4753-b7e6-0e88e76c2d1e": [
            "node_91"
        ],
        "9025c776-a0f2-41bf-b120-6360c8de9e54": [
            "node_91"
        ],
        "9dfc8fe6-a500-402f-8364-a0f407589fb3": [
            "node_91"
        ],
        "2ed9c1e1-ca57-461e-aa6f-5f2a39723476": [
            "node_91"
        ],
        "9b51d523-9443-44ca-a463-18e0f08ac77c": [
            "node_91"
        ],
        "ec52c137-fb7a-407c-8032-b6d836899fc0": [
            "node_91"
        ],
        "1679081a-1610-4e83-aa87-f93718bdb129": [
            "node_92"
        ],
        "24f834e4-1f37-4067-bec5-6f250cce8870": [
            "node_92"
        ],
        "e4e43f64-1894-4db5-85fb-f5f7f2c17867": [
            "node_92"
        ],
        "ce3cabb2-0e7c-42e6-9ed6-d7fea5523003": [
            "node_92"
        ],
        "c425e4f7-81a6-4925-989f-bb3e6606dfcc": [
            "node_92"
        ],
        "8d6e64f4-8f8f-4c5d-85a8-780f14ed2c0d": [
            "node_92"
        ],
        "e7cd42a7-0030-4c16-9966-6e4f82e9cc37": [
            "node_92"
        ],
        "ca2cfd88-d290-49d7-9691-b2b94c86d2f7": [
            "node_92"
        ],
        "c780d7dc-d030-4922-a4d2-ebd8c4151f3a": [
            "node_92"
        ],
        "cd9a2b5e-abc2-4a76-a9cf-1288c3a91bdb": [
            "node_92"
        ],
        "96c1877d-28fa-4499-8fe1-b6a641d6f6d8": [
            "node_93"
        ],
        "f8aae89d-184e-4683-89da-f02874302e75": [
            "node_93"
        ],
        "0fa79790-3e48-4c69-9af2-5f3bab30e3a7": [
            "node_93"
        ],
        "e878d333-b7b2-45fa-a45c-1a89a45f58e9": [
            "node_93"
        ],
        "15509b6f-6300-4e27-a851-6058e78dba9b": [
            "node_93"
        ],
        "a8b461a5-302b-4af3-8047-e71c897d67ab": [
            "node_93"
        ],
        "16378ea8-3b2f-4bee-ba11-a0a05bac1e9a": [
            "node_93"
        ],
        "e0299e73-82d4-4899-a5fb-b898f8ec8183": [
            "node_93"
        ],
        "390cf9bc-3234-49e3-a8a7-53442e44b20f": [
            "node_93"
        ],
        "2b8bfe31-5706-4cac-b3e6-c41a532e1223": [
            "node_93"
        ],
        "b36fec0f-0538-454f-8a04-7ec2163cb4d9": [
            "node_94"
        ],
        "0c754ff1-0327-4602-b220-b61c4ef2badb": [
            "node_94"
        ],
        "e4232091-81e0-4cb9-86b3-542acd594947": [
            "node_94"
        ],
        "631f0f3d-aa2e-43bc-9b5f-db60bdafbfda": [
            "node_94"
        ],
        "baf900f8-d7c7-4edc-9d41-153a8d202eb8": [
            "node_94"
        ],
        "660c4723-0c4e-4193-969b-56689611b139": [
            "node_94"
        ],
        "a9f00af0-b7bb-4580-aab3-929c5a8f1ec7": [
            "node_94"
        ],
        "41d1a569-3c75-477f-8b45-62b299b7fa6f": [
            "node_94"
        ],
        "bac1947d-4db1-42cd-86a4-5afd208bb380": [
            "node_94"
        ],
        "b68cea8c-44e9-4404-8ffb-49e21cbf7217": [
            "node_94"
        ],
        "ed4cb43d-59f2-4e57-bcbc-24d2d6fd0959": [
            "node_95"
        ],
        "d9673f44-1b6d-4b3f-9960-83250598213f": [
            "node_95"
        ],
        "99271d6f-87fe-4424-a5f8-d617d721d47a": [
            "node_95"
        ],
        "a475e0b9-0797-4cf6-bef9-459944a3f577": [
            "node_95"
        ],
        "85bafa0b-e37f-4089-a578-28bd4aadd3bd": [
            "node_95"
        ],
        "46e487ae-8e50-4879-89bd-73ffaa588967": [
            "node_95"
        ],
        "248ef9f6-ea02-4e45-8952-180e3341f9b8": [
            "node_95"
        ],
        "b3fc093d-419f-4e60-839a-2f8a5a995e49": [
            "node_95"
        ],
        "1a2f1290-471f-42d7-8dd0-ae5226110a4b": [
            "node_95"
        ],
        "700d6a41-b85e-4eb5-90c3-9ab9b648dd53": [
            "node_95"
        ],
        "1a2334a3-bfb2-42d5-9bdd-84242500696c": [
            "node_96"
        ],
        "47934a43-4d15-439c-9080-29f3ca5ece36": [
            "node_96"
        ],
        "74d8d626-f083-4799-87df-89c199ca31e2": [
            "node_96"
        ],
        "dd0d664b-34cb-4424-95f2-65a27aa2ee1b": [
            "node_96"
        ],
        "bd1d779f-8f35-4d63-816d-ddd3dfc58391": [
            "node_96"
        ],
        "73e69019-1208-4989-9514-a880425ae177": [
            "node_96"
        ],
        "4a010339-76ae-4dd9-82a7-93820cdd3aa9": [
            "node_96"
        ],
        "b357f262-8bc7-4a43-ba94-90d25c2fc3f7": [
            "node_96"
        ],
        "90f531c1-a2a1-4663-a701-8d0c526f25ee": [
            "node_96"
        ],
        "271c845d-f7cf-4502-a591-f3426de16a92": [
            "node_96"
        ],
        "58098587-317a-40dd-8e8c-842573620942": [
            "node_97"
        ],
        "6f2c03ea-96d0-4e29-b99f-2639c6fa370e": [
            "node_97"
        ],
        "ef1c8ce0-05f9-4005-9b22-cda17855b347": [
            "node_97"
        ],
        "24dbbe6d-be05-493b-90c7-80c5c77381ad": [
            "node_97"
        ],
        "dbee2461-2268-4f58-b5b6-0f401a07a887": [
            "node_97"
        ],
        "4aa1ba05-c07b-4666-8daa-e347f20c0b8a": [
            "node_97"
        ],
        "706aa352-c9bb-4b85-a54b-29bb23c1a531": [
            "node_97"
        ],
        "5eed5ff4-f82f-47e1-87e1-41dd1fe2c21f": [
            "node_97"
        ],
        "56b9c86f-a928-499e-9498-a73628644144": [
            "node_97"
        ],
        "c1d879cf-8c6a-442a-848d-8600a19adaaa": [
            "node_97"
        ],
        "d2669ffe-7beb-48ec-8271-d36c72dbfabe": [
            "node_98"
        ],
        "c0042bec-15b6-4bd4-a93e-7fd98760cf86": [
            "node_98"
        ],
        "156e0e0d-a4fa-429c-8409-431220dac5dc": [
            "node_98"
        ],
        "b017cd18-641c-49ef-aee1-7579905d4ef7": [
            "node_98"
        ],
        "20d45b19-3e29-4ce6-8f8e-89b28d4e5037": [
            "node_98"
        ],
        "b81d42af-4840-4e75-a37e-f5bb5fa4034f": [
            "node_98"
        ],
        "3c35f6e1-8218-4d70-aa5b-caab797ef790": [
            "node_98"
        ],
        "e0c1eaf4-fcce-4647-9445-c6df3ac525f8": [
            "node_98"
        ],
        "243adf1a-3e6e-4934-8f05-08192cf75259": [
            "node_98"
        ],
        "78d67856-973e-49c1-aec2-1494f8b7880b": [
            "node_98"
        ],
        "810207f7-bfd2-4350-8069-66311eccb2c9": [
            "node_99"
        ],
        "a6ff0b73-63d1-49e7-96d3-9db6bd320ba0": [
            "node_99"
        ],
        "5193feb0-ee34-41cf-823d-a0ee4e056d12": [
            "node_99"
        ],
        "817770a0-a4e1-475f-9443-01aa5dd1c843": [
            "node_99"
        ],
        "d65a760c-da91-4b9f-abd1-0ab23d361c35": [
            "node_99"
        ],
        "9330c6d8-e629-46c7-a1b9-abcb42a79fe2": [
            "node_99"
        ],
        "315c34dc-ec06-41d4-9468-42ce9d0b8ca2": [
            "node_99"
        ],
        "6b6e95ef-4415-40a3-81bb-8fa406d6b2c3": [
            "node_99"
        ],
        "8b63c842-754d-4ceb-822c-19d874b6dfa3": [
            "node_99"
        ],
        "f422d89e-3af8-4bbc-9137-98b0b7c226c2": [
            "node_99"
        ],
        "63182019-df9f-4b89-8f07-0d5739df1e7c": [
            "node_100"
        ],
        "15f67438-55f2-4e1d-bcb2-5931cf113613": [
            "node_100"
        ],
        "cab66794-d2fc-49e5-a6ce-f7660eb424d4": [
            "node_100"
        ],
        "d28f0a11-6bc2-4985-8f59-a165599cde00": [
            "node_100"
        ],
        "544c0523-4849-4a4c-9fdd-665819d60ad1": [
            "node_100"
        ],
        "83fed39e-fc22-49cf-bc94-3787328ec3b1": [
            "node_100"
        ],
        "5b0e0b8a-45ba-48d2-ab2b-d5416f1d6089": [
            "node_100"
        ],
        "b1d94630-89a1-4be2-a5bc-6a455898de22": [
            "node_100"
        ],
        "37fc4dd3-224f-42d3-8bc8-48fd1c220d7e": [
            "node_100"
        ],
        "d9a63734-783d-4d2d-9606-295a6c1bc0de": [
            "node_100"
        ],
        "8ad62d6a-b20e-48de-80bc-996076551adf": [
            "node_101"
        ],
        "969b8e6d-3a24-4537-bc91-948c60660254": [
            "node_101"
        ],
        "a21481e3-7e32-431d-b606-03b99ee55278": [
            "node_101"
        ],
        "0d563f3d-9eb9-4e66-9146-7ba34fbdaba1": [
            "node_101"
        ],
        "94928ab3-5bfb-4263-830e-7d645a050b88": [
            "node_101"
        ],
        "6ae6c002-0e19-46f1-93dc-3a7cc85c48b2": [
            "node_101"
        ],
        "e16cc5fa-12ce-4018-95af-8f22bad3d6f6": [
            "node_101"
        ],
        "b1f1c5b7-cc93-408e-8c63-181b47186d2a": [
            "node_101"
        ],
        "96c8a9f7-60be-499c-b4b1-f9f889857d15": [
            "node_101"
        ],
        "bce30228-f7d5-4287-b768-8af1681bd9e1": [
            "node_101"
        ],
        "7049ce02-5fad-4cb3-aa3b-9ac892380878": [
            "node_102"
        ],
        "5f08a1b2-85fb-4fcb-b15e-4d2685d0ebe7": [
            "node_102"
        ],
        "041bcdb1-2df6-49eb-8551-6b4fced1f1bf": [
            "node_102"
        ],
        "e39ca0b7-a0eb-4f4f-899b-2fdb18a9e544": [
            "node_102"
        ],
        "d8ebc361-887c-4fa9-990b-6ed4a2eb52e7": [
            "node_102"
        ],
        "365e4a5a-e965-41ea-9084-9009ddc8160c": [
            "node_102"
        ],
        "6955938f-caee-440d-a6e2-ca19aecaf34d": [
            "node_102"
        ],
        "b2cd2e00-d4fe-4be9-9eb4-a0b61a2ac4fc": [
            "node_102"
        ],
        "4a7c002d-3b2b-49ef-9551-9781e05e14ee": [
            "node_102"
        ],
        "74415071-32ff-4404-9711-1644aad70e28": [
            "node_102"
        ],
        "fe462210-bd24-4985-9ab9-d6a3b5872e60": [
            "node_103"
        ],
        "bdb2a4c5-8e8c-46e9-b1c9-96cb3313dd73": [
            "node_103"
        ],
        "8c68714a-0b29-49ca-b402-4964dcf3b683": [
            "node_103"
        ],
        "d4ce8385-576f-4e7f-add9-0cc3e1b6aae6": [
            "node_103"
        ],
        "460bab6c-056e-4e64-91e8-32a129200577": [
            "node_103"
        ],
        "dbe2305b-ab29-4d7e-8b4a-4ef70396d5b0": [
            "node_103"
        ],
        "76ad8511-e9eb-471f-8671-49fde8e724c7": [
            "node_103"
        ],
        "58f4d02a-f441-4f0a-8307-5da421caa8e1": [
            "node_103"
        ],
        "ff10a404-8b6e-497e-ac72-eb0f6173205b": [
            "node_103"
        ],
        "c23a997c-b6b3-4e1e-a0f7-eb30b687a5ad": [
            "node_103"
        ],
        "1b792e66-2854-4664-8253-8c438ab2f5ac": [
            "node_104"
        ],
        "4db53b0b-0151-4423-bbd7-050c85540c3c": [
            "node_104"
        ],
        "0c55d2bc-fc15-400c-8799-eb35ca4070ed": [
            "node_104"
        ],
        "210e80f2-3e61-4dbe-9331-ed4a66b6cffc": [
            "node_104"
        ],
        "5642f44f-413e-499c-b7d4-1a380b3c90f2": [
            "node_104"
        ],
        "27f4caea-0829-44f5-8bbf-2c0ed41eb32b": [
            "node_104"
        ],
        "92bf4b96-20ca-4208-b149-552e0d64b06e": [
            "node_104"
        ],
        "1fe30c62-ac04-4b42-b3af-7cca812dab23": [
            "node_104"
        ],
        "ff691d9b-7977-4ab0-97a8-8a228a306f2f": [
            "node_104"
        ],
        "51b190a4-e57f-49fc-9a98-932be86ca5cc": [
            "node_104"
        ],
        "8c33e3ff-8c86-4759-a72b-2d98045f76ec": [
            "node_105"
        ],
        "0ce31491-2d50-499c-992d-129ce10c7247": [
            "node_105"
        ],
        "5eee1ad6-9f5d-4fa0-94a9-9c995b994ad8": [
            "node_105"
        ],
        "87367a68-74cc-46b7-a015-6092b142fbcd": [
            "node_105"
        ],
        "02e1bff7-138c-4da4-a056-2497bf7e8484": [
            "node_105"
        ],
        "b6bbd015-f1d0-4e88-bf5c-757a8d2a6bd3": [
            "node_105"
        ],
        "92ef67ad-a5de-4063-b421-c3fc730c6d2e": [
            "node_105"
        ],
        "ea39905f-aeed-47e7-b977-e9d8e2f3504f": [
            "node_105"
        ],
        "be4cffc7-9b80-4722-b8ce-e78f94b4b261": [
            "node_105"
        ],
        "b7a273a6-fbeb-4861-addb-a25bd66e7eb2": [
            "node_105"
        ],
        "c2cc4817-3e26-4d0f-8822-d048515db468": [
            "node_106"
        ],
        "fa9fdba0-8e15-4d50-ad63-086a44e65318": [
            "node_106"
        ],
        "4db0edf1-9039-4169-b640-b5c31eda3728": [
            "node_106"
        ],
        "8ee68ef5-a15e-4ec2-a045-206cd85aa86a": [
            "node_106"
        ],
        "691a54e4-8322-42dc-aeca-01bd7f9a66d8": [
            "node_106"
        ],
        "c368cdc5-422a-4042-bd7f-0611fcc9c5bf": [
            "node_106"
        ],
        "db9c1a9b-17e7-4635-920a-c9bed57c8364": [
            "node_106"
        ],
        "13cc9c8b-358d-4ade-943b-50b1aec3478c": [
            "node_106"
        ],
        "96b51eab-c536-4438-8770-4966b9e16324": [
            "node_106"
        ],
        "0381d794-ed85-42b0-be9e-4652336b6f5b": [
            "node_106"
        ],
        "4428d79d-9ee8-4ea1-be3d-26efc3300f60": [
            "node_107"
        ],
        "47746844-6941-4d9c-b404-5be4b9f52040": [
            "node_107"
        ],
        "013291d1-5d96-4ec1-ada6-a55c92af4140": [
            "node_107"
        ],
        "aa71431b-9868-4e4f-ac79-2568dc8c7739": [
            "node_107"
        ],
        "a17ef721-499b-495d-addc-7c3cff6339d0": [
            "node_107"
        ],
        "8f53824d-05df-444f-9579-4efe7c17cedf": [
            "node_107"
        ],
        "d5888a0c-cb18-43ad-88e1-59bec9e8af2f": [
            "node_107"
        ],
        "4bd24477-5741-4146-b1e5-9a8cb3e0f8d4": [
            "node_107"
        ],
        "752e3573-a20a-481a-842e-c50076b31103": [
            "node_107"
        ],
        "8742203a-8074-4fd1-8e12-c5921a953f24": [
            "node_107"
        ],
        "a756754e-91d4-4878-b1a8-e4df84c85156": [
            "node_108"
        ],
        "c39bdf22-3968-443a-b3e6-3a3d31948d5a": [
            "node_108"
        ],
        "8c40b587-bd59-4767-9837-79791bcc3f97": [
            "node_108"
        ],
        "a7fa1cd5-d912-4dd6-8ccc-5daad4e8df81": [
            "node_108"
        ],
        "efbb711b-f268-4159-a969-392f6b696093": [
            "node_108"
        ],
        "01b850e8-37f4-47fa-a417-c54ee17215ef": [
            "node_108"
        ],
        "dc094018-f2c5-474d-8539-0b3d112d96f2": [
            "node_108"
        ],
        "322ec5a3-b06c-44c8-9136-a9f074b79e34": [
            "node_108"
        ],
        "c3e31b8c-8d74-40fe-8d13-c5133d9f6188": [
            "node_108"
        ],
        "bcdf8188-9ae7-4c9c-a52c-b32a211c06e4": [
            "node_108"
        ],
        "33c9a5ac-117d-4263-b2ac-5bc01cd8453f": [
            "node_109"
        ],
        "f12c850c-435a-460a-bab7-def3ec61b831": [
            "node_109"
        ],
        "1d84d626-62e3-461a-8cba-897909cd7252": [
            "node_109"
        ],
        "72aef7a2-64ba-4d30-8fee-6e5dd5781f9f": [
            "node_109"
        ],
        "6528fe2f-f82b-45ad-acf4-6257af865f96": [
            "node_109"
        ],
        "6295613c-4a36-48ca-93a4-e3b135e56449": [
            "node_109"
        ],
        "738506d2-f417-48b4-8304-1255fd32e5e5": [
            "node_109"
        ],
        "5c68c75a-3aea-41f1-8c77-a6e462e15278": [
            "node_109"
        ],
        "02168750-9097-4a16-b8c0-f93c89b224ae": [
            "node_109"
        ],
        "29d47367-6a08-40dc-b520-f9bf94015192": [
            "node_109"
        ],
        "1abe8b0f-9ff0-4b06-92e3-f82085a0ba95": [
            "node_110"
        ],
        "ea07be02-41be-44ec-a3d1-2730c816f49f": [
            "node_110"
        ],
        "ff758077-bae5-4e24-9e10-fea6052e8768": [
            "node_110"
        ],
        "1f0219f7-a650-4076-bad0-a2a261bd5976": [
            "node_110"
        ],
        "583d0c9a-789d-4795-989d-d61db08bbfae": [
            "node_110"
        ],
        "51569fbd-d29c-4212-b928-663e451f4df1": [
            "node_110"
        ],
        "210b2a2d-24ba-4c9a-b248-4ca65397ad6c": [
            "node_110"
        ],
        "0cab433e-6e5a-4dd5-9efe-2772070f5b5c": [
            "node_110"
        ],
        "221a8469-649f-4f17-9dd2-72c75282253e": [
            "node_110"
        ],
        "cb5ee70e-4506-4015-920a-84baf0ebf205": [
            "node_110"
        ],
        "beb32353-48a4-4c11-a283-28d587dbcc52": [
            "node_111"
        ],
        "e95d2fa4-2795-4302-99f0-060e5ba0cb49": [
            "node_111"
        ],
        "1fb7f892-986b-4482-828d-6d9fba32ea3d": [
            "node_111"
        ],
        "b881ef2b-1f14-47d0-9b8c-29a291dfa506": [
            "node_111"
        ],
        "0093e75e-8be0-4ce2-92de-28a87c5e3910": [
            "node_111"
        ],
        "04dec1d3-dd4c-46fe-9183-943959b9b9a0": [
            "node_111"
        ],
        "d254d053-2d05-4cbf-82e4-169ef79622ad": [
            "node_111"
        ],
        "44196a38-8d82-4394-814e-dd4eb7a6a553": [
            "node_111"
        ],
        "5b39febf-92ae-4156-89f7-603c2ec5bcda": [
            "node_111"
        ],
        "25171f57-8659-45f6-a43b-4974686fada1": [
            "node_111"
        ],
        "0a629838-fb0f-4abe-90e7-f7f86857ddef": [
            "node_112"
        ],
        "5caee24c-5365-4aa1-96b3-8c13343d1bc2": [
            "node_112"
        ],
        "65bc5eb2-a5aa-44ba-b8ce-1ee5fbbd23f3": [
            "node_112"
        ],
        "895d6fbe-b021-4187-95c4-e962d11c8715": [
            "node_112"
        ],
        "383b2bac-6903-4d77-9f1b-1ae50f90728b": [
            "node_112"
        ],
        "7af157ca-9407-47cc-ab51-3812f277266e": [
            "node_112"
        ],
        "5e48f19e-13ec-4e26-8e1a-5d12615bf569": [
            "node_112"
        ],
        "55d06166-40d6-4813-ae58-68fcbc4fb561": [
            "node_112"
        ],
        "4b584f65-e555-4f5d-be86-e20e8d42c6a0": [
            "node_112"
        ],
        "7ed0b33b-1692-46ee-b4fe-00c36af0327f": [
            "node_112"
        ],
        "c043f972-cd78-4dbc-92f0-ddde9c19580c": [
            "node_113"
        ],
        "62bbdf66-7999-41c1-b506-64a3572e3a67": [
            "node_113"
        ],
        "e0909d3d-c988-40e0-9e5c-f04b7b6c01c3": [
            "node_113"
        ],
        "b1ade058-9ae4-439b-a81e-25fdf5019e5e": [
            "node_113"
        ],
        "8e3170e2-1bf6-4e29-931d-b4b1073776d0": [
            "node_113"
        ],
        "fb1ccb44-701a-4126-8f5a-4f1c69851ca1": [
            "node_113"
        ],
        "9158aa4f-96e6-4b7c-8d93-6ca2c5ff7379": [
            "node_113"
        ],
        "093158ea-4c96-4bed-9e9d-c0aa289e43e4": [
            "node_113"
        ],
        "46b4664c-931f-4864-9417-b2457bf2ef40": [
            "node_113"
        ],
        "7e9cc301-a6dd-4361-82a1-42c61b0be2c5": [
            "node_113"
        ],
        "7cd218cc-eb5b-43fe-84ae-f34797a6b6bc": [
            "node_114"
        ],
        "40245ab1-9ddd-4ca7-85c4-b0192c36f0d8": [
            "node_114"
        ],
        "ca958282-3b96-4eae-b8c8-315aaefb329c": [
            "node_114"
        ],
        "f800adc8-3e0b-48c3-bfaa-1859b24a8523": [
            "node_114"
        ],
        "424ac2f2-3619-4ded-ad67-58642fd83611": [
            "node_114"
        ],
        "41f5da4a-5ef9-453a-ba47-897e78b2d326": [
            "node_114"
        ],
        "6dd1c568-aaef-4add-9e21-30c455d86dda": [
            "node_114"
        ],
        "fe44dd35-9e5e-4a2c-a0f8-87bb17c0b323": [
            "node_114"
        ],
        "06293891-038c-44b0-b03d-0e3d301cde4f": [
            "node_114"
        ],
        "871e81bd-b492-4117-93b9-d3a55e50eab2": [
            "node_114"
        ],
        "b7663140-d6c8-46b3-9082-eb68291ee91b": [
            "node_115"
        ],
        "bfbb3d6e-e658-4176-a565-7e4582d4af84": [
            "node_115"
        ],
        "111a0b81-466e-4bf2-acf6-10085fa32ff8": [
            "node_115"
        ],
        "be54e310-49c5-44a2-9b22-4a418f0fb157": [
            "node_115"
        ],
        "df466596-9fe1-4489-b138-80ea02d046d1": [
            "node_115"
        ],
        "b9768e03-c701-4929-ac32-4262aff73ec3": [
            "node_115"
        ],
        "f100cb99-40ea-4cfa-a5bb-a96b000dff3a": [
            "node_115"
        ],
        "83795b52-c140-4e13-bcc4-7e0e7886ae7f": [
            "node_115"
        ],
        "5f55fbeb-f7a5-4030-9735-dbd36ee3ae21": [
            "node_115"
        ],
        "9d3eb2e6-e132-4614-83d4-8007453c8b4e": [
            "node_115"
        ],
        "d043a745-4579-48a0-b04d-d38be8f341dc": [
            "node_116"
        ],
        "ba546fb9-6c94-43dd-8e9e-873edf6854c2": [
            "node_116"
        ],
        "2186b6c9-b259-4a8d-829f-6a5e32f9c5c3": [
            "node_116"
        ],
        "96999606-fa0a-4f54-931c-db661755b67e": [
            "node_116"
        ],
        "8855f61c-bce9-4b2d-b925-7a1f4e3729f2": [
            "node_116"
        ],
        "2ceffc8e-bd6e-46d8-beef-21d607c1f05e": [
            "node_116"
        ],
        "de5f26fe-c2d1-4c6f-a817-bde7ecf2f236": [
            "node_116"
        ],
        "029c34ea-12e9-4b28-8bc3-efdcc6d914dc": [
            "node_116"
        ],
        "0750ed9d-7ad4-4694-93b8-70b0898f83e3": [
            "node_116"
        ],
        "4bd5179b-ceaf-4839-87f6-2a23feda1b2c": [
            "node_116"
        ],
        "7486f11d-6857-443d-afe3-de80ed057892": [
            "node_117"
        ],
        "9e763505-e17e-453f-ad33-3c0f2ea6b5d9": [
            "node_117"
        ],
        "7da5ca9f-ee2a-41c1-a4b3-4a2134c49919": [
            "node_117"
        ],
        "aaeb96ab-ee1f-4c15-8d9b-7489637bfda9": [
            "node_117"
        ],
        "44821d26-a909-47af-9fe9-ee38633bf877": [
            "node_117"
        ],
        "dbf6f743-fec1-43c1-84a5-096b72420281": [
            "node_117"
        ],
        "7606b94b-7db7-45a0-bf20-b7254b46ac2b": [
            "node_117"
        ],
        "9e523af4-3a15-463d-8671-4ad89bc67917": [
            "node_117"
        ],
        "1a6fd3a8-29ce-46ae-805f-eb8cd1decfdf": [
            "node_117"
        ],
        "917e4732-569f-45ea-b322-713f0d44713d": [
            "node_117"
        ],
        "c6a76e2d-ccb4-4bdb-b404-673f0e9f339e": [
            "node_118"
        ],
        "3626e524-6739-4df5-9565-9f0d5d9d31db": [
            "node_118"
        ],
        "3bfb386f-0b98-4709-9145-53dce87a9ad1": [
            "node_118"
        ],
        "5576d5a1-40b9-4ea7-9c3d-32dae8b084c3": [
            "node_118"
        ],
        "1051dbbb-4be1-4a85-92a7-a5a8590c76b6": [
            "node_118"
        ],
        "866dcc84-f69e-4a7c-bbf8-a33f7b7bcd50": [
            "node_118"
        ],
        "9fd39684-e134-4cbe-8738-0ef00006ecbe": [
            "node_118"
        ],
        "18068d50-3f6f-486c-87d2-25808423809c": [
            "node_118"
        ],
        "41ce924f-99ff-43da-83a8-839cc7649b9f": [
            "node_118"
        ],
        "29d38709-a037-4f38-9349-272f6655e981": [
            "node_118"
        ],
        "6e2d0bb8-5c90-47a5-a648-88bf30ad8b3d": [
            "node_119"
        ],
        "008bc7a8-3c65-4d7c-a659-19c58033f236": [
            "node_119"
        ],
        "5cb1325e-eb34-4e66-a7f4-e74f8a1663aa": [
            "node_119"
        ],
        "95cbadfa-93e5-4877-ba33-e1400466a299": [
            "node_119"
        ],
        "e3f1d487-e416-44dd-b5b8-86e445af816a": [
            "node_119"
        ],
        "7316aeb9-4c6e-4c29-a190-eaf64c0dc347": [
            "node_119"
        ],
        "fdb617c6-1d73-430f-b3c4-6cf4c3c44dcc": [
            "node_119"
        ],
        "f1a7d869-18a0-49e3-8c34-bccbc8d1fadd": [
            "node_119"
        ],
        "28deb05d-fc36-4c47-bdf3-c99b49c98397": [
            "node_119"
        ],
        "971c4f84-2309-4898-9e20-067dc9eadad5": [
            "node_119"
        ],
        "15acb2c2-36be-442f-817e-1764f82a4ba2": [
            "node_120"
        ],
        "480e7c79-66f3-4249-8b2d-61460ca956ab": [
            "node_120"
        ],
        "d3c1ca8d-9e24-4d98-9193-9de1677ea7e6": [
            "node_120"
        ],
        "c8e87315-ebcb-43af-a901-bab20c9d70db": [
            "node_120"
        ],
        "8202e774-373c-4184-aeef-9fc9e74bb191": [
            "node_120"
        ],
        "a57d066a-6715-4887-8e77-bf13e0949926": [
            "node_120"
        ],
        "a4ac6103-1ade-4fe8-9ab6-1e312218125e": [
            "node_120"
        ],
        "96f438e6-a4a3-4c86-bbc7-ad089169d5c9": [
            "node_120"
        ],
        "60316bed-dcfb-4c7a-a237-223ae3794317": [
            "node_120"
        ],
        "e6e42b52-4594-4086-b4f0-1f96b7d8423b": [
            "node_120"
        ]
    }
}