# values.yaml
app:
  name: "enterprise-search"
  image:
    repository: docker.aiml.team/products/aiml/enterprise-search/llamasearch
    tag: latest
    pullPolicy: Always
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
  resources:
    limits:
      cpu: "5000m"
      memory: "20Gi"
  env:
    CONFIG_PATH: "/app/config/config.yml"
    OLLAMA_SERVER_URL: "ollama-es-service.aiml-engineering.svc.cluster.local:80"
  volumes:
    config:
      configMapName: "es-cmap"
    data:
      pvcName: "es-pvc"
  nodeName: "l40-1"

ollama:
  name: ollama-es
  namespace: aiml-engineering
  image:
    repository: ollama/ollama
    tag: latest
    pullPolicy: Always
  service:
    type: ClusterIP
    port: 80
    targetPort: 11434
  portName: http
  resources:
    limits:
      nvidia.com/gpu: "1"
      cpu: "5000m"
      memory: "30Gi"
  nodeName: "l40-1"
  env:
    OLLAMA_HOST: "0.0.0.0"
  volumes:
    data:
      pvcName: "ollama"
  gpu:
    # -- Enable GPU integration
    enabled: true
    # -- GPU type: 'nvidia' or 'amd'
    # If 'ollama.gpu.enabled', default value is nvidia
    # If set to 'amd', this will add 'rocm' suffix to image tag if 'image.tag' is not override
    # This is due cause AMD and CPU/CUDA are different images
    type: 'nvidia'
    # -- Specify the number of GPU
    number: 1
  # -- List of models to pull at container startup
  # The more you add, the longer the container will take to start if models are not present
  models:
   - gemma
   - mistral:7b-instruct
   - mixtral
  insecure: true
  livenessProbe:
    enabled: true
    path: /
    initialDelaySeconds: 60
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  # Configure extra options for readiness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  readinessProbe:
    enabled: true
    path: /
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 3
    failureThreshold: 6
    successThreshold: 1

qdrant:
  resources:
    limits:
      nvidia.com/gpu: "1"
      cpu: "5000m"
      memory: "8Gi"
  image:
    repository: qdrant/qdrant
    tag: latest
  service:
    port: 6333
  collectionName: test
  vectorSize: 384
  distance: Cosine
  nodeName: "a6000-1"

redis:
  resources:
    limits:
      cpu: "5000m"
      memory: "8Gi"
  image:
    repository: redis
    tag: latest
  service:
    port: 6379
  nodeName: "a6000-1"
